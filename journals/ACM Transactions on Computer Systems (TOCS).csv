Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
The Totem Single-Ring Ordering and Membership Protocol,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029408206&doi=10.1145%2f210223.210224&partnerID=40&md5=40a31d3d4308fce7b4c4cedcde383f5c,[No abstract available],,Computer networks; Computer operating systems; Data communication systems; Distributed computer systems; Fault tolerant computer systems; Performance; Reliability; Systems analysis; Membership protocol; Reliable delivery; Token passing; Total ordering; Totem single ring protocol; Virtual synchrony; Network protocols
Generating Test Cases for Real-Time Systems from Logic Specifications,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976832662&doi=10.1145%2f210223.210226&partnerID=40&md5=32d5f653acdc519b58ba7a1eb86f58a8,[No abstract available],,
Scalable Concurrent Counting,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029407774&doi=10.1145%2f210223.210225&partnerID=40&md5=53b126aeea915d99b28b42cdbb607594,[No abstract available],,Computer software; Concurrency control; Data storage equipment; Data structures; Large scale systems; Multiprocessing systems; Performance; Queueing theory; Reliability; Synchronization; Combining trees; Counting networks; Message passing; Scalable concurrent counting; Spin locks; Counting circuits
Memory System Performance of Programs with Intensive Heap Allocation,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029352914&doi=10.1145%2f210126.210129&partnerID=40&md5=3e71a105a2bd6ec6e78f0b9707e19252,"Heap allocation with copying garbage collection is a general storage management technique for programming languages. It is believed to have poor memory system performance, To investigate this, we conducted an in-depth study of the memory system performance of heap allocation for memory systems found on many machines. We studied the performance of mostly functional Standard ML programs which made heavy use of heap allocation. We found that most machmes support heap allocation poorly. However, with the appropriate memory system organization, heap allocation can have good performance. The memory system property crucial for achieving good performance was the ability to allocate and initialize a new object into the cache without a penalty. This can be achieved by having subblock placement with a subblock size of one word with a write-allocate pohcy, along with fast page-mode writes or a write buffer. For caches with subblock placement, the data cache overhead was under 9% for a 64K or larger data cache; without subblock placement the overhead was often higher than 50%. © 1995, ACM. All rights reserved.",Automatic storage reclamation; copying garbage collection; garbage collection; generational garbage collection; heap allocation; page mode; subblock placement; write-back; write-buffer; write-miss policy; write-policy; write-through,Associative storage; Buffer storage; Computer programming languages; Computer simulation; Computer systems programming; Design aids; Performance; Automatic storage reclamation; Copying garbage collection; Generational garbage collection; Heap allocation; Page mode; Storage management; Subblock placement; Write buffer; Write-allocate policy; Write-back; Storage allocation (computer)
Debugging Heterogeneous Distributed Systems Using Event-Based Models of behavior,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976842322&doi=10.1145%2f200912.200913&partnerID=40&md5=84a28ab2d3a9a33545bd80084c7ed59a,"We describe a high-level debugging approach, Event-Based Behavioral Abstraction 1995, in which debugging is treated as a process of creating models of expected program behaviors and comparing these to the actual behaviors exhibited by the program. The use of EBBA techniques can enhance debugging-tool transparency, reduce latency and uncertainty for fundamental debugging activities, and accommodate diverse, heterogeneous architectures. Using events and behavior models as a basic mechanism provides a uniform view of heterogeneous systems and enables analysis to be performed in well-defined ways. Their use also enables EBBA users to extend and reuse knowledge gained in solving previous problems to new situations. We describe our behavior-modeling algorithm that matches actual behavior to models and automates many behavior analysis steps. The algorithm matches behavior in as many ways as possible and resolves these to return the best match to the user. It deals readily with partial behavior matches and incomplete information. In particular, we describe a tool set we have built. The tool set has been used to investigate the behavior of a wide range of programs. The tools are modular and can be distributed readily throughout a system. © 1995, ACM. All rights reserved.",Behavior modeling; debugging; events,
Implications of Hierarchical N-Body Methods for Multiprocessor Architectures,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029309970&doi=10.1145%2f201045.201050&partnerID=40&md5=0994b8318a9daa5d3e5e5e98ec4e0505,"To design effective large-scale multiprocessors, designers need to understand the characteristics of the applications that will use the machines. Application characteristics of particular interest include the amount of communication relative to computation, the structure of the communication, and the local cache and memory requirements, as well as how these characteristics scale with larger problems and machines. One important class of applications is based on hierarchical N-body methods, which are used to solve a wide range of scientific and engineering problems efficiently. Important characteristics of these methods include the nonuniform and dynamically changing nature of the domains to which they are applied, and their use of long-range, irregular communication. This article examines the key architectural implications of representative applications that use the two dominant hierarchical N-body methods: the Barnes-Hut Method and the Fast Multipole Method. We first show that exploiting temporal locality on accesses to communicated data is critical to obtaining good performance on these applications and then argue that coherent caches on shared-address-space machines exploit this locality both automatically and very effectively. Next, we examine the implications of scaling the applications to run on larger machines. We use scaling methods that reflect the concerns of the application scientist and find that this leads to different conclusions about how communication traffic and local cache and memory usage scale than scaling based only on data set size. In particular, we show that under the most realistic form of scaling, both the communication-to-computation ratio as well as the working-set size 1995 grow slowly as larger problems are run on larger machines. Finally, we examine the effects of using the two dominant abstractions for interprocessor communication: a shared address space and explicit message passing between private address spaces. We show that the lack of an efficiently supported shared address space will substantially increase the programming complexity and performance overheads for these applications. © 1995, ACM. All rights reserved.",communication abstractions; locality; message passing; N-body methods; parallel applications; parallel computer architecture; scaling; shared address space; shared memory,Buffer storage; Computational complexity; Computer architecture; Data communication systems; Data storage equipment; Hierarchical systems; Performance; Problem solving; Telecommunication traffic; Hierarchical N body methods; Memory structures; Multiple data stream architectures; Multiprocessor architectures; Multiprocessing systems
Techniques for Reducing Consistency-Related Communication in Distributed Shared-Memory Systems,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029354892&doi=10.1145%2f210126.210127&partnerID=40&md5=3e37fa1fe3b30176656c8593e2d98567,"Distributed shared memory (DSM) is an abstraction of shared memory on a distributed-memory machine. Hardware DSM systems support this abstraction at the architecture level; software DSM systems support the abstraction within the runtime system. One of the key problems in building an efficient software DSM system is to reduce the amount of communication needed to keep the distributed memories consistent. In this article we present four techniques for doing so: software release consistency; multiple consistency protocols; write-shared protocols; and an update-with-timeout mechanism. These techniques have been implemented in the Munin DSM system. We compare the performance of seven Munin application programs: first to their performance when implemented using message passing, and then to their performance when running on a conventional software DSM system that does not embody the preceding techniques. On a 16-processor cluster of workstations, Munin's performance is within 5~. of message passing for four out of the seven applications. For the other three, performance is within 29 to 33%. Detailed analysis of two of these three applications indicates that the addition of a function-shipping capability would bring their performance to within 7% of the message-passing performance. Compared to a conventional DSM system, Munin achieves performance improvements ranging from a few to several hundred percent, depending on the application. © 1995, ACM. All rights reserved.",Cache consistency protocols; distributed shared memory; memory models; release consistency; virtual shared memory,Buffer storage; Computer architecture; Computer hardware; Computer operating systems; Computer software; Computer workstations; Data storage equipment; Network protocols; Parallel processing systems; Performance; Storage allocation (computer); Virtual storage; Distributed shared-memory systems; Message passing; Multiple consistency protocols; Runtime system; Shared memory; Software release consistency; Update-with-timeout mechanism; Write-shared protocols; Distributed computer systems
The Zebra Striped Network File System,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976704061&doi=10.1145%2f210126.210131&partnerID=40&md5=fb2336fccf1dc937c03ee10ca400d98d,"Zebra is a network file system that increases throughput by striping the file data across multiple servers. Rather than striping each file separately, Zebra forms all the new data from each client into a single stream, which it then stripes using an approach similar to a log-structured file system. Thm provides high performance for writes of small files as well as for reads and writes of large files. Zebra also writes parity information in each stripe in the style of RAID disk arrays; this increases storage costs slightly, but allows the system to continue operation while a single storage server is unavailable. A prototype implementation of Zebra, built in the Sprite operating system, provides 4-5 times the throughput of the standard Sprite file system or NFS for large files and a 15-300%. improvement for writing small files. © 1995, ACM. All rights reserved.",Log-based striping; log-structured file system; parity computation; RAID,
Effective Cache Prefetching on Bus-Based Multiprocessors,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976656398&doi=10.1145%2f200912.201006&partnerID=40&md5=67cc1a5317a81ed242c51852e8f2752d,"Compiler-directed cache prefetching has the potential to hide much of the high memory latency seen by current and future high-performance processors. However, prefetching is not without costs, particularly on a shared-memory multiprocessor. Prefetching can negatively affect bus utilization, overall cache miss rates, memory latencies and data sharing. We simulate the effects of a compiler-directed prefetching algorithm, running on a range of bus-based multiprocessors. We show that, despite a high memory latency, this architecture does not necessarily support prefetching well, in some cases actually causing performance degradations. We pinpoint several problems with prefetching on a shared-memory architecture 1995 and measure their effect on performance. We then solve those problems through architectural techniques and heuristics for prefetching that could be easily incorporated into a compiler: (1) victim caching, which eliminates most of the cache conflict misses caused by prefetching in a direct-mapped cache, (2) special prefetch algorithms for shared data, which significantly improve the ability of our basic prefetching algorithm to prefetch individual misses, and (3) compiler-based shared-data restructuring, which eliminates many of the invalidation misses the basic prefetching algorithm does not predict. The combined effect of these improvements is to make prefetching effective over a much wider range of memory architectures. © 1995, ACM. All rights reserved.",bus-based multiprocessors; cache prefetching; false sharing; memory latency hiding,
A Simple and Efficient Bus Management Scheme that Supports Continuous Streams,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029308683&doi=10.1145%2f201045.201048&partnerID=40&md5=33c97683b9aacf8abfffa73ffc16980e,"An efficient bandwidth management and access arbitration scheme for an I/O bus in a multimedia workstation is presented. It assumes that a multimedia workstation consists of a number of processing modules which are interconnected by a packet bus. The scheme is efficient in the sense that it allows the bus to support both continuous media transfers and regular random transactions in such a way that continuous streams can meet their real-time constraints independently of random traffic, and random traffic is not delayed significantly by continuous traffic except when traffic load is very high. Implementation guidelines are provided to show that the scheme is practical. Finally, the performance of this scheme is compared with alternative solutions through simulation. © 1995, ACM. All rights reserved.",bus arbitration; bus management; continuous stream; multimedia workstation,Computer architecture; Computer simulation; Computer workstations; Data communication systems; Design aids; Interconnection networks; Packet networks; Performance; Real time systems; Telecommunication traffic; Bus arbitration; Bus management; Continuous stream; Multimedia workstation; Packet bus; Computer systems
Adaptive Block Rearrangement,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029306515&doi=10.1145%2f201045.201046&partnerID=40&md5=3524fb61c7800266ad70721ce24004a6,"An adaptive technique for reducing disk seek times is described. The technique copies frequently referenced blocks from their original locations to reserved space near the middle of the disk. Reference frequencies need not be known in advance. Instead, they are estimated by monitoring the stream of arriving requests. Trace-driven simulations show that seek times can be cut substantially by copying only a small number of blocks using this technique. The technique has been implemented by modifying a UNIX device driver. No modifications are required to the file system that uses the driver. © 1995, ACM. All rights reserved.",data clustering; data replication; seek optimization,Algorithms; Computer simulation; Data processing; Data storage equipment; Information retrieval; Information retrieval systems; Optimization; Performance; Storage allocation (computer); UNIX; Adaptive block rearrangement; Data clustering; Data replication; Seek optimization; Computer systems
Set-Associative Cache Simulation Using Generalized Binomial Trees,1995,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976662882&doi=10.1145%2f200912.200918&partnerID=40&md5=6fe98eeddbed14535f7be6242e59cb2c,"Set-associative caches are widely used in CPU memory hierarchies, I/O subsystems, and file systems to reduce average access times. This article proposes an efficient simulation technique for simulating a group of set-associative caches in a single pass through the address trace, where all caches have the same line size but varying associativities and varying number of sets. The article also introduces a generalization of the ordinary binomial tree and presents a representation of caches in this class using the Generalized Binomial Tree 1995. The tree representation permits efficient search and update of the caches. Theoretically, the new algorithm, GBF_LS, based on the gbt structure, always takes fewer comparisons than the two earlier algorithms for the same class of caches: all-associativity and generalized forest simulation. Experimentally, the new algorithm shows performance gains in the range of 1.2 to 3.8 over the earlier algorithms on address traces of the SPEC benchmarks. A related algorithm for simulating multiple alternative direct-mapped caches with fixed cache size, but varying line size, is also presented. © 1995, ACM. All rights reserved.",all-associativity simulation; binomial tree; cache modeling; inclusion properties; set-associative caches; single-pass simulation; trace-driven simulation,
Parity Logging Disk Arrays,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028492850&doi=10.1145%2f185514.185516&partnerID=40&md5=8dd54768b3fb2b7c86552ef5d1353d1a,"Parity-encoded redundant disk arrays provide highly reliable, cost-effective secondary storage with high performance for reads and large writes. Their performance on small writes, however, is much worse than mirrored disks–the traditional, highly reliable, but expensive organization for secondary storage. Unfortunately, small writes are a substantial portion of the I/O workload of many important, demanding applications such as on-line transaction processing. This paper presents parity logging, a novel solution to the small-write problem for redundant disk arrays. Parity logging applies journalling techniques to reduce substantially the cost of small writes. We provide detailed models of parity logging and competing schemes–mirroring, floating storage, and RAID level 5–and verify these models by simulation. Parity logging provides performance competitive with mirroring, but with capacity overhead close to the minimum offered by RAID level 5. Finally, parity logging can exploit data caching more effectively than all three alternative approaches. © 1994, ACM. All rights reserved.",disk arrays; RAID,Arrays; Computer simulation; Costs; Data processing; Online systems; Performance; Reliability; Societies and institutions; Data caching; Disk arrays; On line transaction processing; Parity logging; Secondary storage; Magnetic disk storage
A Security Architecture for Fault-Tolerant Systems,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976763336&doi=10.1145%2f195792.195823&partnerID=40&md5=609800fe12ece96954e1ed1bfd552518,"Process groups are a common abstraction for fault-tolerant computing in distributed systems. We present a security architecture that extends the process group into a security abstraction. Integral parts of this architecture are services that securely and fault tolerantly support cryptographic key distribution. Using replication only when necessary, and introducing novel replication techniques when it was necessary, we have constructed these services both to be easily defensible against attack and to permit key distribution despite the transient unavailability of a substantial number of servers. We detail the design and implementation of these services and the secure process group abstraction they support. We also give preliminary performance figures for some common group operations. © 1994, ACM. All rights reserved.",key distribution; multicast; process groups,
Design Tradeoffs for Software-Managed TLBs,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028492372&doi=10.1145%2f185514.185515&partnerID=40&md5=9b38d1b9a762f6979edfbb30290802f2,"An increasing number of architectures provide virtual memory support through software-managed TLBs. However, software management can impose considerable penalties that are highly dependent on the operating system's structure and its use of virtual memory. This work explores software-managed TLB design tradeoffs and their interaction with a range of monolithic and microkernel operating systems. Through hardware monitoring and simulation, we explore TLB performance for benchmarks running on a MIPS R2000-based workstation running Ultrix, OSF/1, and three versions of Mach 3.0. © 1994, ACM. All rights reserved.",hardware monitoring; translation lookaside buffer (TLB); trap-driven simulation,Computer architecture; Computer hardware; Computer operating systems; Computer simulation; Data storage equipment; Management; Monitoring; Benchmarks; Hardware monitoring; Software management; Translation lookaside buffers; Trap driven simulation; Virtual memory; Computer software
"A New Approach to I/O Performance Evaluation—Self-Scaling I/O Benchmarks, Predicted I/O Performance",1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976741198&doi=10.1145%2f195792.195812&partnerID=40&md5=284a2fb28197159a4bdd348b37faf004,"Current I/O benchmarks suffer from several chronic problems: they quickly become obsolete; they do not stress the I/O system; and they do not help much in understanding I/O system performance. We propose a new approach to I/O performance analysis. First, we propose a self-scaling benchmark that dynamically adjusts aspects of its workload according to the performance characteristic of the system being measured. By doing so, the benchmark automatically scales across current and future systems. The evaluation aids in understanding system performance by reporting how performance varies according to each of five workload parameters. Second, we propose predicted performance, a technique for using the results from the self-scaling evaluation to estimate quickly the performance for workloads that have not been measured. We show that this technique yields reasonably accurate performance estimates and argue that this method gives a far more accurate comparative performance evaluation than traditional single-point benchmarks. We apply our new evaluation technique by measuring a SPARCstation 1+ with one SCSI disk, an HP 730 with one SCSI-II disk, a DECstation 5000/200 running the Sprite LFS operating system with a three-disk disk array, a Convex C240 minisupercomputer with a four-disk disk array, and a Solbourne 5E/905 fileserver with a two-disk disk array. © 1994, ACM. All rights reserved.",Benchmark; client-server; Design; disk array; file cache; input/output; Measurement; Performance; RAID,
The TickerTAIP Parallel RAID Architecture,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028491338&doi=10.1145%2f185514.185517&partnerID=40&md5=982c49563f7102f21aed0a514b4416db,"Traditional disk arrays have a centralized architecture, with a single controller through which all requests flow. Such a controller is a single point of failure, and its performance limits the maximum number of disks to which the array can scale. We describe TickerTAIP, a parallel architecture for disk arrays that distributes the controller functions across several loosely coupled processors. The result is better scalability, fault tolerance, and flexibility. This article presents the TickerTAIP architecture and an evaluation of its behavior. We demonstrate the feasibility by a working example, describe a family of distributed algorithms for calculating RAID parity, discuss techniques for establishing request atomicity, sequencing, and recovery, and evaluate the performance of the TickerTAIP design in both absolute terms and by comparison to a centralized RAID implementation. We also analyze the effects of including disk-level request-scheduling algorithms inside the array. We conclude that the Ticker TAIP architectural approach is feasible, useful, and effective. © 1994, ACM. All rights reserved.",decentralized parity calculation; disk scheduling; distributed controller; fault tolerance; parallel controller; performance simulation; RAID disk array,Algorithms; Computer aided design; Computer simulation; Control equipment; Data storage equipment; Performance; Reliability; Decentralized parity calculation; Disk scheduling; Distributed controller; Fault tolerance; Parallel controller; RAID parity; Traditional disk array; Computer architecture
Sharing and Protection in a Single-Address-Space Operating System,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976797486&doi=10.1145%2f195792.195795&partnerID=40&md5=e27e7eabc26bc90e925704cf0d6e913a,"This article explores memory sharing and protection support in Opal, a single-address-space operating system designed for wide-address 1994 architectures. Opal threads execute within protection domains in a single shared virtual address space. Sharing is simplified, because addresses are context independent. There is no loss of protection, because addressability and access are independent; the right to access a segment is determined by the protection domain in which a thread executes. This model enables beneficial code-and data-sharing patterns that are currently prohibitive, due in part to the inherent restrictions of multiple address spaces, and in part to Unix programming style. We have designed and implemented an Opal prototype using the Mach 3.0 microkernel as a base. Our implementation demonstrates how a single-address-space structure can be supported alongside of other environments on a modern microkernel operating system, using modern wide-address architectures. This article justifies the Opal model and its goals for sharing and protection, presents the system and its abstractions, describes the prototype implementation, and reports experience with integrated applications. © 1994, ACM. All rights reserved.",64-bit architectures; capability-based systems; microkernel operating systems; object-oriented database systems; persistent storage; protection; single-address-space operating systems; wide-address architectures,
A Coherent Distributed File Cache with Directory Write-Behind,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028430482&doi=10.1145%2f176575.176577&partnerID=40&md5=4e0219f13d9ed7831cc5d28347c970c0,"Extensive caching is a key feature of the Echo distributed file system. Echo client machines maintain coherent caches of file and directory data and properties, with write-behind 1994 of all cached information. Echo specifies ordering constraints on this write-behind, enabling applications to store and maintain consistent data structures in the file system even when crashes or network faults prevent some writes from being completed. In this paper we describe the Echo cache's coherence and ordering semantics, show how they can improve the performance and consistency of applications, explain how they are implemented. We also discuss the general problem of reliably notifying applications and users when write-behind is lost; we addressed this problem as part of the Echo design, but did not find a fully satisfactory solution. © 1994, ACM. All rights reserved.",coherence; file caching; write-behind,Computational linguistics; Constraint theory; Data handling; Data recording; Data storage equipment; Data structures; Errors; File organization; Reliability; Security of data; Coherent distributed file cache; Directory write behind; Extensive caching; File caching; File systems management; Replication; Distributed database systems
Lightweight Recoverable Virtual Memory,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028377578&doi=10.1145%2f174613.174615&partnerID=40&md5=603c6a42212a193d705b77a6e723b445,"Recoverable virtual memoryrefers to regions of a virtual address space on which transactional guarantees are offered. This article describes RVM, an efficient, portable, and easily used implementation of recoverable virtual memory for Unix environments. A unique characteristic of RVM is that it allows independent control over the transactional properties of atomicity, permanence, and serializability. This leads to considerable flexibility in the use of RVM, potentially enlarging the range of applications that can benefit from transactions. It also simplifies the layering of functionality such as nesting and distribution. The article shows that RVM performs well over its intended range of usage even though it does not benefit from specialized operating system support. It also demonstrates the importance of intra- and inter-transaction optimizations. © 1994, ACM. All rights reserved.",Camelot; Coda; logging; paging; persistence; RVM; scalability; throughput; truncation; Unix,Computer aided software engineering; Computer programming; Computer system recovery; Data processing; Database systems; Fault tolerant computer systems; Optimization; Reliability; UNIX; User interfaces; Camelot; Coda; Lightweight recoverable virtual memory; Logging; Paging; Persistence; Scalability; Throughput; Transaction processing; Truncation; Virtual storage
Sequential Consistency versus Linearizability,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028428331&doi=10.1145%2f176575.176576&partnerID=40&md5=7fba68e3409933e3c99802e2f2fe1944,"The power of two well-known consistency conditions for shared-memory multiprocessors, sequential consistency and linearizability, is compared. The cost measure studied is the worst-case response time in distributed implementations of virtual shared memory supporting one of the two conditions. Three types of shared-memory objects are considered: read/write objects, FIFO queues, and stacks. If clocks are only approximately synchronized 1994, then for all three object types it is shown that linearizability is more expensive than sequential consistency. We show that, for all three data types, the worst-case response time is very sensitive to the assumptions that are made about the timing information available to the system. Under the strong assumption that processes have perfectly synchronized clocks, it is shown that sequential consistency and linearizability are equally costly. We present upper bounds for linearizability and matching lower bounds for sequential consistency. The upper bounds are shown by presenting algorithms that use atomic broadcast in a modular fashion. The lower-bound proofs for the approximate case use the technique of “shifting,” first introduced for studying the clock synchronization problem. © 1994, ACM. All rights reserved.",,Algorithms; Computer architecture; Computer systems; Data description; Multiprocessing systems; Response time (computer systems); Storage allocation (computer); Synchronization; Theorem proving; Virtual storage; Linearizability; Multiple data stream architecture; Sequential consistency; Shared memory multiprocessors; Worst case response time; Data storage equipment
File-System Development with Stackable Layers,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028374136&doi=10.1145%2f174613.174616&partnerID=40&md5=b5834d7574f9c53c9f965f4415e3012b,"Filing services have experienced a number of innovations in recent years, but many of these promising ideas have failed to enter into broad use. One reason is that current filing environments present several barriers to new development. For example, file systems today typically stand alone instead of building on the work of others, and support of new filing services often requires changes that invalidate existing work. Stackable file-system design addresses these issues in several ways. Complex filing services are constructed from layer “building blocks,” each of which may be provided by independent parties. There are no syntactic constraints to layer order, and layers can occupy different address spaces, allowing very flexible layer configuration. Independent layer evolution and development are supported by an extensible interface bounding each layer. This paper discusses stackable layering in detail and presents design techniques it enables. We describe an implementation providing these facilities that exhibits very high performance. By lowering barriers to new filing design, stackable layering offers the potential of broad third-party file-system development not feasible today. © 1994, ACM. All rights reserved.",Composability; file system design; operating system structure; reuse,Computer operating systems; Constraint theory; Data description; Data structures; File editors; Hierarchical systems; Interfaces (computer); Systems analysis; Composability; File system development; Reuse; Stackable layers; File organization
Authentication in the Taos Operating System,1994,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028380781&doi=10.1145%2f174613.174614&partnerID=40&md5=42bef19b80054c7443b94209cb4d7c97,"We describe a design for security in a distributed system and its implementation. In our design, applications gain access to security services through a narrow interface. This interface provides a notion of identity that includes simple principals, groups, roles, and delegations. A new operating system component manages principals, credentials, and secure channels. It checks credentials according to the formal rules of a logic of authentication. Our implementation is efficient enough to support a substantial user community. © 1994, ACM. All rights reserved.",cryptography; mathematical logic,Cryptography; Data acquisition; Distributed computer systems; Formal logic; Interfaces (computer); Security of data; Theorem proving; Access control; Authentication; Taos operating systems; Computer operating systems
Cooperative Shared Memory: Software and Hardware for Scalable Multiprocessors,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027699767&doi=10.1145%2f161541.161544&partnerID=40&md5=adac61c79e2ff06c07af584d92c1678d,"We believe the paucity of massively parallel, shared-memory machines follows from the lack of a shared-memory programming performance model that can inform programmers of the cost of operations 1993 and can tell hardware designers which cases are common (so they can build simple hardware to optimize them). Cooperative shared memory, our approach to shared-memory design, addresses this problem. Our initial implementation of cooperative shared memory uses a simple programming model, called Check-In/Check-Out (CICO), in conjunction with even simpler hardware, called Dir1SW. In CICO, programs bracket uses of shared data with a check_in directive terminating the expected use of the data. A cooperative prefetch directive helps hide communication latency. Dir1SW is a minimal directory protocol that adds little complexity to message-passing hardware, but efficiently supports programs written within the CICO model. © 1993, ACM. All rights reserved.",cache coherence; directory protocols; memory systems; programming model; shared-memory multiprocessors,Computer hardware; Computer software; Cache coherence; Cooperative shared memory; Memory systems; Scalable multiprocessors; Shared-memory machines; Storage allocation (computer)
Access Normalization: Loop Restructuring for NUMA Computers,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027694019&doi=10.1145%2f161541.159766&partnerID=40&md5=cb53324645b0b935eead84ca069caa8b,"In scalable parallel machines, processors can make local memory accesses much faster than they can make remote memory accesses. Additionally, when a number of remote accesses must be made, it is usually more efficient to use block transfers of data rather than to use many small messages. To run well on such machines, software must exploit these features. We believe it is too onerous for a programmer to do this by hand, so we have been exploring the use of restructuring compiler technology for this purpose. In this article, we start with a language like HPF-Fortran with user-specified data distribution and develop a systematic loop transformation strategy called access normalization that restructures loop nests to exploit locality and block transfers. We demonstrate the power of our techniques using routines from the BLAS 1993 library. An important feature of our approach is that we model loop transformation using invertible matrices and integer lattice theory. © 1993, ACM. All rights reserved.",Communication; data locality; loop transformation; nonsingular loop transformation; nonuniform memory access machines; parallelizing compilers,FORTRAN (programming language); Parallel processing systems; Access normalization; HPF-Fortran language; NUMA computers; User-specified data; Computer systems
Sentinel Scheduling: A Model for Compiler-Controlled Speculative Execution,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027695220&doi=10.1145%2f161541.159765&partnerID=40&md5=16f30ff01710ebfb0631adc47c2bbd8e,"Speculative execution is an important source of parallelism for VLIW and superscalar processors. A serious challenge with compiler-controlled speculative execution is to efficiently handle exceptions for speculative instructions. In this article, a set of architectural features and compile-time scheduling support collectively referred to as sentinel scheduling is introduced. Sentinel scheduling provides an effective framework for both compiler-controlled speculative execution and exception handling. All program exceptions are accurately detected and reported in a timely manner with sentinel scheduling. Recovery from exceptions is also ensured with the model. Experimental results show the effectiveness of sentinel scheduling for exploiting instruction-level parallelism and overhead associated with exception handling. © 1993, ACM. All rights reserved.",exception detection; exception recovery; instruction scheduling; instruction-level parallelism; speculative execution; superscalar processor; VlIW processor,Scheduling; Compiler-controlled speculative execution; Compiler-time scheduling support; Instruction-level parallelism; Sentinel scheduling; Superscalar processors; Program compilers
High-Speed Switch Scheduling for Local-Area Networks,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027694638&doi=10.1145%2f161541.161736&partnerID=40&md5=7ba2680b9577289a23647039f59810dc,"Current technology trends make it possible to build communication networks that can support high-performance distributed computing. This paper describes issues in the design of a prototype switch for an arbitrary topology point-to-point network with link speeds of up to 1 Gbit/s. The switch deals in fixed-length ATM-style cells, which it can process at a rate of 37 million cells per second. It provides high bandwidth and low latency for datagram traffic. In addition, it supports real-time traffic by providing bandwidth reservations with guaranteed latency bounds. The key to the switch's operation is a technique called parallel iterative matching, which can quickly identify a set of conflict-free cells for transmission in a time slot. Bandwidth reservations are accommodated in the switch by building a fixed schedule for transporting cells from reserved flows across the switch; parallel iterative matching can fill unused slots with datagram traffic. Finally, we note that parallel iterative matching may not allocate bandwidth fairly among flows of datagram traffic. We describe a technique called statistical matching, which can be used to ensure fairness at the switch and to support applications with rapidly changing needs for guaranteed bandwidth. © 1993, ACM. All rights reserved.",ATM networks; iterative matching; statistical matching; switching scheduling,Scheduling; High performance distributed computing; High speed switch scheduling; Point-to-point network; Local area networks
Chores: Enhanced Run-Time Support for Shared-Memory Parallel Computing,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027541455&doi=10.1145%2f151250.151251&partnerID=40&md5=77345f914e94f411bb01e0e676663685,"Parallel computing is increasingly important in the solution of large-scale numerical problems. The difficulty of efficiently hand-coding parallelism, and the limitations of parallelizing compilers, have nonetheless restricted its use by scientific programmers. In this paper we propose a new paradigm, chores, for the run-time support of parallel computing on shared-memory multiprocessors. We consider specifically uniform memory access shared-memory environments, although the chore paradigm should also be appropriate for use within the clusters of a large-scale nonuniform memory access machine. We argue that chore systems attain both the high efficiency of compiler approaches for the common case of data parallelism, and the flexibility and performance of user-level thread approaches for functional parallelism. These benefits are achieved within a single, simple conceptual model that almost entirely relieves the programmer and compiler from concerns of granularity, scheduling, and enforcement of synchronization constraints. Measurements of a prototype implementation demonstrate that the chore model can be supported more efficiently than can traditional approaches to either data or functional parallelism alone. © 1993, ACM. All rights reserved.",,Codes (symbols); Computational methods; Computer architecture; Computer operating systems; Constraint theory; Data processing; Mathematical models; Multiprocessing systems; Parallel processing systems; Program compilers; Real time systems; Storage allocation (computer); Chores; Multiple data stream architectures; Shared memory multiprocessors; Computer systems
"CHAOSarc: Kernel Support for Multiweight Objects, Invocations, and Atomicity in Real-Time Multiprocessor Applications",1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027543771&doi=10.1145%2f151250.151252&partnerID=40&md5=231f266b9d322631938199a1818e1ff9,"CHAOSarc is an object-based multiprocessor operating system kernel that provides primitives with which programmers may easily construct objects of differing types and object invocations of differing semantics, targeting multiprocessor systems, and real-time applications. The CHAOSarc can guarantee desired performance and functionality levels of selected computations in real-time applications. Such guarantees can be made despite possible uncertainty in execution environments by allowing programs to adapt in performance and functionality to varying operating conditions. This paper reviews the primitives offered by CHAOSarc and demonstrates how the required elements of the CHAOSarc real-time kernel are constructed with those primitives. © 1993, ACM. All rights reserved.",,Computational linguistics; Computational methods; Computer architecture; Computer systems programming; Control systems; Multiprocessing systems; Object oriented programming; Parallel processing systems; Real time systems; Robotics; Computer operating system CHAOS; Current program structure; Object based multiprocessor operating system kernel; Process management; Computer operating systems
Waiting Algorithms for Synchronization in Large-Scale Multiprocessors,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027646857&doi=10.1145%2f152864.152869&partnerID=40&md5=c482b59d5cfab9c12d91f24aee442893,"Through analysis and experiments, this paper investigates two-phase waiting algorithms to minimize the cost of waiting for synchronization in large-scale multiprocessors. In a two-phase algorithm, a thread first waits by polling a synchronization variable. If the cost of polling reaches a limit Lpoll and further waiting is necessary, the thread is blocked, incurring an additional fixed cost, B. The choice of Lpoll is a critical determinant of the performance of two-phase algorithms. We focus on methods for statically determining Lpoll because the run-time overhead of dynamically determining Lpoll can be comparable to the cost of blocking in large-scale multiprocessor systems with lightweight threads. Our experiments show that always-block 1993 is a good waiting algorithm with performance that is usually close to the best of the algorithms compared. We show that even better performance can be achieved with a static choice of Lpoll based on knowledge of likely wait-time distributions. Motivated by the observation that different synchronization types exhibit different wait-time distributions, we prove that a static choice of Lpoll can yield close to optimal on-line performance against an adversary that is restricted to choosing wait times from a fixed family of probability distributions. This result allows us to make an optimal static choice of Lpoll based on synchronization type. For exponentially distributed wait times, we prove that setting Lpoll = 1n(e-1)B results in a waiting cost that is no more than e/(e-1) times the cost of an optimal off-line algorithm. For uniformly distributed wait times, we prove that setting Lpoll=1/2(square root of 5 -1)B results in a waiting cost that is no more than (square root of 5 + 1)/2 (the golden ratio) times the cost of an optimal off-line algorithm. Experimental measurements of several parallel applications on the Alewife multiprocessor simulator corroborate our theoretical findings. © 1993, ACM. All rights reserved.",barriers; blocking; competitive analysis; locks; producer-consumer synchronization; spinning; waiting time,Algorithms; Large-scale multiprocessors; Two-phase algorithms; Waiting algorithms; Microprocessor chips
Limits to Low-Latency Communication on High-Speed Networks,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027590139&doi=10.1145%2f151244.151247&partnerID=40&md5=fc2fd6b660019a27c7a1fa2645b17084,"The throughput of local area networks is rapidly increasing. For example, the bandwidth of new ATM networks and FDDI token rings is an order of magnitude greater than that of Ethernets. Other network technologies promise a bandwidth increase of yet another order of magnitude in several years. However, in distributed systems, lowered latency rather than increased throughput is often of primary concern. This paper examines the system-level effects of newer high-speed network technologies on low-latency, cross-machine communications. To evaluate a number of influences, both hardware and software, we designed and implemented a new remote procedure call system targeted at providing low latency. We then ported this system to several hardware platforms 1993 with several different networks and controllers (ATM, FDDI, and Ethernet). Comparing these systems allows us to explore the performance impact of alternative designs in the communication system with respect to achieving low latency, e.g., the network, the network controller, the hose architecture and cache system, and the kernel and user-level runtime software. Our RPC system, which achieves substantially reduced call times (170 μseconds on an ATM network using DECstation 5000/200 hosts), allows us to isolate those components of next-generation networks and controllers that still stand in the way of low-latency communication. We demonstrate that new-generation processor technology and software design can reduce small-packet RPC times to near network-imposed limits, making network and controller design more crucial than ever to achieving truly low-latency communication. © 1993, ACM. All rights reserved.",ATM networks; host-network interfaces; interprocess communication; remote procedure calls; transport level protocols,Computer architecture; Computer software; Data processing; Distributed computer systems; Interfaces (computer); Local area networks; Network protocols; Program processors; Asynchronous transfer mode (ATM) networks; High speed networks; Host network interfaces; Interprocess communication; Low latency communication; Remote procedure calls; Transport level protocols; Data communication systems
Distributed Timestamp Generation in Planar Lattice Networks,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027649548&doi=10.1145%2f152864.152865&partnerID=40&md5=90870c0a9527f86a2f982e8ce5724ecb,"Timestamps are considered for distributed environments in which information flow is restricted to one direction through a planar lattice imposed on a network. For applications in such networks, existing timestamping algorithms require extension and modification. For example, in secure environments, typical timestamps provide a potential signaling channel between incomparable levels. In hierarchical databases, typical timestamps cause peripheral sites to unnecessarily affect the behavior at main sites. Algorithms are presented by which a network node may generate and compare timestamps using timestamp components maintained at dominated nodes in the network. The comparison relation is shown to be acyclic for timestamps produced by the generation algorithm. We discuss ways to safely relax the requirement that the network be a lattice. By example, we show how to modify a simple nonplanar lattice so that the generation algorithm can be applied. Uses of the timestamp generation algorithm in the motivating applications are outlined. © 1993, ACM. All rights reserved.",hierarchical databases; planar lattices; secure databases; timestamps,Algorithms; Database systems; Distributed timestamp generation; Hierarchical databases; Planar lattice networks; Secure databases; Computer software
FLIP: An Internetwork Protocol for Supporting Distributed Systems,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027543704&doi=10.1145%2f151250.151253&partnerID=40&md5=72422d4b5f5095d2630b4b8db3ca330d,"Most modern network protocols give adequate support for traditional applications such as file transfer and remote login. Distributed applications, however, have different requirements 1993. Instead of using ad hoc protocols to meet each of the new requirements, we have designed a new protocol, called the Fast Local Internet Protocol (FLIP), that provides a clean and simple integrated approach to these new requirements. FLIP is an unreliable message protocol that provides both point-to-point communication and multicast communication, and requires almost no network management. Furthermore, by using FLIP we have simplified higher-level protocols such as remote procedure call and group communication, and enhanced support for process migration and security. A prototype implementation of FLIP has been built as part of the new kernel for the Amoeba distributed operating system, and is in daily use. Measurements of its performance are presented. © 1993, ACM. All rights reserved.",,Computer architecture; Computer networks; Computer operating systems; Data communication systems; Distributed computer systems; File organization; Performance; Ad hoc protocols; Amoeba distributed operating system; Fast local internet protocol (FLIP); Specific remote procedure call (RPC) semantics; Network protocols
Metascheduling for Continuous Media,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027648958&doi=10.1145%2f152864.152866&partnerID=40&md5=de3ab9b64747d5ac1418cd55c8792853,"Next-generation distributed systems will support continuous media 1993 in the same framework as other data. Many applications that use continuous media need guaranteed end-to-end performance (bounds on throughput and delay). To reliably support these requirements, system components such as CPU schedulers, networks, and file systems must offer performance guarantees. A metascheduler coordinates these components, negotiating end-to-end guarantees on behalf of clients. The CM-resource model, described in this paper, provides a basis for such a metascheduler. It defines a workload parameterization, an abstract interface to resources, and an algorithm for reserving multiple resources. The model uses an economic approach to dividing end-to-end delay, and it allows system components to “work ahead,” improving the performance of nonreal-time workload. © 1993, ACM. All rights reserved.",multimedia; resource management,Economics; Continuous meda metascheduling; CPU schedulers; File systems; Multimedia; Resource management; Digital devices
A Dynamic Processor Allocation Policy for Multiprogrammed Shared-Memory Multiprocessors,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027594835&doi=10.1145%2f151244.151246&partnerID=40&md5=2a70465d4886fb7458c011721720a0f2,"We propose and evaluate empirically the performance of a dynamic processor-scheduling policy for multiprogrammed shared-memory multiprocessors. The policy is dynamic in that it reallocates processors from one parallel job to another based on the currently realized parallelism of those jobs. The policy is suitable for implementation in production systems in that: —It interacts well with very efficient user-level thread packages, leaving to them many low-level thread operations that do not require kernel intervention. —It deals with thread blocking due to user I/O and page faults. —It ensures fairness in delivering resources to jobs. —Its performance, measured in terms of average job response time, is superior to that of previously proposed schedulers, including those implemented in existing systems. It provides good performance to very short, sequential 1993 requests. We have evaluated our scheduler and compared it to alternatives using a set of prototype implementations running on a Sequent Symmetry multiprocessor. Using a number of parallel applications with distinct qualitative behaviors, we have both evaluated the policies according to the major criterion of overall performance and examined a number of more general policy issues, including the advantage of “space sharing” over “time sharing” the processors of a multiprocessor, and the importance of cooperation between the kernel and the application in reallocating processors between jobs. We have also compared the policies according to other criteia important in real implementations, in particular, fairness and respone time to short, sequential requests. We conclude that a combination of performance and implementation considerations makes a compelling case for our dynamic scheduling policy. © 1993, ACM. All rights reserved.",shared memory parallel processors; threads; two-level scheduling,Data processing; Mathematical models; Parallel processing systems; Program processors; Scheduling; Storage allocation (computer); Dynamic processor allocation policy; Multiprogrammed shared memory multiprocessors; Threads; Two level scheduling; Multiprocessing systems
Design and Verification of the Rollback Chip Using HOP: A Case Study of Formal Methods Applied to Hardware Design,1993,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027595806&doi=10.1145%2f151244.151245&partnerID=40&md5=fef3eea303de9c25e3e46b2bed96d9f3,"The use of formal methods in hardware design improves the quality of designs in many ways: it promotes better understanding of the design; it permits systematic design refinement through the discovery of invariants; and it allows design verification 1993. In this paper we illustrate the use of formal methods in the design of a custom hardware system called the “Rollback Chip” (RBC), conducted using a simple hardware design description language called “HOP”. An informal specification of the requirements of the RBC is first given, followed by a behavioral description of the RBC stating its desired behavior. The behavioral description is refined into progressively more efficient designs, terminating in a structural description. Key refinement steps are based on system invariants that are discovered during the design, and proved correct during design verification. The first step in design verification is to apply a program called PARCOMP to derive a behavioral description from the structural description of the RBC. The derived behavior is then compared against the desired behavior using equational verification techniques. This work demonstrates that formal methods can be fruitfully applied to a nontrivial hardware design. It also illustrates the particular advantages of our approach based on HOP and PARCOMP. Last, but not the least, it formally verifies the RBC mechanism itself. © 1993, ACM. All rights reserved.",,Computer hardware description languages; Computer simulation; Integrated circuit layout; Mathematical models; Microprocessor chips; Rollback chip (RBC); Software package PARCOMP; Computer hardware
Authentication in Distributed Systems: Theory and Practice,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976834054&doi=10.1145%2f138873.138874&partnerID=40&md5=4c3ddea77f00b3dc5ff42e9699795ede,"We describe a theory of authentication and a system that implements it. Our theory is based on the notion of principal and a “speaks for” relation between principals. A simple principal either has a name or is a communication channel; a compound principal can express an adopted role or delegated authority. The theory shows how to reason about a principal's authority by deducing the other principals that it can speak for; authenticating a channel is one important application. We use the theory to explain many existing and proposed security mechanisms. In particular, we describe the system we have built. It passes principals efficiently as arguments or results of remote procedure calls, and it handles public and shared key encryption, name lookup in a large name space, groups of principals, program loading, delegation, access control, and revocation. © 1992, ACM. All rights reserved.",certification authority; delegation; group; interprocess communication; key distribution; loading programs; path name; principal; role; secure channel; speaks for; trusted computing base,
Page Placement Algorithms for Large Real-Indexed Caches,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976736383&doi=10.1145%2f138873.138876&partnerID=40&md5=a146506ce7dfe805e4a3783d4f25d658,"When a computer system supports both paged virtual memory and large real-indexed caches, cache performance depends in part on the main memory page placement. To date, most operating systems place pages by selecting an arbitrary page frame from a pool of page frames that have been made available by the page replacement algorithm. We give a simple model that shows that this naive 1992 page placement leads to up to 30% unnecessary cache conflicts. We develop several page placement algorithms, called careful-mapping algorithms, that try to select a page frame (from the pool of available page frames) that is likely to reduce cache contention. Using trace-driven simulation, we find that careful mapping results in 10–20% fewer (dynamic) cache misses than naive mapping (for a direct-mapped real-indexed multimegabyte cache). Thus, our results suggest that careful mapping by the operating system can get about half the cache miss reduction that a cache size (or associativity) doubling can. © 1992, ACM. All rights reserved.",,
Providing High Availability Using Lazy Replication,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976752528&doi=10.1145%2f138873.138877&partnerID=40&md5=eb256a45d5a266cf7896ccb9d7f8aeca,"To provide high availability for services such as mail or bulletin boards, data must be replicated. One way to guarantee consistency of replicated data is to force service operations to occur in the same order at all sites, but this approach is expensive. For some applications a weaker causal operation order can preserve consistency while providing better performance. This paper describes a new way of implementing causal operations. Our technique also supports two other kinds of operations: operations that are totally ordered with respect to one another and operations that are totally ordered with respect to all other operations. The method performs well in terms of response time, operation-processing capacity, amount of stored state, and number and size of messages; it does better than replication methods based on reliable multicast techniques. © 1992, ACM. All rights reserved.",client/server architecture; fault tolerance; group communication; high availability; operation ordering; replication; scalability; semantics of application,
Network Locality at the Scale of Processes,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026858091&doi=10.1145%2f128899.128900&partnerID=40&md5=b1b91433dc9371eafe583ca64b72d089,"Packets on a LAN can be viewed as a series of references to and from the objects they address. The amount of locality in this reference stream may be critical to the efficiency of network implementations, if the locality can be exploited through caching or scheduling mechanisms. Most previous studies have treated network locality with an addressing granularity of networks or individual hosts. This paper describes some experiments tracing locality at a finer grain, looking at references to individual processes, and with fine-grained time resolution. Observations of typical LANs show high per-process locality; that is, packets to a host usually arrive for the process that most recently sent a packet, and often with little intervening delay. © 1992, ACM. All rights reserved.",context switching; dallying; locality of reference; remote procedure calls,Algorithms; Computer systems programming; Data communication systems; Data structures; Packet switching; Performance; Context switching; Dallying; Locality of reference; Network locality; Remote procedure calls; Local area networks
A Logic for Reasoning About Security,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026900438&doi=10.1145%2f146937.146940&partnerID=40&md5=48e1252358f63476856b85f208e9f938,"A formal framework called Security Logic 1992 is developed for specifying and reasoning about security policies and for verifying that system designs adhere to such policies. Included in this modal logic framework are definitions of knowledge, permission, and obligation. Permission is used to specify secrecy policies and obligation to specify integrity policies. The combination of policies is addressed and examples based on policies from the current literature are given. © 1992, ACM. All rights reserved.",composition knowledge; integrity; logic; obligation; permission; policy; possible-worlds; secrecy; security; time,Computer operating systems; Data processing; Database systems; Formal languages; Formal logic; Logic programming; Composition knowledge; Obligation; Permission; Possible words; Security logic; Specific integrity policy; Security of data
Delivery of Time-Critical Messages Using a Multiple Copy Approach,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026856465&doi=10.1145%2f128899.128902&partnerID=40&md5=ab6c45fac6634189941c8143f3c9b1f9,"Reliable and timely delivery of messages between processing nodes is essential in distributed real-time systems. Failure to deliver a message within its deadline usually forces the system to undertake a recovery action, which introduces some cost 1992 to the system. This recovery cost can be very high, especially when the recovery action fails due to lack of time or resources. Proposed in this paper is a scheme to minimize the expected cost incurred as a result of messages failing to meet their deadlines. The scheme is intended for distributed real-time systems, especially with a point-to-point interconnection topology. The goal of minimizing the expected cost is achieved by sending multiple copies of a message through disjoint routes and thus increasing the probability of successful message delivery within the deadline. However, as the number of copies increases, the message traffic on the network increases, thereby increasing the delivery time for each of the copies. There is therefore a tradeoff between the number of copies of each message and the expected cost incurred as a result of messages missing their deadlines. The number of copies of each message to be sent is determined by optimizing this tradeoff. Simulation results for a hexagonal mesh and a hypercube topology indicate that the expected cost can be lowered substantially by the proposed scheme. © 1992, ACM. All rights reserved.",dynamic failure; time-constrained communication,Computer architecture; Computer system recovery; Copying; Data communication systems; Distributed computer systems; Probability; Real time systems; Topology; Dynamic failure; Hexagonal mesh topology; Hypercube topology; Multiple copy approach; Time constrained communication; Time critical messages; Computer networks
An Effective Synchronization Network for Hot-Spot Accesses,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026903874&doi=10.1145%2f146937.146938&partnerID=40&md5=e076e13a6ddbbcfc4f33585adf1445a0,"In large multiprocessor systems, fast synchronization is crucial for high performance. However, synchronization traffic tends to create “hot-spots” in shared memory and cause network congestion. Multistage shuffle-exchange networks have been proposed and built to handle synchronization traffic. Software combining schemes have also been proposed to relieve network congestion caused by hot-spots. However, multistage combining networks could be very expensive and software combining could be very slow. In this paper, we propose a single-stage combining network to handle synchronization traffic, which is separated from the regular memory traffic. A single-stage combining network has several advantages: 1992 it is attractive from an implementation perspective because only one stage is needed(instead of log N stages); (2) Only one network is needed to handle both forward and returning requests; (3) combined requests are distributed evenly through the network—the wait buffer size is reduced; and (4) fast-finishing algorithms [30] can be used to shorten the network delay. Because of all these advantages, we show that a single-stage combining network gives good performance at a lower cost than a multistage combining network. © 1992, ACM. All rights reserved.",hot spots; memory traffic; parallel processing,Algorithms; Data processing; Data structures; Multiprocessing systems; Parallel processing systems; Process control; Synchronization; Telecommunication traffic; Hot spot accesses; Memory traffic; Multiple data stream architectures; Multistage shuffle exchange networks; Computer networks
Adaptable Concurrency Control for Atomic Data Types,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026900460&doi=10.1145%2f146937.146939&partnerID=40&md5=d2efe4f1e4d2b6d567215bb6552f29e2,"In many distributed systems concurrent access is required to a shared object, where abstract object servers may incorporate type-specific properties to define consistency requirements. Each operation and its outcome is treated as an event, and conflicts may occur between different event types. Hence concurrency control and synchronization are required at the granularity of conflicting event types. With such a fine granularity of locking, the occurrence of conflicts is likely to be lower than with whole-object locking, so optimistic techniques become more attractive. This work describes the design, implementation, and performance of servers for a shared atomic object, a semiqueue, where each server employs either pessimistic or optimistic locking techniques on each conflicting event type. We compare the performance of a purely optimistic server, a purely pessimistic server, and a hybrid server which treats certain event types optimistically and others pessimistically, to demonstrate the most appropriate environment for using pessimistic, optimistic, or hybrid control. We show that the advantages of low overhead on optimistic locking at low conflict levels is offset at higher conflict levels by the wasted work done by aborted transactions. To achieve optimum performance over the whole range of conflict levels, an adaptable server is required, whereby the treatment of conflicting event types can be changed dynamically between optimistic and pessimistic, according to various criteria depending on the expected frequency of conflict. We describe our implementations of adaptable servers which may allocate concurrency control strategy on the basis of state information, the history of conflicts encountered, or by using preset transaction priorities. We show that the adaptable servers perform almost as well as the best of the purely optimistic, pessimistic, or hybrid servers under the whole range of conflict levels, showing the versatility and efficiency of the dynamic servers. Finally we outline a general design methodology for implementing adaptable concurrency control in servers for atomic objects, illustrated using an atomic shared B-tree. © 1992, ACM. All rights reserved.",concurrent access to shared data; hybrid locking; optimistic locking; pessimistic locking; transactions serializability,Adaptive control systems; Computer aided software engineering; Computer operating systems; Computer programming languages; Data structures; Design; Distributed computer systems; Object oriented programming; Optimization; Performance; Synchronization; Trees (mathematics); Concurrency control; Concurrent access to shared type specific abstract data types; Hybrid locking; Language constructs and features; Optimistic locking; Pessimistic locking; Transactions serializability; Computer programming
A Dynamic Network Architecture,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026860454&doi=10.1145%2f128899.128901&partnerID=40&md5=5e37f3628ba8dec73d0eb668343b852f,"Network software is a critical component of any distributed system. Because of its complexity, network software is commonly layered into a hierarchy of protocols, or more generally, into a protocol graph. Typical protocol graphs—including those standardized in the ISO and TCP/IP network architectures—share three important properties; the protocol graph is simple, the nodes of the graph 1992 encapsulate complex functionality, and the topology of the graph is relatively static. This paper describes a new way to organize network software that differs from conventional architectures in all three of these properties. In our approach, the protocol graph is complex, individual protocols encapsulate a single function, and the topology of the graph is dynamic. The main contribution of this paper is to describe the ideas behind our new architecture, illustrate the advantages of using the architecture, and demonstrate that the architecture results in efficient network software. © 1992, ACM. All rights reserved.",composibility; dynamic configuration; reuse,Computer architecture; Computer networks; Computer systems programming; Distributed computer systems; Graph theory; Hierarchical systems; Object oriented programming; Software engineering; Topology; Composibility; Dynamic configuration; Function encapsulation; Network software; Object reuse; Protocol graph; Network protocols
A File System for Continuous Media,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976728167&doi=10.1145%2f138873.138875&partnerID=40&md5=1c4d13b498f00d01d03917e1c6d7a595,"The Continuous Media File System, CMFS, supports real-time storage and retrieval of continuous media data 1992 on disk. CMFS clients read or write files in “sessions,” each with a guaranteed minimum data rate. Multiple sessions, perhaps with different rates, and non-real-time access can proceed concurrently. CMFS addresses several interrelated design issues; real-time semantics fo sessions, disk layout, an acceptance test for new sessions, and disk scheduling policy. We use simulation to compare different design choices. © 1992, ACM. All rights reserved.",disk scheduling; multimedia,
The design and Implementation of a Log-Structured File System,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026812659&doi=10.1145%2f146941.146943&partnerID=40&md5=4d4a2b46e308eb1d31019d3bd9d09506,"This paper presents a new technique for disk storage management called a log-structured file system. A log-structured file system writes all modifications to disk sequentially in a log-like structure, thereby speeding up both file writing and crash recovery. The log is the only structure on disk; it contains indexing information so that files can be read back from the log efficiently. In order to maintain large free areas on disk for fast writing, we divide the log intosegmentsand use a segment cleaner to compress the live information from heavily fragmented segments. We present a series of simulations that demonstrate the efficiency of a simple cleaning policy based on cost and benefit. We have implemented a prototype log-structured file system called Sprite LFS; it outperforms current Unix file systems by an order of magnitude for small-file writes while matching or exceeding Unix performance for reads and large writes. Even when the overhead for cleaning is included, Sprite LFS can use 70% of the disk bandwidth for writing, whereas Unix file systems typically can use only 5–10%. © 1992, ACM. All rights reserved.",disk storage management; fast crash recovery; file system organization; file system performance; high write performance; log-structured; logging; Unix,Computer operating systems; Computer system recovery; Data structures; Data transfer; Database systems; Digital storage; Magnetic disk storage; Performance; Storage allocation (computer); UNIX; Disk storage management; Fast crash recovery; File system performance; High write performance; Log-structured file system; Logging; Segment cleaner; Segments; Sprite LFS; File organization
Experimental Comparison of Memory Management Policies for NUMA Multiprocessors,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976836384&doi=10.1145%2f118544.118546&partnerID=40&md5=f0cef94c8fcb0021e84527407cc424de,"Nonuniformity of memory accessis an almost inevitable feature of the memory architecture in shared memory multiprocessor designs that can scale to large numbers of processors. One implication of NUMA architectures is that the placement and movement of code and data are crucial to performance. As memory architectures become more complex and the nonuniformity becomes less well hidden, system software must assume a larger role in providing memory management support for the programmer. This paper investigates the role of the operating system. We take an experimental approach to evaluating a wide-range of memory management policies. The target NUMA environment is BBN�s GP-1OOOmultiprocessor. Extensive local modifications have been made to the memory management subsystem of BBN�s nX operating system to support multiple policy implementations. Policy comparisons are based on the measured performance of real parallel applications. Our results show that there are memory management policies implemented in our system that can improve the performance of programs written using the simpler uniform memory access (UMA) programming model. While achieving the level of performance of a highly tuned NUMA program is still a difficult problem, some examples come close. There appears to be no single policy that can be considered the best over our set of test applications. Investigations into the contributions made by individual policy features toward overall behavior of the workload provide some insight into the design of a set of effective policies. © 1991, ACM. All rights reserved.",,
Multidimensional Voting,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976670102&doi=10.1145%2f118544.118552&partnerID=40&md5=92bb1a4fb1437a8220cb56b66be7db91,"We introduce a new concept, m ultidimenszonal voting, in which the vote and quorum assignments are k-dimensional vectors of nonnegative integers and each dimension is independent of the others. Multidimensional voting is more powerful than traditional weighted voting because it is equivalent to the general method for achieving synchronization in distributed systems which is based on sets of groups of nodes (quorum sets). We describe an efficient algorithm for finding a multidimensional vote assignment for any given quorum set and show examples of its use. We demonstrate the versatility of multidimensional voting by using it to implement mutual exclusion in fault-tolerant distributed systems and protocols for synchronizing access to fully and partially replicated data. These protocols cannot be implemented by traditional weighted voting. Also, the protocols based on multidimensional voting are easier to implement and/or provide greater flexibility than existing protocols for the same purpose, Finally, we present a generalization of the multidimensional voting scheme, called nested multidzmenszonal uotmg, that can facilitate implementation of replica control protocols that use structured quorum sets. © 1991, ACM. All rights reserved.",,
Algorithms for Unboundedly Parallel Simulations,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976842297&doi=10.1145%2f128738.128739&partnerID=40&md5=8f35e8817fafdeb3981e861e36ef401b,"New methods are presented for parallel simulation of discrete event systems that, when applicable, can usefully employ a number of processors much larger than the number of objects in the system being simulated, Abandoning the distributed event list approach, the simulation problem is posed using recurrence relations. We bring three algorithmic ideas to bear on parallel simulation: parallel prefix computation, parallel merging, and iterative folding. Efficient parallel simulations are given for (in turn) the G/G/l queue, a variety of queueing networks having a global first come first served structure (e.g., a series of queues with finite buffers), acyclic networks of queues, and networks of queues with feedbacks and cycles. In particular, the problem of simulating the arrival and departure times for the first N jobs to a single G/G/l queue is solved in time proportional to N/P + log P using P processors. © 1991, ACM. All rights reserved.",Iteration,
Efficient Trace-Driven Simulation Methods for Cache Performance Analysis,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976706468&doi=10.1145%2f128738.128740&partnerID=40&md5=0ae8ae504276fbb53b620f7ec3159a12,[No abstract available],cache memory; trace reduction; trace-driven simulation,
Improving Round-Trip Time Estimates in Reliable Transport Protocols,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976726744&doi=10.1145%2f118544.118549&partnerID=40&md5=14e97da93226aaaa2183d8b707bfd1a2,"As a reliable, end-to-end transport protocol, the Transmission Control Protocol (TCP) uses positive acknowledgements and retransmission to guarantee delivery. TCP implementations are expected to measure and adapt to changing round-trip delay so that their retransmission behavior balances user throughput and network efficiency. However, TCP suffers from a problem we call retransmission ambiguzty: when an acknowledgement arrives for a datagram that has been retransmitted, there is no indication of which transmission is being acknowledged. As a result, an implementation maybe unable to determine if the round-trip time it measures is for an original transmission or a retransmission of a datagram. Many existing TCP implementations do not handle this problem correctly. Furthermore, the problem of retransmission ambiguity is also a characteristic of other major transport protocols, including 0S1 TP4 and DECnet NSP This paper reviews the various approaches to retransmission and presents a novel and effective approach to the retransmission ambiguity problem. © 1991, ACM. All rights reserved.",round-trip times; transport protocols,
Lightweight Causal and Atomic Group Multicast,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976814834&doi=10.1145%2f128738.128742&partnerID=40&md5=469957c93b87e4a2d70cfb6e2dd5acb0,[No abstract available],fault-tolerant process groups; message ordering; multicast communication,
Disconnected operation in the Coda File System,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026815276&doi=10.1145%2f146941.146942&partnerID=40&md5=aa0d7ce0fc396b4bbabd94bb1e2eca9a,"Disconnected operation is a mode of operation that enables a client to continue accessing critical data during temporary failures of a shared data repository. An important, though not exclusive, application of disconnected operation is in supporting portable computers. In this paper, we show that disconnected operation is feasible, efficient and usable by describing its design and implementation in the Coda File System. The central idea behind our work is that caching of data, now widely used for performance, can also be exploited to improve availability. © 1992, ACM. All rights reserved.",disconnected operation; hoarding; optimistic replication; reintegration; second-class replication; server emulation,Computer networks; Computer operating systems; Computer system recovery; Data transfer; Distributed computer systems; Distributed database systems; Fault tolerant computer systems; Nonvolatile storage; Performance; Personal computers; Reliability; Remote consoles; Caching; Coda file system; Disconnected operation; Distributed file systems; Hoarding; Optimistic replication; Reintegration; Second class replication; Server replication; Computer operating procedures
Reliable Broadcast Algorithms for HARTS,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976771048&doi=10.1145%2f118544.119233&partnerID=40&md5=112f16784e880a164421c542ba1fbade,"The problem of broadcasting in point-to-point interconnection networks with virtual cut-through switching is considered. A simple extension of virtual cut-through is proposed, which provides good support for broadcasting in mesh-connected multicomputers. An implementation of this extension (termed a broadcast primitive) for a hexagonal mesh multicomputer called HARTS, that uses virtual cut-through switching, is also presented. Based on this primitive, a set of broadcast algorithms is developed for the hexagonal mesh topology These algorithms deliver multiple copies of a message from a source node to every other node in the hexagonal mesh through disjoint paths. They can be used for broadcasting in the presence of faulty nodes/links, even when the identity of the faulty components is not known. The performance of these algorithms has been analyzed and compared with the performance of other possible broadcast algorithms. © 1991, ACM. All rights reserved.",,
Ordered and Reliable Multicast Communication,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976696697&doi=10.1145%2f128738.128741&partnerID=40&md5=c1e5ca36e8e026947add698d96a0147c,[No abstract available],message ordering; multicast communication,
Scheduler activations: Effective kernel support for the user-level management of parallelism,1992,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026812740&doi=10.1145%2f146941.146944&partnerID=40&md5=e43abc08d727f23cccc3713078b7aa83,"Threads are the vehicle for concurrency in many approaches to parallel programming. Threads can be supported either by the operating system kernel or by user-level library code in the application address space, but neither approach has been fully satisfactory. This paper addresses this dilemma. First, we argue that the performance of kernel threads is inherently worse than that of user-level threads, rather than this being an artifact of existing implementations; managing parallelism at the user level is essential to high-performance parallel computing. Next, we argue that the problems encountered in integrating user-level threads with other system services is a consequence of the lack of kernel support for user-level threads provided by contemporary multiprocessor operating systems; kernel threads are the wrong abstraction on which to support user-level management of parallelism. Finally, we describe the design, implementation, and performance of a new kernel interface and user-level thread package that together provide the same functionality as kernel threads without compromising the performance and flexibility advantages of user-level management of parallelism. © 1992, ACM. All rights reserved.",multiprocessor; thread,Computer operating procedures; Computer operating systems; Input output programs; Interfaces (computer); Management; Multiprocessing systems; Parallel processing systems; Program processors; Kernel interface; Kernel threads; Operating system kernel; Parallel programming; Parallelism; Scheduler activations; Threads; User level management of parallelism; User-level thread package; Computer systems programming
User-level Interprocess Communication for Shared Memory Multiprocessors,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976658204&doi=10.1145%2f103720.114701&partnerID=40&md5=a3bd21e216b661af1f6db96723c973f0,[No abstract available],multiprocessor; operating system; parallel programming; performance; thread,
Efficient At-Most-Once Messages Based on Synchronized Clocks,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976685665&doi=10.1145%2f103720.103722&partnerID=40&md5=6c99478b03b1bb242f015afa99885f37,"This paper describes a new at-most-once message passing protocol that provides guaranteed detection of duplicate messages even when the receiver has no state stored for the sender. It also discusses how to use at-most-once messages to implement higher-level primitives such as at-once-remote procedure calls and sequenced bytestream protocols. Our performance measurements indicate that at-most-once RPCs can provide at the same cost as less desirable forms of RPCs that do not guarantee at-most-once execution. Our method is based on the assumption that clocks throughout the system are loosely synchronized. Modern clock synchronization protocols provide good bounds on clock skew with high probability; our method depends on the bound for performance but not for correctness. © 1991, ACM. All rights reserved.",at-most-once message passing; message-passing protocols; remote procedure calls; synchronized clocks,
Architectural Support for Reduced Register Saving/Restoring in Single-Window Register Files,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749395138&doi=10.1145%2f103727.103730&partnerID=40&md5=eebb1c093f6aeab2d2678296588009a3,"The use of registers in a processor reduces the data and instruction memory traffic. Since this reduction is a significant factor in the improvement of the program execution time, recent VLSI processors have a large number of registers which can be used efficiently because of the advances in compiler technology. However, since registers have to be saved/restored across function calls, the corresponding register saving and restoring 1991 memory traffic can almost eliminate the overall reduction. This traffic has been reduced by compiler optimizations and by providing multiple-window register files. Although these multiple-window architectures produce a large reduction in the RSR traffic, they have several drawbacks which make the single-window file preferable. We consider a combination of hardware support and compiler optimizations to reduce the RSR traffic for a single-window register file, beyond the reductions achieved by compiler optimizations alone. Basically, this hardware keeps track of the registers that are written during execution, so that the number of registers saved is minimized. Moreover, hardware is added so that a register is saved in the activation record of the function that uses it (instead of in the record of the current function); in this way a register is restored only when it is needed, rather than wholesale on procedure return. We present a register saving and restoring policy that makes use of this hardware, discuss its implementation, and evaluate the traffic reduction when the policy is combined with intraprocedural and interprocedural compiler optimizations. We show that, on the average for the four general-purpose programs measured, the RSR traffic is reduced by about 90 percent for a small register file (i.e., 32 registers), which results in an overall data memory traffic reduction of about 15 percent. © 1991, ACM. All rights reserved.",,
VirtualClock: A New Traffic Control Algorithm for Packet-Switched Networks,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722392&doi=10.1145%2f103720.103721&partnerID=40&md5=052395d39bc82657bc24da167a0ba041,"One of the challenging research issues in building high-speed packet-switched networks is how to control the transmission rate of statistical data flows. This paper describes a new traffic control algorithm, VirtualClock, for high-speed network applications. VirtualClock monitors the average transmission rate of statistical data flows and provides every flow with guaranteed throughput and low queueing delay. It provides firewall protection among individual flows, as in a TDM system, while retaining the statistical multiplexing advantages of packet switching. Simulation results show that the VirtualClock algorithm meets all its design goals. © 1991, ACM. All rights reserved.",data traffic control; performance guarantee; rate-based flow-control algorithms; statistical multiplexing; time-division-multiplexing,
An Efficient and Fault-Tolerant Solution for Distributed Mutual Exclusion,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976715309&doi=10.1145%2f103727.103728&partnerID=40&md5=72a11a55d3fe7afec1020ba930aff818,"In this paper, we present an efficient and fault-tolerant algorithm for generating quorums to solve the distributed mutual exclusion problem. The algorithm uses a logical tree organization of the network to generate tree quorums, which are logarithmic in the size of the network in the best case. Our approach is resilient to both site and communication failures, even when such failures lead to network partitioning. Furthermore, the algorithm exhibits a property of graceful degradation, i.e., it requires more messages only as the number of failures increase in the network. We describe how tree quorums can be used for various distributed applications for providing mutually exclusive access to a distributed resource, managing replicated objects, and atomically commiting a distributed transaction. © 1991, ACM. All rights reserved.",,
Dynamic Adaptation of Real-Time Software,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976848638&doi=10.1145%2f103720.103723&partnerID=40&md5=edc5a2a325b20bcdbeb4999f257f48f5,"In large, dynamic, real-time computer systems, it is frequently most cost effective to employ different software performance and reliability techniques at different levels of granularity, at different times, or within different subsystems. These techniques may include regulation of redundancy and resource allocation, multiversion and multipath execution, adjustments of program attributes such as time-out periods and others. The management of software in such systems is a difficult task. Software that may be adapted to meet varying performance and reliability requirements offers a solution. A REal-time Software Adaptation System 1991 includes a uniform model of adaptable software and provides the tool necessary for programmers to implement algorithms that choose and enact adaptations in real time. RESAS has been implemented on a testbed consisting of a multiprocessor and an attached workstation, and adaptation algorithms have been developed that address the problem of adapting software to achieve two goals: software execution within specified time constraints and software resiliency with respect to computer hardware failures. © 1991, ACM. All rights reserved.",adaptability; dynamic software architectures; real-time systems; software engineering,
Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors,1991,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976718540&doi=10.1145%2f103727.103729&partnerID=40&md5=3d3ba5e2f76d7731f6641ad5ea9f40f9,"Busy-wait techniques are heavily used for mutual exclusion andbarrier synchronization in shared-memory parallel programs.Unfortunately, typical implementations of busy-waiting tend to producelarge amounts of memory and interconnect contention, introducingperformance bottlenecks that become markedly more pronounced asapplications scale. We argue that this problem is not fundamental, andthat one can in fact construct busy-wait synchronization algorithms thatinduce no memory or interconnect contention. The key to these algorithmsis for every processor to spin on separate locally-accessible flag variables,and for some other processor to terminate the spin with a single remotewrite operation at an appropriate time. Flag variables may be locally-accessible as a result of coherent caching, or by virtue ofallocation in the local portion of physically distributed sharedmemory. We present a new scalable algorithm for spin locks that generates 01991 remote references per lockacquisition, independent of the number of processors attempting toacquire the lock. Our algorithm provides reasonable latency in theabsence of contention, requires only a constant amount of space perlock, and requires no hardware support other than a swap-with-memoryinstruction. We also present a new scalable barrier algorithm thatgenerates 0(1) remote references perprocessor reaching the barrier, and observe that two previously-knownbarriers can likewise be cast in a form that spins only onlocally-accessible flag variables. None of these barrier algorithmsrequires hardware support beyond the usual atomicity of memory reads andwrites. We compare the performance of our scalable algorithms with othersoftware approaches to busy-wait synchronization on both a SequentSymmetry and a BBN Butterfly. Our principal conclusion is that contention due to synchronization need not be a problemin large-scale shared-memory multiprocessors. Theexistence of scalable algorithms greatly weakens the case for costlyspecial-purpose hardware support for synchronization, and provides acase against so-called “dance hall” architectures, in whichshared memory locations are equally far from all processors. © 1991, ACM. All rights reserved.",,
Tolerating Failures of Continuous-Valued Sensors,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976743475&doi=10.1145%2f128733.128735&partnerID=40&md5=a7e30a7c43cc221d60a226f512f19107,"One aspect of fault-tolerance in process control programs is the ability to tolerate sensor failure. This paper presents a methodology for transforming a process control program that cannot tolerate sensor failures into one that can. Issues addressed include modifying specifications in order to accommodate uncertainty in sensor values and averaging sensor values in a fault-tolerant manner. In addition, a hierarchy of sensor failure models is identified, and both the attainable accuracy and the run-time complexity of sensor averaging with respect to this hierarchy is discussed. © 1990, ACM. All rights reserved.",distributed sensor networks; fault-tolerance; n-module; redundancy,
Performance of the Firefly RPC,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025388211&doi=10.1145%2f77648.77653&partnerID=40&md5=bf829eebe1fcdde3d3c8add307b6c675,"In this paper we report on the performance of the remote procedure call 1990 implementation for the Firefly multiprocessor and analyze the implementation to account precisely for all measured latency. From the analysis and measurements, we estimate how much faster RPC could be if certain improvements were made. The elapsed time for an intermachine call to a remote procedure that accepts no arguments and produces no results is 2.66 ms. The elapsed time for an RPC that has a single 1440-byte result (the maximum result that will fit in a single packet) is 6.35 ms. Maximum intermachine throughput of application program data using RPC is 4.65 Mbits/s, achieved with four threads making parallel RPCs that return the maximum-size result that fits in a single RPC result packet. CPU utilization at maximum throughput is about 1.2 CPU seconds per second on the calling machine and a little less on the server. These measurements are for RPCs from user space on one machine to user space on another, using the installed system and a 10 Mbit/s Ethernet. The RPC packet exchange protocol is built on IP/UDP, and the times include calculating and verifying UDP checksums. The Fireflies used in the tests had 5 MicroVAX II processors and a DEQNA Ethernet controller. © 1990, ACM. All rights reserved.",,"Computer Networks; Computer Operating Systems; Data Transmission; Computer System Performance; Distributed Systems; Ethernet; Firefly Multiprocessor; Remote Procedure Call; Computer Systems, Digital"
High-Level Language Debugging for Concurrent Programs,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976720108&doi=10.1145%2f128733.128737&partnerID=40&md5=52e96eec55852e9911164ce35c55f5af,"An integrated system design for debugging distributed programs written in concurrent high-level languages is described. A variety of user-interface, monitoring, and analysis tools integrated around a uniform process model are provided. Because the tools are language-based, the user does not have to deal with low-level implementation details of distribution and concurrency, and instead can focus on the logic of the program in terms of language-level objects and constructs. The tools provide facilities for experimentation with process scheduling, environment simulation, and nondeterministic selections. Presentation and analysis of the program's behavior are supported by history replay, state queries, and assertion checking. Assertions are formulated in linear time temporal logic, which is a logic particularly well suited to specify the behavior of distributed programs. The tools are separated into two sets. The language-specific tools are those that directly interact with programs for monitoring of and on-line experimenting with distributed programs. The language-independent tools are those that support off-line presentation and analysis of the monitored information. This separation makes the system applicable to a wide range of programming languages. In addition, the separation of interactive experimentation from off-line analysis provides for efficient exploitation of both user time and machine resources. The implementation of a debugging facility for OCCAM is described. © 1990, ACM. All rights reserved.",distributed debugging; language independence; portability; temporal logic,
The Effects of Processor Architecture on Instruction Memory Traffic,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025477439&doi=10.1145%2f99926.99933&partnerID=40&md5=7e7b23dcb9c62bdf9438706f6c40930b,"The relative amount of instruction traffic for two architectures is about the same in the presence of a large cache as with no cache. Furthermore, the presence of an intermediate-sized cache probably substantially favors the denser architecture. Encoding techniques have a much greater impact on instruction traffic than do the differences between instruction set families such as stack and register set. However, register set architectures have somewhat lower instruction traffic than directly comparable stack architectures of some local variables are allocated in registers. This study has clearly indicated that cache factors should be taken into consideration when making architectural tradeoffs. The differences in memory traffic between two architectures may be greatly amplified in the presence of a cache. © 1990, ACM. All rights reserved.",,Data Storage Units; Cache Memories; Instruction Memory Traffic; Computer Architecture
A Binary Feedback Scheme for Congestion Avoidance in Computer Networks,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025433940&doi=10.1145%2f78952.78955&partnerID=40&md5=8d6adccba9baebb75899979fa3e2362d,"We propose a scheme for congestion avoidance in networks using a connectionless protocol at the network layer. The scheme uses a minimal amount of feedback from the network to the users, who adjust the amount of traffic allowed into the network. The routers in the network detect congestion and set a congestion-indication bit on packets flowing in the forward direction. The congestion indication is communicated back to the users through the transport-level acknowledgment. The scheme is distributed, adapts to the dynamic state of the network, converges to the optimal operating point, is quite simple to implement, and has low overhead. The scheme maintains fairness in service provided to multiple sources. This paper presents the scheme and the analysis that went into the choice of the various decision mechanisms. We also address the performance of the scheme under transient changes in the network and pathological overload conditions. © 1990, ACM. All rights reserved.",,Data Transmission - Packet Switching; Binary Feedback; Congestion Avoidance; Fairness; Computer Networks
"A Formal Protection Model of Security in Centralized, Parallel, and Distributed Systems",1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025477726&doi=10.1145%2f99926.99928&partnerID=40&md5=dd8007bc30d55515833ba23692f933fd,"One way to show that a system is not secure is to demonstrate that a malicious or mistake-prone user or program can break security by causing the system to reach a nonsecure state. A fundamental aspect of a security model is a proof that validates that every state reachable from a secure initial state is secure. A sequential security model assumes that every command that acts as a state transition executes sequentially, while a concurrent security model assumes that multiple commands execute concurrently. This paper presents a security model called the Centralized-Parallel-Distributed model 1990 that defines security for logically, or physically centralized, parallel, and distributed systems. The purpose of the CPD model is to define concurrency conditions that guarentee that a concurrent system cannot reach a state in which privileges are configured in a nonsecure manner. As an example, the conditions are used to construct a representation of a distributed system. © 1990, ACM. All rights reserved.",access control; concurrency control; distributed system security; operating system security; protection model,"Computer Crime; Computers, Digital - Protection; Computer Security; Distributed Computing; Parallel Processing; Computer Systems, Digital"
Multicast Routing in Datagram Internetworks and Extended LANs,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025430666&doi=10.1145%2f78952.78953&partnerID=40&md5=2ca6ec25b628dbc0a8965c91bf7a597a,"Multicasting, the transmission of a packet to a group of hosts, is an important service for improving the efficiency and robustness of distributed systems and applications. Although multicast capability is available and widely used in local area networks, when those LANs are interconnected by store-and-forward routers, the multicast service is usually not offered across the resulting internetwork. To address this limitation, we specify extensions to two common internetwork routing algorithms—distance-vector routing and link-state routing—to support low-delay datagram multicasting beyond a single LAN. We also describe modifications to the single-spanning-tree routing algorithm commonly used by link-layer bridges, to reduce the costs of multicasting in large extended LANs. Finally, we discuss how the use of multicast scope control and hierarchical multicast routing allows the multicast service to scale up to large internetworks. © 1990, ACM. All rights reserved.",,Computer Programming - Algorithms; Data Transmission - Packet Switching; Datagram Internetworks; Internetworking; Multicast Routing; Routing Algorithms; Computer Networks
A logic of Authentication,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025386404&doi=10.1145%2f77648.77649&partnerID=40&md5=c31c79a1b64f95d786181dc068541185,"Authentication protocols are the basis of security in many distributed systems, and it is therefore essential to ensure that these protocols function correctly. Unfortunately, their design has been extremely error prone. Most of the protocols found in the literature contain redundancies or security flaws. A simple logic has allowed us to describe the beliefs of trustworthy parties involved in authentication protocols and the evolution of these beliefs as a consequence of communication. We have been able to explain a variety of authentication protocols formally, to discover subtleties and errors in them, and to suggest improvements. In this paper we present the logic and then give the results of our analysis of four published protocols, chosen either because of their practical importance or because they serve to illustrate our method. © 1990, ACM. All rights reserved.",,"Computer Metatheory - Formal Logic; Computer Systems, Digital - Distributed; Authentication Protocols; Cryptographic Protocols; Key Distribution Protocols; Logic of Authentication; Cryptography"
Disk Arm Movement in Anticipation of Future Requests,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025478119&doi=10.1145%2f99926.99930&partnerID=40&md5=c2f530200725787dcf3568a0ad48a4d5,"When a disk drive's access arm is idle, it may not be at the ideal location. In anticipation of future requests, movement to some other location may be advantageous. The effectiveness of anticipatory disk arm movement is explored. Various operating conditions are considered, and the reduction in seek distances and request response times is determined for them. Suppose that successive requests are independent and uniformly distributed. By bringing the arm to the middle of its range of motion when it is idle, the expected seek distance can be reduced by 25 percent. Nonlinearity in time versus distance can whittle that 25 percent reduction down to a 13 percent reduction in seek time. Nonuniformity in request location, nonPoisson arrival processes, and high arrival rates can whittle the reduction down to nothing. However, techniques are discussed that maximize those savings that are still possible under those circumstances. Various systems with multiple arms are analyzed. Usually, it is best to spread out the arms over the disk area. The both arms should be brought to the middle. © 1990, ACM. All rights reserved.",,Computer Operating Systems - Performance; Disk Arm Movement; Memory Management; Data Storage Units
Concurrent Reading and Writing of Clocks,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976801533&doi=10.1145%2f128733.128736&partnerID=40&md5=5a4293d6b112ad5364d9786b22e86c10,"As an exercise in synchronization without mutual exclusion, algorithms are developed to implement both a monotonic and a cyclic multiple-word clock that is updated by one process and read by one or more other processes. © 1990, ACM. All rights reserved.",concurrent programming; nonatomic operations; synchronization,
“Topologies”—Distributed Objects on Multicomputers,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025430049&doi=10.1145%2f78952.78954&partnerID=40&md5=a35cf5a443e43e663e39123223122e29,"Application programs written for large-scale multicomputers with interconnection structures known to the programmer 1990 use complex communication structures for connecting the applications' parallel tasks. Such structures implement a wide variety of functions, including the exchange of data or control information relevant to the task computations and/or the communications required for task synchronization, message forwarding/filtering under program control, and so on. Topology is a programming and operating system construct that allows programmers to describe and efficiently implement such functionality as distributed objects with well-defined operational interfaces. As with abstract data types, topologies may be reused by any application desiring their functionality. However, in contrast to other research in parallel or distributed object-based operating systems, internally, a topology may be an entirely distributed implementation of the object's functionality, consisting of a communication graph and type-specific computations, which are triggered by messages traversing the graph. Sample computations may perform additions or minimizations of the values traversing a topology, thereby computing a global sum or minimum. Similarly, computations may concatenate or filter messages in order to implement program monitoring, I/O, file storage, or virtual terminal services. Topologies are implemented as an extension of the Intel iPSC hypercube's operating system kernel and have been used with several, large-scale parallel application programs. © 1990, ACM. All rights reserved.",,Computer Operating Systems; Distributed Objects; Multicomputers; Object Based Operating Systems; Computer Systems Programming
A System for Computer Music Performance,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025383553&doi=10.1145%2f77648.77652&partnerID=40&md5=840a934e2907730be5ccf606a95a93f5,"A computer music performance system 1990 is a computer system connected to input devices (including musical keyboards or other instruments) and to graphic and audio output devices. A human performer generates input events using the input devices. The CMPS responds to these events by computing and performing sequences of output actions whose intended timing is determined algorithmically. Because of the need for accurate timing of output actions, the scheduling requirements of a CMPS differ from those of general-purpose or conventional real-time systems. This paper describes the scheduling facilities of FORMULA, a CMPS used by many musicians. In addition to providing accurate timing of output action sequences, FORMULA provides other basic functions useful in musical applications: (1) per-process virtual time systems with independent relationships to real time; (2) process grouping mechanisms and language-level control structures with time-related semantics, and (3) integrated scheduling of tasks (such as compiling and editing) whose real-time constraints are less stringent than those of output action computations. © 1990, ACM. All rights reserved.",Action buffering; deadline scheduling; Design; Human Factors; Languages; message-passing; Performance; process groups; virtual time systems,"Musical Instruments, Electronic - Computer Applications; Computer Music Performance System; FORMULA (Forth Music Language); Musical Instruments"
Deriving Protocol Specifications from Service Specifications Including Parameters,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976760780&doi=10.1145%2f128733.128734&partnerID=40&md5=ad9b79b253f319f63f6cbcbeb920747e,"The service specification concept has acquired an increasing level of recognition by protocol designers. This architectural concept influences the methodology applied to service and protocol definition. Since the protocol is seen as the logical implementation of the service, one can ask whether it is possible to formally derive the specification of a protocol providing a given service. This paper addresses this question and presents an algorithm for deriving a protocol specification from a given service specification. It is assumed that services are described by expressions, where names identifying both service primitives and previously defined services are composed using operators for sequence, parallelism and alternative. Services and service primitives may have input and output parameters. Composition of services from predefined services and service primitives is also permitted. The expression defining the service is the basis for the protocol derivation process. The algorithm presented fully automates the derivation process. Future work will focus on the optimization of traffic between protocol entities and on applications. © 1990, ACM. All rights reserved.",automated protocol design; communication service specification; protocol derivation,
Lightweight Remote Procedure Call,1990,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025385206&doi=10.1145%2f77648.77650&partnerID=40&md5=a3dcd004844588229d2e07bac1988a27,"Lightweight Remote Procedure Call 1990 is a communication facility designed and optimized for communication between protection domains on the same machine. In contemporary small-kernel operating systems, existing RPC systems incur an unnecessarily high cost when used for the type of communication that predominates—between protection domains on the same machine. This cost leads system designers to coalesce weakly related subsystems into the same protection domain, trading safety for performance. By reducing the overhead of same-machine communication, LRPC encourages both safety and performance. LRPC combines the control transfer and communication model of capability systems with the programming semantics and large-grained protection model of RPC. LRPC achieves a factor-of-three performance improvement over more traditional approaches based on independent threads exchanging messages, reducing the cost of same-machine communication to nearly the lower bound imposed by conventional hardware. LRPC has been integrated into the Taos operating system of the DEC SRC Firefly multiprocessor workstation. © 1990, ACM. All rights reserved.",,"Computer Systems, Digital - Distributed; Data Transmission; Firefly Multiprocessor; Remote Procedure Call; Computer Operating Systems"
Using Histories to Implement Atomic Objects,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024765204&doi=10.1145%2f75104.75106&partnerID=40&md5=d7ac1158ed72f7fc877d2855c2d65ed4,"In this paper we describe an approach to implementing atomicity. Atomicity requires that computations appear to be all-or-nothing and executed in a serialization order. The approach we describe has three characteristics. First, it utilizes the semantics of an application to improve concurrency. Second, it reduces the complexity of application-dependent synchronization code by analyzing the process of writing it. Third, our approach hides the protocol used to arrive at a serialization order from the applications. As a result, different protocols can be used without affecting the applications. Our approach uses a history abstraction. The history captures the ordering relationship among concurrent computations. By determining what types of computations exist in the history and their parameters, a computation can determine whether it can proceed. © 1989, ACM. All rights reserved.",Atomic objects; long transactions; semantics; synchronization,Atomic Objects; Concurrency Control; Semantics; Serialization; Synchronization; Database Systems
High-speed implementations of rule-based systems,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024657427&doi=10.1145%2f63404.63405&partnerID=40&md5=1fa9446bad9dc54b2d876e6f614ed700,"Rule-based systems are widely used in artificial intelligence for modeling intelligent behavior and building expert systems. Most rule-based programs, however, are extremely computation intensive and run quite slowly. The slow speed of execution has prohibited the use of rule-based systems in domains requiring high performance and real-time response. In this paper we explore various methods for speeding up the execution of rule-based systems. In particular, we examine the role of parallelism in the high-speed execution of rule-based systems and study the architectural issues in the design of computers for rule-based systems. Our results show that contrary to initial expectations, the speed-up that can be obtained from parallelism is quite limited, only about tenfold. The reasons for the small speed-up are: (1) the small number of rules relevant to each change to data memory; (2) the large variation in the processing requirements of relevant rules; and (3) the small number of changes made to data memory between synchronization steps. Furthermore, we observe that to obtain this limited factor of tenfold speed-up, it is necessary to exploit parallelism at a very fine granularity. We propose that a suitable architecture to exploit such fine-grain parallelism is a shared-memory multiprocessor with 32-64 processors. Using such a multiprocessor, it is possible to obtain execution speeds of about 3800 rule-firings/set. This speed is significantly higher than that obtained by other proposed parallel implementations of rule-based systems. © 1989, ACM. All rights reserved.",OPS5; parallel implementation; production systems; Rete algorithm; rule-based systems; shared-memory multiprocessors,"Artificial Intelligence; Computer Systems, Digital--Parallel Processing; Production Systems; Rule Based Systems; Shared Memory Multiprocessors; Speedup; Computer Architecture"
Decentralizing a global naming service for improved performance and fault tolerance,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024657353&doi=10.1145%2f63404.63406&partnerID=40&md5=022534ceb1bce183580ac6a9199b7cd7,"Naming is an important aspect of distributed system design. A naming system allows users and programs to assign character-string names to objects, and subsequently use the names to refer to those objects. With the interconnection of clusters of computers by wide-area networks and internetworks, the domain over which naming systems must function is growing to encompass the entire world. In this paper we address the problem of a global naming system, proposing a three-level naming architecture that consists of global, administrational, and managerial naming mechanisms, each optimized to meet the performance, reliability, and security requirements at its own level. We focus in particular on a decentralized approach to the lower levels, in which naming is handled directly by the managers of the named objects. Client-name caching and multicast are exploited to implement name mapping with almost optimum performance and fault tolerance. We also show how the naming system can be made secure. Our conclusions are bolstered by experience with an implementation in the V distributed operating system. © 1989, ACM. All rights reserved.",Cache; distributed system; fault tolerance; multicast; naming,"Computer Operating Systems; Computer Fault Tolerance; Distributed File Systems; Global Naming Service; Computer Systems, Digital"
Integrating Security in a Large Distributed System,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024714097&doi=10.1145%2f65000.65002&partnerID=40&md5=4eee9fcdedc2ce5a4002c06ca66aec6c,"Andrew is a distributed computing environment that is a synthesis of the personal computing and timesharing paradigms. When mature, it is expected to encompass over 5,000 workstations spanning the Carnegie Mellon University campus. This paper examines the security issues that arise in such an environment and describes the mechanisms that have been developed to address them. These mechanisms include the logical and physical separation of servers and clients, support for secure communication at the remote procedure call level, a distributed authentication service, a file-protection scheme that combines access lists with UNIX mode bits, and the use of encryption as a basic building block. The paper also discusses the assumptions underlying security in Andrew and analyzes the vulnerability of the system. Usage experience reveals that resource control, particularly of workstation CPU cycles, is more important than originally anticipated and that the mechanisms available to address this issue are rudimentary. © 1989, ACM. All rights reserved.",Access lists; AFS; Andrew; Needham-Schroeder; negative rights; orange book; protection domain; RPC; scalability; trust; UNIX,"Computers, Personal; Cryptography; Andrew Distributed Computing Environment; Computer Security; Time Sharing; Computer Systems, Digital"
An analytical cache model,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024656760&doi=10.1145%2f63404.63407&partnerID=40&md5=0adab4568c50ba46ae36deb906f4fa4e,"Trace-driven simulation and hardware measurement are the techniques most often used to obtain accurate performance figures for caches. The former requires a large amount of simulation time to evaluate each cache configuration while the latter is restricted to measurements of existing caches. An analytical cache model that uses parameters extracted from address traces of programs can efficiently provide estimates of cache performance and show the effects of varying cache parameters. By representing the factors that affect cache performance, we develop an analytical model that gives miss rates for a given trace as a function of cache size, degree of associativity, block size, subblock size, multiprogramming level, task switch interval, and observation interval. The predicted values closely approximate the results of trace-driven simulations, while requiring only a small fraction of the computation cost. © 1989, ACM. All rights reserved.",Cache miss rate; cache model; cache performance; program behavior; spatial locality; temporal locality; trace-driven simulation; working set,Data Storage Units; Cache Miss Rate; Cache Models; Memory Structures; Trace Driven Simulation; Computer Architecture
Memory Coherence in Shared Virtual Memory Systems,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024771302&doi=10.1145%2f75104.75105&partnerID=40&md5=567caa94c897e41e4e6d0a1fa32f0c11,"The memory coherence problem in designing and implementing a shared virtual memory on loosely coupled multiprocessors is studied in depth. Two classes of algorithms, centralized and distributed, for solving the problem are presented. A prototype shared virtual memory on an Apollo ring based on these algorithms has been implemented. Both theoretical and practical results show that the memory coherence problem can indeed be solved efficiently on a loosely coupled multiprocessor. © 1989, ACM. All rights reserved.",Loosely coupled multiprocessors; memory coherence; parallel programming; shared virtual memory,"Computer Programming--Algorithms; Loosely Coupled Multiprocessors; Memory Coherence; Shared Virtual Memory; Computer Systems, Digital"
Preserving and Using Context information In Interprocess Communication,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024716226&doi=10.1145%2f65000.65001&partnerID=40&md5=292415e8c0021bcadd925651eba78046,"When processes in a network communicate, the messages they exchange define a partial ordering of externally visible events. While the significance of this partial order in distributed computing is well understood, it has not been made an explicit part of the communication substrate upon which distributed programs are implemented. This paper describes a new interprocess communication mechanism, called Psync, that explicitly encodes this partial ordering with each message. The paper shows how Psync can be efficiently implemented on an unreliable communications network, and it demonstrates how conversations serve as an elegant foundation for ordering messages exchanged in a distributed computation and for recovering from processor failures. © 1989, ACM. All rights reserved.",Context graph; happened before,"Computer Programming--Algorithms; Database Systems--Distributed; Computer Fault Tolerance; Context Information; Interprocess Communication; Partial Ordering; Psync Protocol; Computer Systems, Digital"
Verified Data Transfer Protocols with Variable Flow Control,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024714732&doi=10.1145%2f65000.65003&partnerID=40&md5=fbd95d35f5a6c399da09149057b4162a,"We present and verify a sliding window protocol which uses modulo-N sequence numbers to achieve reliable flow-controlled data transfer between a producer and a consumer connected by unreliable channels. The consumer's data needs are represented by a receive window whose size can vary with time. The producer entity sends segments of data words that lie within the consumer's receive window. The consumer entity sends acknowledgment, selective acknowledgment, and selective reject messages that inform the producer entity of the current receive window size, the data word next expected, and the reception (or lack of reception) of out-of-sequence data segments. Our protocol is, therefore, a proper extension of existing transport and data link protocol standards such as TCP, IS0 TP, HDLC, ADCCP, and so forth. We consider two types of unreliable channels. The first type, referred to as transport channels, can lose, duplicate, and reorder messages to an arbitrary extent, but impose an upper bound on message lifetimes (which can be very large, e.g., days). The second type, referred to as data link channels, can only lose messages. For both types of channels, we obtain the minimum value of N that ensures safe operation without imposing any constraints on the retransmissions of messages or on the data segment sizes. Thus, any retransmission or acknowledgment policy that optimizes the protocol's performance can be used. For transport channels, this value of N is a function of the maximum message transmission rate, the maximum message lifetime, and the maximum receive window size. For data link channels, this value of N is a function only of the maximum receive window size. We verify progress under three different liveness assumptions: retransmissions initiated by both entities, only by the producer entity, and only by the consumer entity. The protocol also satisfies a convenient noninterference safety property between the acknowledgement, selective acknowledgment, and selective reject messages. The protocols are specified as event-driven systems and verified hierarchically in two major stages. First, we verify that correct flow-controlled data transfer results if the sequence numbers in the channels satisfy certain correct interpretation bounds, irrespective of the types of errors that the channels may have. Second, for both transport and data link channels, we verify that the correct interpretation bounds are enforced by the corresponding minimum values of N. For the verification of the transport channel case, we use a system model with continuous measures of time in which real-time constraints can be formally specified and verified. © 1989, ACM. All rights reserved.",,Computer Networks--Protocols; Data Transfer Protocols; Sliding Window Protocol; Variable Flow Control; Data Transmission
Increasing Availability Under Mutual Exclusion Constraints with Dynamic Vote Reassignment,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024764862&doi=10.1145%2f75104.75107&partnerID=40&md5=84104a295203526529e2cd3242252a73,"Voting is used commonly to enforce mutual exclusion in distributed systems. Each node is assigned a number of votes, and only the group with a majority of votes is allowed to perform a restricted operation. This paper describes techniques for dynamically reassigning votes upon node or link failure, in an attempt to make the system more resilient to future failures. We focus on autonomous methods for achieving this, that is, methods that allow the nodes to make independent choices about changing their votes and picking new vote values, rather than group consensus techniques that require tight coordination among the remaining nodes. Protocols are given which allow nodes to install new vote values while still maintaining mutual exclusion requirements. The lemmas and theorems to validate the protocols are presented. A simple example shows how to apply the method to a database object-locking scheme; the protocols, however, are versatile and general purpose, and can be used for any application requiring mutual exclusion. In addition, policies are presented that allow nodes to autonomously select their new vote values. Simulation results are presented comparing the autonomous methods to static vote assignments and to group consensus strategies. These results demonstrate that under high failure rates, dynamic vote reassignment shows great improvement over a static assignment of votes in terms of availability. In addition, many autonomous methods for determining a new vote assignment yield almost as much availability as a group consensus method and at the same time are faster and more flexible. © 1989, ACM. All rights reserved.",Availability; network partitions; voting,"Database Systems--Distributed; Availability; Dynamic Vote Reassignment; Mutual Exclusion; Network Partitions; Computer Systems, Digital"
Remote Pipes and Procedures for Efficient Distributed Communication,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024063855&doi=10.1145%2f45059.45061&partnerID=40&md5=c563e52d340938091802212b316e0955,"We describe a new communication model for distributed systems that combines the advantages of remote procedure call with the efficient transfer of bulk data. Three ideas form the basis of this model. First, remote procedures are first-class values which can be freely exchanged among nodes, thus enabling a greater variety of protocols to be directly implemented in a remote procedure call framework. Second, a new type of abstract object, called a pipe, allows bulk data and incremental results to be efficiently transported in a type-safe manner. Unlike procedure calls, pipe calls do not return values and do not block a caller. Data sent down a pipe is received by the pipe's sink node in the order sent. Third, the relative sequencing of pipes and procedures can be controlled by combining them into channel groups. Calls on the members of a channel group are guaranteed to be processed in order. Application experience with this model, which we call the Channel Model, is reported. Derived performance bounds and experimental measures demonstrate k pipe calls can perform min( 1 + (r/p), k) times faster than k procedure calls, where r is the total roundtrip remote communication time and p is the procedure execution time. © 1988, ACM. All rights reserved.",Bulk data transfer; channel; channel group; channel model; remote procedure call; sequence stamp; sequence vector; timing invariant,"DATA TRANSMISSION; BULK DATA TRANSFER; CHANNEL MODEL; PERFORMANCE BOUNDS; REMOTE PROCEDURE CALL; COMPUTER SYSTEMS, DIGITAL"
Reliable scheduling in a TMR database system,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024606853&doi=10.1145%2f58564.59294&partnerID=40&md5=9ece3b6c0c69e49ddaefb5f09ab33d6f,"A Triple Modular Redundant (TMR) system achieves high reliability by replicating data and all processing at three independent nodes. When TMR is used for database processing all nonfaulty computers must execute the same sequence of transactions, and this is ensured by a collection of processes known as schedulers. In this paper we study the implementation of efficient schedulers through analysis of various enhancements such as null transactions and message batching. The schedulers have been implemented in an experimental TMR system and the evaluation results are presented here. © 1989, ACM. All rights reserved.",Byzantine agreement; state machine approach; transaction scheduling; triple modular redundancy,Reliability; Scheduling; Message Batching; Null Transactions; Reliable Scheduling; Transaction Processing; Triple Modular Redundancy; Database Systems
Fault Tolerance Under UNIX,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024606852&doi=10.1145%2f58564.58565&partnerID=40&md5=d94319573cba4b00604c76d4f8de2c6f,"The initial design for a distributed, fault-tolerant version of UNIX based on three-way atomic message transmission was presented in an earlier paper [3]. The implementation effort then moved from Auragen Systems1 to Nixdorf Computer where it was completed. This paper describes the working system, now known as the TARGON/32. The original design left open questions in at least two areas: fault tolerance for server processes and recovery after a crash were briefly and inaccurately sketched, rebackup after recovery was not discussed at all. The fundamental design involving three-way message transmission has remained unchanged. However, in addition to important changes in the implementation, server backup has been redesigned and is now more consistent with that of normal user processes. Recovery and rebackup have been completed in a less centralized and thus more efficient manner than previously envisioned. In this paper we review important aspects of the original design and note how the implementation differs from our original ideas. We then focus on the backup and recovery for server processes and the changes and additions in the design and implementation of recovery and rebackup. © 1989, ACM. All rights reserved.",Atomic multiway message transmission; crash handling; file system availability; roll forward recovery; server architecture,"Computer Architecture; Computer Operating Systems; Crash Handling; Multiway Message Transmission; Roll Forward Recovery; Server Architecture; TARGON/32; UNIX; Computer Systems, Digital"
Stating Security Requirements with Tolerable Sets,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024063861&doi=10.1145%2f45059.214409&partnerID=40&md5=8a3088478ca240a86d4e40dcffb3c6d6,"This paper introduces and develops the concept of tolerable sets for analyzing general security requirements. Tolerable sets, and corresponding purging functions and invisibility based on the sets, are used to state and test such requirements. The approach used in this paper resulted from our attempt to apply the noninterference ideas of Goguen and Meseguer to the problem of stating special security requirements in the case of so-called trusted subjects. It turns out that the conditional purging function defined by Goguen and Meseguer is only one example, though an important one, of a conditional purging function. This paper provides a definition and characterization of a general class of purging functions similar to the purging function of Goguen and Meseguer. Furthermore, it relates purging and invisibility to security requirements. Some particular applications are described toward the end of the paper. At the end there are some critical remarks about purging functions. © 1988, ACM. All rights reserved.",Noninterference; security models and requirements; state machine,"COMPUTER SYSTEMS, DIGITAL; COMPUTER SECURITY REQUIREMENTS; PURGING FUNCTIONS; TOLERABLE SETS; DATA PROCESSING"
Efficient (stack) algorithms for analysis of write-back and sector memories,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024607881&doi=10.1145%2f58564.59296&partnerID=40&md5=88ecdc47841a8c5e07c5682fbc08a192,"For the class of replacement algorithms known as stack algorithms, existing analysis techniques permit the computation of memory miss ratios for all memory sizes simultaneously in one pass over a memory reference string. We extend the class of computations possible by this methodology in two ways. First, we show how to compute the effects of copy-backs in write-back caches. The key observation here is that a given block is clean for all memory sizes less than or equal to C blocks and is dirty for all larger memory sizes. Our technique permits efficient computations for algorithms or systems using periodic write-back and/or block deletion. The second extension permits stack analysis simulation for sector (or subblock) caches in which a sector (associated with an address tag) consists of subsectors (or subblocks) that can be loaded independently. The key observation here is that a subsector is present only in caches of size C or greater. Load forward prefetching in a sector cache is shown to be a stack algorithm and is easily simulated using our technique. Running times for our methods are only slightly higher than for a simulation of a single memory size using nonstack techniques. © 1989, ACM. All rights reserved.",Cache; copyback; disk cache; memory hierarchy analysis; sector cache; simulation; stack analysis,"Computer Programming--Algorithms; Cache Memories; Memory System Performance; Replacement Algorithms; Sector Memories; Stack Algorithms; Write Back Memories; Data Storage, Digital"
Cache Performance of Operating System and Multiprogramming Workloads,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024104573&doi=10.1145%2f48012.48037&partnerID=40&md5=e0d539be02c8203b8ba8067e1d0cf327,"Large caches are necessary in current high-performance computer systems to provide the required high memory bandwidth. Because a small decrease in cache performance can result in significant system performance degradation, accurately characterizing the performance of large caches is important. Although measurements on actual systems have shown that operating systems and multiprogramming can affect cache performance, previous studies have not focused on these effects. We have developed a program tracing technique called ATUM (Address Tracing Using Microcode) that captures realistic traces of multitasking workloads including the operating system. Examining cache behavior using these traces from a VAX processor shows that both the operating system and multiprogramming activity significantly degrade cache performance, with an even greater proportional impact on large caches. From a careful analysis of the causes of this degradation, we explore various techniques to reduce this loss. While seemingly little can be done to mitigate the effect of system references, multitasking cache miss activity can be substantially reduced with small hardware additions. © 1988, ACM. All rights reserved.",Cache miss rate; cache performance; cold start; trace-driven simulation; virtual caches,Computer Systems Programming - Multiprogramming; Address Tracing Using Microcode; ATUM; Cache Performance; Multiprogramming Workloads; Program Tracing; Computer Operating Systems
Performance Effects of Architectural Complexity in the Intel 432,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024067295&doi=10.1145%2f45059.214411&partnerID=40&md5=14ba893489755524672892a81ce737e9,"The Intel 432 is noteworthy as an architecture incorporating a large amount of functionality that most other systems perform by software. It has, in effect, “migrated” this functionality from the software into the microcode and hardware. The benefits of functional migration have recently been a subject of intense controversy, with critics claiming that a complex architecture is inherently less efficient than a simple architecture with good software support. This paper examines the performance impact of the incorporation of several kinds of functionality into the Intel 432. Among these are the addressing structure, the caches, instruction alignment, the buses, and the way that garbage collection is handled. A set of several benchmarks is used to quantify the performance effect of each of these decisions. The results indicate that the 432 could have been speeded up very significantly if a small number of implementation decisions had been made differently, and if incrementally better technology had been used in its construction. Even with these modifications, however, the 432 would still have only one-fourth to one times the speed of its contemporaries. These figures may represent the real cost of the 432's style of object-based programming environment. © 1988, ACM. All rights reserved.",Ada; address translation; caches; capabilities; CISC; Intel 432; object-based; object-oriented; procedure calls,"COMPUTER PROGRAMMING; COMPUTER SYSTEMS, DIGITAL - Parallel Processing; ARCHITECTURAL COMPLEXITY; INTEL 432; OBJECT-BASED PROGRAMMING ENVIRONMENT; COMPUTER PROGRAMMING"
A Digital Multisignature Scheme Using Bijective Public-Key Cryptosystems,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024104968&doi=10.1145%2f48012.48246&partnerID=40&md5=cf3da940325f058e93343531963c059a,"A new digital multisignature scheme using bijective public-key cryptosystems that overcomes the problems of previous signature schemes used for multisignatures is proposed. The principal features of this scheme are (1) the length of a multisignature message is nearly equivalent to that for a singlesignature message; (2) by using a one-way hash function, multisignature generation and verification are processed in an efficient manner; (3) the order of signing is not restricted; and (4) this scheme can be constructed on any bijective public-key cryptosystem as well as the RSA scheme. In addition, it is shown that the new scheme is considered as safe as the public-key cryptosystem used in this new scheme. Some variations based on the scheme are also presented. © 1988, ACM. All rights reserved.",RS scheme; signature schemes,Electronic Mail; Bijective Public-Key Cryptosystems; Computer-Based Message Systems; Digital Multisignature Scheme; One-Way Hash Function; Cryptography
A Relational Approach to Monitoring Complex Systems,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024011135&doi=10.1145%2f42186.42323&partnerID=40&md5=de815115337bcb0c0287cedf078d95c2,"Monitoring is an essential part of many program development tools, and plays a central role in debugging, optimization, status reporting, and reconfiguration. Traditional monitoring techniques are inadequate when monitoring complex systems such as multiprocessors or distributed systems. A new approach is described in which a historical database forms the conceptual basis for the information processed by the monitor. This approach permits advances in specifying the low-level data collection, specifying the analysis of the collected data, performing the analysis, and displaying the results. Two prototype implementations demonstrate the feasibility of the approach. © 1988, ACM. All rights reserved.",Graphical monitoring; historical database; relational algebra; TQuel,"DATA PROCESSING - Data Reduction and Analysis; DATABASE SYSTEMS - Relational; DISTRIBUTED SYSTEMS; LOW-LEVEL DATA COLLECTION; MULTIPROCESSORS; COMPUTER SYSTEMS, DIGITAL"
Experiments in SR with Different Upcall Program Structures,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024107426&doi=10.1145%2f48012.48041&partnerID=40&md5=c5ba5432741217ba21dbddb1e7f16976,"This paper explores program designs for layered systems such as communication protocols and server/client systems that do not exhibit a strict hierarchy in their control flow. Clark has proposed structuring such systems, where both upward and downward control flow are required, to use efficient synchronous procedure calls between the layers whenever possible. The term upcall is used by Clark to describe this synchronous upward communication from server to client. Several techniques are possible for structuring such programs using upcalls. Comparisons are made by implementing a communication protocol described by Clark in three different ways. The first method implements all the protocol routines in a single large module. The second method structures the routines into modules occupying vertical slices of the protocol layers, and the third method structures the routines into modules corresponding to the protocol layers. Comparisons are made on two fronts: Preservation of modularity, in order to determine which method shows fault-tolerance and ease of programming, and program performance, which is a key motivation for the upcalls programming style. We conclude that the vertically layered protocol design is to be preferred unless there are many shared variables between the send-side and receive-side, as it is very efficient and provides the best protection of clients from each other. The horizontally layered design is the least efficient, but it is the easiest to program. © 1988, ACM. All rights reserved.",Circular dependencies between routines; communications protocols; concurrent program performance; concurrent program structure; upcalls,Computer Networks - Protocols; Computer Programming - Algorithms; Layered Systems; Server/Client Systems; Upcall Program Structures; Computer Software
Measurement and Evaluation of the MIPS Architecture and Processor,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024063780&doi=10.1145%2f45059.45060&partnerID=40&md5=c1570e145c1c0fe056c2455fda29fd4c,"MIPS is a 32-bit processor architecture that has been implemented as an nMOS VLSI chip. The instruction set architecture is RISC-based. Close coupling with compilers and efficient use of the instruction set by compiled programs were goals of the architecture. The MIPS architecture requires that the software implement some constraints in the design that are normally considered part of the hardware implementation. This paper presents experimental results on the effectiveness of this processor as a program host. Using sets of large and small benchmarks, the instruction and operand usage patterns are examined both for optimized and unoptimized code. Several of the architectural and organizational innovations in MIPS, including software pipeline scheduling, multiple-operation instructions, and word-based addressing, are examined in light of this data. © 1988, ACM. All rights reserved.",Instruction set measurement; RISC architecture,"COMPUTER ARCHITECTURE - Performance; 32-BIT MICROPROCESSOR; BENCHMARKS; MIPS; COMPUTERS, MICROCOMPUTER"
A Tree-Based Algorithm for Distributed Mutual Exclusion,1989,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024607971&doi=10.1145%2f58564.59295&partnerID=40&md5=d7c90dc6ed6907eb2b4d0743930eee6b,"We present an algorithm for distributed mutual exclusion in a computer network of N nodes that communicate by messages rather than shared memory. The algorithm uses a spanning tree of the computer network, and the number of messages exchanged per critical section depends on the topology of this tree. However, typically the number of messages exchanged is O(log N) under light demand, and reduces to approximately four messages under saturated demand. Each node holds information only about its immediate neighbors in the spanning tree rather than information about all nodes, and failed nodes can recover necessary information from their neighbors. The algorithm does not require sequence numbers as it operates correctly despite message overtaking. © 1989, ACM. All rights reserved.",Critical section; decentralized systems,"Computer Networks; Computer Programming--Algorithms; Mathematical Techniques--Trees; Distributed Mutual Exclusion; Message Passing; Tree Based Algorithms; Computer Systems, Digital"
The NTree: A Two Dimension Partial Order for Protection Groups,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024013967&doi=10.1145%2f42186.42187&partnerID=40&md5=07fa55f35853676d2d61ffb4054a63e2,"The benefits of providing access control with groups of users rather than with individuals as the unit of granularity are well known. These benefits are enhanced if the groups are organized in a subgroup partial order. A class of such partial orders, called ntrees, is defined by using a forest of rooted trees or inverted rooted trees as basic partial orders and combining these by refinement. Refinement explodes an existing group into a partially ordered ntree of new groups while maintaining the same relationship between each new group and the nonexploded groups that the exploded group had. Examples are discussed to show the practical significance of ntrees and the refinement operation. It is shown that ntrees can be represented by assigning a pair of integers called lr-values to each group so that g is a subgroup of h if and only if l[g] ≤ l[h] and r[g] ≤ r[h]. Refinement allows a complex ntree to be developed incrementally in a top-down manner and is useful for the initial definition of an ntree as well as for subsequent modifications. To make the latter use of refinement practical, a method is presented for assigning lr-values to the new groups introduced by refinement so lr-values assigned to nonexploded groups need not be changed. It is also shown how to guarantee that the lr-values of the exploded group will get assigned to one of the new groups. © 1988, ACM. All rights reserved.",Access control lists; authorization; hierarchies; partial orders; protection groups,"DATA PROCESSING - Security of Data; MATHEMATICAL TECHNIQUES - Trees; ACCESS CONTROL; NTREE; PROTECTION GROUPS; TWO-DIMENSIONAL PARTIAL ORDER; COMPUTER SYSTEMS, DIGITAL"
The Profile Naming Service,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024108236&doi=10.1145%2f48012.48013&partnerID=40&md5=30feb251bfc20ea4ca97cf1eafd2914c,"Profile is a descriptive naming service used to identify users and organizations. This paper presents a structural overview of Profile's three major components: a confederation of attribute-based name servers, a name space abstraction that unifies the name servers, and a user interface that integrates the name space with existing naming systems. Each name server is an independent authority that allows clients to describe users and organizations with a multiplicity of attributes; the name space abstraction is a client program that implements a discipline for searching a sequence of name servers; and the interface provides a tool with which users build customized commands. Experience with an implementation in the DARPA/NSF Internet demonstrates that Profile is a feasible and effective mechanism for naming users and organizations in a large internet. © 1988, ACM. All rights reserved.",Attribute-based naming; white-pages service,"Computer Networks; Computer Programming - Algorithms; Database Systems - Distributed; Attribute-Based Name Servers; DARPA-NSF Internet; Name Space Abstraction; Naming Service; Profile; User Interface; Computer Systems, Digital"
A Programmable Interface Language for Heterogeneous Distributed Systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023454793&doi=10.1145%2f29868.29870&partnerID=40&md5=07b5a5b9e00980cf68fc58964216b628,"The 1980s have witnessed the emergence of a new architecture for computing based on networks of personal computer workstations. The performance requirements of such systems of workstations places a strain on traditional approaches to network architecture. The integration of diverse systems into this environment introduces functional compatibility issues that are not present in homogeneous networks. Effective prescriptions for functional compatibility, therefore, must go beyond the communication paradigms used in present distributed systems, such as remote procedure calls. This paper proposes a distributed system architecture in which communication follows a programming paradigm. In this architecture a programming language provides remote service interfaces for the heterogeneous distributed system environment. This language is a flexible and efficient medium for implementing service function protocols. In essence, clients and servers communicate by programming one another. © 1987, ACM. All rights reserved.",Distributed systems; heterogeneous systems; local area networks; remote function evaluation; remote procedure call,"COMPUTER INTERFACES; COMPUTER NETWORKS - Local Networks; COMPUTER SYSTEMS, DIGITAL - Distributed; COMPUTERS, PERSONAL; HETEROGENEOUS DISTRIBUTED SYSTEMS; PERSONAL COMPUTER WORKSTATION NETWORKS; PROGRAMMABLE INTERFACE LANGUAGE; COMPUTER PROGRAMMING LANGUAGES"
Disk File Allocation Based on the Buddy System,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023454267&doi=10.1145%2f29868.29871&partnerID=40&md5=f846bc462fdea48eca108ca00ffe4cc2,"The buddy system is known for its speed and simplicity. However, high internal and external fragmentation have made it unattractive for use in operating system file layout. A variant of the binary buddy system that reduces fragmentation is described. Files are allocated on up to t extents, and inoptimally allocated files are periodically reallocated. The Dartmouth Time-Sharing System (DTSS) uses this method. Several installations of DTSS, representing different classes of workload, are studied to measure the method's performance. Internal fragmentation varies from 2-6 percent, and external fragmentation varies from 0-10 percent for expected request sizes. Less than 0.1 percent of the CPU is spent executing the algorithm. In addition, most files are stored contiguously on disk. The mean number of extents per file is less than 1.5, and the upper bound is t. Compared to the tile layout method used by UNIX, the buddy system results in more efficient access but less efficient utilization of disk space. As disks become larger and less expensive per byte, strategies that achieve efficient I/O throughput at the expense of some storage loss become increasingly attractive. © 1987, ACM. All rights reserved.",Buddy system; DTSS; dynamic memory management; dynamic storage allocation; file system design; file system organization; file system performance; storage fragmentation,DATA PROCESSING - File Organization; BUDDY SYSTEM; DISK FILE ALLOCATION; DYNAMIC MEMORY MANAGEMENT; DYNAMIC STORAGE ALLOCATION; FILE SYSTEM DESIGN; COMPUTER OPERATING SYSTEMS
Recovery Management in QuickSilver,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023963197&doi=10.1145%2f35037.35060&partnerID=40&md5=c472e65854a9928581e12af749990f95,"This paper describes QuickSilver, developed at the IBM Almaden Research Center, which uses atomic transactions as a unified failure recovery mechanism for a client-server structured distributed system. Transactions allow failure atomicity for related activities at a single server or at a number of independent servers. Rather than bundling transaction management into a dedicated language or recoverable object manager, Quicksilver exposes the basic commit protocol and log recovery primitives, allowing clients and servers to tailor their recovery techniques to their specific needs. Servers can implement their own log recovery protocols rather than being required to use a system-defined protocol. These decisions allow servers to make their own choices to balance simplicity, efficiency, and recoverability. © 1988, ACM. All rights reserved.",Commit protocol; distributed systems; recovery; transactions,"COMPUTER SYSTEMS, DIGITAL - Distributed; ATOMIC TRANSACTIONS; FAILURE ATOMICITY; QUICKSILVER; RECOVERY MANAGEMENT; COMPUTER OPERATING SYSTEMS"
Public Protection of Software,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023456849&doi=10.1145%2f29868.29872&partnerID=40&md5=338e7f3b811239f167b814c116882c0f,"One of the overwhelming problems that software producers must contend with is the unauthorized use and distribution of their products. Copyright laws concerning software are rarely enforced, thereby causing major losses to the software companies. Technical means of protecting software from illegal duplication are required, but the available means are imperfect. We present protocols that enable software protection, without causing substantial overhead in distribution and maintenance. The protocols may be implemented by a conventional cryptosystem, such as the DES, or by a public key cryptosystem, such as the RSA. Both implementations are proved to satisfy required security criteria. © 1987, ACM. All rights reserved.",Cryptographic protocols; protected CPU; security protocols; single key cryptosystems; software authorization; software distribution; software piracy,CRYPTOGRAPHY; CRYPTOGRAPHIC PROTOCOLS; PUBLIC KEY CRYPTOSYSTEMS; SECURITY PROTOCOLS; SINGLE KEY CRYPTOSYSTEMS; COMPUTER SOFTWARE
On the Reliability of Consensus-Based Fault-Tolerant Distributed Computing Systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023456388&doi=10.1145%2f29868.31332&partnerID=40&md5=c3158e9f7b7b0c4d0487095aa529029f,"The designer of a fault-tolerant distributed system faces numerous alternatives. Using a stochastic model of processor failure times, we investigate design choices such as replication level, protocol running time, randomized versus deterministic protocols, fault detection, and authentication. We use the probability with which a system produces the correct output as our evaluation criterion. This contrasts with previous fault-tolerance results that guarantee correctness only if the percentage of faulty processors in the system can be bounded. Our results reveal some subtle and counterintuitive interactions between the design parameters and system reliability. © 1987, ACM. All rights reserved.",Byzantine Agreement; deterministic and randomized protocols; distributed consensus; fault detection; interactive consistency; stochastic failures,"RELIABILITY; BYZANTINE AGREEMENT; DETERMINISTIC PROTOCOLS; DISTRIBUTED CONSENSUS; FAULT-TOLERANT DISTRIBUTED SYSTEM; RANDOMIZED PROTOCOLS; COMPUTER SYSTEMS, DIGITAL"
Footprints in the Cache,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023456387&doi=10.1145%2f29868.32979&partnerID=40&md5=8325b6d19b6ad90de05d2b37c26fffd0,"This paper develops an analytical model for cache-reload transients and compares the model to observations based on several address traces. The cache-reload transient is the set of cache misses that occur when a process is reinitiated after being suspended temporarily. For example, an interrupt program that runs periodically experiences a reload transient at each initiation. The reload transient depends on the cache size and on the sizes of the footprints in the cache of the competing programs, where a program footprint is defined to be the set of lines in the cache in active use by the program. The model shows that the size of the transient is related to the normal distribution function. A simulation based on program-address traces shows excellent agreement between the model and the observations. © 1987, ACM. All rights reserved.",Cache miss-ratio; program footprint; trace-driven simulation,COMPUTER OPERATING SYSTEMS - Storage Allocation; DATA STORAGE UNITS; ADDRESS TRACES; CACHE-RELOAD TRANSIENTS; MEMORY STRUCTURES; PROGRAM FOOTPRINT; TRACE-DRIVEN SIMULATION; COMPUTER ARCHITECTURE
Managing stored voice in the Etherphone system,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023965684&doi=10.1145%2f35037.35038&partnerID=40&md5=3d389108f46a3410db8557e86145db56,"The voice manager in the Etherphone system provides facilities for recording, editing, and playing stored voice in a distributed personal-computing environment. It provides the basis for applications such as voice mail, annotation of multimedia documents, and voice editing using standard text-editing techniques. To facilitate sharing, the voice manager stores voice on a special voice file server that is accessible via the local internet. Operations for editing a passage of recorded voice simply build persistent data structures to represent the edited voice. These data structures, implementing an abstraction called voice ropes, are stored in a server database and consist of lists of intervals within voice files. Clients refer to voice ropes solely by reference. Interests, additional persistent data structures maintained by the server, serve two purposes: First, they provide a sort of directory service for managing the voice ropes that have been created. More importantly, they provide a reliable reference-counting mechanism, permitting the garbage collection of voice ropes that are no longer needed. These interests are grouped into classes; for some important classes, obsolete interests can be detected and deleted by a class-specific algorithm that runs periodically. © 1988, ACM. All rights reserved.",Distributed languages; object-oriented languages; object-oriented systems; process mobility,"COMPUTER NETWORKS; COMPUTER OPERATING SYSTEMS; COMPUTER SYSTEMS, DIGITAL - Distributed; DATA PROCESSING - Data Structures; ELECTRONIC MAIL; ETHERPHONE SYSTEM; VOICE EDITING; VOICE FILE SERVER; VOICE MANAGER; DIGITAL COMMUNICATION SYSTEMS"
Caching in the Sprite Network File System,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023964092&doi=10.1145%2f35037.42183&partnerID=40&md5=a39d8de246f04df8a46cb4d31e9f85aa,"The Sprite network operating system uses large main-memory disk block caches to achieve high performance in its file system. It provides non-write-through file caching on both client and server machines. A simple cache consistency mechanism permits files to be shared by multiple clients without danger of stale data. In order to allow the file cache to occupy as much memory as possible, the file system of each machine negotiates with the virtual memory system over physical memory usage and changes the size of the file cache dynamically. Benchmark programs indicate that client caches allow diskless Sprite workstations to perform within O-12 percent of workstations with disks. In addition, client caching reduces server loading by 50 percent and network traffic by 90 percent. © 1988, ACM. All rights reserved.",Cache consistency; distributed file caching,"COMPUTER SYSTEMS, DIGITAL - Distributed; CACHE CONSISTENCY; DISTRIBUTED FILE CACHING; DISTRIBUTED FILE SYSTEMS; SPRITE NETWORK; COMPUTER OPERATING SYSTEMS"
801 Storage: Architecture and Programming,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023961031&doi=10.1145%2f35037.42270&partnerID=40&md5=fd8cb6da26ba6f65a103824ac1a6c132,"Based on novel architecture, the 801 minicomputer project has developed a low-level storage manager that can significantly simplify storage programming in subsystems and applications. The storage manager embodies three ideas: (1) large virtual storage, to contain all temporary data and permanent files for the active programs; (2) the innovation of database storage, which has implicit properties of access serializability and atomic update, similar to those of database transaction systems; and (3) access to all storage, including files, by the usual operations and types of a high-level programming language. The IBM RT PC implements the hardware architecture necessary for these storage facilities in its storage controller (MMU). The storage manager and language elements required, as well as subsystems and applications that use them, have been implemented and studied in a prototype operating system called CPR, that runs on the RT PC. Low cost and good performance are achieved in both hardware and software. The design is intended to be extensible across a wide performance/cost spectrum. © 1988, ACM. All rights reserved.",Atomic commit; locking; protection; relocation; segmentation; transaction,"COMPUTER ARCHITECTURE; COMPUTERS, MINICOMPUTER; 801 MINICOMPUTER PROJECT; CPR OPERATING SYSTEM; IBM RT PC; LOW-LEVEL STORAGE MANAGER; COMPUTER OPERATING SYSTEMS"
Fine-Grained Mobility in the Emerald System,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023960862&doi=10.1145%2f35037.42182&partnerID=40&md5=e9e60b251bdbc2759e2cd2793026754d,"Emerald is an object-based language and system designed for the construction of distributed programs. An explicit goal of Emerald is support for object mobility; objects in Emerald can freely move within the system to take advantage of distribution and dynamically changing environments. We say that Emerald has fine-grained mobility because Emerald objects can be small data objects as well as process objects. Fine-grained mobility allows us to apply mobility in new ways but presents implementation problems as well. This paper discusses the benefits of tine-grained mobility, the Emerald language and run-time mechanisms that support mobility, and techniques for implementing mobility that do not degrade the performance of local operations. Performance measurements of the current implementation are included. © 1988, ACM. All rights reserved.",Distributed languages; object-oriented languages; object-oriented systems; process mobility,"COMPUTER PROGRAMMING LANGUAGES; COMPUTER SYSTEMS, DIGITAL - Distributed; DISTRIBUTED LANGUAGES; EMERALD; OBJECT-ORIENTED LANGUAGES; PROCESS MOBILITY; COMPUTER OPERATING SYSTEMS"
Scale and Performance in a Distributed File System,1988,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023964787&doi=10.1145%2f35037.35059&partnerID=40&md5=083722ef52aafa50751c6b9aa16728a0,"The Andrew File System is a location-transparent distributed tile system that will eventually span more than 5000 workstations at Carnegie Mellon University. Large scale affects performance and complicates system operation. In this paper we present observations of a prototype implementation, motivate changes in the areas of cache validation, server process structure, name translation, and low-level storage representation, and quantitatively demonstrate Andrews ability to scale gracefully. We establish the importance of whole-file transfer and caching in Andrew by comparing its performance with that of Sun Microsystems NFS tile system. We also show how the aggregation of files into volumes improves the operability of the system. © 1988, ACM. All rights reserved.",Andrew; caching; operability; scalability; Venus; Vice; Volumes; whole file transfer,"COMPUTER SYSTEMS, DIGITAL - Distributed; ANDREW FILE SYSTEM; DISTRIBUTED FILE SYSTEM; FILE TRANSFER; COMPUTER OPERATING SYSTEMS"
The Information Structure of Distributed Mutual Exclusion Algorithms,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023401462&doi=10.1145%2f24068.28052&partnerID=40&md5=2f9fbb4ee8ad189b1b01e8a2464dd82e,"The concept of an information structure is introduced as a unifying principle behind several of the numerous algorithms that have been proposed for the distributed mutual exclusion problem. This approach allows the development of a generalized mutual exclusion algorithm that accepts a particular information structure at initialization and realizes both known and new algorithms as special cases. Two simple performance metrics of a realized algorithm can be obtained directly from the information structure. A new failure recovery mechanism called local recovery, which requires no coordination between nodes and no additional messages beyond that needed for failure detection, is introduced. © 1987, ACM. All rights reserved.",Failure-tolerant algorithms,"COMPUTER PROGRAMMING - Algorithms; DISTRIBUTED MUTUAL EXCLUSION ALGORITHMS; FAILURE RECOVERY; LOCAL RECOVERY; COMPUTER SYSTEMS, DIGITAL"
Concurrency versus Availability: Atomicity Mechanisms for Replicated Data,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023399337&doi=10.1145%2f24068.27643&partnerID=40&md5=39f41eb7768aecda3d00d1891574a315,"A replicated object is a typed data object that is stored redundantly at multiple locations to enhance availability. Most techniques for managing replicated data have a two-level structure: At the higher level, a replica-control protocol reconstructs the object's state from its distributed components, and at the lower level, a standard concurrency-control protocol synchronizes accesses to the individual components. This paper explores an alternative approach to managing replicated data by presenting two replication methods in which concurrency control and replica management are handled by a single integrated protocol. These integrated protocols permit more concurrency than independent protocols, and they allow availability and concurrency to be traded off: Constraints on concurrency may be relaxed if constraints on availability are tightened, and vice versa. In general, constraints on concurrency and availability cannot be minimized simultaneously. © 1987, ACM. All rights reserved.",Abstract data types; concurrency control; replication; synchronization,COMPUTER PROGRAMMING - Algorithms; ATOMICITY MECHANISMS; REPLICATED DATA; DATABASE SYSTEMS
Remark on “Disk Cashe—miss ratio analysis and design consideration”,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976778975&doi=10.1145%2f7351.8930&partnerID=40&md5=9d7ce3c9c14bab54c95e4a9775e92ae1,[No abstract available],,
A continuum of disk scheduling algorithms,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023287925&doi=10.1145%2f7351.8929&partnerID=40&md5=5836f780521aea0914a581a26e2c0bb3,"A continuum of disk scheduling algorithms, V(R), having endpoints V(0) = SSTF and V(1) = SCAN, is defined. V(R) maintains a current SCAN direction (in or out) and services next the request with the smallest effective distance. The effective distance of a request that lies in the current direction is its physical distance (in cylinders) from the read/write head. The effective distance of a request in the opposite direction is its physical distance plus R x (total number of cylinders on the disk). By use of simulation methods, it is shown that this definitional continuum also provides a continuum in performance, both with respect to the mean and with respect to the standard deviation of request waiting time. For objective functions that are linear combinations of the two measures, μw + kow, intermediate points of the continuum are seen to provide performance uniformly superior to both SSTF and SCAN. A method of implementing V(R) and the results of its experimental use in a real system are presented. © 1987, ACM. All rights reserved.",,"COMPUTER OPERATING SYSTEMS; COMPUTER PROGRAMMING - Algorithms; COMPUTER SIMULATION; DISK SCHEDULING ALGORITHMS; MOVING-HEAD DISK; COMPUTER SYSTEMS, DIGITAL"
The Development and Proof of a Formal Specification for a Multilevel Secure System,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023348314&doi=10.1145%2f13677.22724&partnerID=40&md5=9a0272e8069049c0ee5bad8fcfbc5cf2,"This paper describes current work on the design and specification of a multilevel secure distributed system called SNet. It discusses security models in general, the various problems of information flows in SNet, and the abstract and concrete security model components for SNet. It also introduces Lucid as a language for specifying distributed systems. The model components are expressed in Lucid; these Lucid partial specifications are shown to be correct with respect to the formal model, and the two model components are shown to be consistent. The complete functional specification of SNet in Lucid, its implementation in Concurrent Euclid, and the verification of the implementation with respect to the Lucid specification are not discussed. © 1987, ACM. All rights reserved.",Formal specification; multilevel security; network security,"COMPUTER OPERATING SYSTEMS; COMPUTER PROGRAMMING LANGUAGES; DATA PROCESSING - Security of Data; FORMAL SPECIFICATION; LUCID; MULTILEVEL SECURE SYSTEM; SNET; COMPUTER SYSTEMS, DIGITAL"
Reliable communication in the presence of failures,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023287946&doi=10.1145%2f7351.7478&partnerID=40&md5=5a1bd9f6de744e9eddde4bd40b6e935a,"The design and correctness of a communication facility for a distributed computer system are reported on. The facility provides support for fault-tolerant process groups in the form of a family of reliable multicast protocols that can be used in both local- and wide-area networks. These protocols attain high levels of concurrency, while respecting application-specific delivery ordering constraints, and have varying cost and performance that depend on the degree of ordering desired. In particular, a protocol that enforces causal delivery orderings is introduced and shown to be a valuable alternative to conventional asynchronous communication protocols. The facility also ensures that the processes belonging to a fault-tolerant process group will observe consistent orderings of events affecting the group as a whole, including process failures, recoveries, migration, and dynamic changes to group properties like member rankings. A review of several uses for the protocols in the ISIS system, which supports fault-tolerant resilient objects and bulletin boards, illustrates the significant simplification of higher level algorithms made possible by our approach. © 1987, ACM. All rights reserved.",,"COMPUTER NETWORKS - Protocols; FAULT TOLERANCE; MULTICAST PROTOCOLS; COMPUTER SYSTEMS, DIGITAL"
High-Performance Operating System Primitives for Robotics and Real-Time Control Systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023401548&doi=10.1145%2f24068.24070&partnerID=40&md5=40672a5b3708d1b5c670aad2db2d2af4,"To increase speed and reliability of operation, multiple computers are replacing uniprocessors and wired-logic controllers in modern robots and industrial control systems. However, performance increases are not attained by such hardware alone. The operating software controlling the robots or control systems must exploit the possible parallelism of various control tasks in order to perform the necessary computations within given real-time and reliability constraints. Such software consists of both control programs written by application programmers and operating system software offering means of task scheduling, intertask communication, and device control. The Generalized Executive for real-time Multiprocessor applications (GEM) is an operating system that addresses several requirements of operating software. First, when using GEM, programmers can select one of two different types of tasks differing in size, called processes and microprocesses. Second, the scheduling calls offered by GEM permit the implementation of several models of task interaction. Third, GEM supports multiple models of communication with a parameterized communication mechanism. Fourth, GEM is closely coupled to prototype real-time programming environments that provide programming support for the models of computation offered by the operating system. GEM is being used on a multiprocessor with robotics application software of substantial size and complexity. © 1987, ACM. All rights reserved.",Light-weight processes; operating software; parallelism; robotics,"COMPUTER SYSTEMS, DIGITAL - Multiprocessing; CONTROL SYSTEMS - Computer Applications; ROBOTICS; GENERALIZED EXECUTIVE FOR REAL-TIME MULTIPROCESSOR APPLICATIONS; HIGH-PERFORMANCE OPERATING SYSTEM PRIMITIVES; REAL-TIME CONTROL SYSTEMS; COMPUTER OPERATING SYSTEMS"
Monitoring Distributed Systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023347099&doi=10.1145%2f13677.22723&partnerID=40&md5=5524429ed52168eac178afc0dddeee8f,"The monitoring of distributed systems involves the collection, interpretation, and display of information concerning the interactions among concurrently executing processes. This information and its display can support the debugging, testing, performance evaluation, and dynamic documentation of distributed systems. General problems associated with monitoring are outlined in this paper, and the architecture of a general purpose, extensible, distributed monitoring system is presented. Three approaches to the display of process interactions are described: textual traces, animated graphical traces, and a combination of aspects of the textual and graphical approaches. The roles that each of these approaches fulfill in monitoring and debugging distributed systems are identified and compared. Monitoring tools for collecting communication statistics, detecting deadlock, controlling the non-deterministic execution of distributed systems, and for using protocol specifications in monitoring are also described. Our discussion is based on experience in the development and use of a monitoring system within a distributed programming environment called Jade. Jade was developed within the Computer Science Department of the University of Calgary and is now being used to support teaching and research at a number of university and research organizations. © 1987, ACM. All rights reserved.",Concurrent monitoring; distributed monitoring; dynamic documentation; graphical monitoring,"COMPUTER SOFTWARE - Monitoring; CONCURRENT MONITORING; DEADLOCK; DISTRIBUTED MONITORING; DYNAMIC DOCUMENTATION; PROTOCOL SPECIFICATIONS; COMPUTER SYSTEMS, DIGITAL"
UIO: A uniform I/O system interface for distributed systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023289035&doi=10.1145%2f7351.7353&partnerID=40&md5=67511425996193312ab4b3e41ccbd63b,"A uniform I/O interface allows programs to be written relatively independently of specific I/O services and yet work with a wide variety of the I/O services available in a distributed environment. Ideally, the interface provides this uniform access without excessive complexity in the interface or loss of performance. However, a uniform interface does not arise from careful design of individual system interfaces alone; it requires explicit definition. In this paper, the UIO (uniform I/O) system interface that has been used for the past five years in the V distributed operating system is described, with the focus on the key design issues. This interface provides several extensions beyond the I/O interface of UNIX#8482;, including support for record I/O, locking, atomic transactions, and replication, as well as attributes that indicate whether optional semantics and operations are available. Experience in using and implementing this interface with a variety of different I/O services is described, along with the performance of both local and network I/O. It is concluded that the UIO interface provides a uniform I/O system interface with significant functionality, wide applicability, and no significant performance penalty. © 1987, ACM. All rights reserved.",,"COMPUTER OPERATING SYSTEMS; COMPUTER SYSTEMS, DIGITAL - Distributed; FILES INPUT/OUTPUT; INTERPROCESS COMMUNICATION; REMOTE PROCEDURE CALL; UNIFORM I/O INTERFACE; COMPUTER INTERFACES"
Response Times in Level-Structured Systems,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023400728&doi=10.1145%2f24068.24069&partnerID=40&md5=267746997d0fbc4172d358df67fc3528,"Real-time programs are among the most critical programs in use today, yet they are also among the worst understood and the most difficult to verify. Validation of real-time systems is nonetheless extremely important in view of the high costs associated with failure in typical application areas. We present here a method for deriving response-time properties in complex systems with a level structure based on priority. The method involves a level-by-level examination of the system, in which information distilled from each successive level is used to adjust the results for later levels. The results obtained at each level of the system are not affected by later analyses, which obviates having to consider a complex system as a whole. © 1987, ACM. All rights reserved.",Interrupt-driven systems; priority-based level-structure; timedilation,"COMPUTER SOFTWARE - Reliability; LEVEL-STRUCTURED SYSTEMS; REAL-TIME SYSTEMS; RESPONSE TIMES; COMPUTER SYSTEMS, DIGITAL"
Gaining Efficiency in Transport Services by Appropriate Design and Implementation Choices,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023345492&doi=10.1145%2f13677.13678&partnerID=40&md5=f40961e06cddb48196c12ec2bc29742c,"End-to-end transport protocols continue to be an active area of research and development involving (1) design and implementation of special-purpose protocols, and (2) reexamination of the design and implementation of general-purpose protocols. This work is motivated by the perceived low bandwidth and high delay, CPU, memory, and other costs of many current general-purpose transport protocol designs and implementations. This paper examines transport protocol mechanisms and implementation issues and argues that general-purpose transport protocols can be effective in a wide range of distributed applications because (1) many of the mechanisms used in the special-purpose protocols can also be used in general-purpose protocol designs and implementations, (2) special-purpose designs have hidden costs, and (3) very special operating system environments, overall system loads, application response times, and interaction patterns are required before general-purpose protocols are the main system performance bottlenecks. © 1987, ACM. All rights reserved.",Interprocess communication; performance of communication protocols; transport layer protocols—design and implementation,"COMPUTER NETWORKS - Protocols; INTERPROCESS COMMUNICATION; TRANSPORT LAYER PROTOCOLS; TRANSPORT SERVICES; COMPUTER SYSTEMS, DIGITAL"
A fast mutual exclusion algorithm,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023288130&doi=10.1145%2f7351.7352&partnerID=40&md5=bd2abeece4315f40d41da49037244592,"A new solution to the mutual exclusion problem is presented that, in the absence of contention, requires only seven memory accesses. It assumes atomic reads and atomic writes to shared registers. © 1987, ACM. All rights reserved.",,"COMPUTER PROGRAMMING - Algorithms; MEMORY ACCESSES; MUTUAL EXCLUSION ALGORITHM; COMPUTER SYSTEMS, DIGITAL"
An Optimized Contention Protocol for Broadband Networks,1987,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023400462&doi=10.1145%2f24068.27644&partnerID=40&md5=2e8c5f6042911d40790004957340ff76,"This paper describes the concepts underlying an alternative link-level protocol for broadband local networks. The protocol uses implicit slotting of the contention channel to support larger networks, improve performance, and provide reliable distributed collision recognition without reinforcement. It is designed such that compatible interfaces to existing CSMA/CD-based systems can be provided. © 1987, ACM. All rights reserved.",Cable plant topology; network synchronization; random access,DATA TRANSMISSION; BROADBAND NETWORKS; CARRIER SENSE MULTIPLE ACCESS/COLLISION DETECTION NETWORK; CSMA/CD-BASED SYSTEMS; LOCAL NETWORKS; OPTIMIZED CONTENTION PROTOCOL; COMPUTER NETWORKS
The Integration of Virtual Memory Management and Interprocess Communication in Accent,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022715142&doi=10.1145%2f214419.214422&partnerID=40&md5=2430bbd320b4f183cc7049afc5c5f9a7,"The integration of virtual memory management and interprocess communication in the Accent network operating system kernel is examined. The design and implementation of the Accent memory management system is discussed and its performance, both on a series of message-oriented benchmarks and in normal operation, is analyzed in detail. © 1986, ACM. All rights reserved.",,DATA TRANSMISSION; ACCENT KERNEL; INTERPROCESS COMMUNICATION; VIRTUAL MEMORY MANAGEMENT; COMPUTER OPERATING SYSTEMS
A Tree-Structured Mean Value Analysis Algorithm,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022709498&doi=10.1145%2f214419.214423&partnerID=40&md5=cfb4769d9f65c9d92a4b7837d13265b6,"In a recent paper, Lam and Lien described an algorithm called tree-convolution that can reduce the space and computation time required for evaluating sparse multiclass, product-form queueing networks. In this paper, we develop an exact algorithm based on mean value analysis (MVA) that is the counterpart of the tree-convolution algorithm. The order of reduction in storage and computation achieved by our new Tree-MVA algorithm compared to the standard MVA algorithm is the same order of reduction obtained by the tree-convolution algorithm over that of the standard convolution algorithm. Our Tree-MVA algorithm preserves the inherent simplicity of MVA based algorithms. © 1986, ACM. All rights reserved.",,MATHEMATICAL TECHNIQUES - Trees; MEAN VALUE ANALYSIS ALGORITHM; TREE-STRUCTURED ALGORITHM; COMPUTER PROGRAMMING
The distributed deadlock detection algorithm,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022811544&doi=10.1145%2f6513.6516&partnerID=40&md5=da9d8691495b512e642f02abbf531fb1,"We propose a distributed deadlock detection algorithm for distributed computer systems. We consider two types of resources, depending on whether the remote resource lock granularity and mode can or cannot be determined without access to the remote resource site. We present the algorithm, its performance analysis, and an informal argument about its correctness. The proposed algorithm has a hierarchical design intended to detect the most frequent deadlocks with maximum efficiency. © 1986, ACM. All rights reserved.",Communication deadlock; distributed algorithms; distributed deadlock detection; message communication systems; resource deadlock,"COMPUTER PROGRAMMING - Algorithms; DEADLOCK DETECTION; DISTRIBUTED ALGORITHMS; MESSAGE COMMUNICATION SYSTEMS; COMPUTER SYSTEMS, DIGITAL"
Conversation-Based Mail,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022810162&doi=10.1145%2f6513.6515&partnerID=40&md5=45a551b337b8c8fcd026a1dd2bf41c87,"A new message communication paradigm based on conversations that provides an alternative to memo- and conference-based mail is described. A conversation-based message system groups messages into conversations, and orders messages within a conversation according to the context in which they were written. The message context relation leads to an efficient implementation of conversations in a distributed environment and supports a natural ordering of messages when viewed by the user. Experience with a prototype demonstrates the workability of conversation-based mail and suggests that conversations provide a powerful tool for message communication. © 1986, ACM. All rights reserved.",Conversation; message context,"ELECTRONIC MAIL; CONVERSATION-BASED MAIL; MESSAGE SYSTEMS; COMPUTER SYSTEMS, DIGITAL"
The performance of multiversion concurrency control algorithms,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022807172&doi=10.1145%2f6513.6517&partnerID=40&md5=065ef1576f5cfc1b08d1703fdcd9c1ab,"A number of multiversion concurrency control algorithms have been proposed in the past few years. These algorithms use previous versions of data items in order to improve the level of achievable concurrency. This paper describes a simulation study of the performance of several multiversion concurrency control algorithms, investigating the extent to which they provide increases in the level of concurrency and also the CPU, I/O, and storage costs resulting from the use of multiple versions. The multiversion algorithms are compared with regard to performance with their single-version counterparts and also with each other. It is shown that each multiversion algorithm offers significant performance improvements despite the additional disk accesses involved in accessing old versions of data; the nature of the improvement depends on the algorithm in question. It is also shown that the storage overhead for maintaining old versions that may be required by ongoing transactions is not all that large under most circumstances. Finally, it is demonstrated that it is important for version maintenance to be implemented efficiently, as otherwise the cost of maintaining old versions could outweigh their concurrency benefits. © 1986, ACM. All rights reserved.",Concurrency control; multiple versions,COMPUTER PROGRAMMING - Algorithms; DEADLOCK AVOIDANCE; MULTIVERSION CONCURRENCY CONTROL ALGORITHMS; TRANSACTION PROCESSING; DATABASE SYSTEMS
File Access Performance of Diskless Workstations,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976736818&doi=10.1145%2f6420.6423&partnerID=40&md5=a732f43e34440003e3c8244f359ad231,"This paper studies the performance of single-user workstations that access files remotely over a local area network. From the environmental, economic, and administrative points of view, workstations that are diskless or that have limited secondary storage are desirable at the present time. Even with changing technology, access to shared data will continue to be important. It is likely that some performance penalty must be paid for remote rather than local file access. Our objectives are to assess this penalty and to explore a number of design alternatives that can serve to minimize it. Our approach is to use the results of measurement experiments to parameterize queuing network performance models. These models then are used to assess performance under load and to evahrate design alternatives. The major conclusions of our study are: (1) A system of diskless workstations with a shared file server can have satisfactory performance. By this, we mean performance comparable to that of a local disk in the lightly loaded case, and the ability to support substantial numbers of client workstations without significant degradation. As with any shared facility, good design is necessary to minimize queuing delays under high load. (2) The key to efficiency is protocols that allow volume transfers at every interface (e.g., between client and server, and between disk and memory at the server) and at every level (e.g., between client and server at the level of logical request/response and at the level of local area network packet size). However, the benefits of volume transfers are limited to moderate sizes (8-16 kbytes) by several factors. (3) From a performance point of view, augmenting the capabilities of the shared file server may be more cost effective than augmenting the capabilities of the client workstations. (4) Network contention should not be a performance problem for a lo-Mbit network and 100 active workstations in a software development environment. © 1986, ACM. All rights reserved.",Computer system performance analysis; diskless workstations; distributed systems; file servers; local area networks,
The S/Net's Linda Kernel,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022713864&doi=10.1145%2f214419.214420&partnerID=40&md5=1f0e14225d6ad17eca998b202dda80cc,"Linda is a parallel programming language that differs from other parallel languages in its simplicity and in its support for distributed data structures. The S/Net is a multicomputer, designed and built at AT&T Bell Laboratories, that is based on a fast, word-parallel bus interconnect. We describe the Linda-supporting communication kernel we have implemented on the S/Net. The implementation suggests that Linda's unusual shared-memory-like communication primitives can be made to run well in the absence of physically shared memory; the simplicity of the language and of our implementation's logical structure suggest that similar Linda implementations might readily be constructed on related architectures. We outline the language, and programming methodologies based on distributed data structures; we then describe the implementation, and the performance both of the Linda primitives themselves and of a simple S/Net-Linda matrix-multiplication program designed to exercise them. © 1986, ACM. All rights reserved.",,"COMPUTER SYSTEMS, DIGITAL - Parallel Processing; DATA PROCESSING - Data Structures; COMMUNICATION KERNEL; LINDA PARALLEL PROGRMMING LANGUAGES; S/NET; COMPUTER PROGRAMMING LANGUAGES"
VAXcluster: A Closely-Coupled Distributed System,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022713171&doi=10.1145%2f214419.214421&partnerID=40&md5=d7986ab1d812dd271769b91e0a4a4df5,"A VAXcluster is a highly available and extensible configuration of VAX computers that operate as a single system. To achieve performance in a multicomputer environment, a new communications architecture, communications hardware, and distributed software were jointly designed. The software is a distributed version of the VAX/VMS operating system that uses a distributed lock manager to synchronize access to shared resources. The communications hardware includes a 70 megabit per second message-oriented interconnect and an interconnect port that performs communications tasks traditionally handled by software. Performance measurements show this structure to be highly efficient, for example, capable of sending and receiving 3000 messages per second on a VAX-11/780. © 1986, ACM. All rights reserved.",,"COMPUTER SOFTWARE; INTERSYSTEM COMMUNICATION PROTOCOLS; NETWORK PROTOCOLS; VAXCLUSTERS; COMPUTER SYSTEMS, DIGITAL"
The Vulnerability of Vote Assignments,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976701893&doi=10.1145%2f6420.6421&partnerID=40&md5=1677ac3cc6d03806751a7307b8d96269,"In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of nodes. Each node is assigned a number of votes, and any group with a majority of votes can perform the critical operations. Vote assignments can have a significant impact on system reliability, and in this paper we study the vote assignment problem. To compare vote assignments we define two deterministic measures, node and edge vulnerability. We present various properties of these measures and discuss how they can be computed. For these measures we discuss the selection of the best assignment and propose heuristics to identify good candidate assignments. © 1986, ACM. All rights reserved.",Partitions; voting,
Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation Model,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022806145&doi=10.1145%2f6513.6514&partnerID=40&md5=d19973b1a94218e05c2f063d87c16852,"Using simulation, we examine the efficiency of several distributed, hardware-based solutions to the cache coherence problem in shared-bus multiprocessors. For each of the approaches, the associated protocol is outlined. The simulation model is described, and results from that model are presented. The magnitude of the potential performance difference between the various approaches indicates that the choice of coherence solution is very important in the design of an efficient shared-bus multiprocessor, since it may limit the number of processors in the system. © 1986, ACM. All rights reserved.",Cache coherence; shared-bus multiprocessor; simulation,"COMPUTER SIMULATION; CACHE COHERENCE PROTOCOLS; SHARED-BUS MULTIPROCESSOR; COMPUTER SYSTEMS, DIGITAL"
Measurement and Modeling of Computer Reliability as Affected by System Activity,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976815079&doi=10.1145%2f6420.6422&partnerID=40&md5=f7542a7e94aad73736064b0a235c2ad8,"This paper demonstrates a practical approach to the study of the failure behavior of computer systems. Particular attention is devoted to the analysis of permanent failures. A number of important techniques, which may have general applicability in both failure and workload analysis, are brought together in this presentation. These include: smeared averaging of the workload data, clustering of like failures, and joint analysis of workload and failures. Approximately 17 percent of all failures affecting the CPU were estimated to be permanent. The manifestation of a permanent failure was found to be strongly correlated with the level and type of workload prior to the failure. Although, in strict terms, the results only relate to the manifestation of permanent failures and not to their occurrence, there are strong indications that permanent failures are both caused and discovered by increased activity. More measurements and experiments are necessary to determine their respective contributions to the measured workload/failure relationship. © 1986, ACM. All rights reserved.",Data analysis; failure measurement; system activity; workload measurement,
Independent General Principles for Constructing Responsive Software Systems,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022661054&doi=10.1145%2f6306.6307&partnerID=40&md5=7c977cb624aa336d5192f2c8ba14aa3c,"Three general principles are presented that can be applied in early software life cycle stages for the definition of software requirements and designs with acceptable performance. They are genuine high-level considerations for meeting responsiveness goals without sacrificing understandability and maintainability, and without increasing development time and cost. The principles are derived from the interrelationships of two performance models: a queueing network based on computer system model and an execution graph software model. The performance effect of each of the principles is quantified using the models. Examples are given that illustrate how they can be applied to software systems. © 1986, ACM. All rights reserved.",design methodology; efficiency; performance principles; responsiveness; Software design optimization; software models; software performance; software performance engineering,"COMPUTER SYSTEMS, DIGITAL - Performance; MATHEMATICAL MODELS; COMPUTER SOFTWARE"
A Quorum-Consensus Replication Method for Abstract Data Types,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022659404&doi=10.1145%2f6306.6308&partnerID=40&md5=f16a763eadfb9c605437556f0244fba7,"Replication can enhance the availability of data in distributed systems. This paper introduces a new method for managing replicated data. Unlike many methods that support replication only for uninterpreted files, this method systematically exploits type-specific properties of objects such as sets, queues, or directories to provide more effective replication. Each operation requires the cooperation of a certain number of sites for its successful completion. A quorum for an operation is any such set of sites. Necessary and sufficient constraints on quorum intersections are derived from an analysis of the data type's algebraic structure. A reconfiguration method is proposed that permits quorums to be changed dynamically. By taking advantage of type-specific properties in a general and systematic way, this method can realize a wider range of availability properties and more flexible reconfiguration than comparable replication methods. © 1986, ACM. All rights reserved.",abstract data type; Replication,COMPUTER OPERATING SYSTEMS; COMPUTER PROGRAMMING LANGUAGES; ABSTRACT DATA TYPES; REPLICATION METHOD; DATABASE SYSTEMS
Optimistic Recovery in Distributed Systems,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022112420&doi=10.1145%2f3959.3962&partnerID=40&md5=cc7e0e6aa78817953cd620b612f35c98,"Optimistic Recovery is a new technique supporting application-independent transparent recovery from processor failures in distributed systems. In optimistic recovery communication, computation and checkpointing proceed asynchronously. Synchronization is replaced by causal dependency tracking, which enables a posteriori reconstruction of a consistent distributed system state following a failure using process rollback and message replay. Because there is no synchronization among computation, communication, and checkpointing, optimistic recovery can tolerate the failure of an arbitrary number of processors and yields better throughput and response time than other general recovery techniques whenever failures are infrequent. © 1985, ACM. All rights reserved.",Distributed algorithms; fault-tolerance message replay; optimistic algorithms; orphans transparent recovery; recovery,"COMPUTER OPERATING SYSTEMS; COMPUTER PROGRAMMING - Algorithms; OPTIMISTIC ALGORITHMS; OPTIMISTIC RECOVERY; COMPUTER SYSTEMS, DIGITAL"
Disk Cache—Miss Ratio Analysis and Design Considerations,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022112653&doi=10.1145%2f3959.3961&partnerID=40&md5=aef0aed52a205cc509ac205e456d94b9,"The current trend of computer system technology is toward CPUs with rapidly increasing processing power and toward disk drives of rapidly increasing density, but with disk performance increasing very slowly if at all. The implication of these trends is that at some point the processing power of computer systems will be limited by the throughput of the input/output (I/O) system. A solution to this problem, which is described and evaluated in this paper, is disk cache. The idea is to buffer recently used portions of the disk address space in electronic storage. Empirically, it is shown that a large (e.g., 80-90 percent) fraction of all I/O requests are captured by a cache of an 8-Mbyte order-of-magnitude size for our workload sample. This paper considers a number of design parameters for such a cache (called cache disk or disk cache), including those that can be examined experimentally (cache location, cache size, migration algorithms, block sizes, etc.) and others (access time, bandwidth, multipathing, technology, consistency, error recovery, etc.) for which we have no relevant data or experiments. Consideration is given to both caches located in the I/O system, as with the storage controller, and those located in the CPU main memory. Experimental results are based on extensive trace-driven simulations using traces taken from three large IBM or IBM-compatible mainframe data processing installations. We find that disk cache is a powerful means of extending the performance limits of high-end computer systems. © 1985, ACM. All rights reserved.",Cache controller; disk; I/O buffer,"DATA STORAGE UNITS; CACHE CONTROLLER; DISK CACHE; I/O BUFFER; COMPUTER SYSTEMS, DIGITAL"
Low Cost Management of Replicated Data in Fault-Tolerant Distributed Systems,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022662067&doi=10.1145%2f6306.6309&partnerID=40&md5=1c5b92564f8458e22181ce970675904e,"Many distributed systems replicate data for fault tolerance or availability. In such systems, a logical update on a data item results in a physical update on a number of copies. The synchronization and communication required to keep the copies of replicated data consistent introduce a delay when operations are performed. In this paper, we describe a technique that relaxes the usual degree of synchronization, permitting replicated data items to be updated concurrently with other operations, while at the same time ensuring that correctness is not violated. The additional concurrency thus obtained results in better response time when performing operations on replicated data. We also discuss how this technique performs in conjunction with a roll-back and a roll-forward failure recovery mechanism. © 1986, ACM. All rights reserved.",concurrent update; piggybacked update; Replicated data; rollforward recovery,"COMPUTER SYSTEMS, DIGITAL - Distributed; FAULT-TOLERANT DISTRIBUTED SYSTEMS; REPLICATED DATA; ROLL-FORWARD RECOVERY; UPDATE; DATABASE SYSTEMS"
The Alpine file system,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022152346&doi=10.1145%2f6110.6111&partnerID=40&md5=eb439aacfa2fb69346b38fbd51e2fc2c,"Alpine is a file system that supports atomic transactions and is designed to operate as a service on a computer network. Alpine's primary purpose is to store files that represent databases. An important secondary goal is to store ordinary files representing documents, program modules, and the like. Unlike other file servers described in the literature, Alpine uses a log-based technique to implement atomic file update. Another unusual aspect of Alpine is that it performs all communication via a general-purpose remote procedure call facility. Both of these decisions have worked out well. This paper describes Alpine's design and implementation, and evaluates the system in light of our experience to date. Alpine is written in Cedar, a strongly typed modular programming language that includes garbage-collected storage. We report on using the Cedar language and programming environment to develop Alpine. © 1985, ACM. All rights reserved.",atomic update; File servers; recoverable files; remote procedure calls,COMPUTER NETWORKS; COMPUTER PROGRAMMING LANGUAGES; ALPINE; CEDAR; FILE SERVERS; FILE SYSTEM; DATABASE SYSTEMS
A recursive algorithm for binary multiplication and its implementation,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022150676&doi=10.1145%2f6110.214399&partnerID=40&md5=153db0cb2249878bdce1b33a611ee693,"A new recursive algorithm for deriving the layout of parallel multipliers is presented. Based on this algorithm, a network for performing multiplications of two's complement numbers is proposed. The network can be implemented in a synchronous or an asynchronous way. If the factors to be multiplied have N bits, the area complexity of the network is O(N2) for practical values of N as in the case of cellular multipliers. Due to the design approach based on a recursive algorithm, a time complexity O(log N) is achieved. It is shown how the structure can he pipelined with period complexity O(1) and used for single and double precision multiplication. © 1985, ACM. All rights reserved.",complexity; layout; Multiplier,"COMPUTER SYSTEMS, DIGITAL - Parallel Processing; BINARY MULTIPLICATION; COMPLEXITY; RECURSIVE ALGORITHM; COMPUTER PROGRAMMING"
A distributed mutual exclusion algorithm,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022151877&doi=10.1145%2f6110.214406&partnerID=40&md5=e2ea25ea9686fe5b4f44e728fa59352a,"A distributed algorithm is presented that realizes mutual exclusion among N nodes in a computer network. The algorithm requires at most N message exchanges for one mutual exclusion invocation. Accordingly, the delay to invoke mutual exclusion is smaller than in an algorithm of Ricart and Agrawala, which requires 2*(N - 1) message exchanges per invocation. A drawback of the algorithm is that the sequence numbers contained in the messages are unbounded. It is shown that this problem can be overcome by slightly increasing the number of message exchanges. © 1985, ACM. All rights reserved.",critical section; delay; message exchange; optimality,COMPUTER NETWORKS; DISTRIBUTED MUTUAL EXCLUSION ALGORITHM; MESSAGE EXCHANGE; PROCESS MANAGEMENT; COMPUTER PROGRAMMING
Effects of Job Loading Policies for Multiprogramming Systems in Processing a Job Stream,1986,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022659942&doi=10.1145%2f6306.6310&partnerID=40&md5=1c0ce3b5d2535cfeae4faeb723c5b8ae,"The scheduling of jobs for multiprogramming systems includes the selection of jobs to be loaded into memory (job loading policy or memory schedule) and the scheduling for CPU processing (CPU schedule). There has been a successful empirical claim for the optimal CPU schedule; its optimality has been proved in a Markovian model of job-stream processing that uses the first-come-first-loaded (FCFL) job loading policy. We extend this model to gain insight into the effects of job loading policies. The model studied consists of an input stream of jobs of two classes and a multiple-resource system (the model of a multiprogramming system) with a stack for waiting jobs. The system consists of a finite amount of memory and a cyclic queue of a single (CPU) server station and a multiple (I/O) server station. The values of parameters describing each class of jobs are distinct except the mean I/O service time and the amount of memory required. The estimate of the maximum processing capacity (throughput bound) of the system is obtained and is shown to be achieved by the combination of the empirically claimed optimal CPU schedule and a job loading policy whereby the set of jobs in memory is kept to be (nearly) balanced with respect to the job stream. Furthermore, we show that the job loading policies independent of the system status have no improvement over the FCFL policy. Our investigation, supported by numerical calculations, suggests that much more care may be needed in implementing the job loading policy that aims at the optimal processing capacity than in implementing the optimal CPU schedule. This agrees with what has been conjectured on the basis of empirical studies. © 1986, ACM. All rights reserved.",CPU bound; finite memory size model; finite source queue; I/O bound; Job loading policies; job-stream processing; load balancing; machine repairman model; multiple-resource system; near complete decomposability; processing capacity; throughput,COMPUTER OPERATING SYSTEMS; FINITE MEMORY SIZE MODEL; JOB LOADING POLICIES; MULTIPLE-RESOURCE SYSTEM; THROUGHPUT; COMPUTER SYSTEMS PROGRAMMING
Error Bounds for Performance Prediction in Queuing Networks,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022113667&doi=10.1145%2f3959.3960&partnerID=40&md5=bfa274f0a10746b1e25aa9c6a2126437,"Analytic models based on closed queuing networks (CQNS) are widely used for performance prediction in practical systems. In using such models, there is always a prediction error, that is, a difference between the predicted performance and the actual outcome. This prediction error is due both to modeling errors and estimation errors, the latter being the difference between the estimated values of the CQN parameters and the actual outcomes. This paper considers the second class of errors; in particular, it studies the effect of small estimation errors and provides bounds on prediction errors based on bounds on estimation errors. Estimation errors may be divided into two types: (1) the difference between the estimated value and the average value of the outcome, and (2) the deviation of the actual value from its average. The analysis first studies the sum of both types of errors, then the second type alone. The results are illustrated with three examples. © 1985, ACM. All rights reserved.",Approximate analysis; closed queuing networks; product form networks,"PROBABILITY - Queueing Theory; CLOSED QUEUING NETWORKS; ERROR BOUNDS; PRODUCT FORM NETWORKS; QUEUING NETWORKS; COMPUTER SYSTEMS, DIGITAL"
A discipline for constructing multiphase communication protocols,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022149306&doi=10.1145%2f6110.214400&partnerID=40&md5=76af50559ba46e32072a9cfc8954f3a4,"Many communication protocols can be observed to go through different phases performing a distinct function in each phase. A multiphase model for such protocols is presented. A phase is formally defined to be a network of communicating finite-state machines with certain desirable correctness properties; these include proper termination and freedom from deadlocks and unspecified receptions. A multifunction protocol is constructed by first constructing separate phases to perform its different functions. It is shown how to connect these phases together to realize the multifunction protocol so that the resulting network of communicating finite state machines is also a phase (i.e., it possesses the desirable properties defined for phases). The modularity inherent in multiphase protocols facilitates not only their construction but also their understanding and modification. An abundance of protocols have been found in the literature that can be constructed as multiphase protocols. Three examples are presented here: two versions of IBM's BSC protocol for data link control and a token ring network protocol. © 1985, ACM. All rights reserved.",BSC protocol; communicating processes; Communication protocols; data link control; deadlock freedom; finite-state machines; modularity; multiphase protocols; proper termination; protocol design; token ring protocol,BSC PROTOCOLS; MULTIPHASE COMMUNICATION PROTOCOLS; TOKEN RING NETWORK PROTOCOL; COMPUTER NETWORKS
Distributed Process Groups in the V Kernel,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022067076&doi=10.1145%2f214438.214439&partnerID=40&md5=54a367ad1435684da1df49e90d6a0993,"The V kernel supports an abstraction of processes, with operations for interprocess communication, process management, and memory management. This abstraction is used as a software base for constructing distributed systems. As a distributed kernel, the V kernel makes intermachine boundaries largely transparent. In this environment of many cooperating processes on different machines, there are many logical groups of processes. Examples include the group of tile servers, a group of processes executing a particular job, and a group of processes executing a distributed parallel computation. In this paper we describe the extension of the V kernel to support process groups. Operations on groups include group interprocess communication, which provides an application-level abstraction of network multicast. Aspects of the implementation and performance, and initial experience with applications are discussed. © 1985, ACM. All rights reserved.",Distributed system; interprocess communication; job control; kernel; parallel computation; process group; servers,"COMPUTER SYSTEMS, DIGITAL - Distributed; DISTRIBUTED PROCESS GROUPS; V KERNEL; COMPUTER OPERATING SYSTEMS"
The MVA priority approximation,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976857888&doi=10.1145%2f357401.357406&partnerID=40&md5=4add519058781a6708e9cdfabef1e668,"A Mean Value Analysis (MVA) approximation is presented for computing the average performance measures of closed-, open-, and mixed-type multiclass queuing networks containing Preemptive Resume (PR) and nonpreemptive Head-Of-Line (HOL) priority service centers. The approximation has essentially the same storage and computational requirements as MVA, thus allowing computationally efficient solutions of large priority queuing networks. The accuracy of the MVA approximation is systematically investigated and presented. It is shown that the approximation can compute the average performance measures of priority networks to within an accuracy of 5 percent for a large range of network parameter values. Accuracy of the method is shown to be superior to that of Sevcik's shadow approximation. © 1984, ACM. All rights reserved.",approximate solutions; error analysis; mean value analysis; multiclass queuing networks; priority queuing networks; product form solutions,
End-to-end arguments in system design,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976845043&doi=10.1145%2f357401.357402&partnerID=40&md5=6016f51e753881f00c8d5ee517222238,"This paper presents a design principle that helps guide placement of functions among the modules of a distributed computer system. The principle, called the end-to-end argument, suggests that functions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. Examples discussed in the paper include bit-error recovery, security using encryption, duplicate message suppression, recovery from system crashes, and delivery acknowledgment. Low-level mechanisms to support these functions are justified only as performance enhancements. © 1984, ACM. All rights reserved.",data communication; design principles; protocol design,
Ordering subscribers on cable networks,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976799619&doi=10.1145%2f357401.357405&partnerID=40&md5=8e72b31fa7341e70f0ae2bc53643953f,"This paper describes distributed algorithms enabling subscribers of a cable network to determine their relative position on the cable. As a side effect, these algorithms can be used to compute the number of subscribers. Knowledge of both the number and order of subscribers can be used to enhance network performance. © 1984, ACM. All rights reserved.",distributed protocols; distributed systems; random access,
Performance Analysis of Redundant-Path Networks for Multiprocessor Systems,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022066884&doi=10.1145%2f214438.214443&partnerID=40&md5=1d8967aa847216c46fcb6d31c1454162,"Performance of a class of multistage interconnection networks employing redundant paths is investigated. Redundant path networks provide significant tolerance to faults at minimal costs; in this paper improvements in performance and very graceful degradation are also shown to result from the availability of redundant paths. A Markov model is introduced for the operation of these networks in the circuit-switched mode and is solved numerically to obtain the performance measures of interest. The structure of the networks that provide maximal performance is also characterized. © 1985, ACM. All rights reserved.",Fault tolerance; omega networks; redundant path networks,"MULTISTAGE INTERCONNECTION NETWORKS; PERFORMANCE ANALYSIS; REDUNDANT-PATH NETWORKS; COMPUTER SYSTEMS, DIGITAL"
Performance of the VAX-11/780 Translation Buffer: Simulation and Measurement,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022020051&doi=10.1145%2f214451.214455&partnerID=40&md5=29af6c80f7e2f2ee0bd4fec4bda0329f,"A virtual-address translation buffer (TB) is a hardware cache of recently used virtual-to-physical address mappings. The authors present the results of a set of measurements and simulations of translation buffer performance in the VAX-11/780. Two different hardware monitors were attached to VAX-11/780 computers, and translation buffer behavior was measured. Measurements were made under normal time-sharing use and while running reproducible synthetic time-sharing work loads. Reported measurements include the miss ratios of data and instruction references, the rate of TB invalidations due to context switches, and the amount of time taken to service TB misses. Additional hardware measurements were made with half the TB disabled. Trace-driven simulations of several programs were also run; the traces captured system activity as well as user-mode execution. Several variants of the 11/780 TB structure were simulated. © 1985, ACM. All rights reserved.",,"COMPUTER SIMULATION; COMPUTERS, DIGITAL - Performance; CACHE MEMORIES; HARDWARE MONITOR; TRACE-DRIVEN SIMULATION; TRANSLATION BUFFER; DATA STORAGE UNITS"
A [formula omitted] Algorithm for Mutual Exclusion in Decentralized Systems,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022069122&doi=10.1145%2f214438.214445&partnerID=40&md5=c3e9874f91da34961a2d24a9256c3db0,"An algorithm is presented that uses only c√N messages to create mutual exclusion in a computernetwork, where N is the number of nodes and c a constant between 3 and 5. The algorithm issymmetric and allows fully parallel operation. © 1985, ACM. All rights reserved.",Computer networks; decentralized systems,COMPUTER PROGRAMMING - Algorithms; DECENTRALIZED SYSTEMS; MUTUAL EXCLUSION; COMPUTER NETWORKS
On the Power of Cascade Ciphers,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022069123&doi=10.1145%2f214438.214442&partnerID=40&md5=eb799ab754da707d49514fa8fc01b3ea,"The unicity distance of a cascade of random ciphers, with respect to known plaintext attack, is shown to be the sum of the key lengths. A time-space trade-off for the exhaustive cracking of a cascade of ciphers is shown. The structure of the set of permutations realized by a cascade is studied; it is shown that only l.2k exhaustive experiments are necessary to determine the behavior of a cascade of l stages, each having k key bits. It is concluded that the cascade of random ciphers is not a random cipher. Yet, it is shown that, with high probability, the number of permutations realizable by a cascade of l random ciphers, each having k key bits, is 2lk. Next, it is shown that two stages are not worse than one, by a simple reduction of the cracking problem of any of the stages to the cracking problem of the cascade. Finally, it is shown that proving a nonpolynomial lower bound on the cracking problem of long cascades is a hard task, since such a bound implies that P ≉ NP. © 1985, ACM. All rights reserved.",Cascade; random ciphers; time-space trade-off; unicity distance,DATA PROCESSING - Security of Data; CASCADE CIPHERS; DATA ENCRYPTION; RANDOM CIPHERS; UNICITY DISTANCE; CRYPTOGRAPHY
Distributed Snapshots: Determining Global States of Distributed Systems,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022020346&doi=10.1145%2f214451.214456&partnerID=40&md5=2e6c098a9ceaede944aaca86c67ae215,"This paper presents an algorithm by which a process in a distributed system determines a global state of the system during a computation. Many problems in distributed systems can be cast in terms of the problem of detecting global states. For instance, the global state detection algorithm helps to solve an important class of problems: stable property detection. A stable property is one that persists: once a stable property becomes true it remains true thereafter. Examples of stable properties are “computation has terminated,” “the system is deadlocked” and “all tokens in a token ring have disappeared.” The stable property detection problem is that of devising algorithms to detect a given stable property. Global state detection can also be used for checkpointing. © 1985, ACM. All rights reserved.",,"COMPUTER PROGRAMMING - Algorithms; DISTRIBUTED DEADLOCK DETECTION; DISTRIBUTED SNAPSHOTS; GLOBAL STATES; COMPUTER SYSTEMS, DIGITAL"
Secure Communication Using Remote Procedure Calls,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022015288&doi=10.1145%2f214451.214452&partnerID=40&md5=c8b69ff84fe417a2cedcf19c41553169,"Research on encryption-based secure communication protocols has reached a stage where it is feasible to construct end-to-end secure protocols. The design of such a protocol, built as part of a remote procedure call package, is described. The security abstraction presented to users of the package, the authentication mechanisms, and the protocol for encrypting and verifying remote calls are also described. © 1985, ACM. All rights reserved.",,CRYPTOGRAPHY; REMOTE PROCEDURE CALLS; SECURE COMMUNICATION; COMPUTER NETWORKS
The string-to-string correction problem with block moves,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976728067&doi=10.1145%2f357401.357404&partnerID=40&md5=abee971e4fd0343536da9c59b7854a6c,"The string-to-string correction problem is to find a minimal sequence of edit operations for changing a given string into another given string. Extant algorithms compute a longest common subsequence (LCS) of the two strings and then regard the characters not included in the LCS as the differences. However, an LCS does not necessarily include all possible matches, and therefore does not produce the shortest edit sequence. An algorithm that produces the shortest edit sequence transforming one string into another is presented. The algorithm is optimal in the sense that it generates a minimal covering set of common substrings of one string with respect to another. Two improvements of the basic algorithm are developed. The first improvement performs well on strings with few replicated symbols. The second improvement runs in time and space linear to the size of the input. Efficient algorithms for regenerating a string from an edit sequence are also presented. © 1984, ACM. All rights reserved.",block moves; longest common subsequences; pattern matching; revision control; source control; string deltas; string edits,
Determining the Last Process to Fail,1985,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022020365&doi=10.1145%2f214451.214453&partnerID=40&md5=10320e4bd6db0682099f308e81039744,"A total failure occurs whenever all processes cooperatively executing a distributed task fail before the task completes. A frequent prerequisite for recovery from a total failure is identification of the last set (LAST) of processes to fail. Necessary and sufficient conditions are derived here for computing LAST from the local failure data of recovered processes. These conditions are then translated into procedures for deciding LAST membership, using either complete or incomplete failure data. The choice of failure data is itself dictated by two requirements: (1) it can be cheaply maintained, and (2) it must afford maximum fault-tolerance in the sense that the expected number of recoveries required for identifying LAST is minimized. © 1985, ACM. All rights reserved.",,"DATABASE SYSTEMS - Distributed; COOPERATIVE PROCESSES; EVENT ORDERING; TOTAL FAILURE; COMPUTER SYSTEMS, DIGITAL"
Decoupled access/execute computer architectures,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976822030&doi=10.1145%2f357401.357403&partnerID=40&md5=2e03516b804ee5493c48bda690e12557,"An architecture for high-performance scalar computation is proposed and discussed. The main feature of the architecture is a high degree of decoupling between operand access and execution. This results in an implementation that has two separate instruction streams that communicate via architectural queues. Performance comparisons with a conventional scalar architecture are given, and these show that significant performance gains can be realized. Single-instruction-stream versions, both physical and conceptual, are discussed, with the primary goal of minimizing the differences with conventional architectures. This allows known compilation and programming techniques to be used. Finally, the problem of deadlock in a decoupled system is discussed, and a deadlock prevention method is given. © 1984, ACM. All rights reserved.",decoupled architectures; pipelined computer systems; scalar processing,
Optimality of Scheduling Policy for Processing a Job Stream,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945714815&doi=10.1145%2f2080.357395&partnerID=40&md5=3076f6562fcafacd1e95e6a39991b251,[No abstract available],1/0 bound; CPU bound; CPU scheduling; dispatching policy; finite-source queue; job stream; machine repairman model; Markovian queuing model; multiple-resource system; multiprogramming; near-complete decomposability; preemptive priority,
Preface: Special issue on operating systems principles,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976713658&doi=10.1145%2f2080.357389&partnerID=40&md5=392b3c412769dd96a56272c8b3f04cfa,[No abstract available],,
A class of generalized stochastic Petri nets for the performance evaluation of multiprocessor systems,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976753721&doi=10.1145%2f190.191&partnerID=40&md5=6f31ae972df38748fdeeaedb2fe6a596,"Generalized Stochastic Petri Nets (GSPNs) are presented and are applied to the performance evaluation of multiprocessor systems. GSPNs are derived from standard Petri nets by partitioning the set of transitions into two subsets comprising timed and immediate transitions. An exponentially distributed random firing time is associated with each timed transition, whereas immediate transitions fire in zero time. It is shown that GSPNs are equivalent to continuous-time stochastic processes, and solution methods for the derivation of the steady state probability distribution are presented. Examples of application of GSPN models to the performance evaluation of multiprocessor systems show the usefulness and the effectiveness of this modeling tool. © 1984, ACM. All rights reserved.",,
Experience with Grapevine: The Growth of a Distributed System,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976654081&doi=10.1145%2f2080.2081&partnerID=40&md5=aaf389a4652efec5d06dd96b1ce63ffe,[No abstract available],Grapevine,
A fast file system for UNIX,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976682539&doi=10.1145%2f989.990&partnerID=40&md5=be704968bbe4b36faa1060be6ab0d760,[No abstract available],application program interface; file system design; file system organization; file system performance; UNIX,
Implementing Remote Procedure Calls,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976783312&doi=10.1145%2f2080.357392&partnerID=40&md5=b22c91640068705228900f4d5616e13a,[No abstract available],distributed naming and binding; inter-process communication; performance of communication protocols; remote procedural calls; transport layer protocols,
A Computer Communication Technique Using Content-Induced Transaction Overlap,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976830304&doi=10.1145%2f2080.357393&partnerID=40&md5=73d8661bcfffb93dade0745ad5ca394f,[No abstract available],associative proceeding; communication protocol; data compression; multiaccess channels,
Byzantine generals in action: Implementing fail-stop processors,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976724324&doi=10.1145%2f190.357399&partnerID=40&md5=5f035214a9da86d92520f602494eaa8e,[No abstract available],Byzantine generals; fail-fast; fail-stop,
Synchronizing shared abstract types,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976783965&doi=10.1145%2f989.1188&partnerID=40&md5=4fb3501523fae5962707ff8a93d1a696,[No abstract available],dependencies; locking; transaction serializability,
Computation and Communication in R: A Distributed Database Manager,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976769948&doi=10.1145%2f2080.357390&partnerID=40&md5=555522a8c4ebf9098657d6e80e529a3b,[No abstract available],distributed computation; distributed recovery protocols; site autonomy,
Static grouping of small objects to enhance performance of a paged virtual memory,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976770930&doi=10.1145%2f190.194&partnerID=40&md5=d971afd194a8c08758938c6b145af8d3,[No abstract available],initial placement; object-oriented; paging; programing restructuring; reference trace compression; Smalltalk; static grouping; virtual memory,
A security model for military message systems,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976780900&doi=10.1145%2f989.991&partnerID=40&md5=3609358afb033f9c9f270ad00b5e3d2f,[No abstract available],confinement; message systems; storage channels,
Reliable broadcast protocols,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976768445&doi=10.1145%2f989.357400&partnerID=40&md5=926ae1f7393261db7b4bcbb11f8718f3,[No abstract available],0; broadcasting; failure recovery; message sequencing; multicasting,
Performance analysis of checkpointing strategies,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976696875&doi=10.1145%2f190.357398&partnerID=40&md5=118852f45b2a5560ab618bb8a293cec9,[No abstract available],database recovery; equicost checkpointing strategy; equidistant checkpointing strategy; error recovery; performance modeling and optimization; rollback recovery; system availability,
Preface: Special issue on measurement and modeling of computer systems,1984,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976836735&doi=10.1145%2f190.357396&partnerID=40&md5=ed1906e24fd032a84120ebfc0e6ff60c,[No abstract available],,
A key distribution protocol using event markers,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976731140&doi=10.1145%2f357369.357373&partnerID=40&md5=6d254e59ad6b5810f1d4af876f174ef6,[No abstract available],authentication; encryption; key distribution; networks; protocols,
Optimal Routing in Closed Queuing Networks,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976717011&doi=10.1145%2f357377.357381&partnerID=40&md5=0207fb4df4070e16559e899a649d3637,"In this paper, we establish criteria and propose algorithms for the optimal routing of traffic in closed queuing networks. The objective is to maximize total throughput or (equivalently) to minimize overall average delay. We show that delay is convex over the set of routing patterns in networks with a single class of customers. This enables us to develop a downhill technique for finding the global minimum. The efficiency of our algorithm rests on the fact that the steepest descent direction is readily obtained at each iteration from the MVA algorithm. For multiple-class networks a counterexample is presented to show that convexity does not hold. The technique, however, can still be used to obtain local minima. The algorithm is applied to the optimization of routing in flow-controlled packet-switched networks. Several numerical examples are presented. © 1983, ACM. All rights reserved.",flow control; load leveling; network optimization; packet switching; queuing networks; routing; virtual circuit,
Corrigendum: Computational Algorithms for State-Dependent Queuing Networks,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976798658&doi=10.1145%2f357377.357385&partnerID=40&md5=4b6bb40cfccfdf982a9cd5927c7fd2c6,[No abstract available],,
Cryptographic solution to a problem of access control in a hierarchy,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976752387&doi=10.1145%2f357369.357372&partnerID=40&md5=694c3fa93b7830121f0eee5a041bdc47,[No abstract available],cryptography; key; multilevel security; symmetric and asymmetric cryptosystems,
PACS: A parallel microprocessor array for scientific calculations,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976696809&doi=10.1145%2f357369.357370&partnerID=40&md5=d3c38a4ef3ee6c679e36a53f2fb2b62d,[No abstract available],array processors; distributed systems; highly parallel processors; MIMD; multimicroprocessors; multiprocessing; multiprocessors; nearest neighbor communication; parallel algorithms; parallel language; parallel processors; performance measurement; processor architecture; scientific calculation; supercomputer; synchronization,
Mechanisms that Enforce Bounds on Packet Lifetimes,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976698095&doi=10.1145%2f357377.357382&partnerID=40&md5=8a835cc161a11bdff22373b00d2ab0f2,"For reliable transport protocol operation the lifetime of packets should not exceed an assumed maximum packet lifetime (MPL). A packet's Lifetime is spent in nodes and crossing links and subnetworks. Time spent in nodes and on some links and subnetworks is easily found. Other links and subnetworks may lose, duplicate, delay, and reorder data and not provide transit time information. We present a link-transit-time protocol for bounding the transit time of packets that cross such links and subnetworks. The protocol does not require synchronized clocks. In the protocol a receiving node R occasionally sends the value of its clock reliably to a sending node S, which initializes a software send-timer. Node S uses the send-timer to timestamp packets that are sent to node R. Node R can then overestimate each packet's link or subnetwork transit time. © 1983, ACM. All rights reserved.",internetwork gateways; link-layer protocols; maximum packet lifetime; network-layer protocols; packet switching; subnetworks; three-way handshake; timer-based protocols; transit-time protocols; transport protocols,
Fail-stop processors: An approach to designing fault-tolerant computing systems,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976815497&doi=10.1145%2f357369.357371&partnerID=40&md5=e72c8775fb3d17f54f0262071df5285b,[No abstract available],,
Shared resource matrix methodology: An approach to identifying storage and timing channels,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976667065&doi=10.1145%2f357369.357374&partnerID=40&md5=60bde84643c633d51c98909592992beb,[No abstract available],confinement; covert channels; flow analysis; protection; storage channels; timing channels; validation,
An HDLC Protocol Specification and its Verification Using Image Protocols,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976693592&doi=10.1145%2f357377.357384&partnerID=40&md5=4cff4f74d800cc6adbb96f7530d79153,"We use an event-driven process model to specify a version of the High-Level Data Link Control (HDLC) protocol between two communicating protocol entities. The protocol is verified using the method of projections. The verification serves as a rigorous exercise to demonstrate the applicability of this method to the analysis of real-life communication protocols. The HDLC protocol has two characteristics found in most real-life communication protocols. First, the HDLC protocol operates under real-time constraints that are important not only for its performance but also for its correct logical behavior. We specify this real-time behavior using time variables and time events. Second, the HDLC protocol has three distinguishable functions: connection management, and one-way data transfers between the protocol entities. For each of these functions, we construct an image protocol using the method of projections. With each image protocol we obtain inductively complete invariant assertions that state various desirable logical safety properties. From the properties of image protocols it follows that these safety properties as proved for the image protocols are also satisfied by the HDLC protocol presented herein. We also suggest a minor modification to HDLC that will make it well-structured. © 1983, ACM. All rights reserved.",communicating processes; communication protocols; data link control; HDLC protocol; image protocols; message-passing networks; method of projections,
Transient Behavior of Cache Memories,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976732647&doi=10.1145%2f357377.357379&partnerID=40&md5=5b91d6a5fb4fea3ada99d4bd2eedc3da,"A cache is a small, fast associative memory located between a central processor and primary memory and used to hold copies of the contents of primary memory locations. A key performance measure of a cache is the miss ratio: the fraction of processor references which are not satisfied by the cache and result in primary memory references. The miss ratio is sometimes measured by running a single program to completion; however, in real systems rarely does such uninterrupted execution occur. In this paper a mathematical model is developed which predicts the effect on the miss ratio of running a program in a sequence of interrupted execution intervals. Results from the model are compared to measured miss ratios of real programs executing in an interrupted execution environment. © 1983, ACM. All rights reserved.",hit ratio; memory hierarchy; miss ratio,
Computational Algorithms for State-Dependent Queueing Networks,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976696288&doi=10.1145%2f357353.357359&partnerID=40&md5=8d00cd357318fdd1f9fad6b93272831e,[No abstract available],computational algorithms; convolution algorithm; mean value analysis; mixed networks; product form queueing networks; state-dependence,
On the Generation of Cryptographically Strong Pseudorandom Sequences,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049015677&doi=10.1145%2f357353.357357&partnerID=40&md5=11daa637e8b1e65e5b5bb88c42babf00,[No abstract available],cryptography; one-time pads; pseudorandom sequences; RSA cryptosystems,
The Aggregate Server Method for Analyzing Serialization Delays in Computer Systems,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976792762&doi=10.1145%2f357360.357364&partnerID=40&md5=c8ebc7c7f5b1ee3526997f622027838d,"The aggregate server method is an approximate, iterative technique for analyzing the delays that programs encounter while waiting to enter critical sections, non-reentrant subroutines, and similar software structures that cause processing to become serialized. The method employs a conventional product form queuing network comprised of servers that represent actual I/O devices and processors, plus additional aggregate servers that represent serialized processing activity. The parameters of the product form network are adjusted iteratively to account for contention among serialized and nonserialized customers at each physical device. The algorithm is developed for single-class closed queuing networks with load-independent servers employing processor sharing scheduling disciplines. Validations based on comparisons with exact numerical solutions are presented, and some factors affecting the accuracy of the method are discussed. Extensions to multiclass queuing networks, variable rate servers, and other scheduling disciplines are also suggested. © 1983, ACM. All rights reserved.",aggregate server method; approximation; critical sections; metamodeling; product form; queueing networks; serialization delays,
Interprocess Communication and Processor Dispatching on the Intel 432,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952852372&doi=10.1145%2f357353.357358&partnerID=40&md5=a006c61386ee80ffdf5a9e7e9323896d,[No abstract available],dispatching and scheduling; interprocess communication; microarchitecture; object-based microprocessors,
Editor's Introduction,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976755469&doi=10.1145%2f357353.357354&partnerID=40&md5=c421629ef5972862c099096c4c44fc0d,[No abstract available],,
A VLSI Layout for a Pipelined Dadda Multiplier,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976818602&doi=10.1145%2f357360.357366&partnerID=40&md5=10dfd1cefca2604e9d21fdf1498d1f60,"Parallel counters (unary-to-binary converters) are the principal component of a Dadda multiplier. We specify a design first for a pipelined parallel counter, and then for a complete multiplier. As a result of its structural regularity, the layout is suitable for use in a VLSI implementation. We analyze the complexity of the resulting design using a VLSI model of computation, showing that it is optimal with respect to both its period and latency. In this sense the design compares favorably with other recent VLSI multiplier designs. © 1983, ACM. All rights reserved.",complexity; layout; multiplier; VLSI,
How to Exchange (Secret) Keys,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976804419&doi=10.1145%2f357360.357368&partnerID=40&md5=44d89b316e06cd676bf4a52510e2bd3e,"A protocol is presented whereby two adversaries may exchange secrets, although neither trusts the other. The secrets are the prime factors of their publicly announced composite numbers. The two adversaries can exchange their secrets bit by bit, but each fears the other will cheat by sending “junk” bits. To solve this problem we show how each of the two can prove, for each bit delivered, that the bit is good. Applications are suggested to such electronic business transactions as signing contracts and sending certified electronic mail. © 1983, ACM. All rights reserved.",cryptography; factorization; protocols; public key encryption; secrets; Security; transaction protection protocols,
Distributed Deadlock Detection,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976860609&doi=10.1145%2f357360.357365&partnerID=40&md5=7cb6c73828f94ea47bc89213da8e20c7,"Distributed deadlock models are presented for resource and communication deadlocks. Simple distributed algorithms for detection of these deadlocks are given. We show that all true deadlocks are detected and that no false deadlocks are reported. In our algorithms, no process maintains global information; all messages have an identical short length. The algorithms can be applied in distributed database and other message communication systems. © 1983, ACM. All rights reserved.",communication deadlock; Distributed deadlock detection; message communication systems; resource deadlock,
Preface: Special Issue on Measurement and Modeling of Computer Systems,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976853867&doi=10.1145%2f357360.357361&partnerID=40&md5=66454b32100c943f6e3ecd69a0c95c2d,[No abstract available],,
Implementing Atomic Actions on Decentralized Data,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976737350&doi=10.1145%2f357353.357355&partnerID=40&md5=9cb36dca976749acb050eb7cc9c381cf," Synchronization of accesses to shared data and recovering the state of such data in the case of failures are really two aspects of the same problem—implementing atomic actions on a related set of data items. In this paper a mechanism that solves both problems simultaneously in a way that is compatible with requirements of decentralized systems is described. In particular, the correct construction and execution of a new atomic action can be accomplished without knowledge of all other atomic actions in the system that might execute concurrently. Further, the mechanisms degrade gracefully if parts of the system fail: only those atomic actions that require resources in failed parts of the system are prevented from executing, and there is no single coordinator that can fail and bring down the whole system. © 1983, ACM. All rights reserved.",nested atomic actions; stable storage; time-domain addressing; two-phase commit,
Performance Bound Hierarchies for Queueing Networks,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976719692&doi=10.1145%2f357360.357363&partnerID=40&md5=2aa2ffb345733803891a906b208c2a7a,"In applications of queueing network models to computer system performance prediction, the computational effort required to obtain an exact equilibrium solution of a model may not be justified by the accuracy actually required. In these cases, there is a need for approximation or bounding techniques that can provide the necessary information with less computational effort. This paper presents a new technique that yields performance bounds for single-class separable queueing networks consisting of fixed-rate and delay service centers. Unlike previous approximation or bounding techniques, there is a smooth trade-off between computational effort and accuracy. Any level of accuracy (including the exact solution) can be guaranteed by investing the necessary computational effort. Performance bounds that are sufficiently tight for most practical purposes may be obtained with a fraction of the effort required for the exact solution. Since bounds are produced, as opposed to approximations, guarantees about the accuracy of a model solution can be provided. © 1983, ACM. All rights reserved.",asymptotic analysis; balanced job bounds; bounding analysis; product form networks,
Cache Performance in the VAX-11/780,1983,ACM Transactions on Computer Systems (TOCS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976743569&doi=10.1145%2f357353.357356&partnerID=40&md5=16b9d736dc3c01573ad9238d2471fc86,[No abstract available],hardware monitor; hit ratio,
