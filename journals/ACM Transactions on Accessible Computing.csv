Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
Development of a remote therapy tool for childhood apraxia of speech,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954190775&doi=10.1145%2f2776895&partnerID=40&md5=ca698519da0c93f210df13193b0cceec,"We present a multitier system for the remote administration of speech therapy to children with apraxia of speech. The system uses a client-server architecture model and facilitates task-oriented remote therapeutic training in both in-home and clinical settings. The system allows a speech language pathologist (SLP) to remotely assign speech production exercises to each child through a web interface and the child to practice these exercises in the form of a game on a mobile device. The mobile app records the child's utterances and streams them to a back-end server for automated scoring by a speech-analysis engine. The SLP can then review the individual recordings and the automated scores through a web interface, provide feedback to the child, and adapt the training program as needed. We have validated the system through a pilot study with children diagnosed with apraxia of speech, their parents, and SLPs. Here, we describe the overall client-server architecture, middleware tools used to build the system, speech-analysis tools for automatic scoring of utterances, and present results from a clinical study. Our results support the feasibility of the system as a complement to traditional face-to-face therapy through the use of mobile tools and automated speech analysis algorithms. © 2015 ACM.",Automated speech analysis; Childhood apraxia of speech; Speech therapy,Automation; Client server computer systems; Computer architecture; Middleware; Mobile devices; Speech analysis; Analysis algorithms; Automatic scoring; Client-server architectures; Clinical settings; Remote administration; Speech language pathologists; Speech production; Speech therapy; Speech
Evaluating intelligibility and battery drain of mobile sign language video transmitted at low frame rates and bit rates,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954141176&doi=10.1145%2f2797142&partnerID=40&md5=3d7c22c5381d0720baf393b28eb624f5,"Mobile sign language video conversations can become unintelligible if high video transmission rates cause network congestion and delayed video. In an effort to understand the perceived lower limits of intelligible sign language video intended for mobile communication, we evaluated sign language video transmitted at four low frame rates (1, 5, 10, and 15 frames per second [fps]) and four low fixed bit rates (15, 30, 60, and 120 kilobits per second [kbps]) at a constant spatial resolution of 320 × 240 pixels. We discovered an ""intelligibility ceiling effect,"" in which increasing the frame rate above 10fps did not improve perceived intelligibility, and increasing the bit rate above 60kbps produced diminishing returns. Given the study parameters, our findings suggest that relaxing the recommended frame rate and bit rate to 10fps at 60kbps will provide intelligible video conversations while reducing total bandwidth consumption to 25% of the ITU-T standard (at least 25fps and 100kbps). As part of this work, we developed the Human Signal Intelligibility Model, a new conceptual model useful for informing evaluations of video intelligibility and our methodology for creating linguistically accessible web surveys for deaf people. We also conducted a battery-savings experiment quantifying battery drain when sign language video is transmitted at the lower frame rates and bit rates. Results confirmed that increasing the transmission rates monotonically decreased the battery life. © 2015 ACM.",American Sign Language; Battery power; Bit rate; Communication model; Comprehension; Deaf community; Frame rate; Intelligibility; Mobile phone; Smartphone; Video compression; Web survey,Electric batteries; Image coding; Image communication systems; Image compression; Mobile phones; Mobile telecommunication systems; Speech intelligibility; Surveys; American sign language; Battery power; Bit rates; Communication modeling; Comprehension; Deaf community; Frame rate; Web surveys; Computational linguistics
Audio-based feedback techniques for teaching touchscreen gestures,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954211491&doi=10.1145%2f2764917&partnerID=40&md5=c0a533f0a725f9c1d95bde8a5a90b542,"While sighted users may learn to perform touchscreen gestures through observation (e.g., of other users or video tutorials), such mechanisms are inaccessible for users with visual impairments. As a result, learning to perform gestures without visual feedback can be challenging. We propose and evaluate two techniques to teach touchscreen gestures to users with visual impairments: (1) gesture sonification to generate sound based on finger touches, creating an audio representation of a gesture; and (2) corrective verbal feedback that combined automatic analysis of the user's drawn gesture with speech feedback. To refine and evaluate the techniques, we conducted three controlled laboratory studies. The first study, with 12 sighted participants, compared parameters for sonifying gestures in an eyes-free scenario. We identified pitch+stereo panning as the best combination. In the second study, ten blind and low-vision participants completed gesture replication tasks for single-stroke, multistroke, and multitouch gestures using the gesture sonification feedback. We found that multistroke gestures were more difficult to understand in sonification, but that playing each finger sound serially may improve understanding. In the third study, six blind and low-vision participants completed gesture replication tasks with both the sonification and corrective verbal feedback techniques. Subjective data and preliminary performance findings indicated that the techniques offer complementary advantages: although verbal feedback was preferred overall primarily due to the precision of its instructions, almost all participants appreciated the sonification for certain situations (e.g., to convey speed). This article extends our previous publication on gesture sonification by extending these techniques to multistroke and multitouch gestures. These findings provide a foundation for nonvisual training systems for touchscreen gestures. © 2015 ACM.",Blindness; Gestures; Sonification; Touchscreen; Visual impairments,Audio acoustics; Teaching; Touch screens; Visual communication; Audio representation; Blindness; Controlled laboratories; Feedback techniques; Gestures; Multi-touch gestures; Sonifications; Visual impairment; Stereo image processing
Guiding novice web workers in making image descriptions using templates,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948392249&doi=10.1145%2f2764916&partnerID=40&md5=fdb8fb5fc275a4ba6ed94591504fc20a,"This article compares two methods of employing novice Web workers to author descriptions of science, technology, engineering, and mathematics images to make them accessible to individuals with visual and print-reading disabilities. The goal is to identify methods of creating image descriptions that are inexpensive, effective, and follow established accessibility guidelines. The first method explicitly presented the guidelines to the worker, then the worker constructed the image description in an empty text box and table. The second method queried the worker for image information and then used responses to construct a templatebased description according to established guidelines. The descriptions generated through queried image description (QID) were more likely to include information on the image category, title, caption, and units. They were also more similar to one another, based on Jaccard distances of q-grams, indicating that their word usage and structure were more standardized. Last, the workers preferred describing images using QID and found the task easier. Therefore, explicit instruction on image-description guidelines is not sufficient to produce quality image descriptions when using novice Web workers. Instead, it is better to provide information about images, then generate descriptions from responses using templates. 2015 Copyright is held by the owner/author(s). Publication rights licensed to ACM.",Access Technology; Accessibility (blind and visually impaired); Crowdsourcing; Human computation; Image description,"Computer applications; Crowdsourcing; Human computer interaction; Access technology; Accessibility guidelines; Blind and visually impaired; Human computation; Image descriptions; Image information; Jaccard distance; Science , technology , engineering , and mathematics; Image analysis"
A performance comparison of on-hand versus on-phone nonvisual input by blind and sighted users,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948399957&doi=10.1145%2f2820616&partnerID=40&md5=f3ce806bfc6a9335b25b9f87c38d2783,"On-body interaction, in which the user employs one's own body as an input surface, has the potential to provide efficient mobile computing access for blind users. It offers increased tactile and proprioceptive feedback compared to a phone and, because it is always available, it should allow for quick audio output control without having to retrieve the phone from a pocket or bag. Despite this potential, there has been little investigation of on-body input for users with visual impairments. To assess blind users' performance with on-body input versus touchscreen input, we conducted a controlled lab study with 12 sighted and 11 blind participants. Study tasks included basic pointing and drawing more complex shape gestures. Our findings confirm past work with sighted users showing that the hand results in faster pointing than the phone. Most important, we also show that: (1) the performance gain of the hand applies to blind users as well, (2) the accuracy of where the pointing finger first lands is higher with the hand than the phone, (3) on-hand pointing performance is affected by the location of targets, and (4) shape gestures drawn on the hand result in higher gesture recognition rates than those on the phone. Our findings highlight the potential of on-body input to support accessible nonvisual mobile computing. © 2015 ACM.",Blindness; Mobile computing; Nonvisual interaction; On-body interaction; User study,Mobile computing; Blindness; Input surfaces; Non-visual interaction; On-body interactions; Performance comparison; Performance Gain; User study; Visual impairment; Telephone sets
Iterative design and field trial of an aphasia-friendly email tool,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948403825&doi=10.1145%2f2790305&partnerID=40&md5=eb21bbe2c8ffbb8643929e5b6603777f,"In this article, we describe the iterative design and field trial of Amail, an email client specifically designed for people with aphasia who have problems expressing themselves verbally. We conducted a 3-month study with eight persons with aphasia to better understand how people with aphasia could integrate Amail in their daily life. Subjective data (questionnaires, interviews, and diaries) and objective data (usage logs) were collected to gain understanding of the usage patterns. All persons with aphasia in our study were able to use Amail independently, and four participants continued using Amail after the study period. The usage patterns, especially the frequency and length of the composed email messages, indicated that, over time, persons with aphasia were able to improve their email communication. Email partners also had the impression that their email partners with aphasia were improving gradually. Last but not least, the use of Amail positively influenced the number and quality of social contacts for the persons with aphasia. We also report some of the challenges encountered while conducting the field trial. © 2015 ACM.",Aphasia; Assistive technology; Augmentative and alternative communication; Email; Field evaluation,Human rehabilitation engineering; Surveys; Aphasia; Assistive technology; Augmentative-and-alternative communication; Email communication; Field evaluation; Iterative design; Social contacts; Usage patterns; Electronic mail
"Introduction to the ASSETS'13 special issue, Part 2",2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946563887&doi=10.1145%2f2825095&partnerID=40&md5=f4644a222a5e1711ab892fd196718a54,[No abstract available],,
Towards fully automated motion capture of signs - Development and evaluation of a key word signing avatar,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935145760&doi=10.1145%2f2764918&partnerID=40&md5=c4c141dffae35874a90322c7e7bc09b4,"Motion capture of signs provides unique challenges in the field of multimodal data collection. The dense packaging of visual information requires high fidelity and high bandwidth of the captured data. Even though marker-based optical motion capture provides many desirable features such as high accuracy, global fitting, and the ability to record body and face simultaneously, it is not widely used to record finger motion, especially not for articulated and syntactic motion such as signs. Instead, most signing avatar projects use costly instrumented gloves, which require long calibration procedures. In this article, we evaluate the data quality obtained from optical motion capture of isolated signs from Swedish sign language with a large number of low-cost cameras. We also present a novel dual-sensor approach to combine the data with lowcost, five-sensor instrumented gloves to provide a recording method with low manual postprocessing. Finally, we evaluate the collected data and the dual-sensor approach as transferred to a highly stylized avatar. The application of the avatar is a game-based environment for training Key Word Signing (KWS) as augmented and alternative communication (AAC), intended for children with communication disabilities. © 2015 ACM.",Augmentative and alternative communication (AAC); Motion capture; Sign language; Virtual characters,Computational linguistics; Human rehabilitation engineering; Alternative communication; Augmentative-and-alternative communication; Calibration procedure; Instrumented glove; Motion capture; Optical motion capture; Sign language; Virtual character; Quality control
Perspectives on speech and language interaction for daily Assistive Technology: Introduction to Part 2 - Speaking and Reading Aids,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933036110&doi=10.1145%2f2767690&partnerID=40&md5=ba4252799427654cacf571ae424dd2fb,[No abstract available],,
Perspectives on speech and language interaction for daily assistive technology: Introduction to Part 1 of the special issue,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931272299&doi=10.1145%2f2756765&partnerID=40&md5=97f75abbd43dc2c2244d0946e34d90fc,[No abstract available],,
Investigating information search by people with cognitive disabilities,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930788790&doi=10.1145%2f2729981&partnerID=40&md5=11fe1bbe1162b68ca2b973d9e20fbe9b,"The ability to gather information online has become increasingly important in the past decades. Previous research suggests that people with cognitive disabilities experience challenges when finding information on websites. Although a number of studies examined the impact of various design guidelines on information search by people with cognitive disabilities, our knowledge in this topic remains limited. To date, no study has been conducted to examine how people with cognitive disabilities navigate in different content structures. We completed an empirical study to investigate the impact of different search methods and content structures on the search behavior of people with cognitive disabilities. 23 participants with various cognitive disabilities completed 15 information search tasks under three conditions: browsing a website with a deep structure (4 x 4 x 4 x 4), browsing a website with a broad structure (16 x 16), and searching through a search engine. The results suggest that the participants overwhelmingly preferred the search engine method to the two browsing conditions. The broad structure resulted in significantly higher failure rates than the search engine condition and the deep structure condition. The causes of failed search tasks were analyzed in detail. Participants frequently visited incorrect categories in both the deep structure and the broad structure conditions. However, it was more difficult to recover from incorrect categories on the lower-level pages in the broad structure than in the deep structure. Under the search engine condition, failed tasks were mainly caused by difficulty in selecting the correct link from the returned list, misspellings, and difficulty in generating appropriate search. © 2015 ACM.",Cognitive disabilities; Information search,Behavioral research; Failure analysis; Information retrieval; Websites; Cognitive disability; Content structure; Deep structure; Empirical studies; Engine conditions; Information search; Search behavior; Structure conditions; Search engines
Reconstruction of phonated speech from whispers using formant-derived plausible pitch modulation,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995588395&doi=10.1145%2f2737724&partnerID=40&md5=200c2845c480d7bc02cb58763742cf0d,"Whispering is a natural, unphonated, secondary aspect of speech communications for most people. However, it is the primary mechanism of communications for some speakers who have impaired voice production mechanisms, such as partial laryngectomees, as well as for those prescribed voice rest, which often follows surgery or damage to the larynx. Unlike most people, who choose when to whisper and when not to, these speakers may have little choice but to rely on whispers for much of their daily vocal interaction. Even though most speakers will whisper at times, and some speakers can only whisper, the majority of today's computational speech technology systems assume or require phonated speech. This article considers conversion of whispers into natural-sounding phonated speech as a noninvasive prosthetic aid for people with voice impairments who can only whisper. As a by-product, the technique is also useful for unimpaired speakers who choose to whisper. Speech reconstruction systems can be classified into those requiring training and those that do not. Among the latter, a recent parametric reconstruction framework is explored and then enhanced through a refined estimation of plausible pitch from weighted formant differences. The improved reconstruction framework, with proposed formant-derived artificial pitch modulation, is validated through subjective and objective comparison tests alongside state-of-the-art alternatives. © 2015 ACM.",Algorithms; Design; H.5.2 [information interfaces and presentation]: user interfaces; Performance; Voice reconstruction; Whisper-to-speech conversion; Whispers,Algorithms; Design; Modulation; Speech; User interfaces; H.5.2 [Information Interfaces and Presentation]: User Interfaces; Performance; Reconstruction frameworks; Reconstruction systems; Speech conversion; Speech technology; Vocal interaction; Whispers; Continuous speech recognition
Intelligibility assessment and speech recognizer word accuracy rate prediction for dysarthric speakers in a factor analysis subspace,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931275361&doi=10.1145%2f2746405&partnerID=40&md5=2f5659d4d18a7be49faf8592e5c2683b,"Automated intelligibility assessments can support speech and language therapists in determining the type of dysarthria presented by their clients. Such assessments can also help predict how well a person with dysarthria might cope with a voice interface to assistive technology. Our approach to intelligibility assessment is based on iVectors, a set of measures that capture many aspects of a person's speech, including intelligibility. The major advantage of iVectors is that they compress all acoustic information contained in an utterance into a reduced number of measures, and they are very suitable to be used with simple predictors. We show that intelligibility assessments work best if there is a pre-existing set of words annotated for intelligibility from the speaker to be evaluated, which can be used for training our system. We discuss the implications of our findings for practice. © 2015 ACM.",ASR accuracy prediction; Dysarthria; Factor analysis; Intelligibility assessment; iVectors,Factor analysis; Forecasting; Multivariant analysis; Accuracy prediction; Acoustic information; Assistive technology; Dysarthria; I-vectors; Intelligibility assessment; Language therapist; Speech recognizer; Speech intelligibility
Evaluating a collaborative iPad game's impact on social relationships for children with autism spectrum disorder,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930788308&doi=10.1145%2f2751564&partnerID=40&md5=702647e8df0c032b4b0824ce6acbbaee,"This article describes how collaborative assistive technologies, housed on off-the-shelf, low-cost platforms such as the iPad, can be used to facilitate social relationships in children with autism spectrum disorder (ASD). Through an empirical study of the use of a collaborative iPad game, Zody, we explore how assistive technologies can be used to support social relationships, even without intervention from adults. We discuss how specific design choices can encourage three levels of social relationship: membership, partnership, and friendship. This work contributes to research on both assistive technologies and collaborative gaming through a framework that describes how specific in-game elements can foster social skill development for children with ASD. © 2015 Association for Computing Machinery.",ASD; Autism; Collaborative games; Cooperation; IPad; Social; Social skills,Diseases; Hand held computers; Social aspects; Autism; Collaborative games; Cooperation; IPad; Social; Social skills; Economic and social effects
Making it Simplext: Implementation and evaluation of a text simplification system for Spanish,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995611763&doi=10.1145%2f2738046&partnerID=40&md5=233a7d84d274651c2ead7eb0a7f96eb0,"The way in which a text is written can be a barrier for many people. Automatic text simplification is a natural language processing technology that, when mature, could be used to produce texts that are adapted to the specific needs of particular users. Most research in the area of automatic text simplification has dealt with the English language. In this article, we present results from the Simplext project, which is dedicated to automatic text simplification for Spanish. We present a modular system with dedicated procedures for syntactic and lexical simplification that are grounded on the analysis of a corpus manually simplified for people with special needs. We carried out an automatic evaluation of the system's output, taking into account the interaction between three different modules dedicated to different simplification aspects. One evaluation is based on readability metrics for Spanish and shows that the system is able to reduce the lexical and syntactic complexity of the texts. We also show, by means of a human evaluation, that sentence meaning is preserved in most cases. Our results, even if our work represents the first automatic text simplification system for Spanish that addresses different linguistic aspects, are comparable to the state of the art in English Automatic Text Simplification. © 2015 ACM.",Human evaluation; I.2.7 [natural language processing]: text analysis; Readability measures; Spanish; Syntactic simplification; Text simplification corpus; Text simplification; lexical simplification,Syntactics; Human evaluation; Readability measures; Spanish; Text analysis; Text simplification corpus; Text simplification; lexical simplification; Natural language processing systems
Perspectives on speech and language interaction for daily assistive technology: Overall introduction to the special issue part 3,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937914676&doi=10.1145%2f2791576&partnerID=40&md5=926c0f830ece9b93d2af177bd62c3f21,[No abstract available],,
Individuality-preserving voice conversion for articulation disorders using phoneme-categorized exemplars,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995570285&doi=10.1145%2f2738048&partnerID=40&md5=9561b8f44cbef0d9014e7f1c9cd8f948,"We present a voice conversion (VC) method for a person with an articulation disorder resulting from athetoid cerebral palsy. Themovements of such speakers are limited by their athetoid symptoms and their consonants are often unstable or unclear, which makes it difficult for them to communicate. Exemplar-based spectral conversion using Nonnegative Matrix Factorization (NMF) is applied to a voice from a speaker with an articulation disorder. In our conventional work, we used a combined dictionary that was constructed from the source speaker's vowels and the consonants from a target speaker without articulation disorders in order to preserve the speaker's individuality. However, this conventional exemplar-based approach needs to use all the training exemplars (frames), and it may cause mismatching of phonemes between input signals and selected exemplars. In order to reduce the mismatching of phoneme alignment, we propose a phoneme-categorized subdictionary and a dictionary selection method using NMF. The effectiveness of this method was confirmed by comparing its effectiveness with that of a conventional Gaussian Mixture Model (GMM)-based and a conventional exemplar-based method. © 2015 ACM.",Algorithms; Articulation disorders; Assistive technologies; I.5.4 [applications]: signal processing; Languages; NMF; Voice conversion; Voice reconstruction,Algorithms; Factorization; Gaussian distribution; Linguistics; Matrix algebra; Query languages; Signal processing; Assistive technology; Exemplar based methods; Gaussian Mixture Model; Nonnegative matrix factorization; Phoneme alignments; Selection methods; Spectral conversion; Voice conversion; Speech processing
Evaluation of a context-aware voice interface for ambient assisted living: Qualitative user study vs. quantitative system evaluation,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930344336&doi=10.1145%2f2738047&partnerID=40&md5=8a2feb585ff8368dcb1e34255ec9f423,"This article presents an experiment with seniors and people with visual impairment in a voice-controlled smart home using the SWEET-HOME system. The experiment shows some weaknesses in automatic speech recognition that must be addressed, as well as the need for better adaptation to the user and the environment. Users were disturbed by the rigid structure of the grammar and were eager to adapt it to their own preferences. Surprisingly, while no humanoid aspect was introduced in the system, the senior participants were inclined to embody the system. Despite these aspects to improve, the system has been favorably assessed as diminishing most participant fears related to the loss of autonomy.",Ambient intelligence; Assistive technology; Context-aware interaction; Smart home; User evaluation; Voice command,Ambient intelligence; Assisted living; Automation; Assistive technology; Context-aware interaction; Smart homes; User evaluations; Voice command; Speech recognition
Measuring the performance of a location-aware text prediction system,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930809142&doi=10.1145%2f2739998&partnerID=40&md5=f0d9acae16539056585fcce2518b5a3e,"In recent years, some works have discussed the conception of location-aware Augmentative and Alternative Communication (AAC) systems with very positive feedback from participants. However, in most cases, complementary quantitative evaluations have not been carried out to confirm those results. To contribute to clarifying the validity of these approaches, our study quantitatively evaluated the effect of using language models with location knowledge on the efficiency of a word and sentence prediction system. Using corpora collected for three different locations (classroom, school cafeteria, home), location-specific language models were trained with sentences from each location and compared with a traditional all-purpose language model, trained on all corpora. User tests showed a modest mean improvement of 2.4% and 1.3% for Words Per Minute (WPM) and Keystroke Saving Rate (KSR), respectively, but the differences were not statistically significant. Since our text prediction system relies on the concept of sentence reuse, we ran a set of simulations with language models having different sentence knowledge levels (0%, 25%, 50%, 75%, 100%). We also introduced in the comparison a second location-aware strategy that combines the location-specific approach with the all-purpose approach (mixed approach). The mixed language models performed better under low sentence-reuse conditions (0%, 25%, 50%) with 1.0%, 1.3%, and 1.2% KSR improvements, respectively. The location-specific language models performed better under high sentence-reuse conditions (75%, 100%) with 1.7% and 1.5% KSR improvements, respectively. © 2015 ACM.",Augmentative and alternative communication; Communication rate; Location-awareness; Sentence prediction; Word prediction,Computational linguistics; Forecasting; Human rehabilitation engineering; Augmentative-and-alternative communication; Communication rate; Location awareness; Prediction systems; Quantitative evaluation; Specific languages; Text prediction system; Word prediction; Location
Speech interaction with personal assistive robots supporting aging at home for individuals with Alzheimer's disease,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930328137&doi=10.1145%2f2744206&partnerID=40&md5=942a6aac541c398fca0cf3824f6ffe6e,"Increases in the prevalence of dementia and Alzheimer's disease (AD) are a growing challenge in many nations where healthcare infrastructures are ill-prepared for the upcoming demand for personal caregiving. To help individuals with AD live at home for longer, we are developing a mobile robot, called ED, intended to assist with activities of daily living through visual monitoring and verbal prompts in cases of difficulty. In a series of experiments, we study speech-based interactions between ED and each of 10 older adults with AD as the latter complete daily tasks in a simulated home environment. Traditional automatic speech recognition is evaluated in this environment, along with rates of verbal behaviors that indicate confusion or trouble with the conversation. Analysis reveals that speech recognition remains a challenge in this setup, especially during household tasks with individuals with AD. Across the verbal behaviors that indicate confusion, older adults with AD are very likely to simply ignore the robot, which accounts for over 40% of all such behaviors when interacting with the robot. This work provides a baseline assessment of the types of technical and communicative challenges that will need to be overcome for robots to be used effectively in the home for speech-based assistance with daily living. © 2015 ACM.",Alzheimer's disease; Automatic speech recognition; Human-computer interaction; Mobile robotics; Smart home,Automation; Human computer interaction; Neurodegenerative diseases; Social robots; Speech; Activities of Daily Living; Alzheimer's disease; Automatic speech recognition; Baseline assessment; Healthcare infrastructure; Mobile robotic; Smart homes; Speech interaction; Speech recognition
Automatic detection of phone-based anomalies in dysarthric speech,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930164762&doi=10.1145%2f2739050&partnerID=40&md5=3b1bdcc8694908a082431349e099583f,"Perceptual evaluation is still the most common method in clinical practice for diagnosing and following the progressionofthe conditionofpeople with speech disorders. Although a numberofstudies have addressed the acoustic analysis of speech productions exhibiting impairments, additional descriptive analysis is required to manage interperson variability, considering speakers with the same condition or across different conditions. In this context, this article investigates automatic speech processing approaches dedicated to the detection and localization of abnormal acoustic phenomena in speech signal produced by people with speech disorders. This automatic process aims at enhancing the manual investigation of human experts while at the same time reducing the extent of their intervention by calling their attention to specific parts of the speech considered as atypical from an acoustical point of view. Two different approaches are proposed in this article. The first approach models only the normal speech, whereas the second models both normal and dysarthric speech. Both approaches are evaluated following two strategies: one consists of a strict phone comparison between a human annotation of abnormal phones and the automatic output, while the other uses a ""one-phone delay"" for the comparison. The experimental evaluation of both approaches for the task of detecting acoustic anomalies was conducted on two different corpora composed of French dysarthric speakers and control speakers. These approaches obtain very encouraging results and their potential for clinical uses with different types of dysarthria and neurological diseases is quite promising. © 2015 ACM 1936-7228/2015/05-ART9 15.00.",Automatic speech processing; Dysarthria; Objective detection of acoustic anomalies; Speech disorders; Supervised classification,Acoustics; Audio signal processing; Diagnosis; Speech processing; Telephone sets; Acoustic anomalies; Automatic speech processing; Dysarthria; Speech disorders; Supervised classification; Speech recognition
Automatic assessment of speech capability loss in disordered speech,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930158853&doi=10.1145%2f2739051&partnerID=40&md5=e7693a5828c6e59df5601ceca24facec,"In this article, we report on the use of an automatic technique to assess pronunciation in the context of several types of speech disorders. Even if such tools already exist, they are more widely used in a different context, namely, Computer-Assisted Language Learning, in which the objective is to assess nonnative pronunciation by detecting learners' mispronunciations at segmental and/or suprasegmental levels. In our work, we sought to determine if the Goodness of Pronunciation (GOP) algorithm, which aims to detect phone-level mispronunciations by means of automatic speech recognition, could also detect segmental deviances in disordered speech. Our main experiment is an analysis of speech from people with unilateral facial palsy. This pathology may impact the realization of certain phonemes such as bilabial plosives and sibilants. Speech read by 32 speakers at four different clinical severity grades was automatically aligned and GOP scores were computed for each phone realization. The highest scores, which indicate large dissimilarities with standard phone realizations, were obtained for the most severely impaired speakers. The corresponding speech subset was manually transcribed at phone level; 8.3% of the phones differed from standard pronunciations extracted from our lexicon. The GOP technique allowed the detection of 70.2% of mispronunciations with an equal rate of about 30% of false rejections and false acceptances. Finally, to broaden the scope of the study, we explored the correlation between GOP values and speech comprehensibility scores on a second corpus, composed of sentences recorded by six people with speech impairments due to cancer surgery or neurological disorders. Strong correlations were achieved between GOP scores and subjective comprehensibility scores (about 0.7 absolute). Results from both experiments tend to validate the use of GOP to measure speech capability loss, a dimension that could be used as a complement to physiological measures in pathologies causing speech disorders. © 2015 ACM 1936-7228/2015/05-ART8 15.00.",Automatic assessment of pronunciation; Disordered speech; Goodness of Pronunciation,Computer aided instruction; Pathology; Speech recognition; Telephone sets; Automatic assessment; Automatic speech recognition; Automatic technique; Computer assisted language learning; Goodness of Pronunciation; Neurological disorders; Physiological measures; Strong correlation; Speech
Introduction to the ASSETS'13 special issue,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929164723&doi=10.1145%2f2737200&partnerID=40&md5=4fa036f4d31169205d0c01970c9fe1bd,[No abstract available],,
Experiences of someone with a neuromuscular disease in operating a PC (and ways to successfully overcome challenges),2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924765595&doi=10.1145%2f2700436&partnerID=40&md5=be6f14a6517667092b899b699293dc47,"This article describes the experiences of the first author, who was diagnosed with the neuromuscular disease Friedreich's Ataxia more than 25 years ago, with the innovative approach to human-computer interaction characterized by the software toolOnScreenDualScribe. Originally developed by (and for!) the first author, the tool replaces the standard input devices-that is, keyboard and mouse-with a small numeric keypad, making optimal use of his abilities. This work attempts to illustrate some of the difficulties the first author usually has to face when operating a computer, due to considerable motor problems. The article will discuss what he tried in the past, and whyOnScreenDualScribe, offering various assistive techniques-including word prediction, an ambiguous keyboard, and stepwise pointing operations-is indeed a viable alternative. In a pilot study that was repeated multiple times with slight variations over a period of 3 years, the first author's entry rate withOnScreenDualScribe(including early versions of the tool) increased from 1.38wpm to 6.16wpm, while his achievable typing rate went from 12wpm to 3.5wpm in the course of 24 years. However, the ultimate goal is to help not just one single person, but to make the system-which not only accelerates entry, but also clearly reduces the required effort-available to anyone with similar conditions. © 2015 ACM 1936-7228/2015/03-ART4 $15.00.",Ambiguous keyboard; Dysarthria; Friedreich's Ataxia; Human-computer interaction; Keyboard replacement; Mouse emulator; Neuromuscular disease; Word prediction,Human computer interaction; Neurodegenerative diseases; Neuromuscular rehabilitation; Neurophysiology; Ambiguous keyboard; Dysarthria; Friedreich's ataxias; Keyboard replacement; Mouse emulator; Neuromuscular disease; Word prediction; Mammals
Designing wheelchair-based movement games,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924808579&doi=10.1145%2f2724729&partnerID=40&md5=426251cae4c8fe0396e9c24c2052684c,"People using wheelchairs have access to fewer sports and other physically stimulating leisure activities than nondisabled persons, and often lead sedentary lifestyles that negatively influence their health.While motionbased video games have demonstrated great potential of encouraging physical activity among nondisabled players, the accessibility of motion-based games is limited for persons with mobility disabilities, thus also limiting access to the potential health benefits of playing these games. In our work, we address this issue through the design of wheelchair-accessiblemotion-based game controls.We present KINECTWheels, a toolkit designed to integrate wheelchair movements into motion-based games. Building on the toolkit, we developed CupcakeHeaven, a wheelchair-based video game designed for older adults using wheelchairs, and we created Wheelchair Revolution, a motion-based dance game that is accessible to both persons using wheelchairs and nondisabled players. Evaluation results show that KINECTWheels can be applied tomakemotion-based games wheelchair-accessible, and that wheelchair-based games engage broad audiences in physically stimulating play. Through the application of the wheelchair as an enabling technology in games, our work has the potential of encouraging players of all ages to develop a positive relationship with their wheelchair. © 2015 ACM 1936-7228/2015/03-ART6 $15.00.",Accessibility; Assistive devices; Motion-based games; Older adults; Persons with mobility disabilities; Video games,Health; Wheelchairs; Accessibility; Assistive devices; Motion-based games; Older adults; Persons with mobility disabilities; Video game; Human computer interaction
Filteryedping: Design challenges and user performance of dwell-free eye typing,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925114373&doi=10.1145%2f2724728&partnerID=40&md5=b125eec62f860e2a23f50a312d2bdfde,"The ability to use the movements of the eyes to write is extremely important for individuals with a severe motor disability. With eye typing, a virtual keyboard is shown on the screen and the user enters text by gazing at the intended keys one at a time. With dwell-based eye typing, a key is selected by continuously gazing at it for a specific amount of time. However, this approach has two possible drawbacks: unwanted selections and slow typing rates. In this study, we propose a dwell-free eye typing technique that filters out unintentionally selected letters from the sequence of letters looked at by the user. It ranks possible words based on their length and frequency of use and suggests them to the user. We evaluated Filteryedping with a series of experiments. First, we recruited participants without disabilities to compare it with another potential dwell-free technique and with a dwell-based eye typing interface. The results indicate it is a fast technique that allows an average of 15.95 words per minute after 100min of typing. Then, we improved the technique through iterative design and evaluation with individuals who have severe motor disabilities. This phase helped to identify and create parameters that allow the technique to be adapted to different users. © 2015 ACM.",ALS; AltTyping; DMD; Dwell-free; Eye typing; Filteryedping; Gaze; Motor disability,Iterative methods; ALS; AltTyping; DMD; Dwell-free; Eye typing; Filteryedping; Gaze; Motor disability; Eye movements
Improving public transit accessibility for blind riders by crowdsourcing bus stop landmark locations with Google Street View: An extended analysis,2015,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924810720&doi=10.1145%2f2717513&partnerID=40&md5=66b62e2a1f8d76e0902ab9c7a7526367,"Low-vision and blind bus riders often rely on known physical landmarks to help locate and verify bus stop locations (e.g., by searching for an expected shelter, bench, or newspaper bin). However, there are currently few, if any, methods to determine this informationa priorivia computational tools or services. In this article, we introduce and evaluate a new scalable method for collecting bus stop location and landmark descriptions by combining online crowdsourcing and Google Street View (GSV). We conduct and report on three studies: (i) a formative interview study of 18 people with visual impairments to inform the design of our crowdsourcing tool, (ii) a comparative study examining differences between physical bus stop audit data and audits conducted virtually with GSV, and (iii) an online study of 153 crowd workers on Amazon Mechanical Turk to examine the feasibility of crowdsourcing bus stop audits using our custom tool with GSV. Our findings reemphasize the importance of landmarks in nonvisual navigation, demonstrate that GSV is a viable bus stop audit dataset, and show that minimally trained crowd workers can find and identify bus stop landmarks with 82.5% accuracy across 150 bus stop locations (87.3% with simple quality control). © 2015 ACM 1936-7228/2015/03-ART5 $15.00.",Accessible bus stops; Bus stop auditing; Crowdsourcing accessibility; Google Street View; Low-vision and blind users; Mechanical Turk; Remote data collection,Bus terminals; Bus transportation; Crowdsourcing; Location; Quality control; Scalability; Blind users; Bus stop; Google Street View; Mechanical turks; Remote data; Buses
Haptic 3D surface representation of table-based data for people with visual impairments,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919740513&doi=10.1145%2f2700433&partnerID=40&md5=fd1e7c2cb059cfe5bf271ba27d4154d9,"The UN Convention on the Rights of Persons with Disabilities Article 24 states that ""States Parties shall ensure inclusive education at all levels of education and life long learning."" This article focuses on the inclusion of people with visual impairments in learning processes including complex table-based data. Gaining insight into and understanding of complex data is a highly demanding task for people with visual impairments. Especially in the case of table-based data, the classic approaches of braille-based output devices and printing concepts are limited. Haptic perception requires sequential information processing rather than the parallel processing used by the visual system, which hinders haptic perception to gather a fast overview of and deeper insight into the data. Nevertheless, neuroscientific research has identified great dependencies between haptic perception and the cognitive processing of visual sensing. Based on these findings, we developed a haptic 3D surface representation of classic diagrams and charts, such as bar graphs and pie charts. In a qualitative evaluation study, we identified certain advantages of our relief-type 3D chart approach. Finally, we present an education model for German schools that includes a 3D printing approach to help integrate students with visual impairments. © 2014 ACM.",Haptic information perception; Inclusive education; Information visualization; People with visual impairments,Education computing; Graphic methods; Information systems; Neurophysiology; Cognitive processing; Inclusive education; Information perception; Information visualization; Persons with disabilities; Qualitative evaluations; Sequential information; Visual impairment; 3D printers
Accessing peer social interaction: Using authorable virtual peer technology as a component of a group social skills intervention program,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919742306&doi=10.1145%2f2700434&partnerID=40&md5=a7c2b641facf2831a2bba3503ef43758,"Autism spectrum and related communication and social disorders can severely affect some children's ability to engage in peer social interaction. In this article, we describe and evaluate an Authorable Virtual Peer (AVP), technology designed to help children access peer interactions by supporting them in developing critical social skills. Children interact with the AVP in three ways: (1) engaging in face-to-face interaction with a life-sized, computer-animated child; (2) creating new social behaviors for the AVP; and (3) controlling the AVP using a graphical user interface to select appropriate responses while the AVP interacts with another person. Our evaluation suggests that when an AVP is used as an activity during a social group intervention, a common intervention approach used with children with social and communication difficulties, that children's use of specific social behaviors critical to successful social interaction increases during role-play of common social situations with another child. © 2014 ACM.",Autism; Constructionism; Virtual peers,Artificial life; Graphical user interfaces; Autism; Constructionism; Face-to-face interaction; Intervention programs; New social behaviors; Peer interactions; Social interactions; Virtual peers; Diseases
Automatic task assistance for people with cognitive disabilities in brushing teeth-a user study with the tebra system,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897482459&doi=10.1145%2f2579700&partnerID=40&md5=fc7bc5e7ef2ce51d0fecf3ac32890771,"People with cognitive disabilities such as dementia and intellectual disabilities tend to have problems in coordinating steps in the execution of Activities of Daily Living (ADLs) due to limited capabilities in cognitive functioning. To successfully perform ADLs, these people are reliant on the assistance of human caregivers. This leads to a decrease of independence for care recipients and imposes a high burden on caregivers. Assistive Technology for Cognition (ATC) aims to compensate for decreased cognitive functions. ATC systems provide automatic assistance in task execution by delivering appropriate prompts which enable the user to perform ADLs without any assistance of a human caregiver. This leads to an increase of the user's independence and to a relief of caregiver's burden. In this article, we describe the design, development and evaluation of a novel ATC system. The TEBRA (TEeth BRushing Assistance) system supports people with moderate cognitive disabilities in the execution of brushing teeth. A main requirement for the acceptance of ATC systems is context awareness: explicit feedback from the user is not necessary to provide appropriate assistance. Furthermore, an ATC system needs to handle spatial and temporal variance in the execution of behaviors such as different movement characteristics and different velocities. The TEBRA system handles spatial variance in a behavior recognition component based on a Bayesian network classifier. A dynamic timing model deals with temporal variance by adapting to different velocities of users during a trial. We evaluate a fully functioning prototype of the TEBRA system in a study with people with cognitive disabilities. The main aim of the study is to analyze the technical performance of the system and the user's behavior in the interaction with the system with regard to the main hypothesis: is the TEBRA system able to increase the user's independence in the execution of brushing teeth? © 2014 ACM.",Automatic task assistance; Cognitive disabilities; User study,Behavioral research; Activities of daily living (ADLs); Automatic task assistance; Bayesian network classifiers; Cognitive disability; Intellectual disability; Movement characteristics; Spatial and temporal variances; User study; Handicapped persons
Identifying sign language videos in video sharing sites,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897564945&doi=10.1145%2f2579698&partnerID=40&md5=d5311b3794ff2b56adda14c930afd353,"Video sharing sites enable members of the sign language community to record and share their knowledge, opinions, and worries on a wide range of topics. As a result, these sites have formative digital libraries of sign language content hidden within their large overall collections. This article explores the problem of locating these sign language (SL) videos and presents techniques for identifying SL videos in such collections. To determine the effectiveness of existing text-based search for locating these SL videos, a series of queries were issued to YouTube to locate SL videos on the top 10 news stories of 2011 according to Yahoo!. Overall precision for the first page of results (up to 20 results) was 42%. An approach for automatically detecting SL video is then presented. Five video features considered likely to be of value were developed using standard background modeling and face detection. The article compares the results of an SVM classifier when given all permutations of these five features. The results show that a measure of the symmetry of motion relative to the face position provided the best performance of any single feature. When tested against a challenging test collection that included many likely false positives, an SVM provided with all five features achieved 82% precision and 90% recall. In contrast, the text-based search (queries with the topic terms and ASL or sign language) returned a significant portion of non-SL content-nearly half of all videos found. By our estimates, the application of video-based filtering techniques such as the one proposed here would increase precision from 42% for text-based queries up to 75%. © 2014 ACM.",ASL; Metadata extraction; Sign language; Video analysis; Video sharing,Digital libraries; Face recognition; ASL; Meta-data extractions; Sign language; Video analysis; Video sharing; Websites
Accessibility evaluation of classroom captions,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893353120&doi=10.1145%2f2543578&partnerID=40&md5=935bfd646215532dc015ac07d85e9826,"Real-time captioning enables deaf and hard of hearing (DHH) people to follow classroom lectures and other aural speech by converting it into visual text with less than a five second delay. Keeping the delay short allows end-users to follow and participate in conversations. This article focuses on the fundamental problem that makes real-time captioning difficult: sequential keyboard typing is much slower than speaking. We first surveyed the audio characteristics of 240 one-hour-long captioned lectures on YouTube, such as speed and duration of speaking bursts. We then analyzed how these characteristics impact caption generation and readability, considering specifically our human-powered collaborative captioning approach. We note that most of these characteristics are also present in more general domains. For our caption comparison evaluation, we transcribed a classroom lecture in real-time using all three captioning approaches. We recruited 48 participants (24 DHH) to watch these classroom transcripts in an eye-tracking laboratory. We presented these captions in a randomized, balanced order. We show that both hearing and DHH participants preferred and followed collaborative captions better than those generated by automatic speech recognition (ASR) or professionals due to the more consistent flow of the resulting captions. These results show the potential to reliably capture speech even during sudden bursts of speed, as well as for generating ""enhanced"" captions, unlike other human-powered captioning approaches. © 2014 ACM.",Crowdsourcing; Deaf; Hard of hearing; Real-time captioning,Computer applications; Human computer interaction; Accessibility evaluation; Automatic speech recognition; Classroom lecture; Crowdsourcing; Deaf; Hard of hearings; Human-powered; Real-time captioning; Audition
Greetings from the new editors-in-chief,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893356688&doi=10.1145%2f2557667&partnerID=40&md5=d5a41582bc82646ac5f12c75b98e9fcd,[No abstract available],,
Technology for supporting care staff in residential homes,2014,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893391184&doi=10.1145%2f2543577&partnerID=40&md5=ca7e35f5cc3af706dad7b0e942c0b22d,"Care staff, those who attend to the day-to-day needs of people in residential facilities, represent an important segment of the health-care provision of those entrusted to their care. The potential use of technology by care staff has not been a focus of researcher attention. The work reported here provides initial steps in addressing that gap, considering both the design requirements for this population and presentation of early work on a software system for use by care staff. We describe the development of a software tool for use by care staff, called Portrait, and report two studies related to factors affecting technology use by this population. The results of this research are promising, with Portrait being very positively received by care managers and care staff. Use of this software in a care home for over a month indicated continued use, with care staff returning to the system throughout the test period. The contributions of this research are the identification of factors important in working with a care staff population, the introduction and evaluation of a novel software tool for care staff in residential homes, and the highlighting of potential benefits of technology in assisting care staff. © 2014 ACM.",Care staff; Dementia; Person-centered care; Residential care,Research; Software testing; Care staff; Dementia; Person-centered care; Potential benefits; Residential care; Residential homes; Software systems; Technology use; Housing
Investigating user behavior for authentication methods: A comparison between individuals with down syndrome and neurotypical users,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885657821&doi=10.1145%2f2493171.2493173&partnerID=40&md5=188a6051141e595a22f564d5fc291274,"A wide variety of authentication mechanisms have been designed to ensure information security. Individuals with cognitive disabilities depend on computers and the Internet for a variety of tasks and, therefore, use authentication applications on an everyday basis. However, although there have been numerous studies investigating password usage by neurotypical users, there have been no research studies conducted to examine the use of authentication methods by individuals with cognitive disabilities. In this article, we systematically investigate how individuals with cognitive disabilities, specifically Down syndrome (DS), interact with various user authentication mechanisms. This research provides the first benchmark data on the performance of individuals with DS when using multiple authentication methods. It confirms that individuals with DS are capable of using the traditional alphanumeric passwords with reasonable efficiency. The passwords created by individuals with DS are of similar strength to those created by neurotypical people. Graphic passwords are not as effective as traditional alphanumeric and mnemonic passwords regarding efficiency, and are less preferred by the participants. Based on the findings of the study, we propose design guidelines that aim to assist both practitioners and researchers in designing and developing effective authentication applications that fit the specific needs of individuals with DS. © 2013 ACM.",Authentication; Cognitive disability; Down syndrome,Behavioral research; Benchmarking; Research; Security of data; Alphanumeric passwords; Authentication mechanisms; Authentication methods; Cognitive disability; Down syndrome; Multiple authentications; Research studies; User authentication; Authentication
Effect of Displaying Human Videos during an Evaluation Study of American Sign Language Animation,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886912905&doi=10.1145%2f2517038&partnerID=40&md5=93bae003e176fdce3cd0948979c21507,"Many researchers internationally are studying how to synthesize computer animations of sign language; such animations have accessibility benefits for people who are deaf and have lower literacy in written languages. The field has not yet formed a consensus as to how to best conduct evaluations of the quality of sign language animations, and this article explores an important methodological issue for researchers conducting experimental studies with participants who are deaf. Traditionally, when evaluating an animation, some lower and upper baselines are shown for comparison during the study. For the upper baseline, some researchers use carefully produced animations, and others use videos of human signers. Specifically, this article investigates, in studies where signers view animations of sign language and are asked subjective and comprehension questions, whether participants differ in their subjective and comprehension responses when actual videos of human signers are shown during the study. Through three sets of experiments, we characterize how the Likert-scale subjective judgments of participants about sign language animations are negatively affected when they are also shown videos of human signers for comparison - especially when displayed sideby- side. We also identify a small positive effect on the comprehension of sign language animations when studies also contain videos of human signers. Our results enable direct comparison of previously published evaluations of sign language animations that used different types of upper baselines - video or animation. Our results also provide methodological guidance for researchers who are designing evaluation studies of sign language animation or designing experimental stimuli or questions for participants who are deaf. Additional Key Words and Phrases: Accessibility technology for people who are deaf, American Sign Language, animation, baseline, user study © 2013 ACM 1936-7228/2013/10-ART4 15.00.",,Animation; Research; American sign language; Computer animation; Evaluation study; Key words; Sign language; User study; Quality control
Editorial,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886934740&doi=10.1145%2f2522990.2522991&partnerID=40&md5=8e2fe2a4cb2d64bb8ce4cbdbc375b9ec,[No abstract available],,
Distinguishing users by pointing performance in laboratory and real-world tasks,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886908523&doi=10.101145%2f2517039&partnerID=40&md5=b5ee3d58e51a96adc73cbb6aef396d66,"Accurate pointing is an obstacle to computer access for individuals who experience motor impairments. One of the main barriers to assisting individuals with pointing problems is a lack of frequent and low-cost assessment of pointing ability. We are working to build technology to automatically assess pointing problems during every day (or real-world) computer use. To this end, we have gathered and studied real-world pointing use from individuals with motor impairments and older adults. We have used this data to develop novel techniques to analyze pointing performance. In this article, we present learned statistical models that distinguish between pointing actions from diverse populations using real-world pointing samples. We describe how our models could be used to support individuals with different abilities sharing a computer, or one individual who experiences temporary pointing problems. Our investigation contributes to a better understanding of real-world pointing. We hope that these techniques will be used to develop systems that can automatically adapt to users' current needs in real-world computing environments.",Assistive technology; Pointing performance; Real-world data collection,Computer applications; Human computer interaction; Assistive technology; Computer access; Computing environments; Data collection; Motor impairments; Novel techniques; Pointing action; Real-world task; Population statistics
A haptic tool for group work on geometrical concepts engaging blind and sighted pupils,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885628555&doi=10.1145%2f2493171.2493172&partnerID=40&md5=7975e04b6fafdf3f85c5aa8f70da9c02,"General Terms: Design, Experimentation, Human Factors In the study presented here, two haptic and visual applications for learning geometrical concepts in group work in primary school have been designed and evaluated. The aim was to support collaborative learning among sighted and visually impaired pupils. The first application is a static flattened 3D environment that supports learning to distinguish between angles by means of a 3D haptic device providing touch feedback. The second application is a dynamic 3D environment that supports learning of spatial geometry. The scene is a room with a box containing geometrical objects, which pupils can pick up and move around. The applications were evaluated in four schools with groups of two sighted and one visually impaired pupil. The results showed the support for the visually impaired pupil and for the collaboration to be satisfying. A shared understanding of the workspace could be achieved, as long as the virtual environment did not contain movable objects. Verbal communication was crucial for the work process but haptic guiding to some extent substituted communication about direction. When it comes to joint action between visually impaired and sighted pupils a number of interesting problems were identified when the dynamic and static virtual environments were compared. These problems require further investigation. The study extends prior work in the areas of assistive technology and multimodal communication by evaluating functions for joint haptic manipulation in the unique setting of group work in primary school. © 2013 ACM.",,Communication; Human computer interaction; Three dimensional; Virtual reality; Assistive technology; Collaborative learning; Geometrical objects; Multimodal communications; Shared understanding; Verbal communications; Visual applications; Visually impaired; Geometry
Effects of target expansion on selection performance in older computer users,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885142519&doi=10.1145%2f2514848&partnerID=40&md5=38683cfd241489f5f072c260317a3698,"Point and click interactions using a mouse are an integral part of computer use for current desktop systems. Compared with younger users though, older adults experience greater difficulties performing cursor positioning tasks, and this can present limitations to using a computer easily and effectively. Target expansion is a technique for improving pointing performance where the target grows dynamically as the cursor approaches. This has the advantage that targets conserve screen real estate in their unexpanded state, yet can still provide the benefits of a larger area to click on. This article presents two studies of target expansion with older and younger participants, involving multidirectional point-select tasks with a computer mouse. Study 1 compares static versus expanding targets, and Study 2 compares static targets with three alternative techniques for expansion. Results show that expansion can improve times by up to 14%, and reduce error rates by up to 50%. Additionally, expanding targets are beneficial even when the expansion happens late in the movement, that is, after the cursor has reached the expanded target area or even after it has reached the original target area. The participants' subjective feedback on the target expansion are generally favorable, and this lends further support for the technique. © 2013 ACM.",Computer mouse; Expanding targets; Expansion; Older adults; Point and click; Target selection,Computer applications; Human computer interaction; Computer mouse; Computer users; Desktop system; Older adults; Point and click; Positioning tasks; Subjective feedback; Target selection; Expansion
Performing locomotion tasks in immersive computer games with an adapted eye-tracking interface,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885129692&doi=10.1145%2f2514856&partnerID=40&md5=0c26df79518a40a4d3e5e11fbdcae44f,"Young people with severe physical disabilities may benefit greatly from participating in immersive computer games. In-game tasks can be fun, engaging, educational, and socially interactive. But for those who are unable to use traditional methods of computer input such as a mouse and keyboard, there is a barrier to interaction that they must first overcome. Eye-gaze interaction is one method of input that can potentially achieve the levels of interaction required for these games. How we use eye-gaze or the gaze interaction technique depends upon the task being performed, the individual performing it, and the equipment available. To fully realize the impact of participation in these environments, techniques need to be adapted to the person's abilities. We describe an approach to designing and adapting a gaze interaction technique to support locomotion, a task central to immersive game playing. This is evaluated by a group of young people with cerebral palsy and muscular dystrophy. The results show that by adapting the interaction technique, participants are able to significantly improve their in-game character control. © 2013 ACM.",AAC; Accessible computing; Adaptive interface; Disability; Eye-gaze; Eye-tracking; Game accessibility,Interactive computer graphics; AAC; Accessible computing; Adaptive interface; Disability; Eye-gaze; Eye-tracking; Game accessibility; Computer games
Distinguishing Users by Pointing Performance in Laboratory and Real-World Tasks,2013,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024251476&doi=10.1145%2f2517039&partnerID=40&md5=2f789317a5104b94bd663f90316a4f8a,"Accurate pointing is an obstacle to computer access for individuals who experience motor impairments. One of the main barriers to assisting individuals with pointing problems is a lack of frequent and low-cost assessment of pointing ability. We are working to build technology to automatically assess pointing problems during every day (or real-world) computer use. To this end, we have gathered and studied real-world pointing use from individuals with motor impairments and older adults. We have used this data to develop novel techniques to analyze pointing performance. In this article, we present learned statistical models that distinguish between pointing actions from diverse populations using real-world pointing samples. We describe how our models could be used to support individuals with different abilities sharing a computer, or one individual who experiences temporary pointing problems. Our investigation contributes to a better understanding of real-world pointing. We hope that these techniques will be used to develop systems that can automatically adapt to users' current needs in real-world computing environments. © 2013, ACM. All rights reserved.",Assistive technology; Measurement; Performance; Pointing performance; Real-world data collection,
Situation-specific models of color differentiation,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872461963&doi=10.1145%2f2399193.2399197&partnerID=40&md5=8bc12f4acd8282798834beea500fdee3,"Color is commonly used to represent categories and values in computer applications, but users with Color-Vision Deficiencies (CVD) often have difficulty differentiating these colors. Recoloring tools have been developed to address the problem, but current recolorers are limited in that they work from a model of only one type of congenital CVD (i.e., dichromatism). This model does not adequately describe many other forms of CVD (e.g., more common congenital deficiencies such as anomalous trichromacy, acquired deficiencies such as cataracts or age-related yellowing of the lens, or temporary deficiencies such as wearing tinted glasses or working in bright sunlight), and so standard recolorers work poorly in many situations. In this article we describe an alternate approach that can address these limitations. The new approach, called Situation-Specific Modeling (SSM), constructs a model of a specific user's color differentiation abilities in a specific situation, and uses that model as the basis for recoloring digital presentations. As a result, SSM can inherently handle all types of CVD, whether congenital, acquired, or environmental. In this article we describe and evaluate several models that are based on the SSM approach. Our first model of individual color differentiation (called ICD-1) works in RGB color space, and a user study showed it to be accurate and robust (both for users with and without congenital CVD). However, three aspects of ICD-1 were identified as needing improvement: the calibration step needed to build the situation-specific model, and the prediction steps used in recoloring were too slow for real-world use; and the results of the model's predictions were too coarse for some uses. We therefore developed three further techniques: ICD-2 reduces the time needed to calibrate the model; ICD-3 reduces the time needed to make predictions with the model; and ICD-4 provides additional information about the degree of differentiability in a prediction. Our final result is a model of the user's color perception that handles any type of CVD, can be calibrated in two minutes, and can find replacement colors in near-real time (∼1 second for a 64-color image). The ICD models provide a tool that can greatly improve the perceptibility of digital color for many different types of CVD users, and also demonstrates situation-specific modeling as a new approach that can broaden the applicability of assistive technology. © 2012 ACM.",Color differentiation; Color vision deficiency; Situation-specific modeling,Color image processing; Color vision; Computer applications; Forecasting; Age-related; Assistive technology; Color perception; Color vision deficiencies; Differentiability; Digital color; Digital presentation; Near-real time; Recoloring; RGB color space; User study; Color
How older adults learn to use mobile devices: Survey and field investigations,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872459750&doi=10.1145%2f2399193.2399195&partnerID=40&md5=8d4997f30d95ba816271b1f6e7c53124,"Mobile computing devices, such as smart phones, offer benefits that may be especially valuable to older adults (age 65+). Yet, older adults have been shown to have difficulty learning to use these devices. In the research presented in this article, we sought to better understand how older adults learn to use mobile devices, their preferences and barriers, in order to find new ways to support them in their learning process. We conducted two complementary studies: a survey study with 131 respondents from three age groups (20-49, 50-64, 65+) and an in-depth field study with 6 older adults aged 50+. The results showed, among other things, that the preference for trial-and-error decreases with age, and while over half of older respondents and participants preferred using the instruction manual, many reported difficulties using it. We discuss implications for design and illustrate these implications with an example help system, Help Kiosk, designed to support older adults' learning to use mobile devices. © 2012 ACM.",Learning; Mobile device; Older adults,Computer applications; Human computer interaction; Age groups; Field investigation; Field studies; Help systems; Instruction manuals; Learning; Learning process; Mobile computing devices; Older adults; Mobile devices
Special issue ASSETS 2011,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872436908&doi=10.1145%2f2399193.2399196&partnerID=40&md5=4b02212fcc17046f3fb2587f68f2ff4f,[No abstract available],,
Introduction to special issue on mobile technologies for older users,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872440048&doi=10.1145%2f2399193.2399194&partnerID=40&md5=a48b001ee0aae9dba3edcc48ee39ee39,[No abstract available],,
Representing users in accessibility research,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859402565&doi=10.1145%2f2141943.2141945&partnerID=40&md5=34eee2a034ece94b2e03a48f477a4896,"The need to study representative users is widely accepted within the human-computer interaction (HCI) community. While exceptions exist, and alternative populations are sometimes studied, virtually any introduction to the process of designing user interfaces will discuss the importance of understanding the intended users as well as the significant impact individual differences can have on how effectively individuals can use various technologies. HCI researchers are expected to provide relevant demographics regarding study participants as well as information about experience using similar technologies. Yet in the field of accessibility, we continue to see studies that do not appropriately include representative users. Highlighting ways to remedy this multifaceted problem, we argue that expectations regarding how accessibility research is conducted and reported must be raised if this field is to have the desired impact with regard to inclusive design, the information technologies studied, and the lives of the individuals studied. © 2012 ACM 1936-7228/2012/03-ART7$10.00.",Experimentation; Human Factors,Human computer interaction; Human engineering; Information technology; User interfaces; Experimentation; Inclusive design; Individual Differences; Significant impacts; Research
Understanding age and technology experience differences in use of prior knowledge for everyday technology interactions,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859407351&doi=10.1145%2f2141943.2141947&partnerID=40&md5=7e38dfc993b02f367bb9fe54246a060a,"Technology designers must understand relevant prior knowledge in a target user population to facilitate adoption and effective use. To assess prior knowledge used in naturalistic settings, we systematically collected information about technologies used over 10-day periods from older adults with high and low technology experience and younger adults. Technology repertoires for younger adults and high technology older adults were similar; differences reflected typically different needs for kitchen and health care technologies between the age groups. Technology repertoires for low-technology older adults showed substantial technology usage in many categories. Lower usage compared to high-tech older adults for each category was limited primarily to PC and Internet technologies. Experience differences suggest preferences among low-technology older adults for basic technology usage and for working with people rather than technologies. Participants in all groups were generally successful using their everyday technologies to achieve their goals. Prior knowledge was the most common attribution for success, but external information was also commonly referenced. Relevant prior knowledge included technical, functional, strategy, and self knowledge. High tech older adults did not report more problems than younger adults, but they did attribute more problems to insufficient prior knowledge. Younger adults attributed more problems to interference from prior knowledge. Low-tech older adults reported fewer problems, typically attributing them to insufficient prior knowledge or product/system faults. We discuss implications for further research and design improvements to increase everyday technology success and adoption for high-tech and low-tech older adults. © 2012 ACM 1936-7228/2012/03-ART9$10.00.",Design; Human Factors,Design; Health care; Human engineering; Age groups; Design improvements; Healthcare technology; High tech; High technology; Internet technology; Older adults; Prior knowledge; Technology
Introduction to article 7,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859389835&doi=10.1145%2f2141943.2141944&partnerID=40&md5=b0f8db3656b930bddca44caaebf2684b,[No abstract available],,
Is accessibility conformance an elusive property? A study of validity and reliability of WCAG 2.0,2012,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859388906&doi=10.1145%2f2141943.2141946&partnerID=40&md5=51cda5035196c70eb2c0aed1982a84d8,"The Web Content Accessibility Guidelines (WCAG) 2.0 separate testing into both ""Machine"" and ""Human"" audits; and further classify ""Human Testability"" into ""ReliablyHuman Testable"" and ""Not Reliably Testable""; it is human testability that is the focus of this paper.Wewanted to investigate the likelihood that ""at least 80% of knowledgeable human evaluators would agree on the conclusion"" of an accessibility audit, and therefore understand the percentage of success criteria that could be described as reliably human testable, and those that could not. In this case, we recruited twenty-five experienced evaluators to audit four pages for WCAG 2.0 conformance. These pages were chosen to differ in layout, complexity, and accessibility support, thereby creating a small but variable sample. We found that an 80% agreement between experienced evaluators almost never occurred and that the average agreement was at the 70-75% mark, while the error rate was around 29%. Further, trained-but novice-evaluators performing the same audits exhibited the same agreement to that of our more experienced ones, but a reduction on validity of 6-13%; the validity that an untrained user would attain can only be a conjecture. Expertise appears to improve (by 19%) the ability to avoid false positives. Finally, pooling the results of two independent experienced evaluators would be the best option, capturing at most 76% of the true problems and producing only 24% of false positives. Any other independent combination of audits would achieve worse results. This means that an 80% target for agreement, when audits are conducted without communication between evaluators, is not attainable, even with experienced evaluators, when working on pages similar to the ones used in this experiment; that the error rate even for experienced evaluators is relatively high and further, that untrained accessibility auditors be they developers or quality testers from other domains, would do much worse than this. © 2012 ACM 1936-7228/2012/03-ART8$10.00.",Experimentation; Human factors,Experiments; Human engineering; Websites; Error rate; Experimentation; False positive; Testability; Web content accessibility guidelines; Management
Write-N-Speak: Authoring multimodal digital-Paper materials for speech-Language Therapy,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81755176771&doi=10.1145%2f2039339.2039341&partnerID=40&md5=c7a2db9500b9aa89a9ad5282d74da524,"Aphasia is characterized by a reduced ability to understand and/or generate speech and language. Speech-language therapy helps individuals with aphasia regain language and cope with changes in their communication abilities. The therapy process is largely paper-based, making multimodal digital pen technology a promising tool for supporting therapy activities. We report on ten months of field research where we examine the practice of speech-language therapy, implement Write-N-Speak, a digital-paper toolkit for end-user creation of custom therapy materials, and deploy this system for 12 weeks with one therapist-client dyad in a clinical setting. The therapist used Write-N-Speak to create a range of materials including custom interactive worksheets, photographs programmed with the client's voice, and interactive stickers on household items to aid object recognition and naming. We conclude with a discussion of multimodal digital pen technology for this and other therapy activities.© 2011 ACM 1936-7228/2011/11-ART2 $10.00.",Communication; Multimodal interaction; Older adults; Pen-based computing; Speech-language therapy,Communication; Object recognition; Photography; Speech recognition; Clinical settings; Digital pens; End users; Field research; Multi-modal; Multi-Modal Interactions; Older adults; Pen-based computing; Speech-language therapy; Speech communication
Stroke therapy through motion-Based games: A case study,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81755169013&doi=10.1145%2f2039339.2039342&partnerID=40&md5=dbefb8eceaead82ca1d9bb3cde73b31d,"In the United States alone, more than five million people are living with long term motor impairments caused by a stroke. Recently, video games with affordable motion-based input devices have been proposed as a part of therapy to help people recover lost range of motion and motor control. While researchers have demonstrated the potential utility of therapeutic games through controlled studies, relatively little work has explored their long-term home-based use. We conducted a six-week home study with a 62-year-old woman who was seventeen years post-stroke. She played therapeutic games for approximately one hour a day, five days a week. Over the six weeks, she recovered significant motor abilities, which is unexpected given the time since her stroke. We explore detecting such improvements early, using game logs for daily measurements of motor ability to complement the standard measurements that are taken less often. Through observations and interviews, we present lessons learned about the barriers and opportunities that arise from long-term home-based use of therapeutic games. © 2011 ACM 1936-7228/2011/11-ART3 $10.00.",Stroke rehabilitation; Therapy; Video games,Neuromuscular rehabilitation; Game log; Input devices; Motor abilities; Motor control; Motor impairments; Potential utility; Range of motions; Standard measurements; Stroke rehabilitation; Stroke therapy; Therapy; Video game; Human computer interaction
Introduction assets'10 special issue,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81755176765&doi=10.1145%2f2039339.2039340&partnerID=40&md5=7e2e739d085002b5a5963564e643f8ec,[No abstract available],Accessibility research; Aphasia; Research methods; Sign language; Stroke,
Data-Driven synthesis of spatially inflected verbs for american sign language animation,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81755176764&doi=10.1145%2f2039339.2039343&partnerID=40&md5=56def9ea9f38484bee706e7cd219d261,"We are studying techniques for producing realistic and understandable animations of American Sign Language (ASL); such animations have accessibility benefits for signers with lower levels of written language literacy. This article describes and evaluates a novel method for modeling and synthesizing ASL animations based on samples of ASL signs collected from native signers. We apply this technique to ASL inflecting verbs, common signs in which the location and orientation of the hands is influenced by the arrangement of locations in 3D space that represent entities under discussion. We train mathematical models of hand movement on animation data of signs produced by a native signer. In evaluation studies with native ASL signers, the verb animations synthesized from our model had similar subjective-rating and comprehension-question scores to animations produced by a human animator; they also achieved higher scores than baseline animations. Further, we examine a split modeling technique for accommodating certain verb signs with complex movement patterns, and we conduct an analysis of how robust our modeling techniques are to reductions in the size of their training data. The modeling techniques in this article are applicable to other types of ASL signs and to other sign languages used internationally. Our models' parameterization of sign animations can increase the repertoire of generation systems and can partially automate the work of humans using sign language scripting systems. ©2011 ACM 1936-7228/2011/11-ART4 $10.00.",Accessibility technology for people who are deaf; American Sign Language; Animation; Natural language generation,Mathematical models; Natural language processing systems; 3-D space; Accessibility technology for people who are deaf; American sign language; Complex movement patterns; Data-driven synthesis; Evaluation study; Generation systems; Hand movement; Modeling technique; Natural language generation; Sign language; Training data; Animation
Evaluation of haptic HTML mappings derived from a novel methodology,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955451285&doi=10.1145%2f1952388.1952389&partnerID=40&md5=9776735eb62cdd20dead203dce169022,"As levels of awareness surrounding accessibility increase, designers often look towards using nonvisual technologies to make existing graphical interfaces (e.g. Web pages) more inclusive. As existing haptic design guidance is not targeted to the specific needs of blind Web users, inappropriate touchable representations of graphical objects may be developed and integrated with Web interfaces, thereby reducing the quality of the browsing experience. This paper describes the evaluation of haptic HTML mappings that were developed using a participatory-design based technique, and presented using the Logitech Wingman force-feedback mouse. Findings have shown that participants were able to identify objects presented haptically, and develop a structural representation of layout from exploring content. Participants were able to perform a range of Web-based tasks that were previously found to be difficult for some blind users when using a screen reader alone. The haptic HTML mappings are presented, along with recommendations for their application derived from a validation study. The design guidance presented offers a standard reference tool for Web designers wanting to develop an accessible browsing application, using the benefits offered by a force-feedback mouse. © 2011 ACM.",Blind community; Haptic interfaces; Multimodal interfaces; Web accessibility,Design; HTML; Interactive computer systems; Mapping; Mice (computer peripherals); Websites; Blind community; Blind users; Design guidance; Force-feedback; Graphical interface; Graphical objects; Logitech; Multimodal interfaces; Novel methodology; Screen readers; Structural representation; Validation study; Web accessibility; Web designers; Web interface; Web page; Web users; Haptic interfaces
Identifying behavioral strategies of visually impaired users to improve access to web content,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955449114&doi=10.1145%2f1952388.1952390&partnerID=40&md5=c169dd885ae3f01bea7671e6b95b1b52,"The World Wide Web is a predominantly visual media for presenting and disseminating information. As such, visually impaired users, who access content through audio interaction, are hindered as the Web is not designed with their needs in mind. To compensate for this, visually impaired users develop behavioral strategies to cope when access to the content becomes challenging. While tools exist to aid visually impaired users in accessing the Web, they tend to focus on adapting content to meet the needs of the device rather than the user. Therefore, to further improve Web access an understanding of the behavioral strategies users employ is required. To achieve this, studies of eleven visually impaired Web users were conducted. The data from these sessions were analyzed to develop a framework for identifying strategies that users may employ when they face difficulties accessing the content. Using data for twenty visually impaired users obtained from an independent study, the framework was validated and shown to be flexible and accurate enough to be applicable to multiple data sources. An analysis of the coping strategies identified from the framework revealed six abstract patterns of coping. These patterns were used as the basis for developing behaviordriven transcoding that transformed static Web documents into interactive content by allowing users to navigate between key elements of the page through a consistent set of key presses. Results obtained from a user evaluation of the transcoding support the use of behavior-driven transcoding as a mechanism for improving access to Web content when compared to existing transcoding techniques. This result allows the coping strategies framework to be used as a foundation for further understanding of the strategies visually impaired users employ on Web sites and the transformations required to allow the Web to be accessible to those users. 2011 ACM.",Behavioral Strategies; Coping framework; Transcoding,Information dissemination; Websites; Audio interaction; Behavioral Strategies; Coping framework; Coping strategies; Key elements; Multiple data sources; Transcoding; Transcoding techniques; User evaluations; Visual media; Visually impaired; Visually-impaired users; Web access; Web content; Web document; Web users; Data visualization
Spindex (speech index) improves auditory menu acceptance and navigation performance,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955066113&doi=10.1145%2f1952383.1952385&partnerID=40&md5=d564c422469d9520980f05cd795c9ce8,"Users interact with mobile devices through menus, which can include many items. Auditory menus have the potential to make those devices more accessible to a wide range of users. However, auditory menus are a relatively new concept, and there are few guidelines that describe how to design them. In this paper, we detail how visual menu concepts may be applied to auditory menus in order to help develop design guidelines. Specifically, we examine how to optimize the designs of a new contextual cue, called ""spindex"" (i.e., speech index). We developed and evaluated various design alternatives for spindex and iteratively refined the design with sighted users and visually impaired users. As a result, the ""attenuated"" spindex was the best in terms of preference as well as performance, across user groups. Nevertheless, sighted and visually impaired participants showed slightly different responses and feedback. Results are discussed in terms of acoustical theory, practical display design, and assistive technology design. © 2011 ACM.",Assistive technology; Auditory menus; Spindex,Mobile devices; Acoustical theory; Assistive technology; Auditory menus; Contextual cue; Design alternatives; Design guidelines; Display designs; Navigation performance; Spindex; User groups; Visually impaired; Visually-impaired users; Design
Health problem solving by older persons using a complex government web site: Analysis and implications for web design,2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955069950&doi=10.1145%2f1952383.1952386&partnerID=40&md5=e91db749c7a9e7b236c2850dab948b30,"A large number of health-related Web sites currently exist that offer consumers a wealth of information that can be used to enhance the quality of their lives. Much less attention has been given to Web sites that can support complex health-related problem solving, as opposed to more general information search activities, of user populations such as older adults. In this article, we expand on a prior usability study that examined the performance of 112 older adults who were asked to solve two problems using the U. S. government's Medicare.gov Web site. The indications from that study were that older adults had difficulty carrying out these problem-solving tasks. This article illustrates, in the context of a case study, the use of a structured methodology for obtaining insights into Web site design issues that could make it difficult for healthcare consumers such as older adults to solve health-related problems. Initially, a number of Web design guidelines that have been developed for older users are presented. The argument is made that such checklist-type guidelines, though essential, are difficult to apply to complex Web-based problem-solving activities. Following a review of research in the area of Web-based health information seeking and problem-solving by older adults, the description and implementation of a methodology for aiding designers in anticipating cognitive demands that older users might confront during their problem-solving activities is presented. Detailed analysis of task performance is then presented to demonstrate that very few of the study participants were able to successfully negotiate the solution to the problem. The use of the methodology for identifying a number user-Web site interaction issues and for proposing recommendations particularly relevant to older users, and ultimately for enhancing the accessibility of health Web sites, is highlighted. Finally, a detailed framework is presented that is intended for guiding designers in the application of this methodology. © 2011 ACM.",Government Web sites; Health information seeking; Hierarchical task analysis (HTA); Human-computer interaction; Older adults; Optimization; Troubleshooting,Design; Health; Health care; Human computer interaction; Information use; Job analysis; Knowledge management; Optimization; Websites; Government websites; Health information seeking; Hierarchical task analysis; Older adults; Troubleshooting; Problem solving
"Ability-based design: Concept, principles and examples",2011,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955063060&doi=10.1145%2f1952383.1952384&partnerID=40&md5=15529a19c815c7d0b63fbb69e0a2e6a3,"Current approaches to accessible computing share a common goal of making technology accessible to users with disabilities. Perhaps because of this goal, they may also share a tendency to centralize disability rather than ability. We present a refinement to these approaches called ability-based design that consists of focusing on ability throughout the design process in an effort to create systems that leverage the full range of human potential. Just as user-centered design shifted the focus of interactive system design from systems to users, ability-based design attempts to shift the focus of accessible design from disability to ability. Although prior approaches to accessible computing may consider users' abilities to some extent, ability-based design makes ability its central focus. We offer seven ability-based design principles and describe the projects that inspired their formulation. We also present a research agenda for ability-based design. © 2011 ACM.",Ability-based design; Adaptive user interfaces; Assistive technology; Computer access; Design for all; Inclusive design; Universal design; Universal usability; User interfaces for all,Human computer interaction; Systems analysis; User interfaces; Ability-based design; Adaptive user interface; Assistive technology; Computer access; Design for all; Inclusive design; Universal design; Universal usability; Design
Multimodal presentation of two-dimensional charts: An investigation using open office XML and microsoft excel,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651548035&doi=10.1145%2f1857920.1857925&partnerID=40&md5=3038a4afe9bb37f002d18b34c0ddc4be,"Several solutions, based on aural and haptic feedback, have been developed to enable access to complex on-line and digital information contents for people with visual impairment. Nevertheless, there are several components of widely used software applications that are still beyond the reach of traditional screen readers and Braille displays. This article investigates the nonvisual accessibility issues associated with the graphing component of Microsoft Excel and proposes a novel approach and system. The goal is to provide flexible multi-modal presentation schemes which can help visually impaired users in comprehending themost commonly used two dimensional business charts, demonstrated within the familiar context of Excel charts. The methodology identifies the need for three distinct strategies used in the user interaction with a chart: exploratory, guided, and summarization. These methodologies have been implemented using a multimodal approach, which combines aural cues, speech commentaries, and 3-dimensional haptic feedback. The prototype implementation and the preliminary studies suggest that themultimodality can be effectively realized and users denote preferences in intertwining these methodologies to gain understanding of the content of charts. These methodologies have been implemented in a system, which makes use of the Novint Falcon haptic device and integrated as a plug-in in Microsoft Excel. © 2010 ACM 1936-7228/2010/11- ART8.",Accessible graphs; Assistive technology; Haptic; Nonvisual charts navigation,Haptic interfaces; Navigation charts; Two dimensional; 3-dimensional; Accessible graphs; Assistive technology; Braille display; Commonly used; Digital information; Haptic; Haptic devices; Haptic feedbacks; Microsoft excel; Multi-modal; Multi-modal approach; Nonvisual charts navigation; Plug-ins; Prototype implementations; Screen readers; Software applications; User interaction; Visual impairment; Visually-impaired users; Graphic methods
Orienting kinesthetically: A haptic handheld wayfinder for people with visual impairments,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651534991&doi=10.1145%2f1857920.1857923&partnerID=40&md5=e997d129217c9a6b3af47483710a04f7,"Orientation and position information are vital for people with visual impairments if they are to avoid obstacles and hazards while walking around. We develop and evaluate a haptic direction indicator that delivers directional information in real time through kinesthetic cues. The indicator uses a novel kinesthetic perception method called the pseudo-attraction force technique, which employs the nonlinear relationship between perceived and physical acceleration to generate a force sensation. In an experiment, we find that the haptic direction indicator allowed people with visual impairments to walk safely along a predefined route at their usual walking pace without any previous training, independent of the existence of auditory information. The findings indicate that the haptic direction indicator is effective at delivering simple navigational information, and is a suitable substitute for and/or enhancement to conventional wayfinding methods. © 2010 ACM 1936-7228/2010/11-ART6.",Blind; Haptics; Mobility; Tactile communication,Attraction force; Avoid obstacles; Blind; Directional information; Handhelds; Haptics; Mobility; Navigational information; Non-linear relationships; Position information; Real time; Tactile communication; Visual impairment; Way-finding
Exploratory analysis of collaborative web accessibility improvement,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651557742&doi=10.1145%2f1857920.1857922&partnerID=40&md5=3d19d0abc78ba3b8046b33265bc41c18,"The Web is becoming a platform for daily activities and is expanding the opportunities for collaboration among people all over the world. The effects of these innovations are seen not only in major Web services such as wikis and social networking services but also in accessibility services. Collaborative accessibility improvement has great potential to make the Web more adaptive. Screen reader users, developers, site owners, and any Web volunteers who want to help the users are invited into the activities to improve accessibility in a timely manner. The Social Accessibility Project is an experimental service for a new needs-driven improvement model based on collaborative metadata authoring technologies. In 20 months, about 19,000 pieces of metadata were created for more than 3,000 Web pages through collaboration based on 355 requests submitted from users. We encountered many challenges as we sought to create a new mainstream approach and created distinctive features in new user interfaces to address some of these challenges. Although the new features increased user participation, serious issues remain. The productivity of the volunteers exceeded our expectations, but we found large and important problems in the users' lack of awareness of their own accessibility problems. This is a critical problem for sustaining the active use of the service, because about 70% of the improvement starts with a request from a user. Helping users with visual impairments understand the actual issues is a crucial and challenging topic, and will lead to improved accessibility. We first introduce examples of collaboration, analyze several kinds of statistics on the activities of the users and volunteers of the pilot service, and then discuss our findings and challenges. Five future foci are considered: site-wide metadata authoring, encouraging active participation by users, quality management for the created metadata, metadata for dynamic HTML applications, and collaborations with site owners. © 2010 ACM 1936-7228/2010/11-ART5.",Accessibility; Collaboration; Metadata; Social computing; Web,Metadata; Quality management; User interfaces; Websites; Accessibility; Accessibility problems; Collaboration; Critical problems; Daily activity; Distinctive features; Exploratory analysis; Metadata authoring; Model-based; Screen readers; Social computing; Social networking; User participation; Visual impairment; Web; Web accessibility; Web page; Web services
Usability of a multimodal video game to improve navigation skills for blind children,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651572723&doi=10.1145%2f1857920.1857924&partnerID=40&md5=bc1b849f40137bc262b9cd021d9e0f42,"This work presents an evaluative study on the usability of a haptic device together with a soundbased video game for the development and use of orientation and mobility (O&M) skills in closed, unfamiliar spaces by blind, school-aged children. A usability evaluation was implemented for a haptic device especially designed for this study (Digital Clock Carpet) and a 3D video game (MOVA3D) in order to determine the degree to which the user accepted the device, and the level of the user's satisfaction regarding her interaction with these products for O&M purposes. In addition, a cognitive evaluation was administered. The results show that both the haptic device and the video game are usable, accepted and considered to be pleasant for use by blind children. The results also show that they are ready to be used for cognitive learning purposes. Results from a cognitive study demonstrated significant gains in tempo-spatial orientation skills of blind children when navigating in unfamiliar spaces. © 2010 ACM 1936-7228/2010/11-ART7.",Blind children; Haptic and audio interfaces; Navigation; Virtual environments,Haptic interfaces; Human computer interaction; Navigation; Three dimensional computer graphics; Virtual reality; 3D video; Audio interfaces; Blind children; Cognitive learning; Digital clocks; Haptic devices; Multi-modal; Orientation and mobilities; Spatial orientations; Usability evaluation; User's satisfaction; Video game; Virtual environments; Education
Guest editorial ASSETS 2009,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651541731&doi=10.1145%2f1857920.1857921&partnerID=40&md5=995fac9dd9d6f593baeb23975558e729,[No abstract available],,
Investigating grid-based navigation:The impact of physical disability,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651538491&doi=10.1145%2f1838562.1838565&partnerID=40&md5=477a667842155f236efc20325ca4c86f,"Hands-free speech-based technology can be a useful alternative for individuals that find traditional input devices, such as keyboard and mouse, difficult to use. Various speech-based navigation techniques have been examined, and several are available in commercial software applications. Among these alternatives, grid-based navigation has demonstrated both potential and limitations. In this article, we discuss an empirical study that assessed the efficacy of two enhancements to grid-based navigation: magnification and fine-tuning. The magnification capability enlarges the selected region when it becomes sufficiently small, making it easier to see the target and cursor. The fine-tuning capability allows users to move the cursor short distances to position the cursor over the target. The study involved one group of participants with physical disabilities, an agematched group of participants without disabilities, and a third group that included young adults without disabilities. The results confirm that both magnification and fine-tuning significantly improved the participants' performance when selecting targets, especially small targets. Providing either, or both, of the proposed enhancements substantially reduced the gaps in performance due to disability and age. The results will inform the design of speech-based target selection mechanism, allowing users to select targets faster while making fewer errors. © 2010 ACM.",,Evolutionary algorithms; Navigation; Tuning; Commercial software; Empirical studies; Grid-based; Hands-free; Input devices; Navigation techniques; Physical disability; Short distances; Small targets; Target selection; Tuning capability; Handicapped persons
Accurate and accessible motion-capture glove calibration for sign language data collection,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651591047&doi=10.1145%2f1838562.1838564&partnerID=40&md5=24dba340be48c6e3bdc7978e5cca340e,"Motion-capture recordings of sign language are used in research on automatic recognition of sign language or generation of sign language animations, which have accessibility applications for deaf users with low levels of written-language literacy. Motion-capture gloves are used to record the wearer's handshape. Unfortunately, they require a time-consuming and inexact calibration process each time they are worn. This article describes the design and evaluation of a new calibration protocol for motion-capture gloves, which is designed to make the process more efficient and to be accessible for participants who are deaf and use American Sign Language (ASL). The protocol was evaluated experimentally; deaf ASL signers wore the gloves, were calibrated (using the new protocol and using a calibration routine provided by the glove manufacturer), and were asked to perform sequences of ASL handshapes. Five native ASL signers rated the correctness and understandability of the collected handshape data. In an additional evaluation, ASL signers were asked to perform ASL stories while wearing the gloves and a motion-capture bodysuit (in some cases our new calibration protocol was used, in other cases, the standard protocol). Later, twelve native ASL signers watched animations produced from this motion-capture data and answered comprehension questions about the stories. In both evaluation studies, the new protocol received significantly higher scores than the standard calibration. The protocol has been made freely available online, and it includes directions for the researcher, images and videos of how participants move their hands during the process, and directions for participants (as ASL videos and English text). © 2010 ACM.",Accessibility technology for the deaf; American Sign Language; Animation; Calibration; CyberGlove; Motion-capture glove,Animation; Accessibility technology for the deaf; American sign language; Automatic recognition; Calibration process; Calibration protocols; CyberGlove; Data collection; Deaf users; Evaluation study; Low level; Motion capture; Motion-capture glove; New protocol; Sign language; Standard calibration; Standard protocols; Understandability; Calibration
Multi-Layered interfaces to improve older adults' initial learnability of mobile applications,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651526569&doi=10.1145%2f1838562.1838563&partnerID=40&md5=a7416ffbcf06c9624d4fe05dc812d1d5,"Mobile computing devices can offer older adults (ages 65+) support in their daily lives, but older adults often find such devices difficult to learn and use. One potential design approach to improve the learnability of mobile devices is a Multi-Layered (ML) interface, where novice users start with a reduced-functionality interface layer that only allows them to perform basic tasks, before progressing to a more complex interface layer when they are comfortable. We studied the effects of a ML interface on older adults' performance in learning tasks on a mobile device. We conducted a controlled experiment with 16 older (ages 65-81) and 16 younger participants (age 21-36), who performed tasks on either a 2-layer or a nonlayered (control) address book application, implemented on a commercial smart phone. We found that the ML interface's Reduced- Functionality layer, compared to the control's Full-Functionality layer, better helped users to master a set of basic tasks and to retain that ability 30 minutes later. When users transitioned from the Reduced-Functionality to the Full-Functionality interface layer, their performance on the previously learned tasks was negatively affected, but no negative impact was found on learning new, advanced tasks. Overall, the ML interface provided greater benefit for older participants than for younger participants in terms of task completion time during initial learning, perceived complexity, and preference. We discuss how the ML interface approach is suitable for improving the learnability of mobile applications, particularly for older adults. © 2010 ACM.",Age-related differences; Learnability; Menu design; Mobile devices; Multi-layered interfaces; Older adults; User study,Design; Mobile telecommunication systems; Portable equipment; User interfaces; Age-related; Learnability; Menu design; Multi-layered interfaces; Older adults; User study; Mobile devices
Towards a universally usable human interaction proof: Evaluation of task completion strategies,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651555885&doi=10.1145%2f1786774.1786776&partnerID=40&md5=10f66b29bba398bce7335f61a991daf5,"The need for security features to stop spam and bots has prompted research aimed at developing human interaction proofs (HIPs) that are both secure and easy to use. The primarily visual techniques used in these HIP tools present difficulties for users with visual impairments. This article reports on the development of Human-Interaction Proof, Universally Usable (HIPUU), a new approach to human-interaction proofs based on identification of a series of sound/image pairs. Simultaneous presentation of a single, unified task in two alternative modalities provides multiple paths to successful task completion. We present two alternative task completion strategies, based on differing input strategies (menu-based vs. free text entry). Empirical results from studies involving both blind and sighted users validate both the usability and accessibility of these differing strategies, with blind users achieving successful task completion rates above 90%. The strengths of the alternate task completion strategies are discussed, along with possible approaches for improving the robustness of HIPUU. © 2010 ACM.",Blind users; CAPTCHA; HIP; Security; Universal usability,Human computer interaction; Blind users; CAPTCHAs; Empirical results; Free texts; Human interaction proofs; Humaninteraction; Multiple-path; New approaches; Security features; Universal usability; Visual impairment; Visual techniques; Network security
ITHACA: An Open Source framework for building component-based Augmentative and Alternative Communication applications,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651536725&doi=10.1145%2f1786774.1786775&partnerID=40&md5=40ea38d99d4d9e6ce5f50f394d174037,"As an answer to the disabled community's odyssey to gain access to adaptable, modular, multilingual, cheap and sustainable Augmentative and Alternative Communication (AAC) products, we propose the use of the ITHACA framework. It is a software environment for building componentbased AAC applications, grounded on the Design for All principles and a hybrid-community and commercial-Open Source development model. ITHACA addresses the developers, the vendors, as well as the people who use AAC. We introduce a new viewpoint on the AAC product design-developdistribute lifecycle, and a novel way to search-select-modify-maintain the AAC aid. ITHACA provides programmers with a set of tools and reusable Open Source code for building AAC software components. It also facilitates AAC product vendors to put together sophisticated applications using the available on the Web, independently premanufactured, free or commercial software parts. Furthermore, it provides people who use AAC with a variety of compatible AAC software products which incorporate multimodal, user-tailored interfaces that can fulfill their changing needs. The ITHACA architecture and the proposed fusion of past and current approaches, trends and technologies are explained. ITHACA has been successfully applied by implementing a family of AAC products, based on interchangeable components. Several ready to use ITHACA-based components, including on-screen keyboards, Text-to-Speech, symbol selection sets, e-chatting, emailing, and scanning-based input, as well as four complete communication aids addressing different user cases have been developed. This demonstration showed good acceptance of the ITHACA applications and substantial improvement of the end users' communication skills. Developers' experience on working in ITHACA's Open Source projects was also positively evaluated. More importantly, the potential contribution of the component-based framework and Open Source development model combination to the AAC community emerged. © 2010 ACM.",Augmentative and Alternative Communication; Component; Design for All; Framework; Open Source,Computer programming; Computer software reusability; Human computer interaction; Human rehabilitation engineering; Product design; Augmentative-and-alternative communication; Commercial software; Communication aids; Communication skills; Component based; Component-based framework; Design for all; End users; Multi-modal; On-screen keyboard; Open source development; Open source frameworks; Open source projects; Open sources; Open-source code; Product vendors; Software component; Software environments; Software products; Text to speech; Speech communication
Assessing fit of nontraditional assistive technologies,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651547403&doi=10.1145%2f1786774.1786777&partnerID=40&md5=28af149b0d2fecb8c6f47311db56e1ae,"There is a variety of brain-based interface methods which depend on measuring small changes in brain signals or properties. These methods have typically been used for nontraditional assistive technology applications. Non-traditional assistive technology is generally targeted for users with severe motor disabilities which may last long-term due to illness or injury or short-term due to situational disabilities. Control of a nontraditional assistive technology can vary widely across users depending upon many factors ranging from health to experience. Unfortunately, there is no systematic method for assessing usability of nontraditional assistive technologies to achieve the best control. The current methods to accommodate users through trial-and-error result in the loss of valuable time and resources as users sometimes have diminishing abilities or suffer from terminal illnesses. This work describes a methodology for objectively measuring an individual's ability to control a specific nontraditional assistive technology, thus expediting the technology-fit process. © 2010 ACM.",Assistive technology; Brain-based interfaces; Brain-computer interface; Direct-brain interface; Functional nearinfrared; Galvanic skin response; Individual characteristics; User profiles,Electrophysiology; Fuzzy control; Interfaces (computer); Technology; Assistive technology; Brain interfaces; Functional-near infrared; Galvanic skin response; Individual characteristics; User profile; Brain computer interface
Universal design of auditory graphs: A comparison of sonification mappings for visually impaired and sighted listeners,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651574684&doi=10.1145%2f1714458.1714459&partnerID=40&md5=59185a7669d86fe9e52b4626a704a5bb,"Determining patterns in data is an important and often difficult task for scientists and students. Unfortunately, graphing and analysis software typically is largely inaccessible to users with vision impairment. Using sound to represent data (i.e., sonification or auditory graphs) can make data analysis more accessible; however, there are few guidelines for designing such displays for maximum effectiveness. One crucial yet understudied design issue is exactly how changes in data (e.g., temperature) are mapped onto changes in sound (e.g., pitch), and how this may depend on the specific user. In this study, magnitude estimation was used to determine preferred data-to-display mappings, polarities, and psychophysical scaling functions relating data values to underlying acoustic parameters (frequency, tempo, or modulation index) for blind and visually impaired listeners. The resulting polarities and scaling functions are compared to previous results with sighted participants. There was general agreement about polarities obtained with the two listener populations, with some notable exceptions. There was also evidence for strong similarities regarding the magnitudes of the slopes of the scaling functions, again with some notable differences. For maximum effectiveness, sonification software designers will need to consider carefully their intended users vision abilities. Practical implications and limitations are discussed. © 2010 ACM.",Auditory display; Magnitude estimation; Visually impaired,Computer software; Design; Estimation; Frequency estimation; Acoustic parameters; Auditory display; Data analysis; Data values; Design issues; Magnitude estimation; Modulation indexes; Psychophysical scaling; Scaling functions; Software designers; Sonifications; Universal Design; Vision impairments; Visually impaired; Data visualization
Computer usage by children with down syndrome: Challenges and future research,2010,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651529830&doi=10.1145%2f1714458.1714460&partnerID=40&md5=9fcaf458d8ff42bf9e6e573d0d282fb7,"Children with Down syndrome, like neurotypical children, are growing up with extensive exposure to computer technology. Computers and computer-related devices have the potential to help these children in education, career development, and independent living. Our understanding of computer usage by this population is quite limited. Most of the software, games, and Web sites that children with Down syndrome interact with are designed without consideration of their special needs, making the applications less effective or completely inaccessible. We conducted a large-scale survey that collected computer usage information from the parents of approximately six hundred children with Down syndrome. This article reports the text responses collected in the survey and is intended as a step towards understanding the difficulties children with Down syndrome experience while using computers. The relationship between the age and the specific type of difficulties, as well as related design challenges are also reported. A number of potential research directions and hypotheses are identified for future studies. Due to limitations in survey methodology, the findings need to be further validated through hypothesis-driven, empirical studies. © 2010 ACM.",Children; Computer use; Down syndrome; Human-computer interaction,Computer supported cooperative work; Education; Employment; Knowledge management; Surveys; Career development; Computer technology; Computer use; Design challenges; Down syndrome; Empirical studies; Independent living; Research directions; Survey methodology; Human computer interaction
The development and evaluation of performance-based functional assessment: A methodology for the measurement of physical capabilities,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949094668&doi=10.1145%2f1530064.1530068&partnerID=40&md5=c3ba92967be6f7de827a40d299fd7704,"Understanding and describing the physical capabilities of users with motor impairments is a significant challenge for accessibility researchers and system designers alike. Current practice is to use descriptors such as medical diagnoses to represent a person's physical capabilities. This solution is not adequate due to similarities in functional capabilities between diagnoses as well as differences in capabilities within a diagnosis. An alternative is user self-reporting or observation by another person, but these solutions can be problematic because they rely on individual interpretations of capabilities and may introduce unwanted bias. The current research focuses on defining an objective, quantifiable, repeatable, and efficient methodology for assessing an individual's physical capabilities in relation to use of information technologies. Thirty-one users with a range of physical capabilities participated in the evaluation of the proposed performance-based functional assessmentmethodology. Building on the current standard for such assessments,multiple observers provided independent assessments that served as the gold standard for comparison. Promising metrics produced through the performance-based assessment were identified through comparisons with these observer evaluations. Predictive models were then generated via regression and correlation analysis. The models were validated using a three-fold validation process. Results from this initial research are encouraging, with the resulting models explaining up to 92% of the variance in user capabilities. Directions for future research are discussed. © 2009 ACM.",Accessibility; Functional assessment; HCI; Physical capabilities,Diagnosis; Functional assessment; Accessibility; Correlation analysis; Current practices; Current researches; Descriptors; Functional capabilities; Gold standards; HCI; Independent assessment; Medical diagnosis; Motor impairments; Multiple observers; Performance-based assessment; Physical capabilities; Predictive models; Self-reporting; System designers; Validation process; Research
A linguistically motivated model for speed and pausing in animations of American sign language,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67651118192&doi=10.1145%2f1530064.1530067&partnerID=40&md5=33d3fac1c54dd51ae446ec69e912f814,"Many deaf adults in the United States have difficulty reading written English text; computer animations of American Sign Language (ASL) can improve these individuals' access to information, communication, and services. Planning and scripting the movements of a virtual character's arms and body to perform a grammatically correct and understandable ASL sentence is a difficult task, and the timing subtleties of the animation can be particularly challenging. After examining the psycholinguistics literature on the speed and timing of ASL, we have designed software to calculate realistic timing of the movements in ASL animations. We have built algorithms to calculate the time-duration of signs and the location/length of pauses during an ASL animation. To determine whether our software can improve the quality of ASL animations, we conducted a study in which native ASL signers evaluated the ASL animations processed by our algorithms. We have found that: (1) adding linguistically motivated pauses and variations in sign-durations improved signers' performance on a comprehension task and (2) these animations were rated as more understandable by ASL signers. © 2009 ACM.",Accessibility technology for the deaf; American Sign Language; Animation; Evaluation; Natural language generation,Animation; Time measurement; Accessibility technology for the deaf; American sign language; Comprehension tasks; Computer animation; Evaluation; Natural language generation; Virtual character; Linguistics
Video modeling for training older adults to use new technologies,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649972382&doi=10.1145%2f1525840.1525844&partnerID=40&md5=a724925a4ffb9b19bc931855a01e19dd,"The increasing permeation of technology in our society leads to the challenge that everybody needs to interact with technology systems. Older adults often meet difficulties while trying to interact with complex, demanding systems in their daily life. One approach to enable older adults to use new technologies in a safe and efficient way is the provision of training programs. In this article we report about a promising training strategy using video modeling in conjunction with other instructional methods to enhance learning. Cognitive as well as socio-motivational aspects will be addressed. We assessed if guided error training in video modeling will improve learning outcomes for a Ticket Vending Machine (TVM). To investigate if the training method might be beneficial for younger adults as well, we compared 40 younger and 40 older adult learners in a guided error training course with error-free training. Younger and older participants made fewer mistakes in guided error training, but no differences occurred in task completion times. Moreover, self-efficacy increased with training for both age groups, but no significant differences were found for the training condition. Analysis of knowledge gains showed a significant benefit of guided error training in structural knowledge. Overall, the results showed that guided error training may enhance learning for younger and older adults who are learning to use technology. © 2009 ACM.",Guided error training; Instruction; Older adults; Self-efficacy; Technology use; Video modeling,Guided error training; Instruction; Older adults; Self efficacy; Technology use; Video modeling; Technology
Exploring visual and motor accessibility in navigating a virtual world,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651522362&doi=10.1145%2f1530064.1530069&partnerID=40&md5=c773797b78d4c7e7e1a32b8e75e14d47,"For many millions of users, 3D virtual worlds provide an engaging, immersive experience heightened by a synergistic combination of visual realism with dynamic control of the user's movement within the virtual world. For individuals with visual or dexterity impairments, however, one or both of those synergistic elements are impacted, reducing the usability and therefore the utility of the 3D virtual world. This article considers what features are necessary to make virtual worlds usable by such individuals. Empirical work has been based on a multiplayer 3D virtual world game called PowerUp, to which we have built in an extensive set of accessibility features. These features include in-world navigation and orientation tools, font customization, self-voicing text-tospeech output, key remapping options, and keyboard-only and mouse-only navigation. Through empirical work with legally blind teenagers and adults with cerebral palsy, these features have been refined and validated. Whereas accessibility support for users with visual impairment often revolves around keyboard navigation, these studies emphasized the need to support visual aspects of pointing device actions too. Other notable findings include use of speech to supplement sound effects for novice users, and, for those with cerebral palsy, a general preference to use a pointing device to look around the world, rather than keys or on-screen buttons. The PowerUp accessibility features provide a core level of accessibility for the user groups studied. © 2009 ACM.",3D; Accessibility; Audio interfaces; Cerebral palsy; Input; Virtual worlds,Navigation; Three dimensional; Virtual reality; 3D; Accessibility; Audio interfaces; Cerebral palsy; Input; Virtual worlds; Interactive computer graphics
Being old doesn't mean acting old: How older users interact with spoken dialog systems,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649951322&doi=10.1145%2f1525840.1525842&partnerID=40&md5=c3b3049aac130f5f65201f0dafadd93c,"Most studies on adapting voice interfaces to older users work top-down by comparing the interaction behavior of older and younger users. In contrast, we present a bottom-up approach. A statistical cluster analysis of 447 appointment scheduling dialogs between 50 older and younger users and 9 simulated spoken dialog systems revealed two main user groups, a ""social"" group and a ""factual"" group. ""Factual"" users adapted quickly to the systems and interacted efficiently with them. ""Social"" users, on the other hand, were more likely to treat the system like a human, and did not adapt their interaction style. While almost all ""social"" users were older, over a third of all older users belonged in the ""factual"" group. Cognitive abilities and gender did not predict group membership. We conclude that spoken dialog systems should adapt to users based on observed behavior, not on age. © 2009 ACM.",Aging; Clustering; Cognitive aging; Spoken dialog systems; Voice interfaces,Cluster analysis; Human computer interaction; Aging; Clustering; Cognitive aging; Spoken dialog systems; Voice interfaces; Cognitive systems
Exploring methods to improve pen-based menu selection for younger and older adults,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651524374&doi=10.1145%2f1525840.1525843&partnerID=40&md5=92ce19f835f918faa86c972680a7bb79,"Tablet PCs are gaining popularity, but many individuals still struggle with pen-based interaction. In a previous baseline study, we examined the types of difficulties younger and older adults encounter when using pen-based input. The research reported in this article seeks to address one of these errors, namely, missing just below. This error occurs in a menu selection task when a user's selection pattern is downwardly shifted, such that the top edge of the menu item below the target is selected relatively often, while the corresponding top edge of the target itself is seldom selected. We developed two approaches for addressingmissing just below errors: reassigning selections along the top edge and deactivating them. In a laboratory evaluation, only the deactivated edge approach showed promise overall. Further analysis of our data revealed that individual differences played a large role in our results and identified a new source of selection difficulty. Specifically, we observed two error-prone groups of users: the low hitters, who, like participants in the baseline study, made missing just below errors, and the high hitters, who, in contrast, had difficulty with errors on the item above. All but one of the older participants fell into one of these error-prone groups, reinforcing that older users do need better support for selecting menu items with a pen. Preliminary analysis of the performance data suggests both of our approaches were beneficial for the low hitters, but that additional techniques are needed to meet the needs of the high hitters and to address the challenge of supporting both groups in a single interface. © 2009 ACM.",Aging; Interaction techniques; Menu design; Older users; Pen-based target acquisition,Data handling; Design; Personal computers; User interfaces; Aging; Interaction techniques; Menu design; Older users; Pen-based; Errors
Introduction to the special issue on aging and information technology,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651547173&doi=10.1145%2f1525840.1525841&partnerID=40&md5=a017b7f7d269fc09ecf0ffd26f0ee4cb,This article provides an introduction to the Special Issue on Aging. © 2009 ACM.,Aging; Cognitive aging; Instruction; Menu design; Older adults; Pen interfaces; Quality of life technology; Spoken dialog systems; User privacy preferences; Video modeling; Voice interfaces,Design; Aging; Cognitive aging; Instruction; Menu design; Older adults; Pen interfaces; Quality of life; Spoken dialog systems; User privacy; Video modeling; Voice interfaces; Cognitive systems
ACM Transactions on Accessible Computing: Guest editorial,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651561971&doi=10.1145%2f1530064.1530065&partnerID=40&md5=a59b50dd33d24ba5340be40590da9b52,[No abstract available],,
A3: HCI coding guideline for research using video annotation to assess behavior of nonverbal subjects with computer-based intervention,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450191421&doi=10.1145%2f1530064.1530066&partnerID=40&md5=5bb5bd5236a4e85a4b4608e82f5b3c28,"HCI studies assessing nonverbal individuals (especially those who do not communicate through traditional linguistic means: spoken, written, or sign) are a daunting undertaking. Without the use of directed tasks, interviews, questionnaires, or question-answer sessions, researchers must rely fully upon observation of behavior, and the categorization and quantification of the participant's actions. This problem is compounded further by the lack of metrics to quantify the behavior of nonverbal subjects in computer-based intervention contexts. We present a set of dependent variables called A3 (pronounced A-Cubed) or Annotation for ASD Analysis, to assess the behavior of this demographic of users, specifically focusing on engagement and vocalization. This paper demonstrates how theory from multiple disciplines can be brought together to create a set of dependent variables, as well as demonstration of these variables, in an experimental context. Through an examination of the existing literature, and a detailed analysis of the current state of computer vision and speech detection, we present how computer automation may be integrated with the A3 guidelines to reduce coding time and potentially increase accuracy. We conclude by presenting how and where these variables can be used in multiple research areas and with varied target populations. © 2009 ACM.",Annotation; ASD; Audio feedback; Autism; Coding; Guideline; Intervention; Kappa; Nonverbal; Point-by-point agreement; Reliability; Video; Visualization,Computer vision; Visualization; Annotation; ASD; Audio feedback; Autism; Coding; Guideline; Intervention; Kappa; Nonverbal; Point-by-point agreement; Video; Research
"Disability, age, and informational privacy attitudes in quality of life technology applications: Results from a national Web survey",2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-74849137120&doi=10.1145%2f1525840.1525846&partnerID=40&md5=314c21506eca83aa9ffd871d47cacbff,"Technology aimed at enhancing function and enabling independent living among older and disabled adults is a growing field of research. Privacy concerns are a potential barrier to adoption of such technology. Using data from a national Web survey (n=1,518), we focus on perceived acceptability of sharing information about toileting, taking medications, moving about the home, cognitive ability, driving behavior, and vital signs with five targets: family, healthcare providers, insurance companies, researchers, and government. We also examine acceptability of recording the behaviors using three methods: video with sound, video without sound, and sensors. Results show that sharing or recording information about toileting behavior; sharing information with the government and insurance companies; and recording the information using video were least acceptable. Respondents who reported current disability were significantly more accepting of sharing and recording of information than nondisabled adults, controlling for demographic variables, general technology attitudes, and assistive device use. Results for age were less consistent, although older respondents tended to be more accepting than younger respondents. The study provides empirical evidence from a large national sample of the implicit trade-offs between privacy and the potential for improved health among older and disabled adults in quality of life technology applications. © 2009 ACM.",Quality of life technology; User privacy preferences,Handicapped persons; Insurance; Surveys; Technology; Assistive devices; Cognitive ability; Demographic variables; Driving behavior; Empirical evidence; Health care providers; Independent living; Insurance companies; Potential barriers; Privacy concerns; Quality of life; Quality of life technology; Recording information; Sharing information; Technology application; User privacy; Vital sign; Web surveys; Information dissemination
The effect of voice output on AAC-supported conversations of persons with Alzheimer's disease,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950672676&doi=10.1145%2f1497302.1497305&partnerID=40&md5=36a7ecc397e1d3f950aaa312b815212e,"The purpose of this study was to determine whether the presence or absence of digitized 1-2- word voice output on a direct selection, customized Augmentative and Alternative Communication (AAC) device would affect the impoverished conversations of persons with dementia. Thirty adults with moderate Alzheimer's disease participated in two personally relevant conversations with an AAC device. For twelve of the participants the AAC device included voice output. The AAC device was the FlexiboardTM containing sixteen messages needed to discuss a favorite autobiographical topic chosen by the participant and his/her family caregivers. Ten-minute conversations were videotaped in participants' residences and analyzed for four conversational measures related to the participants' communicative behavior. Results show that AAC devices with digitized voice output depress conversational performance and distract participants with moderate Alzheimer's disease as compared to similar devices without voice output. There were significantly more 1-word utterances and fewer total utterances when AAC devices included voice output, and the rate of topic elaborations/initiations was significantly lower when voice output was present. Discussion about the novelty of voice output for this population of elders and the need to train elders to use this technology is provided. © 2009 ACM.",Alzheimer's disease; Augmentative and Alternative; Communication (AAC); Dementia; Digitized speech synthesis; Language,Linguistics; Speech communication; Speech synthesis; Video recording; Alzheimer's disease; Augmentative and Alternative; Dementia; Digitized speech synthesis; Language; Diseases
Evaluating the STANDUP pun generating software with children with cerebral palsy,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049405436&doi=10.1145%2f1497302.1497306&partnerID=40&md5=ec835d165f551829c8fed3747674ab38,"The interactive STANDUP software was developed to provide children who use augmentative and alternative communication (AAC) with a ""language playground."" The software provides appropriate functionality for users with physical, speech, and language impairments to generate and tell novel punning riddles at different levels of complexity. STANDUP was evaluated with nine children with cerebral palsy during an eight-week study. Results show that the participants were able to generate and tell novel jokes with minimal or no support. The use of STANDUP impacted favorably on general AAC use. The study results also suggested that STANDUP could potentially have a positive effect on social and pragmatic skills. Further research to investigate the impact of STANDUP on communication skills is proposed. Suggestions for future software development include providing users with opportunities to complete jokes and to integrate online dictionaries when new vocabulary is encountered. © 2009 ACM.",Alternative and augmentative communication; Computational humor; Speech generation devices,Linguistics; Software design; Alternative and augmentative communication; Augmentative-and-alternative communication; Cerebral palsy; Communication skills; Computational humor; Language impairments; Online dictionaries; Positive effects; Software development; Speech generation devices; Speech communication
Conception and experimentation of a communication device with adaptive scanning,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651551234&doi=10.1145%2f1497302.1497304&partnerID=40&md5=561307d15a97f87668db018b11656daf,"For some people with motor disabilities and speech disorders, the only way to communicate and to have some control over their environment is through the use of a controlled scanning system operated by a single switch. The main problem with these systems is that the communication process tends to be exceedingly slow, since the system must scan through the available choices one at a time until the desired message is reached. One way of raising the speed of message selection is to optimize the elementary scanning delay in real time so that it allows the user to make selections as quickly as possible without making too many errors. With this objective in mind, this article presents a method for optimizing the scanning delay, which is based on an analysis of the data recorded in ""log files"" while applying the EDiTHsystem[Digital Teleaction Environment for People with Disabilities]. This analysis makes it possible to develop a human-machine interaction model specific to the study, and then to establish an adaptive algorithm for the calculation of the scanning delay. The results obtained with imposed scenarios and then in ecological situations provides a confirmation that our algorithms are effective in dynamically adapting a scan speed. The main advantage offered by the procedure proposed is that it works on timing information alone and thus does not require any knowledge of the scanning device itself. This allows it to work with any scanning device. © 2009 ACM.",Adaptative scanning rate; Alternative communication; Model Human Processor; Modeling; Scanning system,Adaptive algorithms; Communication; Imaging systems; Nanotechnology; Optimization; Profilometry; Speech; Adaptive scanning; Alternative communication; Communication device; Communication process; Ecological situation; Human machine interaction; Log file; Modeling; Motor disability; People with disabilities; Real time; Scanning device; Scanning rate; Scanning system; Scanning systems; Single switch; Speech disorders; Timing information; Scanning
User interaction with word prediction:The effects of prediction quality,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953892340&doi=10.1145%2f1497302.1497307&partnerID=40&md5=2b9b3f5f366bbe77c9c693630d2e4725,"Word prediction systems can reduce the number of keystrokes required to form a message in a letter-based AAC system. It has been questioned, however, whether such savings translate into an enhanced communication rate due to the additional overhead (e.g., shifting of focus and repeated scanning of a prediction list) required in using such a system. Our hypothesis is that word prediction has high potential for enhancing AAC communication rate, but the amount is dependent in a complex way on the accuracy of the predictions. Due to significant user interface variations in AAC systems and the potential bias of prior word prediction experience on existing devices, this hypothesis is difficult to verify. We present a study of two different word prediction methods compared against letter-by-letter entry at simulated AAC communication rates. We find that word prediction systems can in fact speed communication rate (an advanced system gave a 58.6% improvement), and that a more accurate word prediction system can raise the communication rate higher than is explained by the additional accuracy of the system alone due to better utilization (93.6% utilization for advanced versus 78.2% for basic). © 2009 ACM.",Communication rate; User study; Word prediction,Communication; User interfaces; AAC systems; Advanced systems; Communication rate; High potential; Prediction quality; User interaction; User study; Word prediction; Forecasting
Introduction to the special issue on AAC,2009,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651593935&doi=10.1145%2f1497302.1497303&partnerID=40&md5=d52bd216a53431ea4018b65acfb9d1a4,This article presents an introduction to the special issue on Augmentative and Alternative Communication (AAC). © 2009 ACM.,Alternative and augmentative communication; Humancomputer interaction,Alternative and augmentative communication; Augmentative-and-alternative communication
"Access and empowerment: Commentary on ""Computers and People with Disabilities""",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958528430&doi=10.1145%2f1408760.1408765&partnerID=40&md5=fa7383b4fffa489b9f002bed518b9c3f,"A number of positive changes have taken place since Glinert and York's 1992 call-to-arms. Progress reviewed in this article includes evolving considerations of universal design in the marketplace, ubiquitous computing with accessibility features, increasing computing research and conference venues that address needs of users with disabilities, and attention to the importance of user empowerment in development. © 2008 ACM.",Ubiquitous computing; Universal design; User-centered design; Web,Design; Usability engineering; Computing research; People with disabilities; Positive changes; Universal Design; User centered designs; Users with disabilities; Web; Ubiquitous computing
Multimodal trajectory playback for teaching shape information and trajectories to visually impaired computer users,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70049110517&doi=10.1145%2f1408760.1408766&partnerID=40&md5=74e01e52635fd41afb91ad8d34869c34,"There are difficulties in presenting nontextual or dynamic information to blind or visually impaired users through computers. This article examines the potential of haptic and auditory trajectory playback as a method of teaching shapes and gestures to visually impaired people. Two studies are described which test the success of teaching simple shapes. The first study examines haptic trajectory playback alone, played through a force-feedback device, and compares performance of visually impaired users with sighted users. It demonstrates that the task is significantly harder for visually impaired users. The second study builds on these results, combining forcefeedback with audio to teach visually impaired users to recreate shapes. The results suggest that users performed significantly better when presented with multimodal haptic and audio playback of the shape, rather than haptic only. Finally, an initial test of these ideas in an application context is described, with sighted participants describing drawings to visually impaired participants through touch and sound. This study demonstrates in what situations trajectory playback can prove a useful role in a collaborative setting. © 2008 ACM.",Accessibility; Evaluation; Multimodal; Trajectory playback,Accessibility; Application contexts; Collaborative settings; Computer users; Dynamic information; Evaluation; Force feedback devices; Force-feedback; Multi-modal; Shape information; Visually impaired; Visually impaired people; Visually-impaired users; Trajectories
Computers and people with disabilities,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650620466&doi=10.1145%2f1408760.1408761&partnerID=40&md5=136a152f01c0d732726edffb1fffb97c,[No abstract available],Accessibility; HCI; Inclusive design; Interfaces; Ubiquitous computing; Universal access; Web,
"Ubiquitous accessibility, common technology core, and micro assistive technology:Commentary on ""Computers and People with Disabilities""",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958541335&doi=10.1145%2f1408760.1408764&partnerID=40&md5=4476dd56acef092a63bc18f25927dee0,"Much has changed since 1992 when the original CACM article by Ephraim Glinert and Bryant York was published. In the early 1990's, accessibility was mostly an add-on, with only Apple computers having built-in access. Computers were playing an increasingly important role in education and employment, but had not yet completely integrated themselves into all aspects of life as completely as they have today. The World Wide Web as we know it had not yet been born. Today there are accessibility features built directly into every major operating system, and one OS even includes a built-in screen reader. Assistive technologies are more numerous and capable. And awareness of the importance of access is much higher. However, some things have not changed. Assistive technologies lag behind mainstream technologies in both compatibility and functionality. Effective assistive technologies are often beyond the financial reach of those who need them. Effective assistive technologies are not available in many countries and many languages, even though technology is reaching into education, employment, and daily living of more countries and more people in each country every year. In moving forward we need to build on what we have achieved and explore new concepts, such as a common technical core, ubiquitous accessibility, micro assistive technology, and free public accessibility. Cooperative and collaborative approaches also need to be explored if we are to have any hope of catching up and keeping up with the ever-accelerating mainstream information and communication technologies. © 2008 ACM.",Interfaces; Micro-AT; Ubiquitous accessibility,Computer operating systems; Microcomputers; Technology; World Wide Web; Apple Computers; Assistive technology; Catching-up; Collaborative approach; Daily living; Information and Communication Technologies; Interfaces; Micro-AT; Operating systems; People with disabilities; Screen readers; Ubiquitous accessibility; Usability engineering
"Keeping up with technology: Commentary on ""Computers and People with Disabilities""",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958562160&doi=10.1145%2f1408760.1408762&partnerID=40&md5=65ba53ecd5e5794230e68c4065d17e36,"This is a personal response to rereading the Glinert and York [1992] article ""Computers and People with Disabilities."" Comparing the world of assistive technology as it was in 1992 and as it now appears is instructive in terms of the things which have changed - and those which have not. The technology has certainly developed. This applies both to the mainstream and to the assistive technology which aims to make the mainstream accessible. So, in 1992, the GUI was a threat to visually impaired computer users; now there are powerful screen readers available. Yet what does not appear to have changed much is the fact that assistive technologies continue to lag behind the mainstream, constantly having to ""catch up."" Also, while there has been some increase in awareness of the need for accessibility, there is still scope for that awareness to be translated into action. © 2008 ACM.",Interfaces,Personal computers; Assistive technology; Computer users; Interfaces; People with disabilities; Screen readers; Visually impaired; Technology
"Accessible computing - Past trends and future suggestions: Commentary on ""Computers and People with Disabilities""",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-71649098091&doi=10.1145%2f1408760.1408763&partnerID=40&md5=5e698a07a333d78086baa3e73d626248,"This article gives a personal perspective on Glinert and York's 1992 paper, focusing on whether and how the situation has changed over the past 15 years, and makes recommendations for the future of the field of accessible computing with a particular focus on the needs of older people and people with cognitive dysfunction. © 2008 ACM.",Assistive technology; Cognitive dysfunction; Inclusive design; Older and disabled people; Theater in design,Design; Assistive technology; Cognitive dysfunction; Disabled people; Inclusive design; Theater in design; Usability engineering
ACM Transactions on Accessible Computing: Guest Editorial,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651558354&doi=10.1145%2f1361203.1361205&partnerID=40&md5=2019cff8c84e4ca2b56904a76aed280d,[No abstract available],,
"Sibylle, An assistive communication system adapting to the context and its user",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350308073&doi=10.1145%2f1361203.1361209&partnerID=40&md5=39ce671efeb3e102a4bd804df964cb5e,"In this article, we describe the latest version of Sibylle, an AAC system that permits persons who have severe physical disabilities to enter text with any computer application, as well as to compose messages to be read out through speech synthesis. The system consists of a virtual keyboard comprising a set of keypads that allow for the entering of characters or full words by a single-switch selection process. It also includes a sophisticated word prediction component which dynamically calculates the most appropriate words for a given context. This component is auto-adaptive, that is, it learns with every text the user enters. It thus adapts its predictions to the user's language and the current topic of communication as well. So far, the system works for French, German and English. Earlier versions of Sibylle have been used since 2001 in a rehabilitation center (Kerpape, France). © 2008 ACM.",Augmentative and alternative communication; Keystroke saving rate; Latent semantic analysis; User adaptation; Virtual keyboard; Word prediction,Communication systems; Computer applications; Forecasting; Handicapped persons; Human rehabilitation engineering; Semantics; Speech synthesis; Augmentative-and-alternative communication; Latent Semantic Analysis; User adaptation; Virtual Keyboards; Word prediction; Computer keyboards
ACM Transactions on Accessible Computing: Introduction,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651524945&doi=10.1145%2f1361203.1361204&partnerID=40&md5=a9bd34a27a4e3485c0b17a5fae5fd45c,[No abstract available],,
"Goal crossing with mice and trackballs for people with motor impairments: Performance, submovements, and design directions",2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953969417&doi=10.1145%2f1361203.1361207&partnerID=40&md5=f68e7feb2c4bfdb82ffa9944ffd49635,"Prior research shows that people with motor impairments face considerable challenges when using conventional mice and trackballs. One challenge is positioning the mouse cursor within confined target areas; another is executing a precise click without slipping. These problems can make mouse pointing in graphical user interfaces very difficult for some people. This article explores goal crossing as an alternative strategy for more accessible target acquisition. In goal crossing, targets are boundaries that are simply crossed by the mouse cursor. Thus, goal crossing avoids the two aforementioned problems. To date, however, researchers have not examined the feasibility of goal crossing for people with motor difficulties. We therefore present a study comparing area pointing and goal crossing. Our performance results indicate that although Fitts' throughput for able-bodied users is higher for area pointing than for goal crossing (4.72 vs. 3.61 bits/s), the opposite is true for users with motor impairments (2.34 vs. 2.88 bits/s). However, error rates are higher for goal crossing than for area pointing under a strict definition of crossing errors (6.23% vs. 1.94%). We also present path analyses and an examination of submovement velocity, acceleration, and jerk (the change in acceleration over time). These results show marked differences between crossing and pointing and almost categorically favor crossing. An important finding is that crossing reduces jerk for both participant groups, indicating more fluid, stable motion. To help realize the potential of goal crossing for computer access, we offer design concepts for crossing widgets that address the occlusion problem, which occurs when one crossing goal obscures another in persistent mouse-cursor interfaces. This work provides the motivation and initial steps for further exploration of goal crossing on the desktop, and may help researchers and designers to radically reshape user interfaces to provide accessible goal crossing, thereby lowering barriers to access. © 2008 ACM.",Area pointing; Fitts'law; Goal crossing; Motor impairments; Mouse pointing; Movement microstructure; Path analysis; Steering law; Submovements; Target acquisition; Throughput,Automobile exhibitions; Design; Ergonomics; Graphical user interfaces; Interfaces (computer); Mergers and acquisitions; Microstructure; Regression analysis; Research; Targets; Fitts' law; Goal crossing; Motor impairments; Path analysis; Pointing movement; Steering law; Submovements; Target acquisition; Computer control systems
Evaluation of American sign language generation by native ASL signers,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67651140139&doi=10.1145%2f1361203.1361206&partnerID=40&md5=9d1464b055e65496eb35b509bada3c9d,"There are many important factors in the design of evaluation studies for systems that generate animations of American Sign Language (ASL) sentences, and techniques for evaluating natural language generation of written texts are not easily adapted to ASL. When conducting user-based evaluations, several cultural and linguistic characteristics of members of the American Deaf community must be taken into account so as to ensure the accuracy of evaluations involving these users. This article describes an implementation and user-based evaluation (by native ASL signers) of a prototype ASL natural language generation system that produces sentences containing classifier predicates, which are frequent and complex spatial phenomena that previous ASL generators have not produced. Native signers preferred the system's output to Signed English animations - scoring it higher in grammaticality, understandability, and naturalness of movement. They were also more successful at a comprehension task after viewing the system's classifier predicate animations. © 2008 ACM.",Accessibility technology for the deaf; American Sign Language; Animation; Evaluation; Natural language generation,Animation; Classifiers; American sign language; Comprehension tasks; Evaluation; Evaluation study; Natural language generation; Natural language generation systems; Understandability; Written texts; Linguistics
The field evaluation of a mobile digital image communication application designed for people with aphasia,2008,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349574753&doi=10.1145%2f1361203.1361208&partnerID=40&md5=ead175e8c9a8e12d1df51baa39ba5180,"PhotoTalk is an application for a mobile device that allows people with aphasia to capture and manage digital photographs to support face-to-face communication. Unlike any other augmentative and alternative communication device for people with aphasia, PhotoTalk focuses solely on image capture and organization and is designed to be used independently. Our project used a streamlined process with three phases: (1) a rapid participatory design and development phase with two speech-language pathologists acting as representative users, (2) an informal usability study with five aphasic participants, which caught usability problems and provided preliminary feedback on the usefulness of PhotoTalk, and (3) a one-month field evaluation with two aphasic participants followed by a one-month secondary field evaluation with one aphasic participant, which showed that they all used it regularly and relatively independently, although not always for its intended communicative purpose. Our field evaluations demonstrated PhotoTalk's promise in terms of its usability and usefulness in everyday communication. © 2008 ACM.",AAC devices; Aphasia; Cognitive disability; Evaluation; Field study; Mobile technology; Participatory design,Design; Human rehabilitation engineering; Image processing; Mobile devices; Photography; Augmentative and alternative communication devices; Cognitive disability; Digital image; Digital photographs; Face-to-face communications; Field evaluation; Field studies; Image captures; Mobile Technology; Participatory design; Photo-talk; Three phasis; Usability problems; Usability studies; Communication
"Route Descriptions, Spatial Knowledge and Spatial Representations of Blind and Partially Sighted People: Improved Design of Electronic Travel Aids",2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159188004&doi=10.1145%2f3549077&partnerID=40&md5=d3cb31b06c9f0c9b5a2a012d1ee82cee,"The results presented here were obtained from an experimental study of blind people's experiences on two routes with very different characteristics. They are intended to answer three research questions on how blind people identify environmental features while travelling and use environmental information to form spatial representations, and the implications for the design of electronic travel aids to better support mental mapping of space. The results include detailed discussions of the mainly tactile and auditory information used by blind people to identify objects, as well as the different combinations of sensory information used in forming mental maps, the approaches participants used to do this, and the sensory modalities involved. They also provide a categorisation of the main features in participants' descriptions of the two routes. The answers to the three questions include a discussion of the relationship between the sensory information used in route descriptions and mental maps, and the implications of the results for the design of electronic travel aids to support mental mapping, including suggestions for new types of aids and guidelines for aid design.  © 2022 Copyright held by the owner/author(s).",Blind; mental models; object identification; partially sighted; route descriptions; sensory information,Cognitive systems; Information use; Blind; Blind people; Electronic travel aidss; Mental maps; Mental model; Object identification; Partially sighted; Route descriptions; Sensory information; Spatial representations; Mapping
A Systematic Review of User Studies as a Basis for the Design of Systems for Automatic Sign Language Processing,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158118135&doi=10.1145%2f3563395&partnerID=40&md5=017565a1e0f76386c7f3a51958a757fa,"Deaf persons, whether or not they are sign language users, make up one of various existing marginalized populations that historically have been socially and politically underrepresented. Unfortunately, this also happens in technology design. Conducting user studies in which marginalized populations are represented is a step towards guaranteeing their right to participate in choices and decisions that are made for, with, and by them. This article presents and discusses results from a Systematic Literature Review (SLR) of user studies in the design of systems for Automatic Sign Language Processing (ASLP). Following our SLR protocol, from 2,486 papers initially found, we applied inclusion and exclusion criteria to finally select 37 papers in our review. We excluded publications that were not full papers, were not related to our main topic of interest, or that reported results that had been updated by more recent papers. All the selected papers focus on user studies as a basis for the design of three major aspects of ASLP: generation (ASLG), recognition (ASLR), and translation (ASLT). With regard to our specific area of interest, we analyzed four areas related to our research questions: goals and research methods, types of user involvement in the interaction design life cycle, cultural and collaborative aspects, and other lessons learned from the primary studies under review. Salient findings from our analysis show that numerical scale questionnaires are the most frequently used research instruments, co-designing ASLP systems with sign language users is not a common practice (as potential users are included mostly in the evaluation phase), and only seldom are Deaf persons who are sign language users included as members of research teams. These findings point to the need of conducting more inclusive and qualitative research for, with and by Deaf persons who are sign language users.  © 2022 Association for Computing Machinery.",assistive technology; automatic generation; automatic recognition; automatic translation; sign language; systematic review; universal design; User studies,Life cycle; Translation (languages); Assistive technology; Automatic Generation; Automatic recognition; Automatic translation; Deaf persons; Language processing; Sign language; Systematic Review; Universal Design; User study; Paper
ACM TACCESS Special Issue on Adaptive Inclusive AR/VR Systems,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146092396&doi=10.1145%2f3561517&partnerID=40&md5=0295fd9a8860e793f8adc3b0703e5d54,[No abstract available],,
Towards Effective Telerehabilitation: Assessing Effects of Applying Augmented Reality in Remote Rehabilitation of Patients Suffering from Multiple Sclerosis,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149969683&doi=10.1145%2f3560822&partnerID=40&md5=7c3087c0b2a7329b59ece8e4127d1c5f,"Multiple Sclerosis (MS) is a chronic, incurable disease of the central nervous system that is also one of the most common causes of disability among young adults. Despite available pharmacological treatments, the patients often require ongoing, supervised rehabilitation. Thus, therapists are constantly searching for new, effective ways of improving functional performance and quality of life without frequently visiting medical centers. One of the most promising methods is remote telerehabilitation enhanced with an immersive augmented reality (AR) interface. Here, we investigated the effectiveness of using a commercially available AR system in MS patients' treatment. To evaluate such an approach to rehabilitation, we conducted a medical study with 30 MS patients undergoing immunomodulatory treatment. In this study, we evaluated the influence on the patients' upper limbs' hand grip strength and efficiency of the patients' upper limbs. In addition, we also analyzed the level of neurotrophins to assess the potential impact of the training on the brain plasticity process. Our results show that rehabilitation enhanced with AR significantly improves the strength and efficiency of the patients' upper limbs. Furthermore, we further infer that AR-enhanced systems are a promising possibility of training without leaving home.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Augmented reality; mixed reality; multiple sclerosis; neuroplasticity; telerehabilitation,Augmented reality; Efficiency; Patient rehabilitation; Patient treatment; Central nervous systems; Incurable disease; Mixed reality; Multiple sclerosis; Neuroplasticity; Patient's suffering; Pharmacological treatment; Telerehabilitation; Upper limbs; Young adults; Mixed reality
Impact of Online Learning in the Context of COVID-19 on Undergraduates with Disabilities and Mental Health Concerns,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142371967&doi=10.1145%2f3538514&partnerID=40&md5=37c167d7135a7fa027e6484349d6f7c3,"The COVID-19 pandemic upended college education and the experiences of students due to the rapid and uneven shift to online learning. This study examined the experiences of students with disabilities with online learning, with a consideration of surrounding stressors such as financial pressures. In a mixed method approach, we compared 28 undergraduate students with disabilities (including mental health concerns) to their peers during 2020, to assess differences and similarities in their educational concerns, stress levels, and COVID-19-related adversities. We found that students with disabilities entered the Spring quarter of 2020 with significantly higher concerns about classes going online, and reported more recent negative life events than other students. These differences between the two groups diminished 3 months later with the exception of recent negative life events. For a fuller understanding of students' experiences, we conducted qualitative analysis of open-ended interviews. We examined both positive and negative experiences with online learning among students with disabilities and mental health concerns. We describe how online learning enabled greater access - e.g., reducing the need for travel to campus - alongside ways in which online learning impeded academic engagement - e.g., reducing interpersonal interaction. We highlight a need for learning systems to meet the diverse and dynamic needs of students with disabilities.  © 2022 Copyright held by the owner/author(s).",COVID-19; Disability; education; hybrid learning systems; mental health; mixed methods,E-learning; Learning systems; Students; College education; Disability; Financial pressure; Health concerns; Hybrid learning; Hybrid learning system; Life events; Mental health; Mixed method; Online learning; COVID-19
Author Reflections on Creating Accessible Academic Papers,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159197154&doi=10.1145%2f3546195&partnerID=40&md5=7d347ccb86043547500692eea2be9dec,"Academic papers demonstrate inaccessibility despite accessible writing resources made available by SIGACCESS and others. The move from accessibility guidance to accessibility implementation is challenging for authors. Our work focuses on understanding what challenges authors of academic papers face in creating content elements (e.g., tables, charts, images) to better understand how to improve accessibility. We classified 3,866 content elements from 330 papers covering a 10-year sample of academic work from ASSETS to understand the variety used. We also reflected on the design choices that make the content elements inaccessible. We then conducted interviews with 13 academic authors from PhD student through to Professor Emeritus that publish within top-tier accessibility and HCI venues to understand the challenges faced in creating accessible content. We found critical issues in how academics understand and implement accessibility while also balancing the visual design of the paper. We provide recommendations for improving accessibility in the academic paper-writing process and focus on steps that can be taken by authors, publishers, researchers, and universities.  © 2022 Association for Computing Machinery.",Accessibility; charts; content elements; images; tables,Image enhancement; Academic paper; Academic work; Accessibility; Chart; Classifieds; Content element; Critical issues; Image; Table; Visual design; Paper
Implementing Ability-Based Design: A Systematic Approach to Conceptual User Modeling,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158119260&doi=10.1145%2f3551646&partnerID=40&md5=12221709c1a29660e19e2f6540e7115e,"The notion of Ability-Based Design, put forth by Wobbrock et al. [80, 82] as a solution to the challenge of creating accessible technology, has been discussed in human-computer interaction research now for over a decade. However, despite being cited as influential on various projects, the concept still lacks a general characterization of how to implement its required focus on abilities. In particular, it lacks a formulation of how to perceive and model users within an articulated design process. To address this shortcoming, we rely on conceptual user modeling to examine Ability-Based Design and propose a characterization of it that is not dependent upon a specific project or research effort but that enables the ability-based design of new technologies in a systematic manner. Our findings show that Ability-Based Design's focus on abilities requires important changes in typical user modeling approaches that cannot be met with current techniques. Based on the challenges identified through our analysis, we propose a first modification not only of current user modeling but also of current requirements analysis approaches to address abilities and their intertwined dependencies with tasks and contexts as core elements of conceptual models in Ability-Based Design. We thereby demonstrate not only the complexity of modeling users' abilities, but also draw out promising ideas and perspectives for future research, emphasizing the need for future evaluative work on our approach.  © 2022 Association for Computing Machinery.",Ability-based design; conceptual user modeling; methodology,Design; 'current; Ability-based design; Conceptual user modeling; Design-process; Human-computer interaction researches; Methodology; Modeling approach; Requirement analysis; Research efforts; User Modelling; Human computer interaction
Ally: Understanding Text Messaging to Build a Better Onscreen Keyboard for Blind People,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148570975&doi=10.1145%2f3533707&partnerID=40&md5=b6f93c0e508b211f182d8b476db09a7c,"Millions of people worldwide use smartphones every day, but the standard issue QWERTY keyboard is poorly optimized for non-sighted input. In this article, we document the variety of methods blind people use to enter text into their smartphones, and focus on one particular need: sending text messages. We analyze two modern corpora of text messages and contrast them with an older text message corpus, as well as other corpora gathered from news articles, chat rooms, and books. We present a virtual keyboard for blind people optimized for sending text messages called Ally. To evaluate Ally, we conducted two user studies with blind participants. Our first study found increasing speeds and our second study found that half of participants reached comparable speeds to QWERTY, suggesting it may be a viable replacement. We conclude with a discussion of future work for non-sighted text-entry of text messages.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",blind; mobile text-entry; onscreen keyboard; smartphone keyboard; Soft keyboard; vision-impaired,Text messaging; Blind; Blind people; Mobile text entry; News articles; On-screen keyboard; Smart phones; Smartphone keyboard; Soft keyboard; Text-messaging; Vision impaired; Smartphones
Planning Your Journey in Audio: Design and Evaluation of Auditory Route Overviews,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135020498&doi=10.1145%2f3531529&partnerID=40&md5=21dac9d8ab06db13f6eb69b242019f85,"Auditory overviews of routes can provide routing and map information to blind users enabling them to preview route maps before embarking on a journey. This article investigates the usefulness of a system designed to do this through a Preliminary Survey, followed by a Design Study to gather the design requirements, development of a prototype and evaluation through a Usability Study. The design is drawn in two stages with eight audio designers and eight potential blind users. The auditory route overview is sequential and automatically generated as integrated audio. It comprises auditory icons to represent points of interest, earcons for auditory brackets encapsulating repeating points of interest, and speech for directions. A prototype based on this design is developed and evaluated with 22 sighted and eight blind participants. The software architecture of the prototype including the route information retrieval and mapping onto audio has been included. The findings show that both groups perform well in route reconstruction and recognition tasks. Moreover, the functional route information and auditory icons are effectively designed and useful in forming a mental model of the route, which improves over time. However, the design of auditory brackets needs further improvement and testing. At all stages of the system development, input has been acquired from the end-user population and the design is adapted accordingly.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",auditory display design; auditory route overviews; Blind navigation; user-led design,Software prototyping; Auditory display; Auditory display design; Auditory route overview; Blind navigation; Blind users; Design and evaluations; Display designs; Route map; Routings; User-lead design; Fasteners
The Global Care Ecosystems of 3D Printed Assistive Devices,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159205917&doi=10.1145%2f3537676&partnerID=40&md5=e9373f06cae8d91695123e612a618b56,"The popularity of 3D printed assistive technology has led to the emergence of new ecosystems of care, where multiple stakeholders (makers, clinicians, and recipients with disabilities) work toward creating new upper limb prosthetic devices. However, despite the increasing growth, we currently know little about the differences between these care ecosystems. Medical regulations and the prevailing culture have greatly impacted how ecosystems are structured and stakeholders work together, including whether clinicians and makers collaborate. To better understand these care ecosystems, we interviewed a range of stakeholders from multiple countries, including Brazil, Chile, Costa Rica, France, India, Mexico, and the U.S. Our broad analysis allowed us to uncover different working examples of how multiple stakeholders collaborate within these care ecosystems and the main challenges they face. Through our study, we were able to uncover that ecosystems with multi-stakeholder collaborations exist (something prior work had not seen), and these ecosystems showed increased success and impact. We also identified some of the key follow-up practices to reduce device abandonment. Of particular importance are to have ecosystems put in place follow-up practices that integrate formal agreements and compensations for participation (which do not need to be just monetary). We identified that these features helped to ensure multi-stakeholder involvement and ecosystem sustainability. We finished the article with socio-technical recommendations to create vibrant care ecosystems that include multiple stakeholders in the production of 3D printed assistive devices.  © 2022 Association for Computing Machinery.",3D printed assistive technology; 3D printing; fabrication; making,3D printing; Ecosystems; 3-D printing; 3d printed assistive technology; 3D-printing; Assistive devices; Assistive technology; Follow up; Making; Multi-stakeholder; Multiple stakeholders; Upper limb prosthetics; Assistive technology
“I’m Just Overwhelmed”: Investigating Physical Therapy Accessibility and Technology Interventions for People with Disabilities and/or Chronic Conditions,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159365739&doi=10.1145%2f3563396&partnerID=40&md5=60ea79fd5d08a63eae7a13bf3036b1d8,"Many individuals with disabilities and/or chronic conditions (da/cc) experience symptoms that may require intermittent or on-going medical care. However, healthcare is an often-overlooked domain for accessibility work, where access needs associated with temporary and long-term disability must be addressed to increase the utility of physical and digital interactions with healthcare workers and spaces. Our work focuses on a specific domain of healthcare often used by individuals with da/cc: physical therapy (PT). Through a 12-person interview study, we examined how people's access to PT for their da/cc is hampered by social (e.g., physically visiting a PT clinic) and physiological (e.g., chronic pain) barriers, and how technology could improve PT access. In-person PT is often inaccessible to our participants due to lack of transportation and insufficient insurance coverage. As such, many of our participants relied on at-home PT to manage their da/cc symptoms and work towards PT goals. Participants felt that PT barriers, such as having particularly bad symptoms or feeling short on time, could be addressed with well-designed technology that flexibly adapts to the person's dynamically changing needs while supporting their PT goals. We introduce core design principles (adaptability, movement tracking, community building) and tensions (insurance) to consider when developing technology to support PT access. Rethinking da/cc access to PT from a lens that includes social and physiological barriers presents opportunities to integrate accessibility and adaptability into PT technology.  © 2022 Association for Computing Machinery.",Accessibility; chronic conditions; chronic illness; disability; physical therapy; user needs,Health care; Human engineering; Insurance; User interfaces; Accessibility; Chronic conditions; Chronic illness; Digital interactions; Disability; Healthcare workers; Interview study; People with disabilities; Physical interactions; User need; Physiology
Designing Spellcasters from Clinician Perspectives: A Customizable Gesture-Based Immersive Virtual Reality Game for Stroke Rehabilitation,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146050983&doi=10.1145%2f3530820&partnerID=40&md5=1861d33a04e4efd38840ae612fb3cbb6,"Developing games is time-consuming and costly. Overly clinical therapy games run the risk of being boring, which defeats the purpose of using games to motivate healing in the first place [10, 23]. In this work, we adapt and repurpose an existing immersive virtual reality (iVR) game, Spellcasters, originally designed purely for entertainment for use as a stroke rehabilitation game—which is particularly relevant in the wake of COVID-19, where telehealth solutions are increasingly needed [4]. In preparation for participatory design sessions with stroke survivors, we collaborate with 14 medical professionals to ensure Spellcasters is safe and therapeutically valid for clinical adoption. We present our novel VR sandbox implementation that allows medical professionals to customize appropriate gestures and interactions for each patient’s unique needs. Additionally, we share a co-designed companion app prototype based on clinicians’ preferred data reporting mechanisms for telehealth. We discuss insights about adapting and repurposing entertainment games as serious games for health, features that clinicians value, and the potential broader impacts of applications like Spellcasters for stroke management. © 2022 Copyright held by the owner/author(s).",digital therapeutics; game design; games for health; immersive virtual reality; serious games; Stroke rehabilitation; therapy,Game design; Interactive computer graphics; Medical computing; Virtual reality; Clinical therapy; Customizable; Digital therapeutic; Game design; Game for healths; Immersive virtual reality; Medical professionals; Stroke rehabilitation; Tele-health solutions; Therapy; Serious games
A Scoping Review of Assistance and Therapy with Head-Mounted Displays for People Who Are Visually Impaired,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146055501&doi=10.1145%2f3522693&partnerID=40&md5=f052df8267b0cdfef26f13441d52a9a0,"Given the inherent visual affordances of Head-Mounted Displays (HMDs) used for Virtual and Augmented Reality (VR/AR), they have been actively used over many years as assistive and therapeutic devices for the people who are visually impaired. In this article, we report on a scoping review of literature describing the use of HMDs in these areas. Our high-level objectives included detailed reviews and quantitative analyses of the literature, and the development of insights related to emerging trends and future research directions. Our review began with a pool of 1,251 articles collected through a variety of mechanisms. Through a structured screening process, we identified 61 English research articles employing HMDs to enhance the visual sense of people with visual impairments for more detailed analyses. Our analyses reveal that there is an increasing amount of HMD-based research on visual assistance and therapy, and there are trends in the approaches associated with the research objectives. For example, AR is most often used for visual assistive purposes, whereas VR is used for therapeutic purposes. We report on eight existing survey articles, and present detailed analyses of the 61 research articles, looking at the mitigation objectives of the researchers (assistive versus therapeutic), the approaches used, the types of HMDs, the targeted visual conditions, and the inclusion of user studies. In addition to our detailed reviews and analyses of the various characteristics, we present observations related to apparent emerging trends and future research directions. © 2022 Association for Computing Machinery.",assistance; augmented reality; Head-mounted display; HMD; therapy; virtual reality; visual impairment,Helmet mounted displays; Virtual reality; Assistance; Assistive; Emerging trends; Future research directions; Head-mounted-displays; Scoping review; Therapy; Visual impairment; Visually impaired; Augmented reality
Beyond the Cane: Describing Urban Scenes to Blind People for Mobility Tasks,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144066162&doi=10.1145%2f3522757&partnerID=40&md5=27ddc6c2ebd4a8b31f99ca1ba0b95c9d,"Blind people face difficulties with independent mobility, impacting employment prospects, social inclusion, and quality of life. Given the advancements in computer vision, with more efficient and effective automated information extraction from visual scenes, it is important to determine what information is worth conveying to blind travelers, especially since people have a limited capacity to receive and process sensory information. We aimed to investigate which objects in a street scene are useful to describe and how those objects should be described. Thirteen cane-using participants, five of whom were early blind, took part in two urban walking experiments. In the first experiment, participants were asked to voice their information needs in the form of questions to the experimenter. In the second experiment, participants were asked to score scene descriptions and navigation instructions, provided by the experimenter, in terms of their usefulness. The descriptions included a variety of objects with various annotations per object. Additionally, we asked participants to rank order the objects and the different descriptions per object in terms of priority and explain why the provided information is or is not useful to them. The results reveal differences between early and late blind participants. Late blind participants requested information more frequently and prioritized information about objects' locations. Our results illustrate how different factors, such as the level of detail, relative position, and what type of information is provided when describing an object, affected the usefulness of scene descriptions. Participants explained how they (indirectly) used information, but they were frequently unable to explain their ratings. The results distinguish between various types of travel information, underscore the importance of featuring these types at multiple levels of abstraction, and highlight gaps in current understanding of travel information needs. Elucidating the information needs of blind travelers is critical for the development of more useful assistive technologies.  © 2022 Association for Computing Machinery.",assistive technologies; Blindness; impaired vision; independence; mobility; navigation; outdoor; scene description,Assistive technology; Computer programming; Assistive technology; Blind people; Blindness; Impaired vision; Independence; Mobility; Outdoor; Scene description; Travel information; Urban scenes; Conveying
Two-In-One: A Design Space for Mapping Unimanual Input into Bimanual Interactions in VR for Users with Limited Movement,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146048245&doi=10.1145%2f3510463&partnerID=40&md5=79e56fdb6906286b4169dbf617844983,"Virtual Reality (VR) applications often require users to perform actions with two hands when performing tasks and interacting with objects in virtual environments. Although bimanual interactions in VR can resemble real-world interactions—thus increasing realism and improving immersion—they can also pose significant accessibility challenges to people with limited mobility, such as for people who have full use of only one hand. An opportunity exists to create accessible techniques that take advantage of users’ abilities, but designers currently lack structured tools to consider alternative approaches. To begin filling this gap, we propose Two-In-One, a design space that facilitates the creation of accessible methods for bimanual interactions in VR from unimanual input. Our design space comprises two dimensions, bimanual interactions and computer assistance, and we provide a detailed examination of issues to consider when creating new unimanual input techniques that map to bimanual interactions in VR. We used our design space to create three interaction techniques that we subsequently implemented for a subset of bimanual interactions and received user feedback through a video elicitation study with 17 people with limited mobility. Our findings explore complex tradeoffs associated with autonomy and agency and highlight the need for additional settings and methods to make VR accessible to people with limited mobility. © 2022 Association for Computing Machinery.",Accessibility; bimanual; input techniques; interaction techniques; movement limitations; virtual reality,Virtual reality; Accessibility; Bi-manual interaction; Bimanual; Design spaces; Input techniques; Interaction techniques; Movement limitation; Real-world; Two hand; Two in ones; User interfaces
A Participatory Design Approach to Creating Echolocation-Enabled Virtual Environments,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141383648&doi=10.1145%2f3516448&partnerID=40&md5=1edaf75ad941fcf5d32eeb935c8393e2,"As virtual environments—in the form of videogames and augmented and virtual reality experiences—become more popular, it is important to ensure that they are accessible to all. Previous research has identified echolocation as a useful interaction approach to enable people with visual impairment to access virtual environments. In this article, we further investigate the usefulness of echolocation to explore virtual environments. We follow a participatory design approach that comprised a focus group session coupled with two fast prototyping and evaluation iterations. During the focus group session, expert echolocators produced a series of seven design recommendations, of which we implemented and trialed four. Our trials revealed that the use of ambient sounds, the ability to place landmarks, directional control, and the ability to use pre-recorded mouth-clicks produced by expert echolocators improved the overall experience of our participants by facilitating the detection of openings and obstacles. The recommendations presented and evaluated in this article may help to develop virtual environments that support a broader range of users while recognising the value of the lived experience of people with disability as a source of knowledge. © 2022 Copyright held by the owner/author(s).",Echolocation; participatory design; virtual world,Interactive computer graphics; Sonar; Augmented and virtual realities; Design approaches; Echolocation; Fast prototyping; Focus groups; Participatory design; Video-games; Virtual reality experiences; Virtual worlds; Visual impairment; Virtual reality
Comparing Two Safe Distance Maintenance Algorithms for a Gaze-Controlled HRI Involving Users with SSMI,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146053268&doi=10.1145%2f3530822&partnerID=40&md5=5b2464259908cb2033082340f401fecf,People with severe speech and motor impairment often find it difficult to manipulate physical objects due to spasticity and have familiarity with eye pointing based communication. This article presents a novel eye gaze controlled augmented reality human-robot interface that maintains a safe distance of the robot from the operator. We used a bespoke appearance-based eye gaze tracking algorithm and compared two different safe distance maintenance algorithms. We undertook simulation studies followed by a user trial involving end users. Users with severe speech and motor impairment could bring the robotic arm at any designated point within its working envelope in less than 3 minutes. © 2022 Association for Computing Machinery.,assistive technology; Eye gaze tracking; Markov decision process; navigation path; robotics,Augmented reality; Eye tracking; Robots; Assistive technology; Eye gaze tracking; Eye-gaze; Maintenance algorithms; Markov Decision Processes; Motor impairments; Navigation paths; Physical objects; Safe distance; Spasticity; Markov processes
Tactile Materials in Practice: Understanding the Experiences of Teachers of the Visually Impaired,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141214464&doi=10.1145%2f3508364&partnerID=40&md5=ae3cb0bc4a30799b3767f87de2ccdc6f,"Teachers of the visually impaired (TVIs) regularly present tactile materials (tactile graphics, 3D models, and real objects) to students with vision impairments. Researchers have been increasingly interested in designing tools to support the use of tactile materials, but we still lack an in-depth understanding of how tactile materials are created and used in practice today. To address this gap, we conducted interviews with 21 TVIs and a 3-week diary study with eight of them. We found that tactile materials were regularly used for academic as well as non-academic concepts like tactile literacy, motor ability, and spatial awareness. Real objects and 3D models served as “stepping stones” to tactile graphics and our participants preferred to teach with 3D models, despite finding them difficult to create, obtain, and modify. Use of certain materials also carried social implications; participants selected materials that fostered student independence and allow classroom inclusion. We contribute design considerations, encouraging future work on tactile materials to enable student and TVI co-creation, facilitate rapid prototyping, and promote movement and spatial awareness. To support future research in this area, our paper provides a fundamental understanding of current practices. We bridge these practices to established pedagogical approaches and highlight opportunities for growth regarding this important genre of educational materials. © 2022 Copyright held by the owner/author(s).",3D models; tactile graphics; Tactile materials; visual impairments,3D modeling; 3D models; 3d-modeling; Real objects; Spatial awareness; Tactile graphic; Tactile material; Teachers'; Vision impairments; Visual impairment; Visually impaired; Students
MetaCogs: Mitigating Executive Dysfunction via Agent-based Modeling for Metacognitive Strategy Development,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146051757&doi=10.1145%2f3514254&partnerID=40&md5=2c55ba2bffe1b54f6dee001aaa4079ff,"Executive functions (EF) are a collection of cognitive domains governing task initiation, motor planning, attention, and goal-oriented action. Difficulties with EF have marked impacts on adaptive living skills, learning outcomes, and quality of life for people with cognitive and psychosocial disabilities, as well as the broader population. While there is considerable research interest in EF training intervention for disabled populations, very few studies explore metacognitive intervention for people with cognitive disabilities. Metacognition comprises conscious beliefs and strategies around task management and goal setting. Metacognitive awareness has been shown to mediate the effects of executive function on self-regulated learning. Metacognitive interventions have also shown promise in general education, military training, and medical practice. We present a virtual reality experience deploying agent-based modeling to support explicit metacognitive strategy instruction for undergraduate students of all neurotypes. Our results support that explicit instructional material explaining executive function and metacognition in relation to problem-solving experiences influenced participant self-concept and awareness of personal traits and cognitive processes. © 2022 Copyright held by the owner/author(s).",ADHD; autism; executive function; Metacognition; virtual reality,Autonomous agents; Cognitive systems; Computational methods; Problem solving; Simulation platform; Students; ADHD; Agent-based model; Autism; Cognitive domain; Executive dysfunctions; Executive function; Metacognition; Metacognitive strategies; Metacognitives; Strategy development; Virtual reality
A Support Worker Perspective on Use of New Technologies by People with Intellectual Disabilities,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146050410&doi=10.1145%2f3523058&partnerID=40&md5=821e112c2351040a29190a8685313ac4,"People with intellectual disability access innovative technologies in disability community centres in Australia, under the guidance of support workers. This article investigates the perspectives of 15 support workers and 5 managers across four community centres on the introduction and use of technology like tablets, video games, 3D printing, virtual reality, and social robots. They had diverse views on who is responsible for facilitating, embedding, and shaping technology for learning life skills and socializing. We found technology use to be driven by facilitator’s knowledge (pre-existing, observed, or trained), interests, the value they place on the interactions afforded by the technology, and organization values. We discuss how future designs can emphasise communities of users while empowering individuals to achieve their goals. We suggest co-design strategies for assistive technology that involve support workers in the dual roles of proxy and co-user. We finally discuss how broader organisational factors can influence appropriation and use. © 2022 Copyright held by the owner/author(s).",cognitive impairment; disability service providers; Intellectual disability; learning disability; support workers; technology adoption,3D printers; Engineering education; Human resource management; Three dimensional computer graphics; Virtual reality; Cognitive impairment; Community centers; Disability service provider; Innovative technology; Intellectual disability; Learning disabilities; Service provider; Support worker; Technology adoption; Workers'; Assistive technology
“Every Website Is a Puzzle!”: Facilitating Access to Common Website Features for People with Visual Impairments,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146053122&doi=10.1145%2f3519032&partnerID=40&md5=dde0802d8dc6dd7eafe428d33a687648,"Navigating unfamiliar websites is challenging for users with visual impairments. Although many websites offer visual cues to facilitate access to pages/features most websites are expected to have (e.g., log in at the top right), such visual shortcuts are not accessible to users with visual impairments. Moreover, although such pages serve the same functionality across websites (e.g., to log in, to sign up), the location, wording, and navigation path of links to these pages vary from one website to another. Such inconsistencies are challenging for users with visual impairments, especially for users of screen readers, who often need to linearly listen to content of pages to figure out how to access certain website features. To study how to improve access to main website features, we iteratively designed and tested a command-based approach for main features of websites via a browser extension powered by machine learning and human input. The browser extension gives users a way to access high-level website features (e.g., log in, find stores, contact) via keyboard commands. We tested the browser extension in a lab setting with 15 Internet users, including 9 users with visual impairments and 6 without. Our study showed that commands for main website features can greatly improve the experience of users with visual impairments. People without visual impairments also found command-based access helpful when visiting unfamiliar, cluttered, or infrequently visited websites, suggesting that this approach can support users with visual impairments while also benefiting other user groups (i.e., universal design). Our study reveals concerns about the handling of unsupported commands and the availability and trustworthiness of human input. We discuss how websites, browsers, and assistive technologies could incorporate a command-based paradigm to enhance web accessibility and provide more consistency on the web to benefit users with varied abilities when navigating unfamiliar or complex websites. © 2022 Copyright held by the owner/author(s).",intelligent personal assistants; Website accessibility; website commands,Internet users; Keyboard commands; Machine-learning; Navigation paths; Screen readers; Visual cues; Visual impairment; Website accessibility; Website command; Website features; Web Design
Comic Spin: A Comic Creation Tool Enabling Self-expression for People with Aphasia,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132076387&doi=10.1145%2f3508500&partnerID=40&md5=8f4f4bd044ba91f09d58dd263f056f40,"Comics, with their highly visual format, offer a promising opportunity for people who experience challenges with language to express humour and emotion. However, comic creation tools are not designed to be accessible to people with language impairments such as aphasia. We report the design and exploration of Comic Spin, an app for people with aphasia that supports the creation of comic strips by constraining the creative space. We explored the use of Comic Spin in two studies involving creative workshops. Findings showed that people were able to use Comic Spin successfully to create a range of narrative, humorous, and subversive comic strips, and that these enabled people to self-express in ways that went beyond the content of the comic strips themselves.  © 2022 held by the owner/author(s). Publication rights licensed to ACM.",accessibility; aphasia; Comic Spin; comics; constrained creativity; creativity support tools,Accessibility; Aphasia; Comic; Comic spin; Comic strips; Constrained creativity; Creativity support; Creativity support tool; Language impairments; Support tool; Visual languages
AIGuide: Augmented Reality Hand Guidance in a Visual Prosthetic,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132073796&doi=10.1145%2f3508501&partnerID=40&md5=919190290cd941ed81b7f739e68c0719,"Locating and grasping objects is a critical task in people's daily lives. For people with visual impairments, this task can be a daily struggle. The support of augmented reality frameworks in smartphones can overcome the limitations of current object detection applications designed for people with visual impairments. We present AIGuide, a self-contained smartphone application that leverages augmented reality technology to help users locate and pick up objects around them. We conducted a user study to investigate the effectiveness of AIGuide in a visual prosthetic for providing guidance; compare it to other assistive technology form factors; investigate the use of multimodal feedback, and provide feedback about the overall experience. We gathered performance data and participants' reactions and analyzed videos to understand users' interactions with the nonvisual smartphone user interface. Our results show that AIGuide is a promising technology to help people with visual impairments locate and acquire objects in their daily routine. The benefits of AIGuide may be enhanced with appropriate interaction design.  © 2022 Association for Computing Machinery.",augmented reality; Mobile assistive technology; nonvisual guidance interaction; people with visual impairments,Assistive technology; Object detection; Prosthetics; Smartphones; User interfaces; Assistive technology; Critical tasks; Daily lives; Grasping objects; Mobile assistive technology; Non visuals; Nonvisual guidance interaction; People with visual impairment; Smart phones; Visual impairment; Augmented reality
Traveling More Independently: A Study on the Diverse Needs and Challenges of People with Visual or Mobility Impairments in Unfamiliar Indoor Environments,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132067565&doi=10.1145%2f3514255&partnerID=40&md5=ad8ee66d36972db0a427c92ccf28bc8a,"It is much more difficult for people with visual or mobility impairments to prepare for a trip or visit unfamiliar places than it is for people without disabilities. In addition to the usual travel arrangements, one needs to know if the various parts of the travel chain are accessible. To the best of our knowledge, there is no previous work that examines in depth travel behavior for indoor environments for both trip planning and execution, highlighting the special needs of people with low vision, blindness, or mobility impairments (MIs). In this article, we present a survey of 125 participants with blindness, low vision, and MIs. We investigate how mobile they are, what strategies they use to prepare a journey to an unknown building, how they orient themselves there, and what materials they use. For all three groups, our results provide insights into the problem space of the specific information needs when planning and executing a trip. We found that most of our participants have specific mobility problems depending on their disability. Feedback from the participants reveals that there is a large information gap, especially for orientation in buildings, regarding availability of high-quality digital, tactile, and printable indoor maps; accessibility of buildings; and mobility supporting systems. In particular, there is a lack of available and high-quality indoor maps. Our analysis also points out that the specific needs differ for the three groups. Besides the expected between-group differences, large in-group differences can also be found. The current article is an expanded version of earlier work [18] augmented by data of people with MIs.  © 2022 Association for Computing Machinery.",Accessibility; inclusive mobility; indoor maps; mobility impairment; visual impairment,Eye protection; Accessibility; Group differences; High quality; Inclusive mobility; Indoor environment; Indoor map; Low vision; Mobility impairment; Travel behaviour; Visual impairment; Surveys
Customizable Tabular Access to Web Data Records for Convenient Low-vision Screen Magnifier Interaction,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132072593&doi=10.1145%2f3517044&partnerID=40&md5=f398b2d786102ad8c4d135d0895017dc,"To interact with webpages, people with low vision typically rely on screen magnifier assistive technology that enlarges screen content and also enables them to pan the content to view the different portions of a webpage. This back-and-forth panning between different webpage portions makes it especially inconvenient and arduous for screen magnifier users to interact with web data records (e.g., list of flights, products, job advertisements), as this interaction typically involves making frequent comparisons between the data records based on their attributes, e.g., comparing available flights in a travel website based on their prices, durations. To address this issue, we present TableView+, an enhanced version of our previous TableView prototype- A browser extension that leverages a state-of-the-art data extraction method to automatically identify and extract information in web data records, and subsequently presents the information to a screen magnifier user in a compactly arranged data table to facilitate easier comparisons between records. TableView+ introduces new features aimed mostly at addressing the critical shortcomings of TableView, most notably the absence of interface customization options. In this regard, TableView+ enables low-vision users to customize the appearance of the data table based on their individual needs and eye conditions. TableView+ also saves these customizations to automatically apply them to the best extent possible the next time the users interact with the data records on either the same or other similar websites. A user study with 25 low-vision participants showed that with TableView+, the panning time further decreased by 8.5% on unfamiliar websites and by 8.02% on a familiar website than with TableView when compared to a screen magnifier.  © 2022 held by the owner/author(s). Publication rights licensed to ACM.",low vision; screen magnifier; usability; visually impaired; Web accessibility,Data visualization; Assistive technology; Customizable; Data tables; Low vision; Screen magnifier; Usability; Visually impaired; Web accessibility; Web data; Web-page; Websites
Inclusive Improvisation: Exploring the Line between Listening and Playing Music,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132068302&doi=10.1145%2f3506856&partnerID=40&md5=fa2981ddbabd4baf50ad5338f42e5bf9,"The field of Accessible Digital Musical Instruments (ADMIs) is growing rapidly, with instrument designers recognising that adaptations to existing Digital Musical Instruments (DMIs) can foster inclusive music making. ADMIs offer opportunities to engage with a wider range of sounds than acoustic instruments. Furthermore, gestural ADMIs free the music maker from relying on screen, keyboard, and mouse-based interfaces for engaging with these sounds. This brings greater opportunities for exploration, improvisation, empowerment, and flow through music making for people with disability and the communities of practice they are part of. This article argues that developing ADMIs from existing DMIs can speed up the process and allow for more immediate access for those with diverse needs. It presents three case studies of a gestural DMI, originally designed by the first author for his own creative practice, played by people with disability in diverse contexts. The article shows that system-based considerations that enabled an expert percussionist to achieve virtuoso performances with the instrument required minimal hardware and software changes to facilitate greater inclusivity. Understanding the needs of players and customising the system-based movement to sound mappings was of far greater importance in making the instrument accessible.  © 2022 held by the owner/author(s). Publication rights licensed to ACM.",Accessible digital musical instruments; creative engagement; gesture; improvisation,Mammals; Music; Accessible digital musical instrument; Communities of Practice; Creative engagement; Creatives; Flowthrough; Gesture; Improvization; On-screen keyboard; People with disabilities; Speed up; Musical instruments
Shared Privacy Concerns of the Visually Impaired and Sighted Bystanders with Camera-Based Assistive Technologies,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132076747&doi=10.1145%2f3506857&partnerID=40&md5=0898eb925bcdc577ca353d28dc909416,"Camera-based assistive technologies can provide people with visual impairments (PVIs) visually derived information about people in their vicinity. Furthermore, the advent of smart glasses offers the possibility of not only analyzing visual information in front of the wearers but also behind them through an extended field of view. Although such visually available' information can enhance one's social interactions, the privacy and ethical implications for automated judgments about bystanders, especially from the perspective of PVIs, remains underexplored. To study the concerns of both bystanders and PVIs with such technologies, we conducted two online surveys with visually impaired participants as wearers (N = 128) and sighted participants as bystanders (N = 136). Although PVIs found some types of information to be improper or impolite (such as someone's weight), our overarching finding is the shared ethical concern between PVIs and bystanders related to the fallibility of AI, in which bystanders can be misrepresented (algorithmically) by the devices. These mischaracterizations can range from occasional unexpected algorithmic errors (e.g., errors in facial recognition) to the questionable use of AI for determining subjective social constructs (such as gender). Based on our findings, we discuss the design implications and directions for future work in the development of camera-based assistive technologies while mitigating the ethical concerns of PVIs and bystanders.  © 2022 Association for Computing Machinery.",AI ethics; augmented reality; fairness and bias; Privacy; visually impaired,Assistive technology; Cameras; Ethical technology; Face recognition; Surveys; AI ethic; Assistive technology; Camera-based; Ethical concerns; Fairness and bias; Privacy; Privacy concerns; Smart glass; Visual impairment; Visually impaired; Augmented reality
Understanding How Sensory Changes Experienced by Individuals with a Range of Age-Related Cognitive Changes Can Effect Technology Use,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132073645&doi=10.1145%2f3511906&partnerID=40&md5=a0f55f5cff272ba7d472c7af91b13053,"Clinical researchers have identified sensory changes people with age-related cognitive changes, such as dementia and mild cognitive impairment, experience that are different from typical age-related sensory changes. Technology designers and researchers do not yet have an understanding of how these unique sensory changes affect technology use. This work begins to bridge the gap between the clinical knowledge of sensory changes and technology research and design through interviews with people with mild to moderate dementia, mild cognitive impairment, subjective cognitive decline, and healthcare professionals. This extended version of our ASSETS conference paper includes people with a range of age-related cognitive changes describing changes in vision, hearing, speech, dexterity, proprioception, and smell. We discuss each of these sensory changes and ways to leverage optimal modes of sensory interaction for accessible technology use with existing and emerging technologies. Finally, we discuss how accessible sensory stimulation may change across the spectrum of age-related cognitive changes.  © 2022 held by the owner/author(s). Publication rights licensed to ACM.",Dementia; mild cognitive impairment; sensory changes; subjective cognitive decline; technology interaction,Behavioral research; Bridges; Clinical research; Neurodegenerative diseases; Age-related; Clinical researchers; Cognitive decline; Cognitive impairment; Dementia; Mild cognitive impairment; Sensory change; Subjective cognitive decline; Technology interaction; Technology use; Audition
Introduction to the Special Issue on ASSETS'20,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132071473&doi=10.1145%2f3542810&partnerID=40&md5=39baf9d44f9b76f2f19690a6aa718c26,[No abstract available],,
"Reading-Assistance Tools among Deaf and Hard-of-Hearing Computing Professionals in the U.S.: Their Reading Experiences, Interests and Perceptions of Social Accessibility",2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132076819&doi=10.1145%2f3520198&partnerID=40&md5=9d2081507dfdfec7231036f48e66eab3,"Automatic Text Simplification (ATS) software aims at automatically rewrite complex text to make it simpler to read. Prior research has explored the use of ATS as a reading assistance technology, identifying benefits from providing these technologies to different groups of users, including Deaf and Hard-of-hearing (DHH) adults. However, little work has investigated the interests and requirements of specific groups of potential users of this technology. Considering prior work establishing that computing professionals often need to read about new technologies in order to stay current in their profession, in this study, we investigated the reading experiences and interests of DHH individuals with work experience in the computing industry in ATS-based reading assistance tools, as well as their perspective on the social accessibility of those tools. Through a survey and two sets of interviews, we found that these users read relatively often, especially in support of their work, and were interested in tools to assist them with complicated texts; but misperceptions arising from public use of these tools may conflict with participants' desired image in a professional context. This empirical contribution motivates further research into ATS-based reading assistance tools for these users, prioritizing which reading activities users are most interested in seeing the application of this technology, and highlighting design considerations for creating ATS tools for DHH adults, including considerations for social accessibility.  © 2022 Association for Computing Machinery.",Automatic text simplification; people who are deaf or hard of hearing; reading assistance; social accessibility,Audition; 'current; Automatic text simplification; Computing industry; Hard of hearings; People who be deaf or hard of hearing; Potential users; Reading assistance; Simple++; Social accessibility; Work experience; Surveys
Privacy Concerns for Visual Assistance Technologies,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130010243&doi=10.1145%2f3517384&partnerID=40&md5=3913a9a0aa703a1fe06b4605f89dce51,"People who are blind share their images and videos with companies that provide visual assistance technologies (VATs) to gain access to information about their surroundings. A challenge is that people who are blind cannot independently validate the content of the images and videos before they share them, and their visual data commonly contains private content. We examine privacy concerns for blind people who share personal visual data with VAT companies that provide descriptions authored by humans or artifcial intelligence (AI). We frst interviewed 18 people who are blind about their perceptions of privacy when using both types of VATs. Then we asked the participants to rate 21 types of image content according to their level of privacy concern if the information was shared knowingly versus unknowingly with human-or AI-powered VATs. Finally, we analyzed what information VAT companies communicate to users about their collection and processing of users' personal visual data through their privacy policies. Our fndings have implications for the development of VATs that safeguard blind users' visual privacy, and our methods may be useful for other camera-based technology companies and their users.  © 2022 Copyright held by the owner/author(s).",artificial intelligence; blind; camera-based devices; data regulation; image description; privacy; privacy policy analysis; private visual content; remote sighted assistance; Visual assistance technology; visual personal data; visual question answering; visually impaired,Cameras; Data visualization; Blind; Camera-based; Camera-based device; Data regulations; Image descriptions; Policy analysis; Privacy; Privacy policies; Privacy policy analyse; Private visual content; Question Answering; Remote sighted assistance; Visual assistance technology; Visual content; Visual personal data; Visual question answering; Visually impaired; Data privacy
INC-Hg: An Intelligent Collaborative Haptic-Gripper Virtual Reality System,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127375497&doi=10.1145%2f3487606&partnerID=40&md5=c420a64f65278c52b54c87d0073dc038,"Collaborative Virtual Environments (CVE) have shown potential to be an effective social skill training platform for children with Autism Spectrum Disorders (ASD) to learn and practice collaborative and communication skills through peer interactions. However, most existing CVE systems require that appropriately matched partners be available at the same time to promote interaction, which limits their applicability to some community settings due to scheduling constraints. A second shortcoming of these more naturalistic peer-based designs is the intensive resources required to manually code the unrestricted conversations that occurred during the peer-based interactions. To preserve the benefits of CVE-based platforms and mitigate some of the resource limitations related to peer availability, we developed an Intelligent Collaborative Haptic-Gripper System (INC-Hg). This system provides an intelligent agent partner who can understand, communicate, and haptically interact with the user, without requiring the presence of another human peer. The INC-Hg operates in real time and thus is able to perform collaborative training tasks at any time and at the user's pace. INC-Hg can also record the real-time data regarding spoken language and task performance, thereby greatly reducing the resource burden of communication and interaction performance analysis. A preliminary usability study with 10 participants with ASD (ages 8-12 years) indicated that the system could classify the participant's utterances into five classes with an accuracy of 70.34%, which suggested the potential of INC-Hg to automatically recognize and analyze conversational content. The results also indicated high accuracies of the agent to initiate a conversation (97.56%) and respond to the participants (86.52%), suggesting the capability of the agent to conduct proper conversations with the participants. Compared to the results of human-to-human collaborative tasks, the human-to-agent mode achieved higher average collaborative operation ratio (61% compared to 40%) and comparable average frequencies for Initiations and Responses among the participants with ASD. These results offer preliminary support as well as areas of improvement regarding the agent's ability to respond to participants, work with participants to complete tasks, engage in back-and-forth conversations, and support the potential of the agent to be a useful partner for individuals with ASD completing CVE tasks.  © 2022 Association for Computing Machinery.",AI techniques; Autism Spectrum Disorders; Collaborative virtual environments; Conversational agent; Haptic interaction; Social interaction,Diseases; Virtual reality; AI techniques; Autism spectrum disorders; Collaborative haptics; Collaborative virtual environment; Conversational agents; Gripper systems; Haptic interactions; Social interactions; Social skills training; Virtual reality system; Grippers
Supporting People with Acquired Brain Injury to Use a Reminding App; Narrow-deep vs. Broad-shallow User Interfaces,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127379952&doi=10.1145%2f3501275&partnerID=40&md5=bf78e4e4e01ca0b6b65c1c7b9b041336,"People with memory impairments following an acquired brain injury stand to benefit from smartphone apps as memory aids. Due, in part, to usability issues they use smartphone-based reminding less than the general population. Evidence suggests this group may benefit from user interface (UI) designs with more screens with less information per screen (narrow-deep UI) rather than fewer screens with more information per screen (broad-shallow UI). This study compared the difference in speed, accuracy, guidance needed, and task load for 32 people with acquired brain injury when setting reminders using narrow-deep and broad-shallow UI. They were also given cognitive assessments (measuring selective attention, executive functioning, and overall executive and memory ability) and interviewed about their UI preference. There was a significant difference in accuracy; participants were less accurate (they made two more errors on average for every three reminders set) using a broad-shallow compared to narrow-deep UI. The reason for this difference was that participants omitted more information when using broad-shallow UI. There were no differences in speed, guidance required, and overall task-load. Participants with better selective attention and more experience with smartphones benefited the most from narrow-deep UI compared to broad-shallow UI. Most participants preferred one UI over the other. Those who preferred narrow-deep found it easier to use, that they missed less information and liked having one piece of information at a time. Those who preferred broad-shallow found it easier to review the information and felt less likely to lose track. The findings can inform that implementation of UI choices to make apps more accessible for those with cognitive impairments.  © 2022 Association for Computing Machinery.",Acquired brain injury; Assistive technology for cognition; Neuropsychological rehabilitation,Smartphones; Acquired brain injuries; Assistive technology; Assistive technology for cognition; Cognitive assessments; General population; Memory aids; Selective attention; Smartphone apps; Speed accuracy; User interface designs; User interfaces
Career Interview Readiness in Virtual Reality (CIRVR): A Platform for Simulated Interview Training for Autistic Individuals and Their Employers,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127438606&doi=10.1145%2f3505560&partnerID=40&md5=60051e5685b1ee157eef9d22ea0d4174,"Employment outcomes for autistic1 individuals are often poorer relative to their neurotypical (NT) peers, resulting in a greater need for other forms of financial and social support. While a great deal of work has focused on developing interventions for autistic children, relatively less attention has been paid to directly addressing the employment challenges faced by autistic adults. One key impediment to autistic individuals securing employment is the job interview. Autistic individuals often experience anxiety in interview situations, particularly with open-ended questions and unexpected interruptions. They also exhibit atypical gaze patterns that may be perceived as, but not necessarily indicative of, disinterest or inattention. In response, we developed a closed-loop adaptive virtual reality (VR)-based job interview training platform, which we have named Career Interview Readiness in VR (CIRVR). CIRVR is designed to provide an engaging, adaptive, and individualized experience to practice and refine interviewing skills in a less anxiety-inducing virtual context. CIRVR contains a real-time physiology-based stress detection module, as well as a real-time gaze detection module, to permit individualized adaptation. We also present the first prototype of the CIRVR Dashboard, which provides visualizations of data to help autistic individuals as well as potential employers and job coaches make sense of the data gathered from interview sessions. We conducted a feasibility study with 9 autistic and 8 NT individuals to assess the preliminary usability and feasibility of CIRVR. Results showed differences in perceived usability of the system between autistic and NT participants, and higher levels of stress in autistic individuals during interviews. Participants across both groups reported satisfaction with CIRVR and the structure of the interview. These findings and feedback will support future work in improving CIRVR's features in hopes for it to be a valuable tool to support autistic job candidates as well as their potential employers.  © 2022 Association for Computing Machinery.",Autism Spectrum Disorder; Virtual job interview,E-learning; Employment; Autism spectrum disorders; Autistic children; Detection modules; Financial support; Key impediments; Open-ended questions; Real- time; Social support; Virtual job interview; Virtual reality
Development and Evaluation of a Tool for Assisting Content Creators in Making PDF Files More Accessible,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127435184&doi=10.1145%2f3507661&partnerID=40&md5=0fa52ad61cbe47b8fe819163e6665967,"Most PDF documents are inaccessible for people with disabilities, creating barriers in education, science, commerce, e-government, and recreation. Documents in PDF format are considered harder to make accessible than documents in other formats, primarily due to the insufficient tools available to assist content creators. In this article, we present the research and development of Ally, a new tool to assist content creators in remediating their PDF files to improve accessibility. Ally utilizes best practices from other areas of HCI research to create a more efficient and effective interaction for remediating regions, headers, reading order, and tables in a PDF document for improved accessibility. Twenty participants attempted to complete the same PDF accessibility remediation tasks using both Ally and a standard industry tool, Adobe Acrobat Pro. Ally was almost twice as fast and three times as accurate compared to Acrobat Pro, with participants reporting a strong preference for and a much higher level of satisfaction with Ally. The approaches taken in Ally improve the ability to create accessible PDFs efficiently and accurately for the four important aspects studied, but future work will need to incorporate additional functionality, related to remediating alt text, forms, and other aspects of PDF accessibility.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Content accessibility; Matterhorn protocol; PDF accessibility; PDF universal access; Portable Document Format (PDF),Government data processing; Content accessibility; Content creators; Matterhorn protocol; Portable document format; Portable document format accessibility; Portable document format universal access; Portable document formats; Universal access; Pollution
Addressing Accessibility Barriers in Programming for People with Visual Impairments: A Literature Review,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127456529&doi=10.1145%2f3507469&partnerID=40&md5=dcd84e1730f4a5598cc32e41db154be0,"Accessibility issues with programming languages and programming environments pose a major barrier for students with visual impairments to participate in computing related courses as well as threatens the productivity of professional programmers with visual impairments. To remedy this, the past two decades have witnessed an increase in accessibility research designed to investigate and address the challenges faced by people with visual impairments while programming or learning how to program. We conducted a literature review of accessibility research in this domain. The aim was to identify, aggregate, and highlight known accessibility barriers to programming faced by professional programmers and students with visual impairments learning how to code as well as to identify all solutions that have been proposed to address these barriers. We selected and analyzed 70 papers reporting on accessibility of programming and programming environments for people with visual impairments. Numerous barriers to programming by people with visual impairments have been identified in the literature. Some of these barriers are understudied and present opportunities for future work. A lot of studies have also proposed tools and new accessible programming languages to address the accessibility issues of current programming languages and programming environments.  © 2022 Association for Computing Machinery.",Accessibility; Accessible computing; Assistive technologies; Blind programmers; Programming languages; Visual impairments,Students; Accessibility barriers; Accessible computing; Assistive technology; Blind programmer; Language environment; Literature reviews; Professional programmers; Professional students; Programming environment; Visual impairment; Visual languages
Do You Hear What i Hear: The Balancing Act of Designing an Electronic Hockey Puck for Playing Hockey Non-Visually,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127438780&doi=10.1145%2f3507660&partnerID=40&md5=6a978b7c6a00004727b07d95f62fb31f,"Blind hockey is a sport that is gaining popularity in the United States after having an international presence for years. In blind hockey, a modified puck is used that emits sounds via ball bearings that rattle inside the puck when it is moving. The modified puck's lifetime is minimal due to its lack of durability, and it does not provide feedback when the puck stops moving. This article presents an evaluation of multiple prototypes that investigate the appropriate acoustic profiles for an electronic version of a puck that has the ability to overcome some of these challenges. Our approach leverages the use of alternative 3D printable materials and the implementation of four distinct sound profiles: the league-standard puck in blind hockey, a 3.5kHz piezo buzzer, an 800Hz sine tone, and simulated white noise. We present the design and prototype of the pucks, along with benchtop and user validation tests of the prototypes, comparing them to the league standard puck with a focus on acoustic performance. Participants rated the white noise sound profile highest in pleasantness and loudness and the LSP highest in localization. The white noise sound profile was associated with lower angle and distance errors. Of the prototypes produced, the white noise prototype puck appeared to demonstrate the most promise for playing hockey non-visually. We close with a discussion of recommendations for future electronic hockey puck designs to support blind hockey moving forward.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessible technologies; Auditory feedback; Blind athletics; Blind hockey; Localization,3D printers; Acoustic noise; White noise; Accessible technology; Acoustic performance; Auditory feedback; Balancing acts; Blind athletic; Blind hockey; Electronic versions; Localisation; Printable materials; Validation test; Sports
What's in an ALT Tag? Exploring Caption Content Priorities through Collaborative Captioning,2022,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127449955&doi=10.1145%2f3507659&partnerID=40&md5=a3b03614626c7b6e45695416856b23f3,"Evaluating the quality of accessible image captions with human raters is difficult, as it may be difficult for a visually impaired user to know how comprehensive a caption is, whereas a sighted assistant may not know what information a user will need from a caption. To explore how image captioners and caption consumers assess caption content, we conducted a series of collaborative captioning sessions in which six pairs, consisting of a blind person and their sighted partner, worked together to discuss, create, and evaluate image captions. By making captioning a collaborative task, we were able to observe captioning strategies, to elicit questions and answers about image captions, and to explore blind users' caption preferences. Our findings provide insight about the process of creating good captions and serve as a case study for cross-ability collaboration between blind and sighted people.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; Blindness; Captioning; Collaboration,Vision; Blind person; Blind users; Captioning; Case-studies; Collaboration; Collaborative tasks; Image caption; Visually-impaired users; Technology transfer
Effect of Sign-recognition Performance on the Usability of Sign-language Dictionary Search,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118637252&doi=10.1145%2f3470650&partnerID=40&md5=beb1f1ad55c7382b2203bce28da4235d,"Advances in sign-language recognition technology have enabled researchers to investigate various methods that can assist users in searching for an unfamiliar sign in ASL using sign-recognition technology. Users can generate a query by submitting a video of themselves performing the sign they believe they encountered somewhere and obtain a list of possible matches. However, there is disagreement among developers of such technology on how to report the performance of their systems, and prior research has not examined the relationship between the performance of search technology and users' subjective judgements for this task. We conducted three studies using a Wizard-of-Oz prototype of a webcam-based ASL dictionary search system to investigate the relationship between the performance of such a system and user judgements. We found that, in addition to the position of the desired word in a list of results, the placement of the desired word above or below the fold and the similarity of the other words in the results list affected users' judgements of the system. We also found that metrics that incorporate the precision of the overall list correlated better with users' judgements than did metrics currently reported in prior ASL dictionary research. © 2021 Association for Computing Machinery.",American sign language (ASL); dictionary; information retrieval; search,American sign language; Performance; Search; Search technology; Sign language; Sign Language recognition; Sign recognition; Subjective judgement; User judgements
Iterative Design of Sonification Techniques to Support People with Visual Impairments in Obstacle Avoidance,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118631013&doi=10.1145%2f3470649&partnerID=40&md5=44d5de07636d7669ed43abab324b0777,"Obstacle avoidance is a major challenge during independent mobility for blind or visually impaired (BVI) people. Typically, BVI people can only perceive obstacles at a short distance (about 1 m, in case they are using the white cane), and some obstacles are hard to detect (e.g., those elevated from the ground), or should not be hit by the white cane (e.g., a standing person). A solution to these problems can be found in recent computer-vision techniques that can run on mobile and wearable devices to detect obstacles at a distance. However, in addition to detecting obstacles, it is also necessary to convey information about them in real time. This contribution presents WatchOut, a sonification technique for conveying real-time information about the main properties of an obstacle to a BVI person, who can then use this additional feedback to safely navigate in the environment. WatchOut was designed with a user-centered approach, involving four iterations of online listening tests with BVI participants in order to define, improve and evaluate the sonification technique, eventually obtaining an almost perfect recognition accuracy. WatchOut was also implemented and tested as a module of a mobile app that detects obstacles using state-of-the-art computer vision technology. Results show that the system is considered usable and can guide the users to avoid more than 85% of the obstacles. © 2021 Association for Computing Machinery.",navigation assistance; orientation & mobility; Turn-by-turn navigation,Computer vision; Navigation; Computer vision techniques; Iterative design; Navigation assistance; Obstacles avoidance; Orientation & mobility; Sonifications; Turn-by-turn navigation; Visual impairment; Visually impaired people; White cane; Iterative methods
Introduction to the Special Issue on ASSETS'19,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118632765&doi=10.1145%2f3486212&partnerID=40&md5=116330574e5d1eab69cfb19b1a6601a2,[No abstract available],,
Deaf and Hard-of-hearing Users Evaluating Designs for Highlighting Key Words in Educational Lecture Videos,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118650839&doi=10.1145%2f3470651&partnerID=40&md5=961a775a8f6a004f4a2a246c5ee72d07,"There are style guidelines for authors who highlight important words in static text, e.g., bolded words in student textbooks, yet little research has investigated highlighting in dynamic texts, e.g., captions during educational videos for Deaf or Hard of Hearing (DHH) users. In our experimental study, DHH participants subjectively compared design parameters for caption highlighting, including: Decoration (underlining vs. italicizing vs. boldfacing), granularity (sentence level vs. word level), and whether to highlight only the first occurrence of a repeating keyword. In partial contrast to recommendations in prior research, which had not been based on experimental studies with DHH users, we found that DHH participants preferred boldface, word-level highlighting in captions. Our empirical results provide guidance for the design of keyword highlighting during captioned videos for DHH users, especially in educational video genres. © 2021 Association for Computing Machinery.",Caption highlighting; captioning system; deaf and hard of hearing; text highlighting; user study,Caption highlighting; Captioning system; Deaf and hard of hearing; Educational videos; Hard of hearings; Key words; Lecture video; Text highlighting; User study; Word level
"Factors Affecting the Accessibility of Voice Telephony for People with Hearing Loss: Audio Encoding, Network Impairments, Video and Environmental Noise",2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118643831&doi=10.1145%2f3479160&partnerID=40&md5=48d697d47c44b09853018787f439b85e,"This paper describes four studies with a total of 114 individuals with hearing loss and 12 hearing controls that investigate the impact of audio quality parameters on voice telecommunications. These studies were first informed by a survey of 439 individuals with hearing loss on their voice telecommunications experiences. While voice telephony was very important, with high usage of wireless mobile phones, respondents reported relatively low satisfaction with their hearing devices' performance for telephone listening, noting that improved telephone audio quality was a significant need. The studies cover three categories of audio quality parameters: (1) narrowband (NB) versus wideband (WB) audio; (2) encoding audio at varying bit rates, from typical rates used in today's mobile networks to the highest quality supported by these audio codecs; and (3) absence of packet loss to worst-case packet loss in both mobile and VoIP networks. Additionally, NB versus WB audio was tested in auditory-only and audiovisual presentation modes and in quiet and noisy environments. With WB audio in a quiet environment, individuals with hearing loss exhibited better speech recognition, expended less perceived mental effort, and rated speech quality higher than with NB audio. WB audio provided a greater benefit when listening alone than when the visual channel also was available. The noisy environment significantly degraded performance for both presentation modes, but particularly for listening alone. Bit rate affected speech recognition for NB audio, and speech quality ratings for both NB and WB audio. Packet loss affected all of speech recognition, mental effort, and speech quality ratings. WB versus NB audio also affected hearing individuals, especially under packet loss. These results are discussed in terms of the practical steps they suggest for the implementation of telecommunications systems and related technical standards and policy considerations to improve the accessibility of voice telephony for people with hearing loss. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",audio codec; bit rate; cochlear implant; hard of hearing; hearing aid; hearing loss; narrowband audio; packet loss; telecommunications; Voice telephony; wideband audio,Audio acoustics; Cochlear implants; Encoding (symbols); Packet loss; Signal encoding; Telephone sets; Audio codecs; Bit rates; Hard of hearings; Hearing loss; Hearing-aids; Narrow bands; Narrowband audio; Packets loss; Voice telephony; Wide-band; Wideband audio; Audition
Deep Learning Methods for Sign Language Translation,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118613428&doi=10.1145%2f3477498&partnerID=40&md5=5d30dd2fc808b04b72a6b0d67291c978,"Many sign languages are bona fide natural languages with grammatical rules and lexicons hence can benefit from machine translation methods. Similarly, since sign language is a visual-spatial language, it can also benefit from computer vision methods for encoding it. With the advent of deep learning methods in recent years, significant advances have been made in natural language processing (specifically neural machine translation) and in computer vision methods (specifically image and video captioning). Researchers have therefore begun expanding these learning methods to sign language understanding. Sign language interpretation is especially challenging, because it involves a continuous visual-spatial modality where meaning is often derived based on context.The focus of this article, therefore, is to examine various deep learning-based methods for encoding sign language as inputs, and to analyze the efficacy of several machine translation methods, over three different sign language datasets. The goal is to determine which combinations are sufficiently robust for sign language translation without any gloss-based information.To understand the role of the different input features, we perform ablation studies over the model architectures (input features + neural translation models) for improved continuous sign language translation. These input features include body and finger joints, facial points, as well as vector representations/embeddings from convolutional neural networks. The machine translation models explored include several baseline sequence-to-sequence approaches, more complex and challenging networks using attention, reinforcement learning, and the transformer model. We implement the translation methods over multiple sign languages-German (GSL), American (ASL), and Chinese sign languages (CSL). From our analysis, the transformer model combined with input embeddings from ResNet50 or pose-based landmark features outperformed all the other sequence-to-sequence models by achieving higher BLEU2-BLEU4 scores when applied to the controlled and constrained GSL benchmark dataset. These combinations also showed significant promise on the other less controlled ASL and CSL datasets. © 2021 Association for Computing Machinery.",accessibility; attention; Deaf and Hard-of-Hearing; deep learning; sequence modeling; Sign language translation; transformer,Computational linguistics; Computer vision; Convolutional neural networks; Deep learning; Encoding (symbols); Modeling languages; Natural language processing systems; Neural machine translation; Reinforcement learning; Signal encoding; Visual languages; Attention; Deaf and hard-of-hearing; Deep learning; Hard of hearings; Language translation; Learning methods; Sequence models; Sign language; Sign language translation; Transformer; Audition
Introduction to the Special Issue on ASSETS'19,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171788078&doi=10.1145%2f3486212&partnerID=40&md5=a63d058dec519ab9a75276a8f745409e,[No abstract available],,
Irrelevant Gadgets or a Source of Worry,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114314702&doi=10.1145%2f3473463&partnerID=40&md5=bc1593de1aad58ebd72a3d5065c1ac5f,"Wearable activity trackers are routinely applied in physical activity (PA) interventions in late life, but there is little research that focuses on older adults' perspectives on the technology. We conducted a qualitative study with 24 older persons to explore their perspective on wearables and PA. First, we discussed their relationship with PA and wearable trackers during focus groups. Next, nine participants crafted prototypes for wearables during co-design sessions. Through Thematic Analysis, we identified two main themes: (1) PA is personal in terms of preferred activities and reasons for PA, and (2) wearables are an emotional technology, causing negative emotions when resembling medical trackers or pressurizing to perform. We followed upon these results through a survey with 41 participants, which further highlighted individual differences in the perception of wearables. We conclude with questions to guide the design of wearables and reflect on their role to support PA in late life.  © 2021 ACM.",Older adults; participatory design; physical activity; qualitative research; thematic analysis; wearables,Surveys; Co-designs; Focus groups; Individual Differences; Older adults; Physical activity; Qualitative study; Thematic analysis; Wearable technology
Investigating Best Practices for Remote Summative Usability Testing with People with Mild to Moderate Dementia,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114371877&doi=10.1145%2f3460942&partnerID=40&md5=6e52d13981e618a5fcaec0fb90606bae,"People with dementia may miss out on the benefits of using technology, because they often find it difficult to use. Usability testing is one method to identify barriers and areas for improvement in technology. Unfortunately, usability testing is often not conducted with people with dementia, independent of their caregivers. Difficulty recruiting local participants with dementia who regularly use technology further compounds the problem. Remote methods have been proposed as one approach to recruiting hard-to-reach populations. Currently, it is unclear how to effectively conduct remote summative usability testing with people with dementia. We recruited 15 participants. Five took part in the pilot study and 10 participated in the main study. We identify best practices and make suggestions for remote summative usability tests with people who have mild to moderate dementia, independent of caregivers. We discuss our findings in three sections: (1) logistics for planning remote summative usability testing, (2) approaches for conducting remote summative usability testing, including modifications of research methods, and (3) considerations when evaluating findings from remote summative usability sessions. We also present modified usability testing methods we developed to meet the unique needs of users with mild to moderate dementia, and summarize lessons learned and new directions for research on this topic.  © 2021 ACM.",dementia; disability; remote methods; remote summative; Remote usability; UX,Neurodegenerative diseases; Testing; Best practices; Pilot studies; Usability testing; Usability testing methods; Usability tests; Usability engineering
Expanding a Large Inclusive Study of Human Listening Rates,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114382064&doi=10.1145%2f3461700&partnerID=40&md5=a6bd9665a72a406c02d5d2ca4caed7be,"As conversational agents and digital assistants become increasingly pervasive, understanding their synthetic speech becomes increasingly important. Simultaneously, speech synthesis is becoming more sophisticated and manipulable, providing the opportunity to optimize speech rate to save users time. However, little is known about people's abilities to understand fast speech. In this work, we provide an extension of the first large-scale study on human listening rates, enlarging the prior study run with 453 participants to 1,409 participants and adding new analyses on this larger group. Run on LabintheWild, it used volunteer participants, was screen reader accessible, and measured listening rate by accuracy at answering questions spoken by a screen reader at various rates. Our results show that people who are visually impaired, who often rely on audio cues and access text aurally, generally have higher listening rates than sighted people. The findings also suggest a need to expand the range of rates available on personal devices. These results demonstrate the potential for users to learn to listen to faster rates, expanding the possibilities for human-conversational agent interaction.  © 2021 ACM.",accessibility; blind; crowdsourcing; human abilities; listening rate; low-vision; Synthetic speech; visually impaired,Computer applications; Human computer interaction; Conversational agents; Digital assistants; Large-scale studies; Personal devices; Screen readers; Speech rates; Synthetic speech; Visually impaired; Speech synthesis
How Could Equality and Data Protection Law Shape AI Fairness for People with Disabilities?,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114326061&doi=10.1145%2f3473673&partnerID=40&md5=facb8539d748ead3f2bfbf3b3c4f2d21,"This article examines the concept of 'AI fairness' for people with disabilities from the perspective of data protection and equality law. This examination demonstrates that there is a need for a distinctive approach to AI fairness that is fundamentally different to that used for other protected characteristics, due to the different ways in which discrimination and data protection law applies in respect of Disability. We articulate this new agenda for AI fairness for people with disabilities, explaining how combining data protection and equality law creates new opportunities for disabled people's organisations and assistive technology researchers alike to shape the use of AI, as well as to challenge potential harmful uses.  © 2021 ACM.",AI; assistive technology; data protection; disability; discrimination; human rights,Computer applications; Human computer interaction; Assistive technology; Disabled people; People with disabilities; Data privacy
Immersive Virtual Reality for Older Adults,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114307839&doi=10.1145%2f3470743&partnerID=40&md5=3ed187cd5580adad31650290e382e11a,"Despite the proliferation of research on immersive virtual reality (IVR) technologies for older adults, comprehensive guidelines on designing immersive and engaging VR for older adults remain sparse. Therefore, we first compounded 67 guidelines based on published literature. Next, to empirically ground these design recommendations, we provided 37 older adults of diverse ages, education levels, and cognitive abilities with a first VR experience. Analyzing interviews with the 37 older adults via the Laddering method, we found that they generally reported positive experiences with their first VR exposure. With these deepened insights, we reflect on, nuance, and contextualize existing design guidelines, and formulate points to bear in mind when designing accessible and engaging VR experiences for older persons.  © 2021 ACM.",design guidelines; laddering; older adults; Virtual reality; VR,Cognitive ability; Contextualize; Design recommendations; Immersive; Immersive virtual reality; Older adults; Positive experiences; Virtual reality
Fully Autonomous Vehicles for People with Visual Impairment,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114323580&doi=10.1145%2f3471934&partnerID=40&md5=986cce206d4eb455f6a8db4c4a25dc20,"A significant number of individuals in the United States report a disability that limits their ability to travel, including many people who are blind or visually impaired (BVI). The implications of restricted transportation result in negative impacts related to economic security, physical and mental health, and overall quality of life. Fully autonomous vehicles (FAVs) present a means to mitigate travel barriers for this population by providing new, safe, and independent travel opportunities. However, current policies governing interactions with the artificial intelligence (AI) 'at the wheel' of FAVs do not reflect the accessibility needs articulated by BVI people in the extant literature, failing to encourage use cases that would result in life changing mobility. By reviewing the legislative and policy efforts surrounding FAVs, we argue that the heart of this problem is due to a disjointed, laissez-faire approach to FAV accessibility that has yet to actualize the full benefits of this new transportation mode, not only for BVI people, but also for all users. We outline the necessity for a policy framework that guides the design of FAVs to include the concerns of BVI people and then propose legislative and design recommendations aimed to promote enhanced accessibility, transparency, and fairness during FAV travel.  © 2021 ACM.",accessibility (blind and visually impaired); accessible design; artificial intelligence; Autonomous vehicles; transportation policy,Artificial intelligence; Design recommendations; Economic security; Fully-autonomous vehicles; Overall quality; Policy framework; Transportation mode; Visual impairment; Visually impaired; Autonomous vehicles
Towards Designing Mobile Apps for Independent Travel,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114315122&doi=10.1145%2f3460943&partnerID=40&md5=e5101a667615161c3d170dfba053d7c6,"Performing daily independent activities can be a challenge for people with Down's Syndrome (DS). This article investigates how to better support these activities with smart devices based on three cycles of a collaborative participatory action research (PAR) process. The first cycle involved semi-structured interviews (n = 4) with parents and an online survey (n = 39) with people with DS and their parents to explore barriers and opportunities for independent activities. This cycle highlighted that travelling independently was a common challenge among discussed barriers to independent activities for young adults with DS, an issue that smart devices have the potential to overcome. The second cycle involved seven focus group discussions (n = 20) with parents (n = 13) and young adults with DS (n = 7) for gaining deeper insights into barriers to independent travel. We explored key barriers to independent travel and gathered design requirements for smartphone apps to overcome these barriers. In the third cycle, we designed a digital prototype based on participant recommendations and conducted seven focus group meetings (n = 19) with caregivers (n = 12) and individuals with DS (n = 7). This final cycle reviewed the proposed digital prototype and validated the key barriers found in the second cycle. Overall, our studies confirmed that mobile technology can support people with DS in performing daily life activities that increase social inclusion. The studies resulted in identified barriers and requirements along with co-designed solutions for independent travel apps.  © 2021 ACM.",assistive technology; Down's Syndrome; map design; navigation; smartphones; smartwatches; support for independent living,Computer applications; Human computer interaction; Daily life activities; Digital prototype; Down's syndrome; Mobile Technology; Participatory action research; Semi structured interviews; Smartphone apps; Social inclusion; Digital devices
The FATE Landscape of Sign Language AI Datasets: An Interdisciplinary Perspective,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111620729&doi=10.1145%2f3436996&partnerID=40&md5=4fd0359263968bc5997a5e01acae68cd,"Sign language datasets are essential to developing many sign language technologies. In particular, datasets are required for training artificial intelligence (AI) and machine learning (ML) systems. Though the idea of using AI/ML for sign languages is not new, technology has now advanced to a point where developing such sign language technologies is becoming increasingly tractable. This critical juncture provides an opportunity to be thoughtful about an array of Fairness, Accountability, Transparency, and Ethics (FATE) considerations. Sign language datasets typically contain recordings of people signing, which is highly personal. The rights and responsibilities of the parties involved in data collection and storage are also complex and involve individual data contributors, data collectors or owners, and data users who may interact through a variety of exchange and access mechanisms. Deaf community members (and signers, more generally) are also central stakeholders in any end applications of sign language data. The centrality of sign language to deaf culture identity, coupled with a history of oppression, makes usage by technologists particularly sensitive. This piece presents many of these issues that characterize working with sign language AI datasets, based on the authors' experiences living, working, and studying in this space.  © 2021 ACM.","Artificial intelligence (AI); Dataset; Fairness, accountability, and ethics (FATE); Machine learning (ML); Sign language; Transparency",Digital storage; History; Access mechanism; Culture identities; Data collection; Data collectors; Data contributors; Data users; Rights and responsibilities; Sign language; Artificial intelligence
Enhancing Internet Search Abilities for People with Intellectual Disabilities in Sri Lanka,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111679256&doi=10.1145%2f3460202&partnerID=40&md5=cd108b56df28b8c1b1344d1e15301802,"This article presents how young adults with intellectual disability (ID) from Sri Lanka, who had not previously used the Internet, interacted with Google search while enhancing their web search abilities throughout three web search workshops. Considering the little attention paid to the learning needs of people with ID in the current offering of web search learning tools, we iteratively developed a suite of learning tools to support our participants when they need help in the web search workshops. We employed an iterative participatory approach, with observations and semi-structured interviews, to reflect on how to design eLearning tools that enhance the participants' interactions with web search. The qualitative thematic analysis resulted in five distinct themes on strategies to support, build on, and develop the abilities of young adults with IDs as they engage with Google search in their native language: application of existing abilities, basic skills to match learning needs, conceptual understanding, animations to facilitate visual memory, and promoting active engagement. These themes will be a starting point for understanding participants' learning needs and behavior on web search, which would be important for future research on learning support as well as on software design.  © 2021 ACM.",Accessible design; Human-computer interface interaction; People with intellectual disabilities; Web search,Search engines; Software design; Visual languages; Websites; Conceptual understanding; E-learning tool; Intellectual disability; Internet searches; Learning support; Participatory approach; Semi structured interviews; Thematic analysis; Information retrieval
C-Hg: A Collaborative Haptic-Gripper Fine Motor Skill Training System for Children with Autism Spectrum Disorder,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111672742&doi=10.1145%2f3459608&partnerID=40&md5=2caf69d586c75d24c6e217a8944cdb53,"Computer-assisted systems can provide efficient and engaging ASD intervention environments for children with Autism Spectrum Disorder (ASD). However, most existing computer-assisted systems target only one skill deficit (e.g., social conversation skills) and ignore the importance of other areas, such as motor skills, that could also impact social interaction. This focus on a single domain may hinder the generalizability of learned skills to real-world scenarios, because the targeted teaching strategies do not reflect that real-world tasks often involve more than one skill domain. The work presented in this article seeks to bridge this gap by developing a Collaborative Haptic-gripper virtual skill training system (C-Hg). This system includes individual and collaborative games that provide opportunities for simultaneously practicing both fine motor skills (hand movement and grip control skills) as well as social skills (communication and collaboration) and investigating how they relate to each other. We conducted a usability study with 10 children with ASD and 10 Typically Developing (TD) children (8-12 years), who used C-Hg to play a series of individual and collaborative games requiring differing levels of motor and communication skill. Results revealed that participant performance significantly improved in both individual and collaborative fine motor skill training tasks, including significant improvements in collaborative manipulations between partners. Participants with ASD were found to conduct more collaborative manipulations and initiate more conversations with their partners in the post collaborative tasks, suggesting more active collaboration and communication of participants with ASD in the collaborative tasks. Results support the potential of our C-Hg system for simultaneously improving fine motor and social skills, with implications for impacts of improved fine motor skills on social outcomes.  © 2021 ACM.",Autism spectrum disorders; Collaborative virtual environment; Fine motor skill; Force-sensitive gripper; Haptics; HCI; Social skill,Diseases; Grippers; Children with autisms; Collaborative games; Collaborative tasks; Communication and collaborations; Communication skills; Computer-assisted system; Social conversations; Social interactions; Mercury compounds
Toward a Competency-based Approach to Co-designing Technologies with People with Intellectual Disability,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111681616&doi=10.1145%2f3450355&partnerID=40&md5=fef41e475aa2677cba0c10750461147a,"Ability-based design is a useful framework that centralizes the abilities (all that users can do) of people with disabilities in approaching the design of assistive technologies. However, although this framework aspires to support designing with people with all kinds of disabilities, it is mainly effective in supporting those whose abilities can be clearly defined and measured, in particular, physical and sensory attributes of ability. As a result, the ability-based design framework only provides limited guidance to design with users with intellectual disability, whose cognitive, physical, sensory, and practical abilities vary along a spectrum. In this article, we reflect on a long-term co-design study where we leveraged what we termed ""competencies,""i.e., the representative practical skills people develop from their participation in life activities, in particular, mainstream technologies, such as social media and the Internet. Our reflection is based on our experience in designing SkillsTube, a web application we co-designed with young adults with intellectual disability to support them to learn life skills through videos. The app's design, which explored and leveraged their social media participation competencies, supported the fundamental participation of all participants and their peers. Their familiarity with the app's social media-inspired design features fostered confidence in their participation, usability, and engagement. Drawing on the findings and design process of the app, we discuss a Competency-based approach to designing with people with disabilities that extends upon ability-based design, by grounding it in user competencies.  © 2021 ACM.",Accessible design; Competencies; Competency-based design; Intellectual disability; Social media,Social networking (online); Assistive technology; Design features; Design frameworks; Intellectual disability; People with disabilities; Practical skill; Sensory attributes; WEB application; Design
Accessible Web Development: Opportunities to Improve the Education and Practice of web Development with a Screen Reader,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111627140&doi=10.1145%2f3458024&partnerID=40&md5=c2611718129a9bb88170c9ac5af641f8,"There are a growing number of jobs related to web development, yet there is little formal literature about the accessibility of web development with a screen reader. This article describes research to explore (1) web development accessibility issues and their impact on blind learners and programmers; (2) tools and strategies used to address issues; and (3) opportunities for creating inclusive web development curriculum and supportive tools. We conducted a Comprehensive Literature Review (CLR) to formulate accessibility issue categories, then interviewed 12 blind programmers to validate and expand on both issues in education and practice. The CLR yielded five issue categories: (1) visual information without an accessible equivalent, (2) orienting, (3) navigating, (4) lack of support, and (5) knowledge and use of supportive technologies. Our interview findings validated the use of CLR-derived categories and revealed nuances specific to learning and practicing web development. Blind web developers grapple with the inaccessibility of demonstrations and explanations of web design concepts, wireframing software, independent verification of computed Cascading Style Sheets (CSS), and navigating browser-based developer tool interfaces. Tools and strategies include seeking out alternative education materials to learn independently, use of CSS frameworks, collaboration with sighted colleagues, and avoidance of design and front-end development. This work contributes to our understanding of accessibility issues specific to web development and the strategies that blind web developers employ in both educational and applied contexts. We identify areas in which greater awareness and application of accessibility best practices are required in Web education, a need to disseminate existing screen reader strategies and accessible tools, and to develop new tools that support Web design and validation of CSS. Finally, this research signals future directions for the development of accessible web curriculum and supportive tools, including solutions that leverage artificial intelligence, tactile graphics, and supportive-online communities of practice.  © 2021 ACM.",Accessibility; Accessible design tools; Accessible web design; Accessible web development; Human-centered computing; Screen reader; Visually impaired/blind programmers,Artificial intelligence; Planning; Verification; Web Design; Websites; Cascading style sheets; Education material; Literature reviews; On-line communities; Supportive technologies; Supportive tools; Visual information; Web development; Curricula
Melodie: A Design Inquiry into Accessible Crafting through Audio-enhancedWeaving,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105240888&doi=10.1145%2f3444699&partnerID=40&md5=3793ea8d9cdd46a7adbba8b543d82661,"Despite the promise of the maker movement as empowering individuals and democratizing design, people with disabilities still face many barriers to participation. Recent work has highlighted the inaccessible nature of making and introduced more accessible maker technologies, practices, and workspaces. One less explored area of accessible making involves supporting more traditional forms of craftwork, such as weaving and fiber arts. The present study reports an analysis of existing practices at a weaving studio within a residential community for people with vision impairments and explores the creation of an audio-enhanced loom to support this practice. Our iterative design process began with 60 hours of field observations at the weaving studio, complemented by 15 interviews with residents and instructors at the community. These insights informed the design of Melodie, an interactive floor loom that senses and provides audio feedback during weaving. Our design exploration of Melodie revealed four scenarios of use among this community: promoting learning among novice weavers, raising awareness of system state, enhancing the aesthetics of weaving, and supporting artistic performance. We identify recommendations for designing audio-enhanced technologies that promote accessible crafting and reflect on the role of technology in predominantly manual craftwork. © 2021 ACM.",Accessibility; audio; crafting; making; weaving,Looms; Studios; Audio feedbacks; Design Exploration; Field observations; Iterative design; People with disabilities; Residential communities; Role of technologies; Vision impairments; Design
Evaluation of the Use of Real-time 3D Graphics to Augment Therapeutic Music Sessions for Young People on the Autism Spectrum,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105123237&doi=10.1145%2f3445032&partnerID=40&md5=8b2323fc2b51d5ebef0cc9dc0952a39e,"The present research evaluates the effectiveness of CymaSense, a real-time 3D visualisation application developed by the authors, as a means of improving the communicative behaviours of autistic participants through the addition of a visual modality within therapeutic music sessions. Autism spectrum condition (ASC) is a lifelong neurodevelopmental disorder that can affect people in a number of ways, commonly through difficulties in communication. A multi-sensory approach within music sessions encourages people with ASC to engage more with the act of creating music, and with the therapists, increasing their level of communication and social interaction beyond the sessions. This article presents a study evaluating the use of CymaSense within a series of therapeutic music sessions, and a follow-up series of semi-structured interviews. Eight adults with ASC participated in 12 sessions using a single case experimental design approach over a total period of 19 weeks. Using qualitative and quantitative data, the results show an increase in communicative behaviour, for both verbal and non-verbal participants, resulting from the use of CymaSense. Qualitative feedback from interviews provided insight into the factors that contribute to the successful use of the application, as well as aspects that could be improved. © 2021 ACM.",assistive technologies; Autism; cymatics; interactive audio-visual; multi-sensory environments; music therapy; sound visualisation,Computer applications; Human computer interaction; 3D Visualisation; Experimental design approaches; Qualitative feedback; Quantitative data; Real-time 3D graphics; Semi structured interviews; Social interactions; Visual modalities; Diseases
Editorial from the Editors-in-Chief,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105172432&doi=10.1145%2f3456772&partnerID=40&md5=39e26620b5cf5b19b4a7f2dc9211bdc7,[No abstract available],,
Echolocation as a Means for People with Visual Impairment (PVI) to Acquire Spatial Knowledge of Virtual Space,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105227218&doi=10.1145%2f3448273&partnerID=40&md5=d6351ed474d421c184b741c3ae115335,"In virtual environments, spatial information is communicated visually. This prevents people with visual impairment (PVI) from accessing such spaces. In this article, we investigate whether echolocation could be used as a tool to convey spatial information by answering the following research questions: What features of virtual space can be perceived by PVI through the use of echolocation? How does active echolocation support PVI in acquiring spatial knowledge of a virtual space? And what are PVI's opinions regarding the use of echolocation to acquire landmark and survey knowledge of virtual space? To answer these questions, we conducted a two-part within-subjects experiment with 12 people who were blind or had a visual impairment and found that size and materials of rooms and 90-degree turns were detectable through echolocation, participants preferred using echoes derived from footsteps rather than from artificial sound pulses, and echolocation supported the acquisition of mental maps of a virtual space. Ultimately, we propose that appropriately designed echolocation in virtual environments improves understanding of spatial information and access to digital games for PVI. © 2021 ACM.",Echolocation; exploration; virtual world; visual impairment,Ophthalmology; Digital games; Research questions; Sound pulse; Spatial informations; Spatial knowledge; Survey knowledge; Virtual spaces; Visual impairment; Sonar
A Longitudinal Evaluation of Tablet-Based Child Speech Therapy with Apraxia World,2021,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089827539&doi=10.1145%2f3433607&partnerID=40&md5=986773cb1b0cf9390fc0860f82b72616,"Digital games can make speech therapy exercises more enjoyable for children and increase their motivation during therapy. However, many such games developed to date have not been designed for long-term use. To address this issue, we developed Apraxia World, a speech therapy game specifically intended to be played over extended periods. In this study, we examined pronunciation improvements, child engagement over time, and caregiver and automated pronunciation evaluation accuracy while using our game over a multi-month period. Ten children played Apraxia World at home during two counterbalanced 4-week treatment blocks separated by a 2-week break. In one treatment phase, children received pronunciation feedback from caregivers and in the other treatment phase, utterances were evaluated with an automated framework built into the game. We found that children made therapeutically significant speech improvements while using Apraxia World, and that the game successfully increased engagement during speech therapy practice. Additionally, in offline mispronunciation detection tests, our automated pronunciation evaluation framework outperformed a traditional method based on goodness of pronunciation scoring. Our results suggest that this type of speech therapy game is a valid complement to traditional home practice. © 2021 ACM.",childhood apraxia of speech (CAS); computer-aided pronunciation training (CAPT); Games for health; serious games; speech sound disorders (SSDs),Automation; Child speech; Digital games; Mispronunciation detections; Offline; Pronunciation evaluations; Speech therapy; Treatment phase; Speech
Creating Accessible Online Floor Plans for Visually Impaired Readers,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096584383&doi=10.1145%2f3410446&partnerID=40&md5=b5d5f4dcd5578fdbbc62b4d324993c81,"We present a generic model for providing blind and severely vision-impaired readers with access to online information graphics. The model supports fully and semi-Automatic transcription and allows the reader a choice of presentation mediums. We evaluate the model through a case study: online house floor plans. To do so, we conducted a formative user study with severely vision impaired users to determine what information they would like from an online floor plan and how to present the floor plan as a text-only description, tactile graphic, and on a touchscreen with audio feedback. We then built an automatic transcription tool using specialized graphics recognition algorithms. Finally, we measured the quality of system recognition as well as conducted a second user study to evaluate the usefulness of the accessible graphics produced by the tool for each of the three formats. The results generally support the design of the generic model and the usefulness of the tool we have produced. However, they also reveal the inability of current graphics recognition algorithms to handle unforeseen graphical conventions. This highlights the need for automatic transcription systems to return a level of confidence in the recognized components and to present this to the end-user so they can have an appropriate level of trust. © 2020 ACM.",Floor plans; navigation; trust; visual impairment,Computer graphics; Floors; Pattern recognition; Audio feedbacks; Automatic transcription; Generic modeling; Graphics recognition; On-line information; Semi-automatics; Vision impaired; Visually impaired; Quality control
A Comparison of Touchscreen and Mouse for Real-World and Abstract Tasks with Older Adults,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096526645&doi=10.1145%2f3418057&partnerID=40&md5=21119256370644a36120b39140bccedb,"Computer technology is increasingly being used to facilitate the timely identification of cognitive impairment in older adults. Our Cognitive Testing on Computer (C-TOC) project aims to develop a self-Administered online test for older adults to take at their home. Due to the freedom of devices they can use, it is important to investigate whether different input devices can impact test performance. We compared touchscreen and mouse input on both abstract and real-world pointing and dragging tasks: classic Fitts's Law tasks and tasks drawn from C-TOC. The abstract and real-world tasks were designed to require equivalent motor skills. Our research goals were to determine (1) if performance on computerized cognitive tasks are affected by input device, and (2) if performance differences due to input device can be explained by those observed on Fitts's Law tasks. Sixteen older adults completed both types of tasks using a touchscreen and a mouse. We found that input device affected speed on three out of four cognitive tasks while only affecting accuracy on one task. Secondarily, our results suggest that Fitts's Law results of differences in mouse and touch cannot be used to predict device differences in the performance on C-TOC tests. As an additional research goal, we looked into the movement patterns of one real-world dragging task-the C-TOC Pattern Construction task-to see if they could provide richer performance measures, beyond speed and accuracy. Such measures could compensate for the lack of a clinician observer who is typically present in comparable paper-based cognitive tests. We found that older adults naturally adopted different movement patterns on the two devices: They tended to make shorter moves and a greater number of moves on a touchscreen than with a mouse. Altogether, our results suggest that careful device-based performance calibration will be needed in computerized tests. © 2020 ACM.",cognitive testing; dragging; experiment; Input device; mouse; older adults; pointing; touchscreen,Computer testing; Knobs; Cognitive impairment; Computer technology; Computerized tests; Movement pattern; Performance calibrations; Performance measure; Test performance; Timely identification; Mammals
Computer Vision-based Methodology to Improve Interaction for People with Motor and Speech Impairment,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096595438&doi=10.1145%2f3408300&partnerID=40&md5=cf57bb29dd9ef6adcf9beab8b496b220,"Augmentative and Alternative Communication (AAC) aims to complement or replace spoken language to compensate for expression difficulties faced by people with speech impairments. Computing systems have been developed to support AAC; however, partially due to technical problems, poor interface, and limited interaction functions, AAC systems are not widespread, adopted, and used, therefore reaching a limited audience. This article proposes a methodology to support AAC for people with motor impairments, using computer vision and machine learning techniques to allow for personalized gestural interaction. The methodology was applied in a pilot system used by both volunteers without disabilities, and by volunteers with motor and speech impairments, to create datasets with personalized gestures. The created datasets and a public dataset were used to evaluate the technologies employed for gesture recognition, namely the Support Vector Machine (SVM) and Convolutional Neural Network (using Transfer Learning), and for motion representation, namely the conventional Motion History Image and Optical Flow-Motion History Image (OF-MHI). Results obtained from the estimation of prediction error using K-fold cross-validation suggest SVM associated with OF-MHI presents slightly better results for gesture recognition. Results indicate the technical feasibility of the proposed methodology, which uses a low-cost approach, and reveals the challenges and specific needs observed during the experiment with the target audience. © 2020 ACM.",accessibility; Assistive technology; augmentative and alternative communication; computer vision; gesture recognition,Computer vision; Convolutional neural networks; Gesture recognition; Human rehabilitation engineering; Optical flows; Speech communication; Support vector machines; Transfer learning; Augmentative-and-alternative communication; Expression difficulties; Gestural interaction; Interaction functions; K fold cross validations; Machine learning techniques; Motion history images; Motion representation; Learning systems
Experimental Analysis of a Spatialised Audio Interface for People with Visual Impairments,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096601773&doi=10.1145%2f3412325&partnerID=40&md5=9af8200330d899d605ca78051b21c476,"Sound perception is a fundamental skill for many people with severe sight impairments. The research presented in this article is part of an ongoing project with the aim to create a mobile guidance aid to help people with vision impairments find objects within an unknown indoor environment. This system requires an effective non-visual interface and uses bone-conduction headphones to transmit audio instructions to the user. It has been implemented and tested with spatialised audio cues, which convey the direction of a predefined target in 3D space. We present an in-depth evaluation of the audio interface with several experiments that involve a large number of participants, both blindfolded and with actual visual impairments, and analyse the pros and cons of our design choices. In addition to producing results comparable to the state-of-The-Art, we found that Fitts's Law (a predictive model for human movement) provides a suitable metric that can be used to improve and refine the quality of the audio interface in future mobile navigation aids. © 2020 ACM.",active vision; audio interface; Fitts Law; guidance system; Visual impairment,Predictive analytics; Bone-conduction headphones; Depth evaluations; Experimental analysis; Indoor environment; Predictive modeling; Sound perception; Vision impairments; Visual impairment; Interface states
O&M Indoor Virtual Environments for People Who Are Blind,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091153235&doi=10.1145%2f3395769&partnerID=40&md5=6bdf6fed1a37fff1101d49172d49d68c,"BACKGROUND: Knowing their current position in the surroundings constitutes one of the biggest challenges faced by people with visual disabilities when they move around. For them, it is difficult to be aware of the direction in which they are going, and the location of nearby objects and obstacles. In this context, obtaining relevant spatial information is always very significant to these individuals. Hence, the research in the development of assistive technologies for needs and perspectives of people who are blind has been a promising area in terms of the orientation and mobility (O&M) challenges. OBJECTIVE: The purpose of this study is to systematically examine the literature on O&M virtual environments designed to support indoor navigation to identify techniques for both developing and evaluating the usability and cognitive impact of these applications. METHODS: A systematic literature review (SLR) was performed, considering population, intervention, outcomes, and study design as eligibility criteria. After a filtering process from 987 works retrieved from six databases, we extracted data from 51 papers, which meet the study selection criteria. RESULTS: The analysis of the 51 papers describing 31 O&M indoor virtual environments, indicated that O&M virtual environments to support indoor navigation are usually designed for desktop, adopt spatial audio as way to support orientation, and use joystick as primary interaction device. Regarding evaluation techniques, questionnaires, interviews, user observation, and performance logs are commonly used to evaluate usability in this context. In tests involving users, the participants are usually adults aged 21-59 years, who individually spend about 90 minutes split in usually two evaluation sessions. Most papers do not report any strategies to evaluate the cognitive impact of O&M virtual environments on users' navigational and wayfinding skills. Thirteen papers (25.49%) reported the conduction of experiments or quasi-experiments and demonstrated pieces of evidence associated with a positive cognitive impact resultant from O&M indoor virtual environments usage. Finally, only four papers (7.84%) reported the development of indoor maps editors for O&M virtual environments. CONCLUSION: Our SLR summarizes the characteristics of 32 O&M virtual environments. It compiles state-of-the-art for indoor simulations in this domain and highlights their challenges and impacts in O&M training. Also, the absence of clear guidelines to design and evaluate O&M virtual environments and the few available computer editors of indoor maps appear as research opportunities. © 2020 ACM.",Human-computer interaction; multimodal interfaces; orientation and mobility; people with visual impairment,Navigation; Paper; Surveys; Assistive technology; Eligibility criterion; In-door navigations; Interaction devices; Research opportunities; Selection criteria; Spatial informations; Systematic literature review (SLR); Indoor positioning systems
Socio-Technical Aspirations for Children with Special Needs,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090418137&doi=10.1145%2f3396076&partnerID=40&md5=ccfc70ef272b1b8491dc427bd6907df1,"Society's expectations and assistance for children with special needs is rooted in its cultural, societal, and political backdrop. Previous work on the role of culture on assistive or adaptive technology design for children with special needs identified a three-part framework: lifestyle, socio-Technical infrastructure, and monetary and informational resources. Through our work in India, we proposed a fourth dimension to this framework: socio-Technical aspirations. We defined socio-Technical aspirations as the individual-or community-driven ambition and desire to own or use a specific technology for personal benefit or societal acceptance or both. In Finland, we interviewed four parents of children enrolled in a rehabilitation program, with the aim to understand their expectations from and current usage of technology. Findings from Finland reveal a desire for technology for children with special needs to be more engaging than what is currently available. We also identified several attributes that can contribute to socio-Technical aspirations in a given context, including but not limited to: The level of inclusiveness supported in the school, which directly affects how technology is viewed with respect to the social acceptance it provides; the socio-Technical aspirations of the child and how they are perceived and met by the parents and teachers; and previous technology experience of the various stakeholders involved in raising a child with special needs, which determines their attitude toward technology for not only for themselves but also for the child. In this article, we validate the dimension of socio-Technical aspirations to strengthen our case for incorporating stakeholder's socio-Technical aspirations for technology designed or adapted for children with special needs. © 2020 ACM.",assistive technology framework; children with special needs; cross-cultural studies; Socio-Technical aspirations,Computer applications; Human computer interaction; Adaptive technology; Assistive; Attitude toward technologies; Finland; Rehabilitation programs; Social acceptance; Sociotechnical; Special needs; Patient rehabilitation
Use of an Indoor Navigation System by Sighted and Blind Travelers,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090424309&doi=10.1145%2f3407191&partnerID=40&md5=a4c6433097778270fb0247674a4b685e,"This article first reviews the pros and cons of current accessible indoor navigation systems and then describes a study using commercial smart devices to navigate routes through a complex building. Our interest was in comparing performance when using real-Time narrative descriptions (system-Aided condition) vs. a memory-based condition where the same narrative information was only provided to users from the route's origin. We tested two groups of blind and visually impaired (BVI) users, including people above and below 60 years of age, as well as a third sighted control group. Evaluating older BVI participants is important, as the majority of vision loss is age-related, yet navigation performance using access technology is rarely studied with this demographic. Behavioral results demonstrated that access to real-Time (system-Aided) information led to better navigation accuracy and greater confidence by blind users compared to the information-matched memory condition. Performance for blind participants over 60 years old was nearly identical with their younger peers-an important outcome supporting the efficacy of using navigational technologies by this fast-growing population. Route completion accuracy and requests for assistance did not reliably differ between blind and sighted participants when using the system, suggesting that access to narrative route information led to functionally equivalent navigation behavior, irrespective of visual status. Survey results revealed strong user support for real-Time information and provided important guidance for future interface refinements. © 2020 ACM.",blind/visually impaired navigation; Bluetooth location beacons; indoor navigation; Narrative route descriptions; older adult navigation,Navigation systems; Surveys; Blind and visually impaired; Indoor navigation system; Interface refinement; Navigation accuracy; Navigation behavior; Navigation performance; Navigational technologies; Real-time information; Indoor positioning systems
"Design Guidelines and Recommendations for Multimodal, Touchscreen-based Graphics",2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090411688&doi=10.1145%2f3403933&partnerID=40&md5=ba1050c530906ca0c7756fbd5ea584a2,"With content rapidly moving to the electronic space, access to graphics for individuals with visual impairments is a growing concern. Recent research has demonstrated the potential for representing basic graphical content on touchscreens using vibrations and sounds, yet few guidelines or processes exist to guide the design of multimodal, touchscreen-based graphics. In this work, we seek to address this gap by synergizing our collective research efforts over the past eight years and implementing our findings into a compilation of recommendations, which we validate through an iterative design process and user study. We start by reviewing previous work and then collate findings into a set of design guidelines for generating basic elements of touchscreen-based multimodal graphics. We then use these guidelines to generate exemplary graphics in mathematics, specifically bar charts and geometry concepts. We discuss the iterative design process of moving from guidelines to actual graphics and highlight challenges. We then present a formal user study with 22 participants with visual impairments, comparing learning performance on using touchscreen-rendered graphics to embossed graphics. We conclude with qualitative feedback from participants on the touchscreen-based approach and offer areas of future investigation as these recommendation are expanded to include more complex graphical concepts. © 2020 ACM.",accessibility; design; guidelines; Multimodal graphics; touchscreens,Computer applications; Human computer interaction; Basic elements; Iterative design; Learning performance; Multi-modal; Qualitative feedback; Recent researches; Research efforts; Visual impairment; Design
Design Guidelines for an Interactive 3D Model as a Supporting Tool for Exploring a Cultural Site by Visually Impaired and Sighted People,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090420774&doi=10.1145%2f3399679&partnerID=40&md5=76397d9b8ea58d9626084c924d9b6aa8,"Being able to explore and familiarise themselves with the structure and details of a cultural site before actually visiting it is fundamental for orienting visually impaired people during the visit; otherwise, it is particularly difficult to gain a global understanding of the structure and an overall impression of a square, a church, or a large monument. Our project addressed this problem by using low cost 3D models combined with audio descriptions to enable visually impaired users to explore the cultural site autonomously. Audio descriptions are organised into three groups (for historical, practical, and architectural information), and for each group, several tracks are recorded giving increasing levels of details. Users can easily navigate through the audio tracks to follow their tactile exploration by listening to the information they are most interested in. Relevant details are reproduced separately and linked to the main model via the audio tracks. A goal of our model is to enhance the understanding of the cultural site also for partially sighted as well as sighted people, making them able to appreciate the details of the architectural design using both visual and auditory senses. We exploited low-cost and partially open-source technologies, thus rendering our system easily replicable. We evaluated the interactive system with blind, partially sighted, and sighted users. Our user test confirmed the validity of our approach: (1) the 3D models and the tactile reproduction of details obtained via a low-cost 3D printing solution are well perceived by touch; (2) the semantic auditory information activated via perceptible buttons on demand and the different content levels for the audio tracks are suitable for an interactive, autonomous, and satisfying exploration; and (3) relevant details are well perceived. Finally, we propose guidelines to use in the 3D reproduction of buildings or large sites based on our experience. © 2020 ACM.",3D modelling; 3D printing; accessibility; blind people; Intelligent artefacts; interactive audio model; rapid prototyping,3D modeling; 3D printers; Cell proliferation; Costs; Open systems; Semantics; Audio description; Interactive 3-D models; Interactive system; Open-source technology; Tactile exploration; Visually impaired; Visually impaired people; Visually-impaired users; Structural design
VectorEntry,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090411834&doi=10.1145%2f3406537&partnerID=40&md5=02ff905d878eae0a3c5e541e12c417c8,"Mobile phones are now touch-enabled, which allows the use of on-screen keyboards for text entry. Text entry tasks are among the most frequently occurring tasks performed by mobile phone users. However, people with visual impairments find it difficult to use on-screen keyboards, and this affects their digital literacy. In this article, a text entry mechanism is proposed to solve this problem using directional movement gestures suitable for people with visual impairments. Two forms of directional movement gestures, guided and unguided movements, are first studied, and the analysis reveals that unguided directional movement gestures are more suitable for a text entry mechanism for individuals who are visually impaired. Based on this insight, a text entry mechanism called VectorEntry is developed. It uses eight unguided directional movement gestures to select characters on the keyboard of a touch-enabled mobile phone. The keyboard is designed in accordance with the traditional 4×3 telephone keypad. The results of experiments show that the average text entry rate of VectorEntry was 3.3 wpm, 83.3% higher than the state-of-The-Art No-Look Notes used for similar tasks. Its average rate of error in text entry was only 0.19% per character. © 2020 ACM.",Accessible computing; mobile computing; rehabilitation engineering; text entry mechanism; user interface design; visual impairment,Cellular telephones; Average rate; Digital literacies; Directional movements; Mobile-phone users; On-screen keyboard; State of the art; Visual impairment; Visually impaired; Touch screens
Spotlights and Soundscapes,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088293712&doi=10.1145%2f3378576&partnerID=40&md5=945011003053cbc2d8d0fe5515226e3e,"For persons with visual impairment, forming cognitive maps of unfamiliar interior spaces can be challenging. Various technical developments have converged to make it feasible, without specialized equipment, to represent a variety of useful landmark objects via spatial audio, rather than solely dispensing route information. Although such systems could be key to facilitating cognitive map formation, high-density auditory environments must be crafted carefully to avoid overloading the listener. This article recounts a set of research exercises with potential users, in which the optimization of such systems was explored. In Experiment 1, a virtual reality environment was used to rapidly prototype and adjust the auditory environment in response to participant comments. In Experiment 2, three variants of the system were evaluated in terms of their effectiveness in a real-world building. This methodology revealed a variety of optimization approaches and recommendations for designing dense mixed-reality auditory environments aimed at supporting cognitive map formation by visually impaired persons.  © 2020 ACM.",auditory displays; cognitive maps; Navigation,Audio equipment; Mixed reality; Optimization approach; Potential users; Route information; Specialized equipment; Technical development; Virtual-reality environment; Visual impairment; Visually impaired persons; Cognitive systems
Introduction to the Special Issue on Technology to Support Independent Orientation and Mobility of People with Visual Impairments,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088319188&doi=10.1145%2f3398652&partnerID=40&md5=203b25ed90fa92fc15d95e9bf556e858,[No abstract available],,
X-Road: Virtual Reality Glasses for Orientation and Mobility Training of People with Visual Impairments,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088317000&doi=10.1145%2f3377879&partnerID=40&md5=6228596dbdb320e2b82b4cf6d18ff204,"Orientation and Mobility (O8M) classes teach people with visual impairments how to navigate the world; for instance, how to cross a road. Yet, this training can be difficult and dangerous due to conditions such as traffic and weather. Virtual Reality (VR) can overcome these challenges by providing interactive controlled environments. However, most existing VR tools rely on visual feedback, which limits their use with students with visual impairment. In a collaborative design approach with O8M instructors, we designed an affordable and accessible VR system for O8M classes, called X-Road. Using a smartphone and a Bespoke headmount, X-Road provides both visual and audio feedback and allows users to move in space as in the real world. In a study with 13 students with visual impairments, X-Road proved to be an effective alternative to teaching and learning classical O8M tasks, and both students and instructors were enthusiastic about this technology. We conclude with design recommendations for inclusive VR systems.  © 2020 ACM.",Accessibility; augmented reality; mobility training; virtual reality; visual impairment,E-learning; Feedback; Students; Virtual reality; Visual communication; Audio feedbacks; Collaborative design; Controlled environment; Design recommendations; Real-world; Teaching and learning; Visual feedback; Visual impairment; Roads and streets
Tactile Working Memory Capacity of Users Who Are Blind in an Electronic Travel Aid Application with a Vibration Belt,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088303062&doi=10.1145%2f3372273&partnerID=40&md5=263d559bd12edf4dfb99417052438d27,"Electronic travel aids (ETAs) can increase the safety and comfort of pedestrians who have a visual impairment by displaying obstacles through a vibrotactile navigation belt. Building a complete picture of relevant obstacles and finding a safe route requires ETA users to integrate vibrotactile cues over time and space in their tactile working memory. Previous research suggests that the sense of touch exhibits a working memory that has characteristics similar to vision and audition. However, the capacity of the tactile working memory and the effects of secondary tasks are still under-researched. We investigated tactile working memory capacity of 14 adolescent participants who are blind in an immediate, whole report recall test. Participants received trials consisting of one to five vibration patterns presented sequentially at different locations on their torso representing obstacles with a direction (vibration location) and distance (vibration pattern). Recall performance was assessed under four conditions: baseline and with distracting background sounds and/or while walking with the long cane. Both walking and ignoring distracting sounds are relevant for everyday use of an ETA and were expected to decrease memory performance. We calculated the 75% correct scores for two memory performance measures: the number of items in a trial (numerosity), and item location and pattern correct. In the baseline condition, the scores were close to ceiling (i.e., 5 items). However, in the presence of distracting sounds and while walking, the scores were reduced to 3.2 items for numerosity and 1.6 items for location and identity correct. We recommend using 2 items as the maximum tactile working memory load in an applied setting unless users are trained and/or can adopt their strategy without unacceptable costs, such as reducing their walking speed.  © 2020 ACM.",blind; electronic travel aids; human information processing; Tactile display; working memory,Belts; Navigation systems; Pedestrian safety; Vibrotactile aids; Base-line conditions; Distracting sounds; Electronic travel aidss; Memory performance; Secondary tasks; Sense of touch; Vibration pattern; Visual impairment; Location
Mental Maps and the Use of Sensory Information by Blind and Partially Sighted People,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088312322&doi=10.1145%2f3375279&partnerID=40&md5=b3dca2735a6a1f378956476fed30b47d,"This article aims to fill an important gap in the literature by reporting on blind and partially sighted people's use of spatial representations (mental maps) from their perspective and when travelling on real routes. The results presented here were obtained from semi-structured interviews with 100 blind and partially sighted people in five different countries. They are intended to answer three questions about the representation of space by blind and partially sighted people, how these representations are used to support travel, and the implications for the design of travel aids and orientation and mobility training. They show that blind and partially sighted people do have spatial representations and that a number of them explicitly use the term mental map. This article discusses the variety of approaches to spatial representations, including the sensory modalities used, the use of global or local representations, and the applications to support travel. The conclusions summarize the answers to the three questions and include a two-level preliminary classification of the spatial representations of blind and partially sighted people.  © 2020 ACM.",Blind; mental model; partially sighted; sensory information; spatial representation,Computer applications; Human computer interaction; Mental maps; Semi structured interviews; Sensory information; Sensory modality; Spatial representations; Travel aid; Cognitive systems
Critical Reflections on Technology to Support Physical Activity among Older Adults,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096031521&doi=10.1145%2f3374660&partnerID=40&md5=17bcfcdb7db514b5873f9dcf3a7bdb36,"Contemporary policy on ageing overwhelmingly focuses on active ageing and achieving a sustainable increase in disability-free years, leading to an agenda that promotes interventions that often focus on deficits of older persons with little consideration of their perspectives on physical activity. As the integration of technology to support physical activity routines becomes more common, this trend also becomes relevant to the Human-Computer Interaction (HCI) research community. In this article, we present findings from a structured search of technical systems addressing physical activity among older adults that were published at the most cited HCI venues. Drawing from Thematic Analysis, we explore how the model of active ageing informs existing research, and how it is operationalized in technology design. We find that the deficit-focused perspective on ageing is reflected in many technology solutions published at the most visible HCI venues, and discuss shortcomings and strengths of present research to help guide discourse and future work in HCI.  © 2020 ACM.",movement-based games; Older adults; physical activity; rehabilitation; review; wearables,Computer applications; Critical reflections; Disability-free; Human-computer interaction researches; Physical activity; Technical systems; Technology designs; Technology solutions; Thematic analysis; Human computer interaction
An Epidemiology-inspired Large-scale Analysis of Android App Accessibility,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097579255&doi=10.1145%2f3348797&partnerID=40&md5=e2db5eb8fada1a1421613770a14382a8,"Accessibility barriers in mobile applications (apps) can make it challenging for people who have impairments or use assistive technology to use those apps. Ross et al.'s epidemiology-inspired framework emphasizes that a wide variety of factors may influence an app's accessibility and presents large-scale analysis as a powerful tool for understanding the prevalence of accessibility barriers (i.e., inaccessibility diseases). Drawing on this framework, we performed a large-scale analysis of free Android apps, exploring the frequency of accessibility barriers and factors that may have contributed to barrier prevalence. We tested a population of 9,999 apps for seven accessibility barriers: few TalkBack-focusable elements, missing labels, duplicate labels, uninformative labels, editable TextViews with contentDescription, fully overlapping clickable elements, and undersized elements. We began by measuring the prevalence of each accessibility barrier across all relevant element classes and apps. Missing labels and undersized elements were the most prevalent barriers. As a measure of the spread of barriers across apps, we assessed the five most reused classes of elements for missing labels and undersized elements. The Image Button class was among the most barrier-prone of the high reuse element classes; 53% of Image Button elements were missing labels and 40% were undersized. We also investigated factors that may have contributed to the high barrier prevalence in certain classes of elements, selecting examples based on prior knowledge, our analyses, and metrics of reuse and barrier-proneness. These case studies explore: (1) how the few TalkBack-focusable elements accessibility barrier relates to app category (e.g., Education, Entertainment) and the tools used to implement an app, (2) the prevalence of label-based barriers in image-based buttons, (3) design patterns that affect the labeling and size of Radio Buttons and Checkboxes, and (4) accessibility implications of the sizing of third-party plug-in elements. Our work characterizes the current state of Android accessibility, suggests improvements to the app ecosystem, and demonstrates analysis techniques that can be applied in further app accessibility assessments.  © 2020 ACM.",accessibility; large-scale analyses; Mobile applications,Factor analysis; Fasteners; Statistics; Accessibility barriers; Analysis techniques; Assistive technology; Content description; Design Patterns; Large-scale analysis; Mobile applications; Prior knowledge; Android (operating system)
Reviewing Speech Input with Audio,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097583132&doi=10.1145%2f3382039&partnerID=40&md5=fbce8cc9763cd03c790c51161976547a,"Speech input is a primary method of interaction for blind mobile device users, yet the process of dictating and reviewing recognized text through audio only (i.e., without access to visual feedback) has received little attention. A recent study found that sighted users could identify only about half of automatic speech recognition (ASR) errors when listening to text-to-speech output of the ASR results. Blind screen reader users, in contrast, may be better able to identify ASR errors through audio due to their greater use of speech interaction and increased ability to comprehend synthesized speech. To compare the experiences of blind and sighted users with speech input and ASR errors, as well as to compare their ability to identify ASR errors through audio-only interaction, we conducted a lab study with 12 blind and 12 sighted participants. The study included a semi-structured interview portion to qualitatively understand experiences with ASR, followed by a controlled speech input task to quantitatively compare participants' ability to identify ASR errors in their dictated text. Findings revealed differences between blind and sighted participants in terms of how they use speech input and their level of concern for ASR errors (e.g., blind users were more highly concerned). In the speech input task, blind participants were able to identify only 40% of ASR errors, which, counter to our hypothesis, was not significantly different from sighted participants' performance. In depth analysis of speech input, ASR errors, and strategy of identifying ASR errors scrutinized how participants entered a text with speech input and reviewed it. Our findings indicate the need for future work on how to support blind users in confidently using speech input to generate accurate, error-free text.  © 2020 ACM.",ASR errors; blind; dictation; Speech input; synthesized speech; text entry; visual impairment,Character recognition; Errors; Speech; Visual communication; Automatic speech recognition; In-depth analysis; Mobile device users; Semi structured interviews; Speech interaction; Synthesized speech; Text to speech; Visual feedback; Speech recognition
"Exploring the Needs, Preferences, and Concerns of Persons with Visual Impairments Regarding Autonomous Vehicles",2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093101656&doi=10.1145%2f3372280&partnerID=40&md5=1ed03e9b99554558341f3eaad26a77bd,"Fully autonomous or ""self-driving""vehicles are an emerging technology that may hold tremendous mobility potential for blind or visually impaired persons who are currently unable to drive a conventional motor vehicle. Despite the considerable potential of self-driving vehicle technology to address this mobility issue, however, the needs and preferences of persons with visual disabilities regarding this technology have been insufficiently investigated. In this article, we present the results of two studies that are focused on exploring the needs, preferences, and concerns of persons with visual impairments as it relates to self-driving vehicles. Study one investigated user acceptance, concerns, and willingness to buy partially and fully automated vehicles using a 39-question Internet-based survey distributed in the United States to visually impaired respondents (n = 516). Study two explores the opinions of 38 participants who are blind and low vision, using focus group methodology, regarding emerging self-driving vehicle technology. Collectively our findings suggest that while persons with visual impairments may be optimistic regarding the potential for enhanced mobility and independence that may result from the emergence of self-driving vehicles, concerns exist regarding the implementation of this technology that have been largely unexplored and under investigated.  © 2020 ACM.",accessibility; Autonomous vehicles; self-driving vehicles; visual impairment,Surveys; Conventional motors; Emerging technologies; Enhanced mobility; Focus group methodology; Vehicle technology; Visual disability; Visually impaired; Visually impaired persons; Autonomous vehicles
Design for social accessibility method cards: Engaging users and reflecting on social scenarios for accessible design,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078233632&doi=10.1145%2f3369903&partnerID=40&md5=ecd8a8f3c86601bcd077935a98bfa404,"This article is an extended version of our 2018 ASSETS paper entitled, “Incorporating Social Factors in Accessible Design.” In our ASSETS paper, we demonstrated the viability of the Design for Social Accessibility perspective through a series of user-centered workshops with professional designers. With this expanded article, we conducted a follow-up research study with a user-centered design course that examined the use of Design for Social Accessibility Method Cards over a longer design cycle, specifically as the method and cards contributed to a term-long project, rather than just a workshop. We also offer a new analysis on work leading to the development of Design for Social Accessibility, with a focus on how practical considerations in the design process influence how designers engage accessible design. We found that the concrete and real-life scenarios in the Design for Social Accessibility Method Cards helped mediate useful interactions between student designers and deaf and hard-of-hearing users. In addition, we identified how practical choices in investigating strategies for socially accessible design enabled designers to center disabled perspectives. The contributions of this work'when added to the findings of our ASSETS 2018 paper on incorporating social factors'demonstrate the viability of Design for Social Accessibility by providing: (1) empirical data showing that designers can use the Design for Social Accessibility perspective and method cards to generate accessible designs and appropriately engage deaf and hard-of-hearing users to incorporate social considerations; and (2) a summative analysis highlighting practical steps for how designers can use the Design for Social Accessibility perspective and methods cards to create accessible designs. © 2019 Association for Computing Machinery.",Accessibility; Design workshops; User-centered design,Audition; Curricula; Accessibility; Design workshops; Extended versions; Hard of hearings; Professional designers; Research studies; Social scenarios; Summative analysis; User centered design
Accessibility information needs in the enterprise,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078241929&doi=10.1145%2f3368620&partnerID=40&md5=cfcff76f104604d8c3ef8b1f4b89a9f8,"We describe the questions asked about accessibility, both through information searches and direct queries, within a large multinational corporation over a period of two years, finding an emphasis on topics covering enterprise requirements for testing, recording, and reporting compliance. Our analysis finds that up to 66% of these questions may be answerable by an accessibility ontology, but only 26% of the terms in the questions are concepts found in existing available accessibility ontologies. To fill this gap, we introduce the Enterprise Accessibility Conformance Ontology, which extends previous ontologies to include the relevant concepts. We demonstrate the use of the ontology to provide a unifying model of the accessibility domain that contributed to a 22% performance improvement for a question-answering accessibility conformance chatbot. © 2019 Association for Computing Machinery.",Accessibility; Compliance; Conformance; Enterprise; Ontology; Section 508; Standards; WCAG,Industry; Regulatory compliance; Standards; Accessibility; Compliance; Conformance; Section 508; WCAG; Ontology
Introduction to the special issue on assets'18,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078253959&doi=10.1145%2f3372925&partnerID=40&md5=1421b9ca8abe11715deed340049b7b39,[No abstract available],,
Greetings from the new editors-in-Chief,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078225700&doi=10.1145%2f3372922&partnerID=40&md5=5e4bfe06f287397a589c1331024bfc21,[No abstract available],,
Blind leading the sighted: Drawing Design Insights from Blind Users towards More Productivity-oriented Voice Interfaces,2020,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078259472&doi=10.1145%2f3368426&partnerID=40&md5=c628586ba50f97ddadcae20c0ee85a2c,"Voice-activated personal assistants (VAPAs) are becoming smaller, cheaper, and more accurate, such that they are now prevalent in homes (e.g., Amazon Echo, Sonos One) and on mobile devices (e.g., Google Assistant, Apple Siri) around the world. VAPAs offer considerable potential to individuals who are blind, offering efficiencies over gesture-based input on touchscreen devices. However, research is just beginning to reveal the ways in which these technologies are used by people who are blind. In the first of two studies, we interviewed 14 blind adults with experience of home and/or mobile-based VAPAs, surfacing myriad accessibility, usability, and privacy issues for this community. A second study analyzing podcast content from 28 episodes relating to blind interactions with VAPAs was then undertaken to validate and extend findings from the first study. In addition to verifying prior findings, we learned that blind users wanted to leverage VAPAs for more productivity-oriented tasks and increased efficiency over other interaction modalities. We conclude that (1) VAPAs need to support a greater variety of AI personas, each specializing in a specific type of task; (2) VAPAs need to maintain continuity of voice interaction for both usability and accessibility; and (3) blind VAPA users, and especially blind technology podcasters, are expert voice interface users who should be incorporated into design processes from the beginning. We argue that when the blind lead the sighted through voice interface design, both blind and sighted users can benefit. © 2019 Association for Computing Machinery.",Accessibility; Blind; Usability; Visual impairment; Voice user interface; Voice-activated personal assistant,Efficiency; Productivity; User interfaces; Accessibility; Blind; Personal assistants; Usability; Visual impairment; Voice user interface; Design
Designing and evaluating a customizable head-mounted vision enhancement system for people with low vision,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076990746&doi=10.1145%2f3361866&partnerID=40&md5=a0e2a6cb7ace8b8767b58f3e4fc76de4,"Recent advances in head-mounted displays (HMDs) present an opportunity to design vision enhancement systems for people with low vision, whose vision cannot be corrected with glasses or contact lenses. We aim to understand whether and how HMDs can aid low vision people in their daily lives. We designed ForeSee, an HMD prototype that enhances people's view of the world with image processing techniques such as magnification and edge enhancement. We evaluated these vision enhancements with 20 low vision participants who performed four viewing tasks: image recognition and reading tasks from near- and far-distance. We found that participants needed to combine and adjust the enhancements to comfortably complete the viewing tasks. We then designed two input modes to enable fast and easy customization: speech commands and smartwatchbased gestures. While speech commands are commonly used for eyes-free input, our novel set of onscreen gestures on a smartwatch can be used in scenarios where speech is not appropriate or desired. We evaluated both input modes with 11 low vision participants and found that both modes effectively enabled low vision users to customize their visual experience on the HMD. We distill design insights for HMD applications for low vision and spur new research directions. © 2019 Association for Computing Machinery.",Accessibility; Head-mounted displays (HMD); Interaction techniques; Low vision,Image enhancement; Image recognition; Wearable computers; Accessibility; Head mounted displays; Image processing technique; Interaction techniques; Low vision; Vision enhancement; Vision enhancement systems; Visual experiences; Helmet mounted displays
Deep learning compensation of rotation errors during navigation assistance for people with visual impairments or blindness,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077006017&doi=10.1145%2f3349264&partnerID=40&md5=71e6a5b9071efdaf3fd2602bbd322a9e,"Navigation assistive technologies are designed to support people with visual impairments during mobility. In particular, turn-by-turn navigation is commonly used to provide walk and turn instructions, without requiring any prior knowledge about the traversed environment. To ensure safe and reliable guidance, many research efforts focus on improving the localization accuracy of such instruments. However, even when the localization is accurate, imprecision in conveying guidance instructions to the user and in following the instructions can still lead to unrecoverable navigation errors. Even slight errors during rotations, amplified by the following frontal movement, can result in the user taking an incorrect and possibly dangerous path. In this article, we analyze trajectories of indoor travels in four different environments, showing that rotation errors are frequent in state-of-art navigation assistance for people with visual impairments. Such errors, caused by the delay between the instruction to stop rotating and when the user actually stops, result in overrotation. To compensate for over-rotation, we propose a technique to anticipate the stop instruction so that the user stops rotating closer to the target rotation. The technique predicts over-rotation using a deep learning model that takes into account the user's current rotation speed, duration, and angle; the model is trained with a dataset of rotations performed by blind individuals. By analyzing existing datasets, we show that our approach outperforms a naive baseline that predicts over-rotation with a fixed value. Experiments with 11 blind participants also show that the proposed compensation method results in lower rotation errors (18.8° on average) compared to the non-compensated approach adopted in state-of-the-art solutions (30.1°). © 2019 Association for Computing Machinery.",Navigation assistance; Orientation & mobility; Turn-by-turn navigation,Errors; Navigation; Rotation; Assistive technology; Blind individuals; Compensation method; Localization accuracy; Navigation error; Research efforts; State of the art; Visual impairment; Deep learning
"Interactive Technologies Designed for Children with Autism: Reports of Use and Desires from Parents, Teachers, and Therapists",2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075632381&doi=10.1145%2f3342285&partnerID=40&md5=4ee3ff6e76f612f67a4e5f0c28209850,"Autism spectrum disorder (ASD) affects many people; the Center for Disease Control and Prevention estimates that 1 in 59 children are currently identified with ASD in the United States. Although it is difficult to generalize about people with ASD due to their heterogeneity, many share an affinity for technologies; as such, numerous academic endeavors and commercial products have focused on the creation of interactive technologies for ASD. In this article, we present findings from 19 interviews and 230 surveys with parents, teachers, and therapists who had children with ASD in their care and had considered or used interactive technologies with those children. We aimed to understand how interactive technologies were used, perceived, desired, and discovered. Findings of use and perception included the following: participants had tried a wide range of commercially available technologies but had very few reported products in common, products were limited to commercial mobile-based apps, and apps were typically perceived positively. In regard to desires, participants hoped for future technologies on diverse platforms (e.g., robots, virtual reality) with more consideration given to personalization, customization, and incorporation of audio and video. Findings about discovery included the following: participants chose technologies in an information-poor environment, and although there are many academic projects aimed at participants' desires, no participants reported any experience working with researchers. Implications of this study include the need for a recommendation and information sharing system to help people choose and discover appropriate and effective interactive technologies that are a good fit for their child. This work also pointed to a need for such a system to include findings from lab (experimental and usability) studies of commercially available interactive technologies to provide measures of efficacy and usability. Our envisioned system could also potentially help academic researchers with outreach to wider audiences. © 2019 Association for Computing Machinery. All rights reserved.",Autism; children; interactive technologies,Disease control; Virtual reality; Autism; Autism spectrum disorders; Center for disease control and preventions; children; Children with autisms; Commercial products; Information sharing systems; Interactive technology; Diseases
Editorial: A message from the outgoing editors-in-chief,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072015092&doi=10.1145%2f3345019&partnerID=40&md5=505033fed82500605056d432fbc574e5,[No abstract available],,
Find and seek: Assessing the impact of table navigation on information look-up with a screen reader,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072047604&doi=10.1145%2f3342282&partnerID=40&md5=442f71ad2f798ab7f3a0df062e133c2a,"Web designers use visual cues such as layout and typography to make pages easier to navigate and understand. Yet, screen readers generally ignore these features and present page information in a linear audio stream. We investigate whether transcoding the visual semantics of grid-based layouts to tables supports better navigation. In a controlled experiment, participants navigated re-written pages significantly faster when doing data synthesis tasks and more accurately when looking up information meeting multiple criteria. Participants rated their table navigation experience better in terms of effort, memorization, ease of navigation, understanding of page information, and confidence in submitted answers. Participants attributed these gains to the table structure's support for (1) predictable audio presentation, (2) adopting an appropriate search strategy, and (3) making sense of page content. Contrary to the established belief that tables are inaccessible, our results show that tables can facilitate navigation when users need to synthesize across page content. © 2019 Association for Computing Machinery.",Audio interfaces; Cognitive load; Screen reader; Spatial layout; Table navigation; Web accessibility,Semantics; Websites; Audio interfaces; Cognitive loads; Screen readers; Spatial layout; Table navigation; Web accessibility; Navigation
Introduction to the special issue on assets'17 (part 2),2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072032530&doi=10.1145%2f3345021&partnerID=40&md5=3dcba0def926591ae45ae87041cc352e,[No abstract available],,
Navcog3 in the wild: Large-scale Blind Indoor Navigation Assistant with Semantic Features,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072012389&doi=10.1145%2f3340319&partnerID=40&md5=4ed1290a8713168f14dcae04f57caf4b,"NavCog3 is a smartphone turn-by-turn navigation assistant system we developed specifically designed to enable independent navigation for people with visual impairments. Using off-the-shelf Bluetooth beacons installed in the surrounding environment and a commodity smartphone carried by the user, NavCog3 achieves unparalleled localization accuracy in real-world large-scale scenarios. By leveraging its accurate localization capabilities, NavCog3 guides the user through the environment and signals the presence of semantic features and points of interest in the vicinity (e.g., doorways, shops). To assess the capability of NavCog3 to promote independent mobility of individuals with visual impairments, we deployed and evaluated the system in two challenging real-world scenarios. The first scenario demonstrated the scalability of the system, which was permanently installed in a five-story shopping mall spanning three buildings and a public underground area. During the study, 10 participants traversed three fixed routes, and 43 participants traversed free-choice routes across the environment. The second scenario validated the system's usability in the wild in a hotel complex temporarily equipped with NavCog3 during a conference for individuals with visual impairments. In the hotel, almost 14.2h of system usage data were collected from 37 unique users who performed 280 travels across the environment, for a total of 30,200m traversed. © 2019 Association for Computing Machinery.",Indoor navigation; Points of interest; User evaluation; Visual impairments; Voice interaction,Indoor positioning systems; Semantics; Smartphones; In-door navigations; Points of interest; User evaluations; Visual impairment; Voice interaction; Navigation
Introduction to the special issue on ASSETS'17,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067255644&doi=10.1145%2f3325866&partnerID=40&md5=0845d1591557c453195d7bf28b3230aa,[No abstract available],,
Design and psychometric evaluation of American sign language translations of usability questionnaires,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067240514&doi=10.1145%2f3314205&partnerID=40&md5=69fb759ad188215095242f29c4e86835,"To promote greater inclusion of people who are Deaf and Hard of Hearing (DHH) in studies conducted by Human-Computer Interaction (HCI) researchers or professionals, we have undertaken a project to formally translate several standardized usability questionnaires from English to ASL. Many deaf adults in the U.S. have lower levels of English reading literacy, but there are currently no standardized usability questionnaires available in American Sign Language (ASL) for these users. A critical concern in conducting such a translation is to ensure that the meaning of the original question items has been preserved during translation, as well as other key psychometric properties of the instrument, including internal reliability, criterion validity, and construct validity. After identifying best-practices for such a translation and evaluation project, a bilingual team of domain experts (including native ASL signers who are members of the Deaf community) translated the System Usability Scale (SUS) and Net Promoter Score (NPS) instruments into ASL and then conducted back-translation evaluations to assess the faithfulness of the translation. The new ASL instruments were employed in usability tests with DHH participants, to assemble a dataset of response scores, in support of the psychometric validation.We are disseminating these translated instruments, as well as collected response values from DHH participants, to encourage greater participation in HCI studies among DHH users. © 2019 Association for Computing Machinery.",American Sign Language; ASL-NPS; ASL-SUS; Construct validity; Criterion validity; Factor analysis; Internal reliability; Net promoter score; NPS; SUS; System usability scale; Translation,Audition; Factor analysis; Human computer interaction; Neptunium; Reliability analysis; Statistical tests; Surveys; Usability engineering; American sign language; ASL-SUS; Construct validity; Criterion validity; Internal reliabilities; Net promoter score; System usability; Translation (languages)
Tradeoffs in the efficient detection of sign language content in video sharing sites,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067232736&doi=10.1145%2f3325863&partnerID=40&md5=970037a99d7fd5280d824441559f735d,"Video sharing sites have become keepers of de-facto digital libraries of sign language content, being used to store videos including the experiences, knowledge, and opinions of many in the deaf or hard of hearing community. Due to limitations of term-based search over metadata, these videos can be difficult to find, reducing their value to the community. Another result is that community members frequently engage in a push-style delivery of content (e.g., emailing or posting links to videos for others in the sign language community) rather than having access be based on the information needs of community members. In prior work, we have shown the potential to detect sign language content using features derived from the video content rather than relying on metadata. Our prior technique was developed with a focus on accuracy of results and are quite computationally expensive, making it unrealistic to apply them on a corpus the size of YouTube or other large video sharing sites. Here, we describe and examine the performance of optimizations that reduce the cost of face detection and the length of video segments processed.We show that optimizations can reduce the computation time required by 96%, while losing only 1% in F1 score. Further, a keyframe-based approach is examined that removes the need to process continuous video. This approach achieves comparable recall but lower precision than the above techniques. Merging the advantages of the optimizations, we also present a staged classifier, where the keyframe approach is used to reduce the number of non-sign language videos fully processed. An analysis of the staged classifier shows a further reduction in average computation time per video while achieving similar quality of results. © 2019 Association for Computing Machinery.",ASL; Metadata extraction; Sign language; Video analysis; Video sharing,Audition; Digital libraries; Metadata; Quality control; Websites; Computation time; Efficient detection; Hard of hearings; Meta-data extractions; Quality of results; Sign language; Video analysis; Video sharing; Face recognition
Predicting the understandability of imperfect english captions for people who are deaf or hard of hearing,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067244060&doi=10.1145%2f3325862&partnerID=40&md5=42b7f53b4c6bbdbeb7d2b25da57e378b,"Automatic Speech Recognition (ASR) technology has seen major advancements in its accuracy and speed in recent years, making it a possiblemechanism for supporting communication between people who are Deaf or Hard-of-Hearing (DHH) and their hearing peers. However, state-of-the-art ASR technology is still imperfect in many realistic settings. Researchers who evaluate ASR performance often focus on improving the Word Error Rate (WER) metric, but it has been found to have little correlation with human-subject performance for many applications. This article describes and evaluates several new captioning-focused evaluation metrics for predicting the impact of ASR errors on the understandability of automatically generated captions for people who are DHH. Through experimental studies with DHH users, we have found that our new metric (based on word-importance and semantic-difference scoring) is more closely correlated with DHH user's judgements of caption quality-as compared to pre-existing metrics for ASR evaluation. © 2019 Association for Computing Machinery.",Accessibility for people who are deaf or hard-of-hearing; Automatic speech recognition; Caption understandability evaluation; Real-time captioning system,Audition; Quality control; Semantics; Speech communication; Automatic speech recognition; Automatically generated; English captions; Evaluation metrics; Hard of hearings; Real time; Semantic difference; Understandability; Speech recognition
Making emergency calls more accessible to older adults through a hands-free speech interface in the house,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067230101&doi=10.1145%2f3310132&partnerID=40&md5=60b8ac6d002de5d3644dd06337d0afbd,"Wearable personable emergency response (PER) systems are the mainstream solution for allowing frail and isolated individuals to call for help in an emergency. However, these devices are not well adapted to all users and are often not worn all the time, meaning they are not available when needed. This article presents a Voice User Interface system for emergency-call recognition. The interface is designed to permit hands-free interaction using natural language. Crucially, this allows a call for help to be registered without necessitating physical proximity to the system. The system is based on an ASR engine and is tested on a corpus collected to simulate realistic situations. The corpus contains French speech from 4 older adults and 13 younger people wearing an old-age simulator to hamper their mobility, vision, and hearing. On-line evaluation of the preliminary system showed an emergency-call error rate of 27%. Subsequent off-line experimentation improved the results (call error rate 24%), demonstrating that emergency-call recognition in the home is achievable. Another contribution of this work is the corpus, which is made available for research with the hope that it will facilitate related research and quicker development of robust methods for automatic emergency-call recognition in the home. © 2019 Association for Computing Machinery.",Ambient assisted living; Assistive technology; Emergency call; Specific voice recognition,Assisted living; Audition; User interfaces; Ambient assisted living; Assistive technology; Emergency calls; Emergency response; Hands-free interactions; On-line evaluation; Physical proximity; Voice user interface; Speech recognition
"Effects of extended use of an age-friendly computer system on assessments of computer proficiency, attitudes, and usability by older non-computer users",2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067254958&doi=10.1145%2f3325290&partnerID=40&md5=cd1969d429a7fd9ece56a6d535d9f64b,"This study examined the impact of use of a computer software application designed specifically for older people known as PRISM-a Personal Reminder Information and Social Management system-which was installed on a computer that was placed in the homes of adults aged 65 to 98 years, who were at risk for social isolation and had minimal or no computer skills and no computers in their homes. Participants received face-to-face training on the system in their homes over several days and a variety of measures were collected at baseline and at 12 months. A growth mixture model applied to participants' usage of the system over the course of 12 months revealed two distinct subpopulations of users-less-frequent users and more-frequent users- who after one year of exposure to the system differed in computer proficiency, attitudes toward computers, and ratings of system usability. These two groups did not differ on computer proficiency and computer attitude measures at baseline. The more-frequent user group, however, had significantly higher fluid cognitive abilities. Additional analytical models were used to further examine the relationships among the study measures. The implications of the findings are discussed in terms of the importance of usability for promoting initial engagement with a system and that increased engagement with the system can instill beliefs in these older adults that they can successfully transition to other computer-based technologies and applications. The results also underscore the importance of the user-centered design approach and designing highly usable systems for older adults with low technology proficiency. © 2019 Association for Computing Machinery.",Age-friendly design; Computer attitudes; Computer proficiency; Older adults; Usability,Application programs; Personal computers; Usability engineering; User centered design; Age-friendly; Computer attitude; Computer based technologies; Older adults; Social management; Software applications; Usability; User-centered design approaches; Information management
Effects of aging on small target selection with touch input,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062284821&doi=10.1145%2f3300178&partnerID=40&md5=feb91b83a9ac0a1bc5727904b86bf9ed,"Age-related declines in physical and cognitive function can result in target selection difficulties that hinder device operation. Previous studies have detailed the different types of target selection errors encountered, as well as how they vary with age and with input device for mouse and pen interaction. We extend this work to describe the types of age-related selection errors encountered with small touchscreen devices. Consistent with prior results, we found that older adults had longer target selection times, generated higher error rates, and encountered a broader range of selection difficulties (e.g., miss errors and slip errors) relative to a younger comparison group. However, in contrast to the patterns previously found with pen interaction, we found that miss error (i.e., both landing and lifting outside the target bounds) was a more common source of errors for older adults than slip error (i.e., landing on the target but slipping outside the target bounds before lifting). Moreover, aging influenced both miss and slip errors in our study of touch interaction, whereas for pen interaction, age has been found to influence only slip errors. These differences highlight the need to consider pen and touch interaction separately despite both being forms of direct input. Based on our findings, we discuss possible approaches for improving the accessibility of touch interaction for older adults. © 2019 Association for Computing Machinery.",Accessibility; Finger touch input; Mobile devices; Older adults; Target selection difficulties; Touchscreen technologies,Human computer interaction; Mobile computing; Accessibility; Cognitive functions; Device operations; Older adults; Pen interactions; Target selection; Touch inputs; Touch interaction; Errors
Design of a physiology-based adaptive virtual reality driving platform for individuals with ASD,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062267518&doi=10.1145%2f3301498&partnerID=40&md5=661ff17d1f878d5d4a51adeee9bee6da,"Driving is essential for many people in developed countries to achieve independence. Individuals with Autism Spectrum Disorder (ASD), in addition to having social skill deficits, may experience difficulty in learning to drive due to deficits in attention-shifting, performing sequential tasks, integrating visual-motor responses, and coordinating motor response. Lacking confidence and feeling anxiety further exacerbates these concerns. While there is a growing body of research regarding assessment of driving behavior or comparisons of driving behaviors between individuals with and without ASD, there is a lack of driving simulator that is catered toward the needs of individuals with ASD. We present the development of a novel closed-loop adaptive Virtual Reality (VR) driving simulator for individuals with ASD that can infer one's engagement based on his/her physiological responses and adapts driving task difficulty based on engagement level in real-time. We believe that this simulator will provide opportunities for learning driving skills in a safe and individualized environment to individuals with ASD and help them with independent living. We also conducted a small user study with teenagers with ASD to demonstrate the feasibility and tolerability of such a driving simulator. Preliminary results showed that the participants found the engagement-sensitive system more engaging and more enjoyable than a purely performance-sensitive system. These findings could support future work into driving simulator technologies, which could provide opportunities to practice driving skills in cost-effective, supportive, and safe environments. © 2019 Association for Computing Machinery.",Affective computing; ASD; Autism intervention; Driving; Dynamic difficulty adjustment (DDA); Physiological signal,Automobile simulators; Behavioral research; Cost effectiveness; Diseases; Human computer interaction; Physiology; Virtual reality; Affective Computing; Autism intervention; Autism spectrum disorders; Developed countries; Driving; Driving task difficulties; Physiological response; Physiological signals; Physiological models
The current status of accessibility in mobile apps,2019,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062303311&doi=10.1145%2f3300176&partnerID=40&md5=98555e550a2a02bc0f7177368080bc7e,"This study evaluated the status of accessibility in mobile apps by investigating the graphical user interface (GUI) structures and conformance to accessibility guidelines of 479 Android apps in 23 business categories from Google Play. An automated tool, IBM Mobile Accessibility Checker (MAC), was used to identify the accessibility issues, which were categorized as a violation (V), potential violation (PV), or warning (W). The results showed 94.8%, 97.5%, and 66.4% of apps studied contained issues related to V, PV, or W, respectively. Five widget categories (TextView, ImageView, View, Button, and ImageButton) were used to create 92% of the total number of the GUI elements and caused 89%, 78%, and 86% of V, PV, and W, respectively. These accessibility issues were mainly caused by lack of element focus, missing element description, low text color contrast, lack of sufficient spacing between elements, and less than minimum sizes of text fonts and elements. Together, these accessibility issues accounted for 97.0%, 77.8%, and 94.5% of V, PV, and W, respectively. This study proposed coverage measures to estimate the percentage of accessibility issues identified by an automated tool. The result showed that MAC, on average, identified about 67% of accessibility issues in mobile apps. Two new accessibility conformance measures were proposed in this study: inaccessible element rate (IAER) and accessibility issue rate (AIR). IAER estimates the percentage of GUI elements that are inaccessible. AIR calculates the percentage of the actual number of accessibility issues relative to the maximum number of accessibility issues. Average IAER and AIR scores were 27.3%, 19.9%, 6.3% and 20.7%, 15.0%, 5.4% for V, PV, and W, respectively, for the studied apps. The IAER score showed approximately 30% of the GUI elements had accessibility issues, and the AIR score indicated that 15% of the accessibility issues remained and need to be fixed to make the apps accessible. © 2019 Association for Computing Machinery.",Accessibility; Accessibility evaluation; Disability; Graphical user interface (GUI); Mobile; Mobile apps; Usability,Computer applications; Human computer interaction; Accessibility; Accessibility evaluation; Disability; Graphical user interfaces (GUI); Mobile; Mobile apps; Usability; Graphical user interfaces
Towards Devising a Low-cost and Easy-to-use Arithmetic Learning Framework for Economically Less-privileged Visually Impaired Children,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057204793&doi=10.1145%2f3265756&partnerID=40&md5=ecd7cd5274aa39a4a0824b8ec17a66a0,"Basic arithmetic operations are essential skills needed in our life, and this is no different for the visually impaired. However, working arithmetic out on paper is always a challenge for visually impaired people. This situation is exacerbated by low-resource settings due to a paucity of low-cost and easy-to-use solutions. As a remedy to this situation, we propose a low-cost and easy-to-use arithmetic learning framework and draw a contrast between the conventional means of solving arithmetic problems and our proposed framework. Our proposal is engendered from comprehensive studies, both qualitative and quantitative, over the challenges faced by visually impaired children from two low-income countries. These studies are conducted in three phases'exploratory, descriptive, and explanatory'involving six visually impaired children and sixteen visually impaired grownups. User evaluation of our framework, in disguise of a tutorial session, confirms its acceptability and adaptability, along with its effectiveness in evoking interest in arithmetic. We believe that our study and proposed framework will help in breaking barriers to similar challenges in other developing regions across the border. © 2018 Association for Computing Machinery.",Arithmetic learning; Economically less-privileged children; Low-resource settings; Visual-impairment,Computer applications; Human computer interaction; Arithmetic operations; Economically less-privileged children; Learning frameworks; Low income countries; Low-resource settings; Visual impairment; Visually impaired children; Visually impaired people; Costs
Project Star Catcher: A novel immersive virtual reality experience for upper limb rehabilitation,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057150161&doi=10.1145%2f3265755&partnerID=40&md5=769fff316b00e646b5da8f23db485504,"Modern immersive virtual reality experiences have the unique potential to motivate patients undergoing physical therapy for performing intensive repetitive task-based treatment and can be utilized to collect real-time user data to track adherence and compliance rates. This article reports the design and evaluation of an immersive virtual reality game using the HTC Vive for upper limb rehabilitation, titled “Project Star Catcher” (PSC), aimed at users with hemiparesis. The game mechanics were adapted from modified Constraint Induced Therapy (mCIT), an established therapy method where users are asked to use the weaker arm by physically binding the stronger arm. Our adaptation changes the physical to psychological binding by providing various types of immersive stimulation to influence the use of the weaker arm. PSC was evaluated by users with combined developmental and physical impairments as well as stroke survivors. The results suggest that we were successful in providing a motivating experience for performing mCIT as well as a cost-effective solution for real-time data capture during therapy. We conclude the article with a set of considerations for immersive virtual reality therapy game design. © 2018 Copyright is held by the owner/author(s).",Constraint-induced therapy; Disability; HTC Vive; Rehabilitation; Serious games; Stroke; Therapy; Virtual reality,Cost effectiveness; Patient rehabilitation; Patient treatment; Serious games; Stars; Virtual reality; Constraint-induced therapy; Disability; HTC Vive; Stroke; Therapy; Neuromuscular rehabilitation
Design of a haptic-gripper virtual reality system (HG) for analyzing fine motor behaviors in children with autism,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057194924&doi=10.1145%2f3231938&partnerID=40&md5=518347915422c1fa1b003f207c38719f,"Fine motor skills, including grasping, manipulating, and reaching for objects, are a documented weakness for many children with Autism Spectrum Disorders (ASD). However, relatively less research has attempted to address these motor deficits, especially by taking advantage of advanced technology. To explore potential mechanisms for expanding accessibility to fine motor intervention for people with ASD, we present the design and implementation of a feasibility study of a novel Haptic-Gripper Virtual Reality System (Hg). Hg is capable of providing analysis and practice opportunities of fine motor skills in an adaptive and low-cost virtual environment with real-time auditory, visual, and haptic feedback. The Haptic Gripper in Hg can detect a user's grip force and hand location and provide haptic feedback to guide hand movement and grip control while completing several simple and engaging virtual fine motor tasks. We conducted a feasibility study with six children with ASD and six typically developing (TD) children and found that participants were interested in using the Haptic Gripper and could quickly get used to the system. Although the results are preliminary and limited, we observed medium to strong correlations between the proposed fine motor skill metrics and the scores achieved with a standardized fine motor skill test and improvements of participants in accuracy and steadiness of movement and force control. This study provides important guidance for future investigations of the Hg's potential for assessing and improving fine motor manipulation skills. © 2018 Association for Computing Machinery.",Autism; Fine motor skills; Force-sensitive gripper; Haptic interaction; Virtual tasks,Diseases; Feedback; Planning; Virtual reality; Autism; Children with autisms; Design and implementations; Feasibility studies; Fine motors; Haptic interactions; Virtual reality system; Virtual tasks; Grippers
Effects of virtual reality properties on user experience of individuals with autism,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057152264&doi=10.1145%2f3267340&partnerID=40&md5=7efba11c137b60b85eb0bd9a15a23983,"In recent years, virtual reality (VR) has been become a popular training tool for individuals with Autism Spectrum Disorder (ASD). Although VR was proven to be a promising tool for individuals with ASD, effects of VR properties or attributes of user interfaces designed for VR on user experience is still an unexplored area. In this study, we explore effects of five attributes of user interfaces designed for VR on user experience of high-functioning individuals with Autism Spectrum Disorder (HFASD): instruction methods, visual fidelity, view zoom, clutter, and motion. Our motivation is to give positive contribution to the design of future VR training applications for individuals with ASD so that more benefits can be gained. Three VR experiences were designed and implemented, and a user study was performed with 15 high-functioning individuals with ASD and 15 neurotypical individuals as the control group. Results indicated that using animated instructions and avoiding verbal instructions, using low visual fidelity and normal view zoom, and using no clutter and no motion in VR warehouse training applications targeting individuals with HFASD are good design practices. © 2018 Association for Computing Machinery.",Autism spectrum disorder; Training; User experience; User interface attributes; Virtual reality; Warehouse tasks,Clutter (information theory); Diseases; Personnel training; Virtual reality; Warehouses; Autism spectrum disorders; Control groups; Instruction methods; Training applications; Training tools; User experience; Verbal instructions; Visual fidelity; User interfaces
Extraction of emotional information via visual scanning patterns: A feasibility study of participants with schizophrenia and neurotypical individuals,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057177614&doi=10.1145%2f3282434&partnerID=40&md5=5db30b03366750c150ccbc1864e1fa90,"Emotion recognition impairment is a core feature of schizophrenia (SZ), present throughout all stages of this condition, and leads to poor social outcome. However, the underlying mechanisms that give rise to such deficits have not been elucidated and hence, it has been difficult to develop precisely targeted interventions. Evidence supports the use of methods designed to modify patterns of visual attention in individuals with SZ in order to effect meaningful improvements in social cognition. To date, however, attention-shaping systems have not fully utilized available technology (e.g., eye tracking) to achieve this goal. The current work consisted of the design and feasibility testing of a novel gaze-sensitive social skills intervention system called MASI-VR. Adults from an outpatient clinic with confirmed SZ diagnosis (n = 10) and a comparison sample of neurotypical participants (n = 10) were evaluated on measures of emotion recognition and visual attention at baseline assessment, and a pilot test of the intervention system was evaluated on the SZ sample following five training sessions over three weeks. Consistent with the literature, participants in the SZ group demonstrated lower recognition of faces showing medium intensity fear, spent more time deliberating about presented emotions, and had fewer fixations in comparison to neurotypical peers. Furthermore, participants in the SZ group showed significant improvement in the recognition of fearful faces post-training. Preliminary evidence supports the feasibility of a gaze-sensitive paradigm for use in assessment and training of emotion recognition and social attention in individuals with SZ, thus warranting further evaluation of the novel intervention. © 2018 Association for Computing Machinery.",,Behavioral research; Diseases; Speech recognition; Baseline assessment; Emotion recognition; Emotional information; Feasibility studies; Feasibility testing; Outpatient clinic; Training sessions; Visual Attention; Eye tracking
"""wear It Loud"": How and why hearing aid and cochlear implant users customize their devices",2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061202733&doi=10.1145%2f3214382&partnerID=40&md5=c586bd8bef67feb776cf1653bda0b25c,"We investigate the role of aesthetic customization in managing sociocultural issues of assistive technology (AT) use. First, we examined an online forum dedicated to customized hearing AIDS and cochlear implants to understand the breadth of activity occurring in this space. Next, we conducted a series of interviews to understand motivational factors and sociocultural outcomes related to expressive AT. We found that community members discussed customization tools and techniques, shared their customizations, and provided each other with encouragement and support. Community members customized their devices as a means of self-expression that demonstrated the wearer's fashion sense, revealed favorite sports teams and characters, and marked holidays and personal milestones. We also found that aesthetic customization worked on multiple levels to create personal and meaningful relationships with one's AT and with other AT users, and also to manage societal expectations regarding hearing loss. Our findings may inform the design of assistive technologies that better support personalization, customization, and self-expression. © 2018 Association for Computing Machinery.",cochlear implants; deafness; Do-It-yourself assistive technology; hearing AIDS; online communities; social acceptability,Cochlear implants; Hearing aids; Social networking (online); Assistive technology; Cochlear implant users; deafness; On-line communities; Personalizations; Social acceptability; Societal expectations; Tools and techniques; Audition
Autonomous selection and printing of 3D models for people who are blind,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053907054&doi=10.1145%2f3241066&partnerID=40&md5=4ae599db5ef7b8ec60d103c4d83143f7,"3D models are an important means for understanding spatial contexts. Today these models can be materialized by 3D printing, which is increasingly used at schools for people with visual impairments. In contrast to sighted people, people with visual impairments have so far, however, neither been able to search nor to print 3D models without assistance. This article describes our work to develop an aid for people with visual impairments that would facilitate autonomous searching for and printing of 3D models. In our initial study, we determined the requirements to accomplish this task by means of a questionnaire and developed a first approach that allowed personal computer-based 3D printing. An extended approach allowed searching and printing using common smartphones. In our architecture, technical details of 3D printers are abstracted by a separate component that can be accessed via Wi-Fi independently of the actual 3D printer used. It comprises a search of the models in an annotated database and 3D model retrieval from the internet. The whole process can be controlled by voice interaction. The feasibility of autonomous 3D printing for people with visual impairments is shown with a first user study. Our second user study examines the usability of the user interface when searching for 3D models on the internet and preparing them for the materialization. The participants were able to define important printing settings, whereas other printing parameters could be determined algorithmically. © 2018 Association for Computing Machinery.",3D models; 3D printing; Accessibility; Autonomous; Blind; Exploration; Graphics; Hardware abstraction; Independent; Internet; Print server; Retrieval; Self-reliant; Tactile; Tangible; User study; Visually impaired,Abstracting; Internet; Natural resources exploration; Personal computers; Printing presses; Self organizing maps; User interfaces; 3-D printing; 3D models; Accessibility; Autonomous; Blind; Graphics; Hardware abstractions; Independent; Print server; Retrieval; Self-reliant; Tactile; Tangible; User study; Visually impaired; 3D printers
"“I knew that, I was just testing you”: Understanding Older Adults’ Impression management tactics during usability studies",2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053928612&doi=10.1145%2f3226115&partnerID=40&md5=64bcd7ceaa3db6a0d11bdb4eadbf2bd4,"Research has shown that participants often engage in impression management (IM) to present themselves in a favorable way, out of desire to increase self-esteem or enhance how others perceive them. This tendency has also been shown to affect the validity and reliability of studies. Yet, little is known about how older adults’ IM efforts influence the process of usability studies, even though the literature suggests that individuals perform more IM as they age, possibly to avoid negative stereotypes of ageing. Through a mixed-methods approach, we conducted two exploratory usability studies with older adults (65+). We found that participants performed a range of IM tactics including supplication (i.e., portraying oneself as weak or dependent to obtain help) and exemplification (i.e., doing more than is necessary). We discuss how IM tactics influence the study and define strategies to manage them. © 2018 Association for Computing Machinery.",Impression management; Older adults; Usability evaluation,Computer applications; Human computer interaction; Impression management; Mixed method; Older adults; Self esteem; Usability evaluation; Usability studies; Usability engineering
Feedback and guidance to support children with intellectual disabilities in discovery learning with a tangible interactive tabletop,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053889128&doi=10.1145%2f3226114&partnerID=40&md5=3e88c736883cb388dc6313ce621dde8e,"By coupling dynamic digital representations to physical objects, tangible environments expand the possibilities for providing scaffolding in discovery learning processes. This is particularly promising in the case of children with intellectual disabilities, for whom the typical lack of structure of discovery-based activities is challenging. In this research, empirical studies were undertaken where children with intellectual disabilities engaged in a process of discovery using a tangible interactive tabletop, which provided a substantial amount of feedback. Two conditions of human mediation (free and guided exploration) were compared, to identify which one enabled more opportunities for discovery, in combination with design aspects of system feedback. Episodes of discovery were found to be much more frequent than episodes of disruption in both conditions, confirming the potential of tangible tabletops, in particular the importance of informational system feedback to learners' exploratory actions. Nevertheless, human mediation is still needed for children with intellectual disabilities despite the feedback capabilities of tangible environments. Although children explored more in free sessions (in terms of amount of exploratory actions), guided exploration produced more episodes of discovery, reinforcing the importance of external guidance for increasing the attention to learning concepts. © 2018 Association for Computing Machinery.",Children; Discovery learning; Feedback; Intellectual disabilities; Scaffolding; Tangible environments,Feedback; Scaffolds; Children; Discovery learning; Intellectual disability; Scaffolding; Tangible environments; Interactive devices
Emotionally oriented analysis of the experiences of visually impaired people on facebook,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061192061&doi=10.1145%2f3230739&partnerID=40&md5=2724c1c4079d666fe677f93089130a33,"With technological advancements, there has been a vast increase in the number of companies that fight over their market share. In search of a differentiating factor, companies are investing more and more in their products' emotional designs. This researched work has evaluated the affects that are caused in visually impaired people when using Facebook's features and then compared them with the experiences of sighted users. To do that, these two types of Facebook users were subjected to a questionnaire that was based on the PANAS affect scale. Once the information was collected, statistics were employed so as to evaluate both users' feelings. The results have shown that there were significant statistical differences between the sighted and the visually impaired users when the ""affects"" were evaluated by using the PANAS tool. The five ""negative affects"" that were selected (Irritability, Uselessness, Frustration, Sadness, and Confusion) were largely more relevant for the blind people in most of the evaluated features. This has indicated some serious accessibility problems. However, a high frequency of the five ""positive affects"" that were considered (Satisfaction, Pleasantness, Surprise, Excitement, Interest, and Determination) were additionally observed for both of these two groups. These results were interpreted as feelings of both social inclusion and social exclusion, indicating the possibility of exploring technological devices that were unavailable not long ago. After analyzing their experiences in their usage of the Facebook features, the findings have also highlighted the many differing emotions that are felt by the visually impaired and the sighted users. The resulting outcomes have indicated that there are some issues that are still open to problems and difficulties. Moreover, these issues involve human-computer interactions. Nevertheless, fortunately, there is light at the end of the tunnel, as will be revealed. © 2018 Association for Computing Machinery.",Accessibility; blind; Facebook; negative affect; positive affect; user experiences; visually impaired,Competition; Human computer interaction; Accessibility; blind; Facebook; Negative affects; Positive affects; User experience; Visually impaired; Social networking (online)
A collaborative system for suitable wheelchair route planning,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054009579&doi=10.1145%2f3237186&partnerID=40&md5=a8dcb254b257f825774d7e0d6e288338,"Route planning is a challenging problem for urban computing that usually involves the processing of a huge amount of data and collaborative user feedback. Traditionally, route planning services are street-based, that is, even paths for a pedestrian are suggested in terms of streets. However, such models are not suitable for users with certain disabilities. To address this problem, we have performed a requirement analysis with a group of wheelchair-users and their companions to understand their urban mobility experience. Given that perspective, we describe in this article a sidewalk-based model to accommodate the needs for a wheelchair route planning service. The model is mathematically defined as a graph, where the vertices are the city block corners and the edges are the sidewalks or crosswalks. The edge costs are derived from important accessibility features, such as distance, path inclination, and existence and maintenance conditions of curb ramps, crosswalks, and sidewalks. The model has been designed so that user feedback is considered to help updating the model when accessibility issues are detected, by wheelchair-users and companions, or solved, by the department of city planning. We also present a route planning algorithm that provides a set of alternative routes based on accessibility conditions, and a shortcut recommender algorithm to support accessibility-related decision making by the department of city planning. Experiments, by using PgRouting and PostGIS with open data, are reported for a Brazilian city neighborhood to validate the model and the route planning service. © 2018 Association for Computing Machinery.",Accessible shortest path; Geographic information systems; Shortcut recommendation; Sidewalk-based route planning; User collaboration,Crosswalks; Decision making; Geographic information systems; Pavements; Planning; Wheelchairs; Collaborative systems; Collaborative users; Recommender algorithms; Requirement analysis; Route planning; Shortcut recommendation; Shortest path; User collaborations; Graph theory
Introduction to the special issue on fabrication technologies and do-it-yourself accessibility,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052563951&doi=10.1145%2f3242162&partnerID=40&md5=df5186ec83dbed6afc9631fa15d7de96,[No abstract available],,
Designing gesture-based applications for individuals with developmental disabilities: Guidelines from user studies in India,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043779792&doi=10.1145%2f3161710&partnerID=40&md5=e260398ffb550ebe218a6e29bb7b2a79,"Gesture interaction provides a multitude of benefits to individuals with developmental disabilities, from enhancing social, motor and cognitive skills to providing a safe and controlled environment for simulating real-world scenarios. As gesture-based applications gain ground in the special education domain, we study their potential in the Indian context. Together with Tamana, an NGO in New Delhi, we have been conducting a series of exploratory user studies since October 2013. This includes the design and evaluation of three gesture-based applications to impart social and life skills to individuals with developmental disabilities. The Kirana application employs socially appropriate gestures to teach the life skill of buying day-to-day items from a local Indian grocery. Balloons promotes joint attention skills through collaborative interaction. HOPE improves motor coordination and social and cognitive skills, with increasing levels of difficulty. Based on studies with these applications, this article presents guidelines for designing gesture-based applications for individuals with developmental disabilities. The guidelines focus on (a) designing applications that cater to a larger group of individuals to encourage collaboration and inclusion, for instance, providing easy and controllable transitions between different task levels, and balancing interaction and content complexity; (b) addressing the challenges in conducting research in this domain, with respect to ethical and procedural decisions; and (c) designing for Technology acceptance within the Indian context, for example, by following a collaborative and stakeholder inclusive approach, and addressing apprehensions towards Technology adoption. These guidelines aim to benefit other practitioners working in this domain and especially in the educational Technology context of India. © 2018 ACM.",Design for all; Gesture interaction design; HCI; Individuals with developmental disabilities,Computer applications; Collaborative interaction; Controlled environment; Design and evaluations; Design for all; Developmental disability; Gesture interaction; Technology acceptance; Technology adoption; Human computer interaction
Tenets for social accessibility: Towards humanizing disabled people in design,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043788547&doi=10.1145%2f3178855&partnerID=40&md5=e2dae9ef625e92dff32b6f4098878005,"Despite years of addressing disability in Technology design and advocating user-centered design practices, popular mainstream Technologies remain largely inaccessible for people with disabilities. We conducted a design course study investigating how student designers regard disability and explored how designing for multiple disabled and nondisabled users encouraged students to think about accessibility in the design process. Across two university course offerings one year apart, we examined how students focused on a design project while learning user-centered design concepts and techniques, working with people with and without disabilities throughout the project. In addition, we compared how students incorporated disability-focused design approaches within a classroom setting. We found that designing for multiple stakeholders with and without disabilities expanded student understanding of accessible design by demonstrating that people with the same disability could have diverse needs and by aligning such needs with those of nondisabled users. We also found that using approaches targeted toward designing for people with disabilities complemented interactions with users, particularly with regard to managing varying abilities across users, or incorporating social aspects. Our findings contribute to an understanding about how we might incur change in design practice by working with multiple stakeholders with and without disabilities whenever possible. We refined Design for Social Accessibility by incorporating these findings into three tenets emphasizing: (1) design for disability ought to incorporate users with and without disabilities, (2) design should address functional and social factors simultaneously, and (3) design should include tools to spur consideration of social factors in accessible design. © 2018 ACM.",Design for social accessibility,Curricula; Economic and social effects; Social aspects; Students; Teaching; Classroom settings; Design approaches; Design practice; Disabled people; Multiple stakeholders; People with disabilities; Technology designs; University course; User centered design
Introduction to the ASSETS'16 special issue,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043774184&doi=10.1145%2f3183374&partnerID=40&md5=1eb319ca9ceb3d2f9b723112431dbb3a,[No abstract available],,
WeAllWalk: An Annotated Dataset of Inertial Sensor Time Series from BlindWalkers,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097872093&doi=10.1145%2f3161711&partnerID=40&md5=bf979b41a00747fa2794969afcde5478,"We introduce WeAllWalk, a dataset of inertial sensor time series collected from blind and sighted walkers using a long cane or a guide dog. Ten blind volunteers (seven using a long cane, one using a guide dog, and two alternating use of a long cane and of a guide dog) as well as five sighted volunteers contributed to the data collection. The participants walked through fairly long and complex indoor routes that included obstacles to be avoided and doors to be opened. Inertial data were recorded by two iPhone 6s carried by our participants in their pockets and carefully annotated. Ground-Truth heel strike times were measured by two small inertial sensor units clipped to the participants' shoes. We also present an in-depth comparative analysis of various step counting and turn detection algorithms as tested on WeAllWalk. This analysis reveals interesting differences between the achievable accuracy of step and turn detection across different communities of sighted and blind walkers.  © 2018 ACM.",Inertial sensing; step counting; turn detection; wayfinding,Time series; Comparative analysis; Data collection; Detection algorithm; Ground truth; Heel strikes; Inertial sensor; Step counting; Inertial navigation systems
Pictures in your mind: Using interactive gesture-controlled reliefs to explore art,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049787398&doi=10.1145%2f3155286&partnerID=40&md5=cd2eec230d4a6fc12da16a22c5159f01,"Tactile reliefs offer many benefits over the more classic raised line drawings or tactile diagrams, as depth, 3D shape, and surface textures are directly perceivable. Although often created for blind and visually impaired (BVI) people, a wider range of people may benefit from such multimodal material. However, some reliefs are still difficult to understand without proper guidance or accompanying verbal descriptions, hindering autonomous exploration. In this work, we present a gesture-controlled interactive audio guide (IAG) based on recent low-cost depth cameras that can be operated directly with the hands on relief surfaces during tactile exploration. The interactively explorable, location-dependent verbal and captioned descriptions promise rapid tactile accessibility to 2.5D spatial information in a home or education setting, to online resources, or as a kiosk installation at public places. We present aworking prototype, discuss design decisions, and present the results of two evaluation studies: the first with 13 BVI test users and the second follow-up study with 14 test users across a wide range of people with differences and difficulties associated with perception, memory, cognition, and communication. The participant-led research method of this latter study prompted new, significant and innovative developments. 2018 Copyright is held by the owner/author(s). © 2018 Association for Computing Machinery. All Rights Reserved.",Auditory interface; Blind; Cognitive disability; Design for all; Gestures; Learning disability; Low vision; Multimodal interaction,Computer applications; Human computer interaction; Auditory interfaces; Blind; Cognitive disability; Design for all; Gestures; Learning disabilities; Low vision; Multi-Modal Interactions; Textures
Insights on assistive orientation and mobility of people with visual impairment based on large-scale longitudinal data,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043773391&doi=10.1145%2f3178853&partnerID=40&md5=481f9183141e4ee74bd9a8c1e8555ec3,"Assistive applications for orientation and mobility promote independence for people with visual impairment (PVI). While typical design and evaluation of such applications involves small-sample iterative studies, we analyze large-scale longitudinal data from a geographically diverse population. Our publicly released dataset from iMove, a mobile app supporting orientation of PVI, contains millions of interactions by thousands of users over a year. Our analysis (i) examines common functionalities, settings, assistive features, and movement modalities in iMove dataset and (ii) discovers user communities based on interaction patterns. We find that the most popular interaction mode is passive, where users receive more notifications, often verbose, while in motion and perform fewer actions. The use of built-in assistive features such as enlarged text indicate a high presence of users with residual sight. Users fall into three distinct groups: (C1) users interested in surrounding points of interest, (C2) users interacting in short bursts to inquire about current location, and (C3) users with long active sessions while in motion. iMove was designed with C3 in mind, and one strength of our contribution is providing meaningful semantics for unanticipated groups, C1 and C2. Our analysis reveals insights that can be generalized to other assistive orientation and mobility applications. © 2018 ACM.",Behavior analysis; Clustering; Navigation; Orientation; People with visual impairment,Crystal orientation; Navigation; Population statistics; Semantics; Assistive applications; Behavior analysis; Clustering; Interaction modes; Interaction pattern; Longitudinal data; Points of interest; Visual impairment; Ophthalmology
Drop-down menuwidget identification using HTML structure changes classification,2018,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057884179&doi=10.1145%2f3178854&partnerID=40&md5=0aae65e3a2b8d3319a608a163d96cb6e,"Widgets have been deployed in rich internet applications for more than 10 years. However, many of the widgets currently available on the web do not implement current accessibility design solutions standardized in ARIA (Accessible Rich Internet Applications) specification, hence are not accessible to disabled users. This article sets out an approach for automatically identifying widgets on the basis of machine-learning algorithms and the classification of mutation records; it is an HTML5 technology that logs all changes that occur in the structure of a web application. Automatic widget identification is an essential component for the elaboration of automatic ARIA evaluation and adaptation strategies. Thus, the aim of this article is to take steps toward easing the software-engineering process of ARIA widgets. The proposed approach focuses on the identification of drop-down menu widgets. An experiment with real-world web applications was conducted and the results showed evidence that this approach is capable of identifying these widgets and can outperform previous state-of-the-art techniques based on an F-measure analysis conducted during the experiment. © 2018 ACM.",Aria; Automatic identification of widgets; Drop-down menu widget; Fly-out menus; Web accessibility; Widgets,Automation; HTML; Learning algorithms; Learning systems; Software engineering; Web services; Aria; Automatic identification; Fly-out menus; Web accessibility; Widgets; Drops
"Experiencing EVA Park, a multi-user virtual world for people with aphasia",2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032887482&doi=10.1145%2f3134227&partnerID=40&md5=aacc788c9561f7ae94b7d6eb04fabdae,"Virtual worlds are used in wide-ranging ways by many people with long-term health conditions, but their use by people with aphasia (PWA) has been limited. In contrast, this article reports the use of EVA Park, a multi-user virtual world designed for PWA to practice conversations, focusing on people's emotional, social, and conversational experiences. An analysis of observation and interview data collected from 20 people with aphasia who participated in a 5-week therapy intervention revealed key themes related to user experience. The themes offer a rich insight into aspects of the virtual world experience for PWA that go beyond therapeutic outcomes. They are as follows: affect (positive and negative); types of conversation, miscommunication, and misunderstanding; immersion in the virtual world; social presence and initiative and flow. Overall, the study showed that participants experienced positive emotional and social outcomes. We argue that this was achieved as a consequence of EVA Park being not only accessible but also a varied and entertaining environment within which PWA experienced both the realistic and the quirky while engaging with others and having fun.",Accessibility; Aphasia; Field evaluation; Virtual worlds,Virtual reality; Accessibility; Aphasia; Field evaluation; Health condition; Social outcomes; Social presence; Therapeutic outcomes; Virtual worlds; Interactive computer graphics
(In)visibility in disability and assistive technology,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032945409&doi=10.1145%2f3132040&partnerID=40&md5=a6a49ad7893a8cd419800eedd25cc482,"In this article, we present a meta-analysis of research examining visibility of disability. In interrogating the issue of visibility and invisibility in the design of assistive technologies, we open a discussion about how perceptions surrounding disability can be probed through an examination of visibility and how these tensions do, and perhaps should, influence assistive technology design and research. © 2017 ACM.",Assistive technology design; Assistive technology evaluation; Hidden disability; Identity; Invisible disability; Social interactions; Stigma,Computer applications; Human computer interaction; Assistive technology; Hidden disability; Identity; Invisible disability; Social interactions; Stigma; Visibility
"""Hands on"" visual recognition for visually impaired users",2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028569680&doi=10.1145%2f3060056&partnerID=40&md5=98908668ae8ffd90d75737a8b4b281ed,"Blind or visually impaired (BVI) individuals are capable of identifying an object in their hands by combining the available visual cues (if available) with manipulation. It is harder for them to associate the object with a specific brand, a model, or a type. Starting from this observation, we propose a collaborative system designed to deliver visual feedback automatically and to help the user filling this semantic gap. Our visual recognition module is implemented by means of an image retrieval procedure that provides real-time feedback, performs the computation locally on the device, and is scalable to newcategories and instances.We carry out a thorough experimental analysis of the visual recognition module, which includes a comparative analysis with the state of the art. We also present two different system implementations that we test with the help of BVI users to evaluate the technical soundness, the usability, and the effectiveness of the proposed concept. © 2017 ACM.",Single-instance object recognition; Systems for visually impaired users,Object recognition; Visual communication; Collaborative systems; Comparative analysis; Experimental analysis; Real-time feedback; Retrieval procedures; System implementation; Visual recognition; Visually-impaired users; Semantics
Fast human-computer interaction by combining gaze pointing and Face gestures,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028566856&doi=10.1145%2f3075301&partnerID=40&md5=9c2ac16cd789957d10118853883c15ad,"In this work, we show how our open source accessibility software, the FaceSwitch, can help motor-impaired subjects to efficiently interact with a computer hands-free. The FaceSwitch enhances gaze interaction with video-based face gestures interaction. The emerging multimodal system allows for interaction with a user interface by means of gaze pointing for target selection and facial gestures for target-specific action commands. The FaceSwitch maps facial gestures to specific mouse or keyboard events such as: left mouse click, right mouse click, or page scroll down. Hence, facial gestures serve the purpose of mechanical switches.With this multimodal interaction paradigm, the user gazes at the object in the user interface with which it wants to interact and then triggers a target-specific action by performing a face gesture. Through a rigorous user study, we have obtained quantitative evidence that suggests our proposed interaction paradigm improves the performance of traditional accessibility options, such as gaze-only interaction or gaze with a single mechanical switch interaction while coming close in terms of speed and accuracy with traditional mouse-based interaction.Wemake the FaceSwitch software freely available to the community so the output of our research can help the target audience. © 2017 ACM.",Accessibility; Accessible computing; Assistive technologies; Face tracking; Gaze interaction; Human factors; Human factors and ergonomics; Human performance; Human-computer interaction,Ergonomics; Human engineering; Mammals; Open source software; Open systems; Transportation; User interfaces; Accessibility; Accessible computing; Assistive technology; Face Tracking; Gaze interaction; Human factors and ergonomics; Human performance; Human computer interaction
The Tangible Desktop: A multimodal approach to nonvisual computing,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028573248&doi=10.1145%2f3075222&partnerID=40&md5=5769b29e7441fa1a9c866424dae36fd5,"Audio-only interfaces, facilitated through text-to-speech screen reading software, have been the primary mode of computer interaction for blind and low-vision computer users for more than four decades. During this time, the advances that have made visual interfaces faster and easier to use, from direct manipulation to skeuomorphic design, have not been paralleled in nonvisual computing environments. The screen reader-dependent community is left with no alternatives to engage with our rapidly advancing technological infrastructure. In this article, we describe our efforts to understand the problems that exist with audio-only interfaces. Based on observing screen reader use for 4 months at a computer training school for blind and low-vision adults, we identify three problem areas within audio-only interfaces: ephemerality, linear interaction, and unidirectional communication. We then evaluated a multimodal approach to computer interaction called the Tangible Desktop that addresses these problems by moving semantic information from the auditory to the tactile channel. Our evaluation demonstrated that among novice screen reader users, Tangible Desktop improved task completion times by an average of 6 minutes when compared to traditional audio-only computer systems. © 2017 ACM.",Accessibility; Assistive technology; Blindness; Haptic; Hardware; Tangible; Vibrotactile feedback; Visual impairment,Computer hardware; Semantics; Accessibility; Assistive technology; Blindness; Haptic; Tangible; Vibro-tactile feedbacks; Visual impairment; Audio systems
Evaluation of language feedback methods for student videos of American Sign Language,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017554828&doi=10.1145%2f3046788&partnerID=40&md5=adc0b6457b1cd451037455a956546aae,"This research investigates how to best present video-based feedback information to students learning American Sign Language (ASL); these results are relevant not only for the design of a software tool for providing automatic feedback to students but also in the context of how ASL instructors could convey feedback on students' submitted work. It is known that deaf children benefit from early exposure to language, and higher levels of written language literacy have been measured in deaf adults who were raised in homes using ASL. In addition, prior work has established that new parents of deaf children benefit from technologies to support learning ASL. As part of a long-term project to design a tool to automatically analyze a video of a students' signing and provide immediate feedback about fluent and non-fluent aspects of their movements, we conducted a study to compare multiple methods of conveying feedback to ASL students, using videos of their signing. Through two user studies, with a Wizard-of-Oz design, we compared multiple types of feedback in regard to users' subjective judgments of system quality and the degree students' signing improved (as judged by an ASL instructor who analyzed recordings of students' signing before and after they viewed each type of feedback). The initial study revealed that displaying videos to students of their signing, augmented with feedback messages about their errors or correct ASL usage, yielded higher subjective scores and greater signing improvement. Students gave higher subjective scores to a version in which time-synchronized pop-up messages appeared overlaid on the student's video to indicate errors or correct ASL usage. In a subsequent study, we found that providing images of correct ASL face and hand movements when providing feedback yielded even higher subjective evaluation scores from ASL students using the system. © 2017 ACM.",American sign language; Education; Feedback; User study,Feedback; Students; American sign language; Automatic feedback; Feed back information; Feedback messages; Immediate feedbacks; Long-term projects; Subjective evaluations; User study; Education
Vocational rehabilitation of individuals with autism spectrum disorder with virtual reality,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017614804&doi=10.1145%2f3046786&partnerID=40&md5=66a12b5047a62bf06b3bab93c1fbc02e,"In this article, a virtual reality system for vocational rehabilitation of individuals with disabilities (VR4VR) is presented. VR4VR uses immersive virtual environments to assess and train individuals with cognitive and physical disabilities. This article focuses on the system modules that were designed and developed for the Autism Spectrum Disorder (ASD) population. The system offers training on six vocational skills that were identified as transferrable to and useful in many common jobs. These six transferable skills are cleaning, loading the back of a truck, money management, shelving, environmental awareness, and social skills. This article presents the VR4VR system, the design considerations for the ASD population, and the findings with a cohort of nine neurotypical individuals (control group) and nine high-functioning individuals with ASD (experiment group) who used the system. Good design practices gathered throughout the study are also shared for future virtual reality applications targeting individuals with ASD. Research questions focused on the effectiveness of the virtual reality system on vocational training of high-functioning individuals with ASD and the effect of distracters on task performance of high-functioning individuals with ASD. Follow-up survey results indicated that for individuals with ASD, there was improvement in all of the trained skills. No negative effects of the distracters were observed on the score of individuals with ASD. The proposed VR4VR system was found by professional job trainers to provide effective vocational training for individuals with ASD. The system turned out to be promising in terms of providing an alternative practical training tool for individuals with ASD. © 2017 ACM.",Autism spectrum disorder; Virtual reality; Vocational rehabilitation,Diseases; Occupational therapy; Patient rehabilitation; Surveys; Autism spectrum disorders; Design considerations; Environmental awareness; Immersive virtual environments; Physical disability; Virtual reality system; Vocational rehabilitation; Vocational training; Virtual reality
"Introduction to the ASSETS'15 special issue, Part 2",2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018501067&doi=10.1145%2f3051486&partnerID=40&md5=328714331da93b067265abe161724a80,[No abstract available],,
Consistency of a tactile pattern set,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017626901&doi=10.1145%2f3053723&partnerID=40&md5=f7ac3d21ad0e03b6f35ca0299e199b13,"Consistency over multiple images is a central requirement in most guidelines for creating tactile graphics. By contrast, tactile consistency over multiple production media for tactile graphics is not very common. In this article, we describe a user-centered approach of developing a tactile fill pattern set to be used for tactile graphics on microcapsule paper, tactile matrix embossers, and dynamic tactile pin-matrix devices. We show the results of our iterative user evaluations with visually impaired and blind-folded sighted participants. Finally, we present a Scalable Vector Graphics pattern set that comprises nine intuitively recognizable and distinctive patterns keeping their meaning and recognizability over the different production media. © 2017 ACM.",Blind users; Evaluation; Pin-matrix device; SVG filling patterns; Tactile graphics; Texture,Computer applications; Human computer interaction; Textures; Blind users; Evaluation; Filling patterns; Pin-matrix device; Tactile graphics; Contrast media
Personalized assistive web for improving mobile web browsing and accessibility for visually impaired users,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017622456&doi=10.1145%2f3053733&partnerID=40&md5=40c5771396d64661e27ca3b1faa18d8f,"Mobile web browsing has become a daily routine for many people, including those with visual impairments. However, usability and accessibility challenges of mobile handheld devices may compromise the benefits of mobile web access, particularly for users with visual impairments. To improve mobile web accessibility, we propose a Personalized Assistive Web (PAW) that aims to improve skimming in mobile web browsing for users with visual impairments through hierarchical outline view and personalization adaptations in this research. We empirically evaluated PAW via a controlled lab experiment with 21 blind participants and 34 sighted participants. The empirical results provide strong evidence for the positive impacts of the hierarchical outline view adaptation on user performance of information search (i.e., search time) and perceptions (i.e., perceived ease of use and perceived usefulness) across the two groups of participants and demonstrate that the positive effects of adaptation personalization vary with participants. The findings not only demonstrate the effectiveness of the hierarchical outline view adaptation for blind and sighted participants but also reveal some important similarities and interesting differences in the effect of personalized adaptation between the two groups of participants. This research provides design and technical insights that are instrumental for improving mobile web accessibility. © 2017 ACM.",Hierarchical outline view adaptation; Mobile web; Personalization; Visually impaired users,Transportation; Websites; Hierarchical outline view adaptation; Mobile handheld devices; Mobile web; Mobile web browsing; Perceived ease of use; Perceived usefulness; Personalizations; Visually-impaired users; Web crawler
Regression analysis of demographic and technology-experience factors influencing acceptance of sign language animation,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017548952&doi=10.1145%2f3046787&partnerID=40&md5=648482209ab046e76a0716ba6ecb9e69,"Software for automating the creation of linguistically accurate and natural-looking animations of American Sign Language (ASL) could increase information accessibility for many people who are deaf. As compared to recording and updating videos of human ASL signers, technology for automatically producing animation from an easy-to-update script would make maintaining ASL content on websites more efficient. Most sign language animation researchers evaluate their systems by collecting subjective judgments and comprehensionquestion responses from deaf participants. Through a survey (N = 62) and multiple-regression analysis, we identified relationships between (a) demographic and technology-experience characteristics of participants and (b) the subjective and objective scores collected from them during the evaluation of sign language animation systems. These relationships were experimentally verified in a subsequent user study with 57 participants, which demonstrated that specific subpopulations have higher comprehension or subjective scores when viewing sign language animations in an evaluation study. This finding indicates that researchers should collect and report a set of specific characteristics about participants in any publications describing evaluation studies of their technology, a practice that is not yet currently standard among researchers working in this field. In addition to investigating this relationship between participant characteristics and study results, we have also released our survey questions in ASL and English that can be used to measure these participant characteristics, to encourage reporting of such data in future studies. Such reporting would enable researchers in the field to better interpret and compare results between studies with different participant pools. © 2017 ACM.",Accessibility technology for people who are deaf; American Sign Language; Animation; User study,Animation; Population statistics; Regression analysis; Transportation; Accessibility technology for people who are deaf; American sign language; Animation systems; Evaluation study; Information accessibility; Multiple regression analysis; Sign language; User study; Surveys
"Introduction to the ASSETS'15 Special Issue, Part 1",2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017200230&doi=10.1145%2f3051484&partnerID=40&md5=31fbc6725ff6857c854a835625d2f35c,[No abstract available],,
Mind your crossings: Mining GIS imagery for crosswalk localization,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017221987&doi=10.1145%2f3046790&partnerID=40&md5=bcdbb53abdfb38be93fdeaad33a02cd7,"For blind travelers, finding crosswalks and remaining within their borders while traversing them is a crucial part of any trip involving street crossings. While standard Orientation & Mobility (O&M) techniques allow blind travelers to safely negotiate street crossings, additional information about crosswalks and other important features at intersections would be helpful in many situations, resulting in greater safety and/or comfort during independent travel. For instance, in planning a trip a blind pedestrian may wish to be informed of the presence of all marked crossings near a desired route. We have conducted a survey of several O&M experts from the United States and Italy to determine the role that crosswalks play in travel by blind pedestrians. The results show stark differences between survey respondents from the U.S. compared with Italy: the former group emphasized the importance of following standard O&M techniques at all legal crossings (marked or unmarked), while the latter group strongly recommended crossing at marked crossings whenever possible. These contrasting opinions reflect differences in the traffic regulations of the two countries and highlight the diversity of needs that travelers in different regions may have. To address the challenges faced by blind pedestrians in negotiating street crossings, we devised a computer vision-based technique that mines existing spatial image databases for discovery of zebra crosswalks in urban settings. Our algorithm first searches for zebra crosswalks in satellite images; all candidates thus found are validated against spatially registered Google Street View images. This cascaded approach enables fast and reliable discovery and localization of zebra crosswalks in large image datasets.While fully automatic, our algorithm can be improved by a final crowdsourcing validation. To this end, we developed a Pedestrian Crossing Human Validation web service, which supports crowdsourcing, to rule out false positives and identify false negatives. © 2017 ACM.",Autonomous navigation; Crowdsourcing; Orientation and mobility; Satellite and street-level imagery; Visual impairments and blindness,Crosswalks; Crowdsourcing; Laws and legislation; Satellite imagery; Search engines; Surveys; Traffic signals; Web services; Autonomous navigation; False negatives; Important features; Satellite images; Standard orientations; Street crossing; Traffic regulations; Visual impairment; Image enhancement
Design and real-world evaluation of eyes-free yoga: An exergame for blind and low-vision exercise,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017198791&doi=10.1145%2f3022729&partnerID=40&md5=9b9a78b848275c59996ec98d969b4ac0,"People who are blind or low vision may have a harder time participating in exercise due to inaccessibility or lack of encouragement. To address this, we developed Eyes-Free Yoga using the Microsoft Kinect that acts as a yoga instructor and has personalized auditory feedback based on skeletal tracking. We conducted two different studies on two different versions of Eyes-Free Yoga: (1) a controlled study with 16 people who are blind or low vision to evaluate the feasibility of a proof-of-concept and (2) an 8-week in-home deployment study with 4 people who are blind or low vision, with a fully functioning exergame containing four full workouts and motivational techniques. We found that participants preferred the personalized feedback for yoga postures during the laboratory study. Therefore, the personalized feedback was used as ameans to build the core components of the system used in the deployment study and was included in both study conditions. From the deployment study, we found that the participants practiced Yoga consistently throughout the 8-week period (Average hours = 17; Average days of practice = 24), almost reaching the American Heart Association recommended exercise guidelines. On average, motivational techniques increased participant's user experience and their frequency and exercise time. The findings of this work have implications for eyesfree exergame design, including engaging domain experts, piloting with inexperienced users, using musical metaphors, and designing for in-home use cases. © 2017 ACM.",Accessibility; Audio feedback; Deployment; Exergames; Eyes-free; Health; Kinect; Motivation; video games; Visual impairments; Yoga,Feedback; Motivation; Accessibility; Audio feedbacks; Deployment; Exergames; Eyes-free; Kinect; Video game; Visual impairment; Yoga; Health
On the evaluation of novel sonification techniques for non-visual shape exploration,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017223492&doi=10.1145%2f3046789&partnerID=40&md5=0551cf7770ddf7f62389ef42a1345579,"There are several situations in which a person with visual impairment or blindness needs to extract information from an image. For example, graphical representations are often used in education, in particular, in STEM (science, technology, engineering, and mathematics) subjects. In this contribution, we propose a set of six sonification techniques to support individuals with visual impairment or blindness in recognizing shapes on touchscreen devices. These techniques are compared among themselves and with two other sonification techniques already proposed in the literature. Using Invisible Puzzle, a mobile application which allows one to conduct non-supervised evaluation sessions, we conducted tests with 49 subjects with visual impairment and blindness, and 178 sighted subjects. All subjects involved in the process successfully completed the evaluation session, showing a high level of engagement, demonstrating, therefore, the effectiveness of the evaluation procedure. Results give interesting insights into the differences among the sonification techniques and, most importantly, show that after a short training, subjects are able to successfully identify several different shapes. © 2017 ACM.",Evaluation techniques; Image sonification; Touch screen; Visual impairments,"Engineering education; Eye protection; Human computer interaction; Ophthalmology; Different shapes; Evaluation techniques; Extract informations; Graphical representations; Mobile applications; Science , technology , engineering , and mathematics; Sonifications; Visual impairment; Touch screens"
Investigating laboratory and everyday typing performance of blind users,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015762593&doi=10.1145%2f3046785&partnerID=40&md5=e5ccb6e9fcd9d5ae7144f3d797c5bffb,"Over the last decade there have been numerous studies on touchscreen typing by blind people. However, there are no reports about blind users- everyday typing performance and how it relates to laboratory settings. We conducted a longitudinal study involving five participants to investigate how blind users truly type on their smartphones. For 12 weeks, we collected field data, coupled with eight weekly laboratory sessions. This article provides a thorough analysis of everyday typing data and its relationship with controlled laboratory assessments. We improve state-of-the-art techniques to obtain intent from field data, and provide insights on real-world performance. Our findings show that users improve over time, even though it is at a slow rate. Substitutions are the most common type of error and have a significant impact on entry rates in both field and laboratory settings. Results show that participants are 1.3-2 times faster when typing during everyday tasks. On the other hand, they are less accurate. We finished by deriving some implications that should inform the design of a future virtual keyboard for nonvisual input. Moreover, findings should be of interest to keyboard designers and researchers looking to conduct field studies to understand everyday input performance. © 2017 ACM.",Behavior; Blind; Errors; Everyday; In-the-wild; Input; Laboratory; Longitudinal; Mobile; Performance; Text-entry; Touchscreen,Computer applications; Errors; Human computer interaction; Touch screens; Behavior; Blind; Everyday; Input; Longitudinal; Mobile; Performance; Text entry; Laboratories
Skin conductance as an in situ marker for emotional arousal in children with neurodevelopmental communication impairments: Methodological considerations and clinical implications,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017616164&doi=10.1145%2f3035536&partnerID=40&md5=cb645faf90273d2344ae72f91cff1630,"Even though electrodermal activity has been widely used in the study of psychological states and processes for over 130 years, the use of such technology in situ, within the context of daily activities, remains a major challenge. Recent technological advancements have led to the development of wearable biosensors that noninvasively measure electrical conductance across the skin. These biosensors represent a new approach for skin conductance assessment, as a proxy for emotional arousal, in children with neurodevelopmental communication impairments who are often described as having difficulties with emotional regulation, expressing thoughts and feelings, and present a higher prevalence of challenging behaviors. Here we provide an overview of skin conductance and explore the benefits of recent technological advancements for applied research and clinical practice. We draw on user experience from two experimental interventions involving eight children with neurodevelopmental impairments. In both cases investigators monitored phasic and tonic EDA measures in situ using wearable biosensors. We share the behavioral and technical challenges experienced across these two experimental contexts, and propose associated considerations for future use. Specifically, sensor functioning, synchronization, and data preprocessing/analysis difficulties, as well as behavioral findings related to developmental differences, sensor tolerance over time, and sensor placement are discussed. © 2017 ACM.",Autism; Electrodermal activity (EDA); Emotional arousal; In situ; Neurodevelopmental communication impairments; Skin conductance (SC); User experience,Electrodes; Wearable technology; Autism; Electrodermal activity; Emotional arousal; Neurodevelopmental communication impairments; Skin conductance; User experience; Biosensors
Principles for designing large-format refreshable haptic graphics using touchscreen devices: An evaluation of nonvisual panning methods,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017538681&doi=10.1145%2f3035537&partnerID=40&md5=1fbcafbd0a974aa211b27b86292c91d5,"Touchscreen devices, such as smartphones and tablets, represent a modern solution for providing graphical access to people with blindness and visual impairment (BVI). However, a significant problem with these solutions is their limited screen real estate, which necessitates panning or zooming operations for accessing large-format graphical materials such as maps. Non-visual interfaces cannot directly employ traditional panning or zooming techniques due to various perceptual and cognitive limitations (e.g., constraints of the haptic field of view and disorientation due to loss of one's reference point after performing these operations). This article describes the development of four novel non-visual panning methods designed from the onset with consideration of these perceptual and cognitive constraints. Two studies evaluated the usability of these panning methods in comparison with a non-panning control condition. Results demonstrated that the exploration, learning, and subsequent spatial behaviors were similar between panning and non-panning conditions, with one panning mode, based on a two-finger drag technique, revealing the overall best performance. Findings provide compelling evidence that incorporating panning operations on touchscreen devices - the fastest growing computational platform among the BVI demographic - is a viable, low-cost, and immediate solution for providing BVI people with access to a broad range of large-format digital graphical information. © 2017 ACM.",Accessibility (blind and visually impaired); Assistive technology; Auditory cues; Haptic cues; Non-visual maps; Touchscreens; Vibro-audio interface,Digital devices; Touch screens; Assistive technology; Audio interfaces; Auditory cues; Blind and visually impaired; Haptic cues; Non visuals; Haptic interfaces
Design and development of one-switch video games for children with severe motor disabilities,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027516758&doi=10.1145%2f3085957&partnerID=40&md5=a4e1f8a97e8e7639f2f69ed6d580ac3e,"Video games are not just played for fun; they have become a handy instrument for the cognitive, emotional, and social development of children. However, several barriers prevent many children with disabilities from playing action-oriented video games, alone or with their peers. In particular, children with severe motor disabilities, who rely on one-switch interaction for accessing electronic devices, find fast-paced games that require rapid decision-making and timely responses, completely unplayable. This article contributes to lowering such barriers by presenting GNomon (Gaming NOMON), a software framework based on the NOMON mode of interaction that allows the creation of action-oriented single-switch video games. The article reports the results of two studies that evaluate the playability and rehabilitation suitability of GNomon-based video games. The playability of GNomon-based games is evaluated by assessing their learnability, effectiveness, errors, satisfaction, memorability, and enjoyability with a group of eight children with severe motor disabilities.The suitability for pediatric rehabilitation is determined by means of a focus group with a team of speech therapists, physiotherapists, and psychologists from a Local Health Agency in Turin, Italy. The results of the playability study are positive: All children had fun playing GNomon-based video games, and seven of eight were able to interact and play autonomously. The results of the rehabilitation-suitability study also entail that GNomon-based games can be exploited in training hand-eye coordination and maintenance of selective attention over time. The article finally offers critical hindsight and reflections and shows possible new future game concepts. © 2017 ACM.",Accessible games; Action-oriented games; Children with disabilities; One-switch interaction; Single-switch selection,Computer programming; Decision making; Electric switches; Patient rehabilitation; Switching; Accessible games; Action-oriented; Children with disabilities; One-switch interaction; Single switch; Human computer interaction
Process measures of dyadic collaborative interaction for social skills intervention in individuals with Autism Spectrum Disorders,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028576112&doi=10.1145%2f3107925&partnerID=40&md5=159995a4e4742f6fa8929838049baeac,"Technology-based social skills interventions have shown promise for people with Autism Spectrum Disorder (ASD), a neurodevelopmental disorder characterized by impairments in social interaction and communication. Primary advantages of a technology-based approach to intervention relate to consistency of service delivery as well as an ability to quantitatively measure process and outcomes. Despite these strengths, however, many current computer-supported systems rely on survey data or data collected post-interaction. In response, we have developed and pilot-tested DOSE (Dyad-Operated Social Encouragement), a novel game and data acquisition platform for collaborative skills intervention that leverages the ability of software to collect time-series, speech audio, and event information for the purposes of finer-grained analyses of dyadic interactions. A pilot study involving 12 participant dyads-comprised of children with ASD and typically developing (TD) peers (6 ASD-TD dyads and 6 TD-TD dyads)-was conducted and several metrics were computed during interactions. Preliminary results suggest that the DOSE system is engaging to users, is capable of collecting a wide range of quantitative process measures, and that post-training measures show preliminary evidence of increased communication and activity coordination. Furthermore, DOSE has been made open-source, allowing other investigators to use and extend DOSE for a variety of applications. © 2017 ACM.",Autism spectrum disorder,Data acquisition; Open source software; Software testing; Time series analysis; Autism spectrum disorders; Collaborative interaction; Dyadic interaction; Pilot studies; Service delivery; Social interactions; Social skills; Technology-based; Diseases
Improving the accessibility of mobile OCR apps via interactive modalities,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028523839&doi=10.1145%2f3075300&partnerID=40&md5=b72d195283471aee8a163c7dddc4e793,"We describe two experiments with a system designed to facilitate the use of mobile optical character recognition (OCR) by blind people. This system, implemented as an iOS app, enables two interaction modalities (autoshot and guidance). In the first study, augmented reality fiducials were used to track a smartphone's camera, whereas in the second study, the text area extent was detected using a dedicated text spotting and text line detection algorithm. Although the guidance modality was expected to be superior in terms of faster text access, this was shown to be true only when some conditions (involving the user interface and text detection modules) are met. Both studies also showed that our participants, after experimenting with the autoshot or guidance modality, appeared to have improved their skill at taking OCR-readable pictures even without use of such interaction modalities. © 2017 ACM.",Accessibility; Blindness; Mobile devices; OCR,Augmented reality; Character recognition; Mobile devices; Optical character recognition; Transportation; Accessibility; Blind people; Blindness; Fiducials; Optical character recognition (OCR); Text areas; Text detection; Text line detection; User interfaces
Social predictors of assistive technology proficiency among teachers of students with visual impairments,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011407684&doi=10.1145%2f2999569&partnerID=40&md5=c1178d28b165bfcd6f8436576db9ce69,"Assistive technology (AT) is critical for K-12 students who have visual impairments to engage with their education and is predictive of positive postsecondary outcomes and future employment. Teachers of students with visual impairments (TVIs) act as the primary gatekeepers of AT for these students. Unfortunately, only about 40% of TVIs integrate AT into their practice. Efforts to predict TVIs' AT proficiency based on their preservice training have been unsuccessful. The current study proposes and confirms that TVIs' AT proficiency is related to their identification with a social community of practice (CoP) that values AT. Results from n = 505 North American TVIs produced a Spearman's correlation of ρ = 0.49 between estimated AT proficiency and CoP identification. The relationship was strongest among TVIs with lower AT proficiency and CoP identification. Results have implications for industry, researchers, teacher preparation programs, personnel who administer and train assistive technologies, and policymakers concerned with ensuring that AT is available to students who have visual impairments. Mere availability of AT is insufficient to ensure its successful introduction to K-12 students with visual impairments, which relies on TVIs' AT proficiency for meaningful implementation. Developers and advocates of AT for K-12 students with visual impairments must consider the social context in which AT proficiency develops and provide appropriate social supports. © 2016 ACM.",Accessibility; Assistive technology; Community of practice; Personnel preparation; Social networks; Special education; Visual impairment,Education; Personnel; Social networking (online); Social sciences computing; Teaching; Accessibility; Assistive technology; Community of practice; Special education; Visual impairment; Students
Multimodal perception of histological images for persons who are blind or visually impaired,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011324277&doi=10.1145%2f3026794&partnerID=40&md5=723edcd26893b59f123fba4cae9cfca3,"Lack of suitable substitute assistive technology is a roadblock for students and scientists who are blind or visually impaired (BVI) from advancing in careers in science, technology, engineering, and mathematics (STEM) fields. It is challenging for persons who are BVI to interpret real-time visual scientific data which is commonly generated during lab experimentation, such as performing light microscopy, spectrometry, and observing chemical reactions. To address this problem, a real-time multimodal image perception system was developed to allow standard laboratory blood smear images to be perceived by BVI individuals by employing a combination of auditory, haptic, and vibrotactile feedback. These sensory feedback modalities were used to convey visual information through alternative perceptual channels, thus creating a palette of multimodal, sensory information. Two sets of image features of interest (primary and peripheral features) were applied to characterize images. A Bayesian network was applied to construct causal relations between these two groups of features. In order to match primary features with sensor modalities, two methods were conceived. Experimental results confirmed that this real-time approach produced higher accuracy in recognizing and analyzing objects within images compared to conventional tactile images. © 2017 ACM.",Blind or visually impaired; Haptics; Image perception; Multi-modality; Sensorial substitution; Vibrotactile,Bayesian networks; Professional aspects; Sensory feedback; Haptics; Image perception; Multi modality; Vibrotactile; Visually impaired; Feedback
Accessible touchscreen technology for people with visual impairments: A survey,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011393249&doi=10.1145%2f3022701&partnerID=40&md5=37bea79ff20f17ca16feec685cb39461,"Touchscreens have become a de facto standard of input for mobile devices as they most optimally use the limited input and output space that is imposed by their form factor. In recent years, people who are blind and visually impaired have been increasing their usage of smartphones and touchscreens. Although basic access is available, there are still many accessibility issues left to deal with in order to bring full inclusion to this population. Many of the accessibility problems are complex; in the past decade, various solutions have been explored. This article provides a review of the current state of the art of touchscreen accessibility for people with visual impairments and identifies new directions for research. © 2017 ACM.",Accessibility; Blind; Eyes-free; Gestures; Mobile computing; Nonvisual; Touchscreens; Visually impaired,Mobile computing; Transportation; Accessibility; Blind; Eyes-free; Gestures; Non visuals; Visually impaired; Touch screens
ACE: A colour palette design tool for balancing aesthetics and accessibility,2017,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011340472&doi=10.1145%2f3014588&partnerID=40&md5=4398003839eb4ee4c65f5ae16cc25754,"Colour can convey a mood or elicit a particular emotion and, in terms of web design, colour can influence attitudes, perceptions, and behaviours. However, many websites demonstrate inaccessible colour choices. Numerous online colour palette design tools only focus on assisting designers with either the aesthetics or accessibility of colours.With a user-centered design approach, we developed the Accessible Colour Evaluator (ACE, daprlab.com/ace) which enhances web developers' and designers' ability to balance aesthetic and accessibility constraints. We distributed an online questionnaire to 28 web developers and designers to understand their attitudes and utilisation of accessibility guidelines, as well as to gather initial design requirements for ACE. With this information, we created three low-fidelity paper prototypes that were used to create two high-fidelity prototypes. The high-fidelity prototypes were discussed with 4 web developers and designers during a design workshop, and their feedback was used to develop the final version of ACE. A comparative evaluation of ACE and three existing alternative tools was conducted with 10 new web developers and designers. All participants were able to complete a colour palette design task when using ACE and identified ACE as their most preferred tool. The mean scores for the six TLX measures show ACE as providing the best performance and causing the lowest frustration. Finally, we conducted a small focus group with 3 web developers and designers to gather qualitative feedback about ACE. Participants identified a number of ACE's strengths and made suggestions for future extensions and improvements. 2017 Copyright is held by the owner/author(s).",Aesthetics; Colour vision deficiency; Colourblindness; User-centered design; Web accessibility; Web design,Behavioral research; Color; Color vision; Transportation; Web Design; Websites; Accessibility guidelines; Aesthetics; Colourblindness; Comparative evaluations; Online questionnaire; Qualitative feedback; User-centered design approaches; Web accessibility; User centered design
Exploring auditory graphing software in the classroom: The effect of auditory graphs on the classroom environment,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007018022&doi=10.1145%2f2994606&partnerID=40&md5=bc4e577eda82d1311dd2d727293798ca,"Students who are visually impaired make up a population with unique needs for learning. Some tools have been developed to support these needs in the classroom. One such tool, the Graph and Number line Input and Exploration software (GNIE), was developed by the Georgia Institute of Technology Sonification Lab. GNIE was deployed for use in a middle school math classroom at the Georgia Academy for the Blind (GAB) for 2 years starting in fall 2012. We interviewed the middle school math teacher throughout the deployment to learn about the challenges faced when teaching: lesson planning, execution, and review. We also observed how these changed when using GNIE compared to traditional teaching materials. During these 2 years, we conducted interviews and focus groups with students to learn about their attitudes toward tactile graphs compared to auditory graphs. With these in mind, we present lessons learned from the use of GNIE in a real-world classroom and implications for design of software to aid graphical learning for students with vision impairments. © 2016 ACM.",,Education; Teaching; Classroom environment; Design of softwares; Georgia Institute of Technology; Math teachers; Middle school; Teaching materials; Vision impairments; Visually impaired; Students
Teach or design? How older adults' use of ticket vending machines could be more effective,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994131733&doi=10.1145%2f2935619&partnerID=40&md5=958ea2a957eb9e44e1c2118a27c26084,"The dominance of computer technology in work and leisure poses challenges for older people. Their lack of computer experience and computer literacy impedes their ability to explore and use new interactive systems. This is particularly challenging for the design of public access systems, such as ticket vending machines (TVM). This article describes a conflict relevant for many designers considering age-related differences in technology use: should the user be taught to use the existing design or should the design be changed to accommodate older users? An experiment was conducted to directly compare these alternative approaches with each other and with a simulation of an existing TVM. It compares three TVM designs regarding the usability criteria of effectiveness, efficiency and satisfaction, controlling for age, and cognitive and motivational characteristics. 62 older (M = 68 years) and 62 younger (M = 25 years) participants were split into three groups: The control group solved 11 tasks using a simulation of the TVM, the video group watched a brief instructional video before solving the same tasks with the same TVM, and the wizard group used a redesigned wizard interface instead. Results indicate that young and old participants' performance improved after watching the video, but older participants improved more, reaching the effectiveness of the young control group. In the wizard condition, age differences in effectiveness and satisfaction were eliminated; however, speed differences remained in all conditions. The results suggest that the simple integration of minimal video instruction or a task-oriented wizard design can make public access systems truly universally usable, and that the wizard TVM was a true ""walk-up-and-use system."" © 2016 ACM.",Computer literacy; Ticket vending machines (TVM),Computers; Age-related differences; Computer experience; Computer literacy; Computer technology; Instructional videos; Interactive system; Ticket vending machines; Video instructions; Vending machines
Evaluating haptic and auditory directional guidance to assist blind people in reading printed text using finger-mounted cameras,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994187934&doi=10.1145%2f2914793&partnerID=40&md5=1e089ed50f7bcad7530c2a767ac9148c,"The recent miniaturization of cameras has enabled finger-based reading approaches that provide blind and visually impaired readers with access to printed materials. Compared to handheld text scanners such as mobile phone applications, mounting a tiny camera on the user's own finger has the potential to mitigate camera framing issues, enable a blind reader to better understand the spatial layout of a document, and provide better control over reading pace. A finger-based approach, however, also introduces the need to guide the reader in physically navigating a document, such as tracing along lines of text. While previous work has proposed audio and haptic directional finger guidance for this purpose, user studies of finger-based reading have not provided an in-depth performance analysis of the finger-based reading process. To further investigate the effectiveness of finger-based sensing and feedback for reading printed text, we conducted a controlled laboratory experiment with 19 blind participants, comparing audio and haptic directional finger guidance within an iPad-based testbed. As a small follow-up, we asked four of those participants to return and provide feedback on a preliminary wearable prototype called HandSight. Findings from the controlled experiment show similar performance between haptic and audio directional guidance, although audio may offer an accuracy advantage for tracing lines of text. Subjective feedback also highlights trade-offs between the two types of guidance, such as the interference of audio guidance with speech output and the potential for desensitization to haptic guidance. While several participants appreciated the direct access to layout information provided by finger-based exploration, important concerns also arose about ease of use and the amount of concentration required. We close with a discussion on the effectiveness of finger-based reading for blind users and potential design improvements to the HandSight prototype. © 2016 ACM.",Accessibility; Real-time OCR; Visual impairments; Wearables,Cameras; Economic and social effects; Feedback; Wearable technology; Accessibility; Blind and visually impaired; Controlled experiment; Controlled laboratories; Mobile phone applications; Real time; Visual impairment; Wearables; Air navigation
Tablet-based activity schedule in mainstream environment for children with autism and children with ID,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969941477&doi=10.1145%2f2854156&partnerID=40&md5=8550c83581693d65e249806495714016,"Including children with autism spectrum disorders (ASD) in mainstream environments creates a need for new interventions whose efficacy must be assessed in situ. This article presents a tablet-based application for activity schedules that has been designed following a participatory design approach involving mainstream teachers, special education teachers, and school aides. This application addresses two domains of activities: classroom routines and verbal communications. We assessed the efficiency of our application with two overlapping user studies in mainstream inclusion, sharing agroupof children with ASD. Thefirst experiment involved10children with ASD, where five children were equipped with our tabled-based application and five were not equipped. We show that (1) the use of the application is rapidly self-initiated (after 2 months for almost all the participants) and (2) the tabletsupported routines are better performed after 3 months of intervention. The second experiment involved 10 children equipped with our application; it shared the data collected for the five children with ASD and compared them with data collected for five children with intellectual disability (ID). We show that (1) children with ID are not autonomous in the use of the application at the end of the intervention, (2) both groups exhibited the same benefits on classroom routines, and (3) children with ID improve significantly less their performance on verbal communication routines. These results are discussed in relation with our design principles. Importantly, the inclusion of a group with another neurodevelopmental condition provided insights about the applicability of these principles beyond the target population of children with ASD. © 2016 ACM 1936-7228/2016/05-ART9 $15.00.",Educative inclusion in mainstream environment; Idiosyncratic multimedia contents; Participatory design,Diseases; Children with autisms; Design Principles; Educative inclusion in mainstream environment; Intellectual disability; Multimedia contents; Participatory design; Special education; Verbal communications; Teaching
Isolated sign language recognition with Grassmann covariance matrices,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969941401&doi=10.1145%2f2897735&partnerID=40&md5=dc073aa846830937722e8c3f4a66878b,"In this article, to utilize long-term dynamics over an isolated sign sequence, we propose a covariance matrix-based representation to naturally fuse information from multimodal sources. To tackle the drawback induced by the commonly used Riemannian metric, the proximity of covariance matrices is measured on the Grassmann manifold. However, the inherent Grassmann metric cannot be directly applied to the covariance matrix. We solve this problem by evaluating and selecting the most significant singular vectors of covariance matrices of sign sequences. The resulting compact representation is called the Grassmann covariance matrix. Finally, the Grassmann metric is used to be a kernel for the support vector machine, which enables learning of the signs in a discriminative manner. To validate the proposed method, we collect three challenging sign language datasets, on which comprehensive evaluations show that the proposed method outperforms the state-of-the-art methods both in accuracy and computational cost. © 2016 ACM 1936-7228/2016/05-ART14 $15.00.",Covariance matrix; Grassmann manifold; Hearing loss; Sign language,Audition; Computational linguistics; Compact representation; Comprehensive evaluation; Grassmann manifold; Hearing loss; Matrix based representation; Sign language; Sign Language recognition; State-of-the-art methods; Covariance matrix
The effect of font type on screen readability by people with dyslexia,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970044531&doi=10.1145%2f2897736&partnerID=40&md5=e111c1f02f2374d304cd079e3480c134,"Around 10% of the people have dyslexia, a neurological disability that impairs a person's ability to read and write. There is evidence that the presentation of the text has a significant effect on a text's accessibility for people with dyslexia. However, to the best of our knowledge, there are no experiments that objectively measure the impact of the typeface (font) on screen reading performance. In this article, we present the first experiment that uses eye-tracking to measure the effect of typeface on reading speed. Using a mixed between-within subject design, 97 subjects (48 with dyslexia) read 12 texts with 12 different fonts. Font types have an impact on readability for people with and without dyslexia. For the tested fonts, sans serif, monospaced, and roman font styles significantly improved the reading performance over serif, proportional, and italic fonts. On the basis of our results, we recommend a set of more accessible fonts for people with and without dyslexia. © 2016 ACM.",Best practices; Dyslexia; Eye-tracking; Font; Learning disability; Legibility; Readability; Typeface; Web accessibility,Computer applications; Human computer interaction; Best practices; Dyslexia; Font; Learning disabilities; Legibility; Readability; Typeface; Web accessibility; Eye tracking
"An analysis of age, technology usage, and cognitive characteristics within information retrieval tasks",2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019541460&doi=10.1145%2f2856046&partnerID=40&md5=c04f3c011ec3f2c172fd523fef93ee4b,"This work presents two studies that aim to discover whether age can be used as a suitable metric for distinguishing performance between individuals or if other factors can provide greater insight. Information retrieval tasks are used to test the performance of these factors. First, a study is introduced that examines the effect that fluid intelligence and Internet usage has on individuals. Second, a larger study is reported on that examines a collection of Internet and cognitive factors in order to determine to what extent each of these metrics can account for disorientation in users. This work adds to growing evidence showing that age is not a suitable metric to distinguish between individuals within the field of human-computer interaction. It shows that factors such as previous Internet experience and fluid-based cognitive abilities can be used to gain better insight into users’ reported browsing experience during information retrieval tasks. © 2016 ACM",And Phrases: Older adults; Cognitive ability; HCI; Search strategies; Web search,Information retrieval; Cognitive ability; Cognitive characteristics; Cognitive factors; Internet usage; Older adults; Search strategies; Technology usages; Web searches; Human computer interaction
Investigating the implications of 3D printing in special education,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963779894&doi=10.1145%2f2870640&partnerID=40&md5=76e4478d72df13aaf289691a304290bd,"Consumer-grade digital fabrication such as 3D printing is on the rise, and we believe it can be leveraged to great benefit in special education. Although 3D printing is infiltrating mainstream education, little research has explored 3D printing in the context of students with special support needs. We describe our studies on this topic and the resulting contributions. We initially conducted a formative study exploring the use of 3D printing at three locations serving populations with varying ability, including individuals with cognitive, motor, and visual impairments. We found that 3D design and printing perform three functions in special education: (1) STEM engagement, (2) creation of educational aids for accessible curriculum content, and (3) making custom adaptive devices. As part of our formative work, we also discussed a case study in the codesign of an assistive hand grip created with occupational therapists at one of our investigation sites. This work inspired further studies on the creation of adaptive devices using 3D printers. We identified the needs and constraints of these therapists and found implications for a specialized 3D modeling tool to support their use of 3D printers. We developed GripFab, 3D modeling software based on feedback from therapists, and used it to explore the feasibility of in-house 3D object designs in support of accessibility. Our contributions include case studies at three special education sites and discussion of obstacles to efficient 3D printing in this context. We have extended these contributions with a more in-depth look at the stakeholders and findings from GripFab studies. We have expanded our discussion to include suggestions for researchers in this space, in addition to refined suggestions from our earlier work for technologists creating 3D modeling and printing tools, therapists seeking to leverage 3D printers, and educators and administrators looking to implement these design tools in special education environments. © 2016 ACM.",3D printing; Assistive technology; Children; Cognitive impairment; Developmental disability; Digital fabrication; Rapid prototyping; Special education; Visual impairment,Curricula; Education; Engineering education; Printing; Printing machinery; Printing presses; Rapid prototyping; Wave filters; 3-D printing; Assistive technology; Children; Cognitive impairment; Developmental disability; Digital fabrication; Special education; Visual impairment; 3D printers
"Best practices for teaching accessibility in university classrooms: Cultivating awareness, understanding, and appreciation for diverse users",2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963825578&doi=10.1145%2f2831424&partnerID=40&md5=9387458624337980074b1c71a026bc95,"As Information and Communication Technologies (ICTs) become more diffuse, developers and designers need to consider a growing diversity of users including people with disabilities and aging populations. As a result, computing education needs to respond by providing students opportunities to learn about accessibility and designing for inclusion. This article presents results of a qualitative research study of practices in teaching accessibility in university-level programs in the US. The study included interviews with 18 professors from some of the top universities in the US and a content analysis of syllabi and other teaching materials. Using the pedagogical theory of authentic learning and elements from the 21st Century Skills framework, we found that instructors emphasized the need for students to develop awareness and understanding for a diversity of ICT users through multiple different experiences; experiences that included research projects that directly involve users with disabilities, guest speakers, field trips, simulating disabilities, and the use of videos/movies. Additionally, instructors used multiple resources (e.g., research papers, online resources), in part, to offset the challenge that there is a perceived lack of a comprehensive textbook. Instructors also emphasized the importance of their individual initiative; that is, the inclusion of accessible topics or courses was often linked to a faculty member's research and/or personal commitment. This article contributes to a gap in the literature by disseminating and sharing different approaches to teaching accessibility across multiple instructors, courses, and campuses. © 2016 ACM.",Accessibility; Pedagogy,Computation theory; Cultivation; Data mining; Education; Students; Transportation; Accessibility; Information and Communication Technologies; Pedagogy; People with disabilities; Qualitative research; Theory of authentic learning; University classrooms; Users with disabilities; Teaching
"Introduction to the ASSETS'14 Special Issue, Part 2",2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963754220&doi=10.1145%2f2891030&partnerID=40&md5=3d12f22abd4ed6450b215cf93b7b8da1,[No abstract available],,
Scanning for digital content: How blind and sighted people perceive concurrent speech,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964555804&doi=10.1145%2f2822910&partnerID=40&md5=ffdfeadbf3f5ac39d1990f12627d18f2,"The widespread availability of digital media has changed the way that people consume information and has impacted the consumption of auditory information. Despite this recent popularity among sighted people, the use of auditory feedback to access digital information is not new for visually impaired users. However, its sequential nature undermines both blind and sighted people's ability to efficiently find relevant information in the midst of several potentially useful items. We propose taking advantage of the Cocktail Party Effect, which states that people are able to focus on a single speech source among several conversations, but still identify relevant content in the background. Therefore, in contrast to one sequential speech channel, we hypothesize that people can leverage concurrent speech channels to quickly get the GIST of digital information. In this article, we present an experiment with 46 (23 blind, 23 sighted) participants,which aims to understand people's ability to search for relevant content listening to two, three, or four concurrent speech channels. Our results suggest that both blind and sighted people are able to process concurrent speech in scanning scenarios. In particular, the use of two concurrent sources may be used both to identify and understand the content of the relevant sentence. Moreover, three sources may be used for most people depending on the task intelligibility demands and user characteristics. Contrasting with related work, the use of different voices did not affect the perception of concurrent speech but was highly preferred by participants. To complement the analysis, we propose a set of scenarios that may benefit from the use of concurrent speech sources, for both blind and sighted people, toward a Design for All paradigm.",Accessibility; Auditory feedback; Blind; Cocktail party effect; Concurrent speech; Scanning; Screen reader; Sighted; Simultaneous speech; Skimming; Spatial audio; Visually impaired; Web browsing,Digital storage; Scanning; Web browsers; Accessibility; Auditory feedback; Blind; Cocktail party effects; Screen readers; Sighted; Skimming; Spatial audio; Visually impaired; Speech
Sign transition modeling and a scalable solution to continuous sign language recognition for real-world applications,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958523377&doi=10.1145%2f2850421&partnerID=40&md5=864741e8f5b6b9fdcdb50ea8a904f44c,"We propose a new approach to modeling transition information between signs in continuous Sign Language Recognition (SLR) and address some scalability issues in designing SLR systems. In contrast to Automatic Speech Recognition (ASR) in which the transition between speech sounds is often brief and mainly addressed by the coarticulation effect, the sign transition in continuous SLR is far from being clear and usually not easily and exactly characterized. Leveraging upon hidden Markov modeling techniques from ASR, we proposed a modeling framework for continuous SLR having the following major advantages, namely: (i) the system is easy to scale up to large-vocabulary SLR; (ii) modeling of signs as well as the transitions between signs is robust even for noisy data collected in real-world SLR; and (iii) extensions to training, decoding, and adaptation are directly applicable even with new deep learning algorithms. A pair of low-cost digital gloves affordable for the deaf and hard of hearing community is used to collect a collection of training and testing data for real-world SLR interaction applications. Evaluated on 1,024 testing sentences from five signers, a word accuracy rate of 87.4% is achieved using a vocabulary of 510 words. The SLR speed is in real time, requiring an average of 0.69s per sentence. The encouraging results indicate that it is feasible to develop real-world SLR applications based on the proposed SLR framework.",Hidden markov models; Sign language recognition; Speech recognition; Transition modeling,Audition; Computational linguistics; Hidden Markov models; Markov processes; Modeling languages; Automatic speech recognition; Large vocabulary; Model transition; Scalability issue; Scalable solution; Sign Language recognition; Training and testing; Transition model; Speech recognition
A pool of representative users for accessibility research: Seeing through the eyes of the users,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955501515&doi=10.1145%2f2845088&partnerID=40&md5=a868b0a3feea9ab54eea59da6a46af7e,"A critical element of accessibility research is the exploration and evaluation of ideas with representative users. However, it is often difficult to recruit such a range of users, particularly in a timely manner, nor is it easy for new researchers to understand how to recruit relevant populations or feel confident in communicating with older or ""vulnerable"" users. We report on the establishment of a large user pool created to facilitate accessibility research through recruiting sizeable numbers of older adults potentially interested in taking part in research studies about technology. We suggest points to guide new researchers and invite other experts to build on these. We also sketch some of the lessons learned from creating and maintaining this pool of individuals, including thoughts on issues for others wishing to set up similar pools. © 2016 ACM.",,Transportation; Critical elements; Large users; Older adults; Research studies; Lakes
Self-conscious or self-confident? A diary study conceptualizing the social accessibility of assistive technology,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955446493&doi=10.1145%2f2827857&partnerID=40&md5=4a15bf772e5ca1459373371df98d8aeb,"With the recent influx of smartphones, tablets, and wearables such as watches and glasses, personal interactive device use is increasingly visible and commonplace in public and social spaces. Assistive Technologies (ATs) used by people with disabilities are observable to others and, as a result, can affect how AT users are perceived. This raises the possibility that what we call ""social accessibility"" may be as important as ""functional accessibility"" when considering ATs. But, to date, ATs have almost exclusively been regarded as functional aids. For example, ATs are defined by the Technical Assistance to the States Act as technologies that are ""used to increase, maintain or improve functional capabilities of individuals with disabilities."" To investigate perceptions and self-perceptions of AT users, we conducted a diary study of two groups of participants: people with disabilities and people without disabilities. Our goal was to explore the types of interactions and perceptions that arise around AT use in social and public spaces. During our 4-week study, participants with sensory disabilities wrote about feeling either self-conscious or self-confident when using an assistive device in a social or public situation. Meanwhile, participants without disabilities were prompted to record their reactions and feelings whenever they saw ATs used in social or public situations. We found that AT form and function does influence social interactions by impacting self-efficacy and self-confidence. When the design of form or function is poor, or when inequality between technological accessibility exists, social inclusion is negatively affected, as are perceptions of ability. We contribute a definition for the ""social accessibility"" of ATs and subsequently offer Design for Social Accessibility (DSA) as a holistic design stance focused on balancing an AT user's sociotechnical identity with functional requirements. © 2016 ACM 1936-7228/2016/01-ART5 $15.00.",Abandonment; Accessibility; Assistive devices; Assistive technologies; AT; Functional accessibility; Interaction design; Interface design; Product design; Social accessibility; Social interactions; Stigma,Design; Product design; Social sciences; Transportation; Abandonment; Accessibility; Assistive devices; Assistive technology; AT; Functional accessibility; Interaction design; Interface designs; Social accessibility; Social interactions; Stigma; Economic and social effects
Tactile graphics with a voice,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955503618&doi=10.1145%2f2854005&partnerID=40&md5=de6fae2460b5e110f32e70243faca7f0,"We discuss the development of Tactile Graphics with a Voice (TGV), a system used to access label information in tactile graphics using QR codes. Blind students often rely on tactile graphics to access textbook images. Many textbook images have a large number of text labels that need to be made accessible. In order to do so, we propose TGV, which uses QR codes to replace the text, as an alternative to Braille. The codes are read with a smartphone application. We evaluated the system with a longitudinal study where 10 blind and low-vision participants completed tasks using three different modes on the smartphone application: (1) no guidance, (2) verbal guidance, and (3) finger-pointing guidance. Our results show that TGV is an effective way to access text in tactile graphics, especially for those blind users who are not fluent in Braille. We also found that preferences varied greatly across the modes, indicating that future work should support multiple modes. We expand upon the algorithms we used to implement the finger pointing, algorithms to automatically place QR codes on documents. We also discuss work we have started on creating a Google Glass version of the application. ©2016 ACM.",,Signal encoding; Smartphones; Textbooks; Blind users; Finger pointing; Label information; Longitudinal study; Low vision; Multiple modes; Smart-phone applications; Text labels; Codes (symbols)
Introduction to the ASSETS '14 Special Issue,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955502414&doi=10.1145%2f2853995&partnerID=40&md5=ac6a047ebea33a813a7c6e3b8a32b745,[No abstract available],,
Exploring traditional phones as an e-mail interface for older adults,2016,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955457618&doi=10.1145%2f2839303&partnerID=40&md5=e02c9cbc65ea10e49ac260ac1307c8a6,"This article explores the design and development of voice interfaces via traditional telephones as a way of supporting asynchronous online communication for older adults. E-mail is the primary form of online communication for older adults. However, e-mail communication currently requires access to and the ability to use an Internet-connected computer or device, whichmay be problematic due to barriers of physical access, expense, insufficient computer skill, or other accessibility issues. To address this, the present work leverages the pervasive hardware of traditional phones and familiar nonvisual models of phone-based interaction to create a new e-mail interface for older adults. We examine the potential of e-mail interaction via traditional phones through long-term field observations, prototype testing, and a four-week field-based user study. Our findings indicate that a simple voice e-mail interface accessed through traditional phones is usable for older adults and is a useful way for offline older adults to interact with an e-mail account. The ease of use and convenience of a phone-based interface are important given the ""work"" of keeping in touch over e-mail, and this approach has the potential to open up new avenues of online access for older adults who are still offline or who have late-life disabilities that make using traditional graphical e-mail systems difficult. This project contributes new insights regarding the ways in which voice interfaces can support asynchronous online communication for older adults and provides design guidance for the development of subsequent voice interfaces. © 2016 ACM 1936-7228/2016/01-ART5 $15.00.",Communication; E-mail; Older adults; Telephones,Communication; Online systems; Telephone; Telephone sets; Design and Development; Design guidance; E-mail systems; Email communication; Older adults; On-line communication; Prototype testing; Voice interfaces; Electronic mail
MouseClicker: Exploring Tactile Feedback and Physical Agency for People with Hand Motor Impairments,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189680417&doi=10.1145%2f3648685&partnerID=40&md5=58ea224cec5e6c0e9d38a9504f6dbda8,"Assistive technology (AT) design is critical in enabling functionality for people with disabilities, blending essential elements of both practical utility and user experience. Traditionally, AT has successfully addressed core functional needs, such as enabling cursor movement and clicking actions with devices like computer mice. However, a comprehensive approach to AT design also necessitates a thorough consideration of sensory feedback, including tactile sensations, ergonomics, and auditory cues like button click sounds. These aspects are not merely supplementary but are integral to the device’s functionality, enhancing user interaction and long-term comfort, especially for individuals with motor impairments. In this work, we present MouseClicker, a mechatronic AT to surrogate physical agency over a computer mouse and to foster the haptic sensory experience of clicking on it tailored specifically for an individual with Spinal Muscular Atrophy (SMA) who faces challenges in using a standard mouse due to severe hand motor impairments. Our design aims at replicating the holistic experience of clicking a mouse, from its functional mechanical actions to its nuanced tactile and auditory feedback. This work details the MouseClicker’s design and reports on an exploratory user study aimed at identifying optimal vibrotactile feedback parameters – such as location, and intensity – that represent mouse button clicks. MouseClicker presents a step forward in AT design by integrating the functionality, sensory feedback, and the overall experience of taking control over non-AT devices. © 2024 Copyright held by the owner/author(s).",computer mouse; facial expressions; Hand motor impairments; hands-free input; haptic feedback; holistic inclusion,Assistive technology; Blending; Ergonomics; Feedback; Mammals; Assistive technology; Computer mouse; Facial Expressions; Hand motor impairment; Hand-free input; Hands-free; Haptic feedbacks; Holistic inclusion; Motor impairments; Technology designs; Sensory feedback
Exploring the Strategies People with Parkinson's Disease Use to Self-track Symptoms and Medications,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189670144&doi=10.1145%2f3649454&partnerID=40&md5=e17a59a47aaf0d1618376bdc14408347,"Self-tracking has great potential in empowering individuals with a chronic illness in managing their condition. Parkinson’s Disease (PD) is a common neurodegenerative disease that affects millions of people worldwide. PD presents a broad range of motor and non-motor symptoms that are unique to each person with PD, thus requiring unique intervention needs for people with PD. Self-tracking can aid treatment for people with PD, by recording their experiences and responses to intervention. We conducted semi-structured interviews with 26 people with PD (PwPD), six caregivers (CGs), and three healthcare providers (HPs) to acquire a better understanding of their experiences with the strategies and challenges of self-tracking. Five tracking strategies were identified: mental tracking, analog tracking, tracking with general-purpose technology, specialized technology tracking, and tracking by proxy. We also uncovered challenges experienced during self-tracking, such as symptoms not always distinctive or easy to describe, inaccuracy of tracking, lack of perceived usefulness of tracked data, interaction barriers with technology, and lack of proper tracking tools. Our findings contribute to existing literature and yield insights to guide the inclusive design of self-tracking tools for PD. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",challenges; design guidelines; inclusive; Parkinson’s disease; self-tracking; strategies,Aids treatments; Challenge; Chronic illness; Condition; Design guideline; Inclusive; Parkinson's disease; Parkinson’s disease; Self-tracking; Strategy; Neurodegenerative diseases
Health Data Visualization Literacy Skills of Young Adults with Down Syndrome and the Barriers to Inference-making,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189682923&doi=10.1145%2f3648621&partnerID=40&md5=9bf50fc2adba57ddf186f0b580c7db65,"As health management becomes more intertwined with data, an individual’s ability to read, interpret, and engage with personal health information in data visualizations is increasingly critical to one’s quality of care. People with Down Syndrome already experience greater health disparities than their typically developing peers. Inaccessible health information and technologies have the potential to magnify inequities further. Inaccessible health data can be an additional barrier to people with Down Syndrome’s ability to adopt and use health systems or devices, make informed decisions about their bodies, and advocate for themselves in health contexts. By examining their underlying data visualization literacy skills, our exploratory study involving ten young adults with Down Syndrome identifies several design opportunities to improve the accessibility of health data visualizations (HDVs) by addressing the cascade of negative effects caused by inference-making barriers in HDVs. © 2024 Copyright held by the owner/author(s).",Accessibility; data visualization; Down Syndrome; health informatics; people with disabilities,Medical informatics; Visualization; Accessibility; Down's syndrome; Health data; Health disparities; Health informatics; Health management; People with disabilities; Personal health informations; Quality of care; Young adults; Data visualization
Stress Detection of Autistic Adults during Simulated Job Interviews Using a Novel Physiological Dataset and Machine Learning,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189666764&doi=10.1145%2f3639709&partnerID=40&md5=30890dd74f0e954267714a956b8e7009,"The interview process has been identified as one of the major barriers to employment of autistic individuals, which contributes to the staggering rate of under and unemployment of autistic adults. Decreasing stress during the interview has been shown to improve interview performance. However, in order to effectively provide insights on stress to both interviewees and interviewers, it is necessary to first effectively measure stress. This work explores physiological stress detection through wearable sensing as a means of obtaining quantitative stress measures from young autistic adults undergoing a virtual simulated interview using supervised machine learning techniques. Several supervised learning models were explored and it was found that Elastic Net Regression had the best accuracy with individual models with an accuracy of 84.8% while Support Vector Regression models evaluated with leave-one-out cross validation had a group accuracy of 75.4%. The predictions from the stress model were used with data visualization techniques in order to provide insights on the interview process from both a group and individual viewpoint, showing that stress trends can be found and evaluated using the stress model. This work also addresses a major gap in physiological stress detection literature by presenting a novel dataset of physiological data and ground truth labels for 15 autistic young adults undergoing a simulated interview. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",affective computing; Autism Spectrum Disorder; physiological stress detection; virtual job interview,Data visualization; E-learning; Learning systems; Regression analysis; Stresses; Support vector machines; Affective Computing; Autism spectrum disorders; Job interviews; Machine-learning; Performance; Physiological stress; Physiological stress detection; Stress detection; Stress models; Virtual job interview; Physiology
"Invisible, Unreadable, and Inaudible Cookie Notices: An Evaluation of Cookie Notices for Users with Visual Impairments",2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189659393&doi=10.1145%2f3641281&partnerID=40&md5=0504faf3360ba84bf148346b9c8895f1,"This article investigates the accessibility of cookie notices on websites for users with visual impairments (VI) via a set of system studies on top UK websites (n = 46) and a user study (n = 100). We use a set of methods and tools—including accessibility testing tools, text-only browsers, and screen readers—to perform our system studies. Our results demonstrate that the majority of cookie notices on these websites have some form of accessibility issue, including contrast issues, not having headings, and not being read aloud immediately when the page is loaded. We discuss how such practices impact the user experience and privacy and provide a set of recommendations for multiple stakeholders for more accessible websites and better privacy practices for users with VIs. To complement our technical contribution, we conduct a user study, finding that people with VIs generally have a negative view of cookie notices and believe our recommendations could help their online experience. © 2024 Copyright held by the owner/author(s).",Accessibility; assistive technology; cookie notices; screen readers; user privacy; visual impairments,Human engineering; Accessibility; Assistive technology; Cookie notice; Screen readers; System study; Testing tools; User privacy; User study; Users' experiences; Visual impairment; Websites
Measuring the Accuracy of Automatic Speech Recognition Solutions,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182596121&doi=10.1145%2f3636513&partnerID=40&md5=3a96270979d12a7172ffab806a569948,"For d/Deaf and hard of hearing (DHH) people, captioning is an essential accessibility tool. Significant developments in artificial intelligence mean that automatic speech recognition (ASR) is now a part of many popular applications. This makes creating captions easy and broadly available—but transcription needs high levels of accuracy to be accessible. Scientific publications and industry report very low error rates, claiming that artificial intelligence has reached human parity or even outperforms manual transcription. At the same time, the DHH community reports serious issues with the accuracy and reliability of ASR. There seems to be a mismatch between technical innovations and the real-life experience for people who depend on transcription. Independent and comprehensive data is needed to capture the state of ASR. We measured the performance of 11 common ASR services with recordings of Higher Education lectures. We evaluated the influence of technical conditions like streaming, the use of vocabularies, and differences between languages. Our results show that accuracy ranges widely between vendors and for the individual audio samples. We also measured a significant lower quality for streaming ASR, which is used for live events. Our study shows that despite the recent improvements of ASR, common services lack reliability in accuracy. © 2024 Copyright held by the owner/author(s).",captions; real time; subtitles; Transcription,Audition; Speech recognition; Automatic speech recognition; Caption; Error rate; Hard of hearings; Life experiences; Performance; Real- time; Scientific publications; Subtitle; Technical innovation; Artificial intelligence
Helping or Hindering: Inclusive Design of Automated Task Prompting for Workers with Cognitive Disabilities,2024,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182593460&doi=10.1145%2f3628447&partnerID=40&md5=afee301ad2696295a761f38173b40233,"Of the ∼8.8 million working-age adults with cognitive disabilities in the United States, only 28.6% are employed, contributing to a poverty rate (26.1%) for people with cognitive disabilities (PwCDs) that is more than twice that for people without disabilities. PwCDs who are employed are often still marginalized via reduced hours and pay, largely due to their more limited capability to perform work efficiently and independently. As evidence, warehouse and shelf stocking jobs that serve as employment for a significant percentage of PwCDs, often require frequent intervention from a job coach in the workplace, impacting the pay and self-esteem of these workers. This study’s objective was to remove barriers to employment for PwCD through inclusive design of technology supports in warehouse and similar settings. Specifically, a nonlinear context-aware prompting system (NCAPS) was developed, iteratively refined, and tested. In a pilot crossover study, subjects with cognitive disabilities participated in simulated work sessions, picking orders in a small warehouse environment using the NCAPS and industry standard paper tickets. Their performance was assessed in terms of errors and productivity, and their insights and perspectives were gathered. The resulting NCAPS prevented or corrected all errors for all but one participant. It also increased productivity for participants with the poorest baseline (paper ticket) performance, but decreased productivity for those with high baseline performance. No significant difference was observed in system usability scale (SUS) scores between methods. Topics emerging from user input highlighted the need for technological supports for PwCD to be simple and flexible in operation, and reliable to maintain user trust. By prioritizing robustness and intuitiveness, flexible technology supports can be developed to empower workers with a broad range of abilities, including those with temporary and situational impairments. Such tools would reduce barriers to employment, including stigma, discrimination, and other barriers to equity. © 2024 Copyright held by the owner/author(s).",assistive technology (AT); people with cognitive disabilities; prompting systems; technological supports; Vocational; warehouse navigation,Cognitive systems; Iterative methods; Warehouses; Assistive technology; Cognitive disability; Context-aware prompting; People with cognitive disability; Prompting system; Technological supports; Vocational; Warehouse navigation; Workers'; Employment
Guidelines for Designing Social Networking Sites for Older Adults: A Systematic Review with Thematic Synthesis,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173266970&doi=10.1145%2f3615662&partnerID=40&md5=84bd7da0a6e1c04debeee9d528642c82,"Social networking site (SNS) inaccessibility remains a barrier for many older adults. Increasingly, research has sought to address these shortcomings with recommendations for design. However, commercial uptake of these findings remains limited, in part, due to the scattering of recommendations across publications, heterogeneity in the SNS systems and features examined, and a lack of sensitivity within the existing guidelines to the heterogeneity of the target demographic. To counter these challenges, we conducted a systematic review following a thematic synthesis approach of 25 empirical studies on SNS design recommendations for older adults. From these, we synthesized a cohesive set of ten distinct design recommendations. These include ensuring an easy-to-use interface, improving social connection features, ensuring personal privacy, and introducing customized features and personalized content. In synthesizing the results, particular care was taken to capture the ways in which population diversity moderates recommendations. The results of this review can serve as a resource for designers and practitioners working on inclusive SNS for older adults. They also highlight the need for additional research into understanding user diversity in relation to SNS accessibility.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",design and usability; older adult; SNS; Social networking site,Design and usability; Design recommendations; Empirical studies; Older adults; Social networking site; Social-networking; Synthesised; Systematic Review; Social networking (online)
Supporting Social Inclusion with DIY-ATs: Perspectives of Kenyan Caregivers of Children with Cognitive Disabilities,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173583661&doi=10.1145%2f3616378&partnerID=40&md5=32c9137fe8eea9ddce2ca8c51bb9b35a,"Do-It-Yourself assistive technologies (DIY-ATs) that can be designed, fabricated, or customized by non-technical individuals can enable people with disabilities and their community members to create and customize their own technological solutions. DIY-ATs may better fit user needs than mass-produced alternatives. Recently, researchers have started to explore the possibilities and challenges of using DIY-ATs in contexts other than the Global North, where access to digital ATs is limited. Previous research has not yet studied the perspectives of caregivers of children with disabilities towards these technologies. We present findings from an interview study with caregivers of children and youth with cognitive disabilities in Western Kenya who used a DIY-AT system as a research probe. Participants described how negative beliefs about people with disabilities result in social exclusion and discrimination and explained how increased opportunities for social interaction and learning mediated through DIY and other customizable ATs for their children could support their inclusion, safety, and access to future opportunities. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",disability; DIY assistive technologies; interdependence; Kenya; participatory design,Engineering education; Assistive technology; Cognitive disability; Disability; DIY assistive technology; Do it yourself; Interdependence; Kenya; Participatory design; People with disabilities; Social inclusion; Assistive technology
"""Why are there so many steps?"": Improving Access to Blind and Low Vision Music Learning through Personal Adaptations and Future Design Ideas",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173285987&doi=10.1145%2f3615663&partnerID=40&md5=de26f85e769fbdd3c63297cafe0fba56,"Music can be a catalyst for self-development, creative expression, and community building for blind or low vision (BLV) individuals. However, BLV music learners face complex obstacles in learning music. They are highly reliant on their learning environment and music teachers for accommodations and flexibility. Prior research identified the challenges faced by BLV musicians. Yet, limited research has addressed these challenges through the development of technology. Drawing upon the experience and suggestions of 40 BLV professional musicians, amateur musicians and music teachers (including sighted teachers with experience teaching blind students), we identified five themes: (1) Key Challenges of BLV Music Learning, (2) Personal Adaptations to Overcome Music Learning Challenges, (3) Perspectives on Current and Future Assistive Technologies, (4) Contention Between Braille Music and Auditory Learning, and (5) Role of Human Support for Music Learning. Together, these findings outline a path to make music learning more accessible to BLV people. To this end, we describe opportunities for enhanced audio cues for musical communication, recommend integrating vibrotactile feedback to aid music reading and design technology that supports independence and interdependence in music learning.  © 2023 Copyright held by the owner/author(s).",assistive technologies for music learning; Blind music learning; music pedagogy; self developed strategies,Audio acoustics; Computer aided instruction; Engineering education; Assistive technology; Assistive technology for music learning; Blind music learning; Design ideas; Future designs; Low vision; Music pedagogy; Personal adaptations; Self developed strategy; Teachers'; Music
Performance and Pleasure: Exploring the Perceived Usefulness and Appeal of Physical Activity Data Visualizations with Older Adults,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173576636&doi=10.1145%2f3615664&partnerID=40&md5=e76bc2516a17c5ed6e4ff12f695c18d9,"Wearable activity trackers hold the promise of making older adults aware of their levels of physical activity (PA), encouraging them to remain or become physically active. However, little is known about older adults' preferences regarding data visualizations of PA, which is of concern as many of the currently implemented visualizations strongly emphasize performance. In our work, we present findings from a study (N = 44) in which we combined semi-structured interviews and an online survey to explore different approaches towards visualizing PA data for older adults. Through thematic analysis and statistical analysis, we highlight that visualizations' perceived usefulness and appeal is individual and mediated by the lived experiences of late life, and that the potential of performance and pleasure can be leveraged to be complementary. On this basis, we discuss design opportunities for visualizations of PA data specifically addressing the needs of older adults from the perspective of PA in late life. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Older adults; performance; physical activity; pleasure; visualizations,Older adults; Online surveys; Perceived usefulness; Performance; Physical activity; Pleasure; Semi structured interviews; Thematic analysis; Visualization
Digital Musical Instruments in Special Educational Needs Schools: Requirements from the Music Teachers' Perspective and the Status Quo in Germany,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173246486&doi=10.1145%2f3616015&partnerID=40&md5=f7a9ed30a73446cf17993d624996a149,"Digital musical instruments (DMIs) offer the possibility to create barrier-free access to active music-making and to unique sound aesthetics for a broad group of people, including those who experience disabling barriers to access when using traditional acoustic musical instruments. However, current music education research focuses primarily on app-based DMIs. Although these devices have numerous advantages, such as ubiquitous availability and flexibility, they may be experienced as disabling by people with severe cognitive or complex disabilities. Thus, they only partially exploit the potential of DMIs for special educational needs (SEN) music practices, which we outline in this article. However, given that no comprehensive studies have yet been conducted on the use of DMIs in SEN schools, the actual motives and barriers for SEN school teachers to employ different types of DMIs in class are largely unknown. To address this research gap, we present the results of a quantitative survey covering all SEN schools in 12 of Germany's 16 federal states. We surveyed the status quo of DMI use in SEN schools and the perceived potential of DMIs and DMI-related information needs from the music teachers' perspective. Our findings demonstrate that DMIs are only rarely used in Germany, with the exception of established standard DMIs such as keyboards and music apps. Unfortunately, accessible DMIs (ADMIs) are hardly used. Related to the rare use of DMIs in SEN schools, we also identified a lack of domain-specific knowledge among music teachers and concluded that there was a need to develop DMIs specifically designed for use in classroom education. Finally, we discuss the potential of using open-source DMI technology as well as the importance of identifying music teachers' attitudes during DMI development.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Assistive music technology; inclusion; music education; special needs education,Assistive technology; Domain Knowledge; E-learning; Music; Assistive; Assistive music technology; Barrier-free; Free access; Music education; Music technologies; Special educational needs; Special needs educations; Status quo; Teachers'; Musical instruments
Introduction to the Special Issue on ASSETS'21,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168979311&doi=10.1145%2f3605947&partnerID=40&md5=e655415ef42e2e4cdc1cfbc62e663b45,[No abstract available],,
The Design and Prototyping of an App to Teach Adults with Intellectual and Developmental Disabilities to Empower Them Against Abuse,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168759456&doi=10.1145%2f3569585&partnerID=40&md5=30708c5f1dd545daa97c300ab98f1c02,"In the United States, the abuse of individuals with intellectual and developmental disabilities (I/DD) is at epidemic proportions. However, the reporting of such abuse has been severely lacking. It has been found that individuals with I/DD are more aware of when and how to report abuse when they have received abuse-prevention training. Consequently, in this article we present the design and prototyping of a mobile-computing app called Recognize that empowers adults with I/DD to independently learn about abuse. To this end, we first conducted an auto-ethnographic co-design of Recognize with individuals and self-advocates from the I/DD community. Next, based on the outcomes from the co-design process, we developed three initial prototype variants of Recognize and performed a preliminary user study with six individuals with I/DD who have experience teaching others with I/DD about abuse. Based on the findings of this preliminary user study, we created a consolidated prototype of Recognize and performed a more detailed qualitative user study with 11 individuals with I/DD who represented the eventual users of Recognize. The participants in this user study found it to be viable for use by individuals with I/DD. We end the article with a discussion of the implications of our findings toward the development of a deployable version of Recognize and similar apps. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",abuse; developmental disability; education; Empowerment; intellectual disability; user study,Abuse; Co-designs; Design-process; Developmental disability; Empowerment; Intellectual disability; Learn+; Mobile-computing; Prevention training; User study; Design
"Understanding the Usages, Lifecycle, and Opportunities of Screen Readers' Plugins",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168764441&doi=10.1145%2f3582697&partnerID=40&md5=a0c011c55d49ee888e9459d001c4df95,"Screen reader plugins are small pieces of code that blind users can download and install to enhance the capabilities of their screen readers. This article aims to understand why blind users use these plugins, as well as how these plugins are developed, deployed, and maintained. To this end, we conducted an interview study with 14 blind users to gain individual perspectives and analyzed 2,000 online posts scraped from three plugin-related forums to gain the community perspective. Our study revealed that screen reader users rely on plugins for various reasons, such as to improve the usability of screen readers and application software, to make partially accessible applications accessible, and to receive custom auditory feedback. Furthermore, installing plugins is easy; uninstalling them is unlikely; and finding them online is ad hoc, challenging, and sometimes poses security threats. In addition, developing screen reader plugins is technically demanding; only a handful of people develop plugins. Unfortunately, most plugins do not receive updates once distributed and become obsolete. The lack of financial incentives plays in the slow growth of the plugin ecosystem. Further, we outlined the complex, tripartite collaboration among individual blind users, their online communities, and developer communities in creating a plugin. Additionally, we reported several phenomena within and between these communities that are likely to influence a plugin's development. Based on our findings, we recommend creating a community-driven repository for all plugins hosted on a peer-to-peer infrastructure, engaging third-party developers, and raising general awareness about the benefits and dangers of plugins. We believe our findings will inspire HCI researchers to embrace the plugin-based distribution model as an effective way to combat accessibility and usability problems in non-visual interaction and to investigate potential ways to improve the collaboration between blind users and developer communities. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",assistive technology; extension; NVDA; plugin; screen reader; scripts; visual impairments,Life cycle; Applications software; Assistive technology; Blind users; Extension; Interview study; NVDA; Plug-ins; Screen readers; Script; Visual impairment; Application programs
How the Alt Text Gets Made: What Roles and Processes of Alt Text Creation Can Teach Us AboutInclusive Imagery,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769113&doi=10.1145%2f3587469&partnerID=40&md5=23bbad2c1c43e00e399b8489fc5b6721,"Many studies within Accessible Computing have investigated image accessibility, from what should be included in alternative text (alt text), to possible automated, human-in-the-loop, or crowdsourced approaches to alt text generation. However, the processes through which practitioners make alt text in situ have rarely been discussed. Through interviews with three artists and three accessibility practitioners working with Google, as well as 25 end users, we identify four processes of alt text creation used by this company - The User-Evaluation Process, The Lone Writer Process, The Team Write-A-Thon Process, and The Artist-Writer Process - and unpack their potential strengths and weaknesses as they relate to access and inclusive imagery. We conclude with a discussion of what alt text researchers and industry professionals can learn from considering alt text in situ, including opportunities to support user feedback, cross-contributor consistency, and organizational or technical changes to production processes. © 2023 Copyright held by the owner/author(s).",accessibility practitioners; Alt text creation processes; image accessibility; inclusive imagery,Accessibility practitioner; Alt text creation process; Creation process; End-users; Google+; Human-in-the-loop; Image accessibility; Inclusive imagery; Text generations; User evaluations; Petroleum reservoir evaluation
Machine Generation of Audio Description for Blind and Visually Impaired People,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769594&doi=10.1145%2f3590955&partnerID=40&md5=4139126fb1123e34330c9892dc82df4f,"Automating the generation of audio descriptions (AD) for blind and visually impaired (BVI) people is a difficult task, since it has several challenges involved, such as: identifying gaps in dialogues; describing the essential elements; summarizing and fitting the descriptions into the dialogue gaps; generating an AD narration track, and synchronizing it with the main soundtrack. In our previous work (Campos et al. [6]), we propose a solution for automatic AD script generation, named CineAD, which uses the movie's script as a basis for the AD generation. This article proposes extending this solution to complement the information extracted from the script and reduce its dependency based on the classification of visual information from the video. To assess the viability of the proposed solution, we implemented a proof of concept of the solution and evaluated it with 11 blind users. The results showed that the solution could generate a more succinct and objective AD but with a similar users' level of understanding compared to our previous work. Thus, the solution can provide relevant information to blind users using less video time for descriptions.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",accessibility; Audio description; automatic; people with visual impairment,Accessibility; Audio description; Automatic; Blind and visually impaired; Blind users; Essential elements; People with visual impairment; Script generation; Visual impairment; Visually impaired people; Classification (of information)
Mathematical Content Browsing for Print-disabled Readers Based on Virtual-world Exploration and Audio-visual Sensory Substitution,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163978296&doi=10.1145%2f3584365&partnerID=40&md5=cc228b5eb47c1a6deb0e5a818b84ff0b,"Documents containing mathematical content remain largely inaccessible to blind and visually impaired readers because they are predominantly published as untagged PDFs, which do not include the semantic data necessary for effective accessibility. Equations in such documents consist of text interlaced with lines and other graphical elements and cannot be interpreted using a screen reader. We present a browsing approach for print-disabled readers specifically aimed at such mathematical content. This approach draws on the navigational mechanisms often used to explore the virtual worlds of text adventure games with audio-visual sensory substitution for graphical content. The relative spatial placement of the elements of an equation are represented as a virtual world so the reader can navigate between elements. Text elements are announced conventionally using synthesised speech, while graphical elements, such as roots and fraction lines, are rendered using a modification of the vOICe algorithm. The virtual world allows the reader to interactively discover the spatial structure of the equation, while the rendition of graphical elements as sound allows the shape and identity of elements that cannot be synthesised as speech to be discovered and recognised. The browsing approach was evaluated by 11 blind and 14 sighted participants in a user trial that included identifying twelve equations extracted from PDF documents. Overall, equations were identified completely correctly in 78% of cases (74% and 83%, respectively, for blind and sighted subjects). If partial correctness is considered, then the performance is substantially higher. Feedback from the blind subjects indicated that the technique allows spatial information and graphical detail to be discovered. We conclude that the integration of a spatial model represented as a virtual world in conjunction with audio-visual sensory substitution for non-textual elements can be an effective way for blind and visually impaired readers to read currently inaccessible mathematical content in PDF documents. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; mathematics; sensory substitution; virtual worlds,Air navigation; Data visualization; Interactive computer graphics; Virtual reality; Accessibility; Audio-visual; Blind and visually impaired; Content browsing; Graphical elements; PDF document; Semantic data; Sensory substitution; Virtual worlds; Visual sensory; Semantics
"Experimental Evaluation of Multi-scale Tactile Maps Created with SIM, a Web App for Indoor Map Authoring",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161946181&doi=10.1145%2f3590775&partnerID=40&md5=b6bc2121fc4f098c18e263548c561879,"In this article, we introduce Semantic Interior Mapology (SIM), a web app that allows anyone to quickly trace the floor plan of a building, generating a vectorized representation that can be automatically converted into a tactile map at the desired scale. The design of SIM is informed by a focus group with seven blind participants. Maps generated by SIM at two different scales have been tested by a user study with 10 participants, who were asked to perform a number of tasks designed to ascertain the spatial knowledge acquired through map exploration. These tasks included cross-map pointing and path finding, and determination of turn direction/walker orientation during imagined path traversal. By and large, participants were able to successfully complete the tasks, suggesting that these types of maps could be useful for pre-journey spatial learning.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Tactile maps,Semantics; Experimental evaluation; Floorplans; Focus groups; Multi-scales; Path finding; Path traversals; Spatial knowledge; Tactile maps; User study; Web App; Maps
Introduction to the Special Issue on W4A’21,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159300858&doi=10.1145%2f3587165&partnerID=40&md5=8b6787bcf3720608f1bc9d64fe430684,[No abstract available],,
WordMelodies: Supporting the Acquisition of Literacy Skills by Children with Visual Impairment through a Mobile App,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152627625&doi=10.1145%2f3565029&partnerID=40&md5=aac45827f28541085abbb94eab0d3832,"WordMelodies is a mobile app that aims to support inclusive teaching of literacy skills for primary school students. Thus it was designed to be accessible both visually and through screen reader, and it includes over 80 different types of exercises for practicing literacy skills, each with adjustable difficulty levels, in Italian and in English. WordMelodies is freely available for iOS and Android devices. However, it has not been previously evaluated with children having visual impairments. Thus, in this article, we evaluate the app usability, its perceived ease of use, appreciation and children's autonomy while using it, as well as the characteristics of the end users. To achieve this, we conducted a user study with 11 primary school students with visual impairments, and we analyzed app usage logs collected from 408 users in over 1 year from the app publication. We show that app usability is high, and most exercises can be completed autonomously. The exercises are also perceived to be easy to perform, and they are appreciated by the participants. Finally, we provide insights on how to address the identified app limitations and propose future research directions.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",literacy education; mobile edutainment apps; Visual impairment,E-learning; Students; End-users; Literacy education; Mobile app; Mobile edutainment; Mobile edutainment app; Perceived ease-of-use; Primary schools; School students; Screen readers; Visual impairment; Ophthalmology
"Tangible Progress: Tools, Techniques, and Impacts of Teaching Web Development to Screen Reader Users",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152622977&doi=10.1145%2f3585315&partnerID=40&md5=dd4c6fbd76046a38a690b3ad27bba462,"Despite a growing demand for Web Development and adjacent tech skills, there is a lack of accessible skills training for screen reader users. To address this gap, we developed tools and techniques to support screen reader users in learning web development. In this article, we describe our design, implementation, and evaluation of a nine-week web development workshop, designed to introduce screen reader users to HTML, CSS, and JavaScript. We taught the remote workshop using synchronous lectures followed by one-on-one time with Teaching Assistants (TAs) and included a resource-rich website, tactile diagrams, and discussion forum. We evaluated the effectiveness of our tools and the impact of the workshop during, immediately following, and one year after the workshop. At its conclusion, students demonstrated their knowledge of web development basics by creating and publishing their own websites; showed an increase in self-efficacy; and maintained a high level of interest in the subject. Participation also benefited TAs who reported increased confidence in understanding accessibility concepts, increased interest in pursuing work related to accessibility, and plans to apply what they learned. One year after the workshop, both students and TAs reported a lasting impact. Most notably, students had applied their understanding of design concepts, reported that the workshop helped them prepare for career changes or helped them in their current job functions, and that it gave them both the language and confidence to problem-solve web and accessibility issues. TAs felt that the workshop broadened their understanding of blind students' abilities; especially when provided with accessible materials and tools, it gave them a better understanding of digital accessibility and assistive technologies, and they shared examples of how they continue to apply learnings and advocate for accessibility. Based on these findings, we recommend techniques and tools to support screen reader users' learning web development, the inclusion of job-focused sub-topics, and suggestions for engaging with post-secondary institutions to pair service learning with tech skills training. We close with recommendations for implementing and adapting the workshop using our open-educational materials to expand the availability and breadth of accessible tech skills training and co-learning experiences for post-secondary students.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; accessible web design; accessible web development; blind programmers; human-centered computing; screen reader,Web Design; Accessibility; Accessible web design; Accessible web development; Blind programmer; Growing demand; Human-centered computing; Screen readers; Skill training; Teaching assistants; Web development; Students
"""It could be better. It could be much worse"": Understanding Accessibility in User Experience Practice with Implications for Industry and Education",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152621891&doi=10.1145%2f3575662&partnerID=40&md5=f09b0dbf989cd1bdd841db7fb043d189,"While accessibility is acknowledged as a crucial component in design, many technologies remain inaccessible for people with disabilities. As part of a study to better understand UX practice to inform pedagogy, we analyzed 58 interview sessions that included 65 senior user experience (UX) professionals and asked them ""How do you consider accessibility in your work?""Using transitivity analysis from critical discourse analysis, our findings provide insight into the disparate practices of individuals and organizations. Key findings include the growing role of design systems to structurally address accessibility and the range of organizational strategies, including dedicated teams. We also found that the categories of accessibility consideration were somewhat superficial and largely focused on vision-related challenges. Additionally, our findings support previous work that many practitioners did not feel their formal education adequately prepared them to address accessibility. We conclude with implications for education and industry, namely, the importance of implementing and teaching design systems in human-computer interaction and computer-science programs.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; design systems; industry practice; user experience practice,Engineering education; User interfaces; Accessibility; Critical discourse analysis; Design systems; Formal education; Industry practices; Organizational strategy; People with disabilities; Senior user; User experience practice; Users' experiences; Human computer interaction
Enriching Social Sharing for the Dementia Community: Insights from In-Person and Online Social Programs,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152633048&doi=10.1145%2f3582558&partnerID=40&md5=c7bbba9973e99a5fd8fa97319e71a640,"The dementia community faces major challenges in social engagements, which have been further complicated by the prolonged physical distancing measures due to the COVID-19 pandemic. Designing digital tools for in-person social sharing in family and care facility settings has been well explored, but comparatively little HCI work has focused on the design of community-based social technologies for virtual settings. We present our virtual fieldwork on remote social activities explored by one dementia community in response to the impacts of the pandemic. Building upon our previously published on-site fieldwork in this community, we expand on our initial publication by follow-up interviewing caregivers and facilitators and reflecting on a virtual social program. Through thematic analysis and contrasting in-person and online formats of the program, we deepened the understanding of virtual social engagements of the dementia community, examining their efforts to leverage physical objects and environments, enhance open and flexible experiences, and expand collaborative space. We propose to open new design opportunities through holistic approaches, including reimagining community social spaces, rethinking agency in people with dementia and caregivers, and diversifying HCI support across communities and stakeholders.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",assistive technology; community-based research; Social computing; videoconferencing,Digital devices; Neurodegenerative diseases; Assistive technology; Community based research; Community-based; Digital tools; Social computing; Social engagement; Social projects; Social sharing; Social technologies; Videoconferencing; Video conferencing
"The Transparency of Automatic Web Accessibility Evaluation Tools: Design Criteria, State of the Art, and User Perception",2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146544931&doi=10.1145%2f3556979&partnerID=40&md5=98b65afc8d75be5ee090e7505c3ee1e6,"Several Web accessibility evaluation tools have been put forward to reduce the burden of identifying accessibility barriers for users, especially those with disabilities. One common issue in using accessibility evaluation tools in practice is that the results provided by different tools are sometimes unclear, and often diverging. Such limitations may confuse the users who may not understand the reasons behind them, and thus hamper the possible adoption of such tools. Hence, there is a need for tools that shed light on their actual functioning, and the success criteria and techniques supported. For this purpose, we must identify what criteria should be adopted in order for such tools to be transparent and to help users better interpret their results. In this paper, we discuss such issues, provide design criteria for obtaining user-centred and transparent accessibility evaluation tools, and analyse how they have been addressed by a representative set of open, license-free, accessibility tools. We also report on the results of a survey with 138 users of such tools, aimed at capturing the perceived usefulness of previously identified transparency requirements. Finally, we performed a user study with 18 users working in the Web design or accessibility fields with the goal of receiving more feedback about the transparency of a selected subset of accessibility tools.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; automatic validation tools; transparency,Web Design; Accessibility; Accessibility evaluation; Automatic validation; Automatic validation tool; Design criteria; Evaluation tool; State of the art; Tool designs; Validation tools; Web accessibility; Transparency
AccessComics2: Understanding the User Experience of an Accessible Comic Book Reader for Blind People with Textual Sound Effects,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152635752&doi=10.1145%2f3555720&partnerID=40&md5=0f12da6c872304fb5fffa6f0ab2edb99,"For people with visual impairments, many studies have been conducted to improve the accessibility of various types of images on the web. However, the majority of the work focused on photos or graphs. In this study, we propose AccessComics, an accessible digital comic book reader for people with visual impairments. To understand the accessibility of existing platforms, we first conducted a formative online survey with 68 participants who are blind or have low vision asking about their prior experiences with audiobooks and eBooks. Then, to learn the implications of designing an accessible comic book reader for people with visual impairments, we conducted an interview study with eight participants and collected feedback about our system. Considering our findings that a brief description of the scene and sound effects are desired when listening to comic books, we conducted a follow-up study with 16 participants (8 blind, 8 sighted) to explore how to effectively provide scene descriptions and sound effects, generated based on the onomatopoeia and mimetic words that appear in comics. Then we assessed the impact of the overall reading experience and if it differs depending on the user group. The results show that the presence of scene descriptions was perceived to be useful for concentration and understanding the situation, while the sound effects were perceived to make the book-reading experience more immersive and realistic. Based on the findings, we suggest design implications specifying features that future accessible comic book readers should support.  © 2023 Association for Computing Machinery.",audiobooks; blind; Comics; eBooks; onomatopoeia/mimetic words; people with visual impairments; scene descriptions; screen readers; sound effects; textual sound effects,Electronic publishing; Audiobook; Blind; Comic; E-books; Mimetics; Onomatopoeia/mimetic word; People with visual impairment; Scene description; Screen readers; Sound effects; Textual sound effect; Visual impairment; Image enhancement
Creating 'a Simple Conversation': Designing a Conversational User Interface to Improve the Experience of Accessing Support for Study,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152629514&doi=10.1145%2f3568166&partnerID=40&md5=cf73cb4da1c7500e6e1a8d3ad845b1d9,"Administrative processes are ubiquitous in modern life and have been identified as a particular burden to those with accessibility needs. Students who have accessibility needs often have to understand guidance, fill in complex forms, and communicate with multiple parties to disclose disabilities and access appropriate support. Conversational user interfaces (CUIs) could allow us to reimagine such processes, yet there is currently limited understanding of how to design these to be accessible, or whether such an approach would be preferred. In the ADMINS (Assistants for the Disclosure and Management of Information about Needs and Support) project, we implemented a virtual assistant (VA) which is designed to enable students to disclose disabilities and to provide guidance and suggestions about appropriate support. ADMINS explores the potential of CUIs to reduce administrative burden and improve the experience of arranging support by replacing a static form with written or spoken dialogue. This article reports the results of two trials conducted during the project. A beta trial using an early version of the VA provided understanding of accessibility challenges and issues in user experience. The beta trial sample included 22 students who had already disclosed disabilities and 3 disability support advisors. After improvements to the design, a larger main trial was conducted with 134 students who disclosed their disabilities to the university using both the VA and the existing form-based process. The results show that the VA was preferred by most participants to completing the form (64.9% vs 23.9%). Qualitative and quantitative feedback from the trials also identified accessibility and user experience barriers for improving CUI design, and an understanding of benefits and preferences that can inform further development of accessible CUIs for this design space.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",accessibility; artificial intelligence; chatbots; Conversational user interfaces; trial; user experience; virtual assistants,Students; User experience; Accessibility; Administrative process; Chatbots; Complex forms; Conversational user interface; Provide guidances; Simple++; Trial; Users' experiences; Virtual assistants; User interfaces
The Accessibility of Data Visualizations on the Web for Screen Reader Users: Practices and Experiences During COVID-19,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152624036&doi=10.1145%2f3557899&partnerID=40&md5=fb6f34109b26a2227a3e66361a86a155,"Data visualization has become an increasingly important means of effective data communication and has played a vital role in broadcasting the progression of COVID-19. Accessible data representations, however, have lagged behind, leaving areas of information out of reach for many blind and visually impaired (BVI) users. In this work, we sought to understand (1) the accessibility of current implementations of visualizations on the web; (2) BVI users' preferences and current experiences when accessing data-driven media; (3) how accessible data representations on the web address these users' access needs and help them navigate, interpret, and gain insights from the data; and (4) the practical challenges that limit BVI users' access and use of data representations. To answer these questions, we conducted a mixed-methods study consisting of an accessibility audit of 87 data visualizations on the web to identify accessibility issues, an online survey of 127 screen reader users to understand lived experiences and preferences, and a remote contextual inquiry with 12 of the survey respondents to observe how they navigate, interpret, and gain insights from accessible data representations. Our observations during this critical period of time provide an understanding of the widespread accessibility issues encountered across online data visualizations, the impact that data accessibility inequities have on the BVI community, the ways screen reader users sought access to data-driven information and made use of online visualizations to form insights, and the pressing need to make larger strides towards improving data literacy, building confidence, and enriching methods of access. Based on our findings, we provide recommendations for researchers and practitioners to broaden data accessibility on the web.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Accessibility; accessible data visualization; audit; blind; data visualization; user experience; visually impaired; web accessibility,Navigation; Visualization; Accessibility; Accessible data visualization; Audit; Blind; Blind and visually impaired users; Data representations; Screen readers; Users' experiences; Visually impaired; Web accessibility; Data visualization
Video Conferencing Tools: Comparative Study of the Experiences of Screen Reader Users and the Development of More Inclusive Design Guidelines,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152634756&doi=10.1145%2f3573012&partnerID=40&md5=f635cc956ee1757afa475c0d70c32105,"Since the first lockdown in 2020, video conferencing tools have become increasingly important for employment, education, and social interaction, making them essential tools in everyday life. This study investigates the accessibility and usability of the desktop and mobile versions of three popular video conferencing tools, Zoom, Google Meet, and MS Teams, for visually impaired people interacting via screen readers and keyboard or gestures. This involved two inspection evaluations to test the most important features of the desktop and mobile device versions and two surveys of visually impaired users to obtain information about the accessibility of the selected video conferencing tools. Sixty-five people answered the survey for desktop and 94 for mobile platforms. The results showed that Zoom was preferred to Google Meet and MS Teams but that none of the tools was fully accessible via screen reader and keyboard or gestures. Finally, the results of this empirical study were used to develop a set of guidelines for designers of video conferencing tools and assistive technology.  © 2023 Association for Computing Machinery.",accessibility; blind people; evaluation methodology; guidelines; screen reader; screen reader users; survey; Videoconferencing tools,Assistive technology; Accessibility; Blind people; Evaluation methodologies; Google+; Guideline; Screen reader user; Screen readers; Video-conferencing; Videoconferencing tool; Video conferencing
Accuracy and Reliability of At-Home Quantification of Motor Impairments Using a Computer-Based Pointing Task with Children with Ataxia-Telangiectasia,2023,ACM Transactions on Accessible Computing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152628292&doi=10.1145%2f3581790&partnerID=40&md5=c0324324f2bd1167aa10ccc8a7c6efa0,"Methods for obtaining accurate quantitative assessments of motor impairments are essential in accessibility research, design of adaptive ability-based assistive technologies, as well as in clinical care and medical research. Currently, such assessments are typically performed in controlled laboratory or clinical settings under professional supervision. Emerging approaches for collecting data in unsupervised settings have been shown to produce valid data when aggregated over large populations, but it is not yet established whether in unsupervised settings measures of research or clinical significance can be collected accurately and reliably for individuals. We conducted a study with 13 children with ataxia-telangiectasia and 9 healthy children to analyze the validity, test-retest reliability, and acceptability of at-home use of a recent active digital phenotyping system, called Hevelius. Hevelius produces 32 measures derived from the movement trajectories of the mouse cursor and then generates a quantitative estimate of motor impairment in the dominant arm using the dominant arm component of the Brief Ataxia Rating Scale (BARS). The severity score estimates generated by Hevelius from single at-home sessions deviated from clinician-assigned BARS scores more than the severity score estimates generated from single sessions conducted under researcher supervision. However, taking a median of as few as 2 consecutive sessions produced severity score estimates that were as accurate or better than the estimates produced from single supervised sessions. Further, aggregating as few as 2 consecutive sessions resulted in good test-retest reliability (ICC = 0.81 for A-T participants). This work demonstrated the feasibility of performing accurate and reliable quantitative assessments of individual motor impairments in the dominant arm through tasks performed at home without supervision by the researchers. Further work is needed, however, to assess how broadly these results generalize.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Active digital phenotyping; ataxia; ataxia-telangiectasia; motor impairments; remote assessment,Clinical research; Mammals; Population statistics; Active digital phenotyping; Ataxia; Ataxia telangiectasia; Motor impairments; Phenotyping; Pointing tasks; Quantitative assessments; Rating scale; Remote assessment; Test-retest reliability; Reliability
