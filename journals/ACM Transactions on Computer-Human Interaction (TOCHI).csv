Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
Demonstrational and Constraint-Based Techniques for Pictorially Specifying Application Objects and Behaviors,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722764&doi=10.1145%2f212430.212443&partnerID=40&md5=3ab318e2da8430e14a0ceb71def87e42,[No abstract available],,
Internal Representation and Rule Development in Object-Oriented Design,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976811583&doi=10.1145%2f212430.212450&partnerID=40&md5=0f22d7a1110332c82e20ac83e6877f61,[No abstract available],,
Evaluation of the CyberGlove as a Whole-Hand Input Device,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722021&doi=10.1145%2f212430.212431&partnerID=40&md5=5eeadbfb8d0bd952040333da903703d7,"We present a careful evaluation of the sensory characteristics of the CyberGlove model CG1801 whole-hand input device. In particular, we conducted an experimental study that investigated the level of sensitivity of the sensors, their performance in recognizing angles, and factors that affected accuracy of recognition of flexion measurements. Among our results, we show that hand size differences among the subjects of the study did not have a statistical effect on the accuracy of the device.We also analyzed the effect of different software calibration approaches on accuracy of the sensors. © 1995, ACM. All rights reserved.",CyberGlove<sup>TM</sup>; device evaluation; hand input; input devices,
Development and Evaluation of Hypermedia for Museum Education: Validation of Metrics,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976713505&doi=10.1145%2f212430.212435&partnerID=40&md5=30b2d1df21ff3992fbd46e3f17e68f73,[No abstract available],,
"Relief from the Audio Interface Blues: Expanding the Spectrum of Menu, List, and Form Styles",1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976815693&doi=10.1145%2f210181.210183&partnerID=40&md5=071e50f5e5d8667f575e5909ce73d2d0,"Menus, lists, and forms are the workhorse dialogue structures in telephone-based interactive voice response applications. Despite diversity in applications, there is a surprising homogeneity in the menu, list, and form styles commonly employed. There are, however, many alternatives, and no single style fits every prospective application and user population. A design space for each dialogue structure organizes the alternatives and provides a framework for analyzing their benefits and drawbacks. In addition to phone-based interactions, the design spaces apply to any limited-bandwidth, temporally constrained display devices, including small-screen devices such as personal digital assistants 1995 and screen phones. © 1995, ACM. All rights reserved.",ADSI; forms; interactive voice response(IVR); menus; PDA; skip and scan; voice mail,
HoloSketch: A Virtual Reality Sketching / Animation Tool,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976837910&doi=10.1145%2f210079.210087&partnerID=40&md5=e0a1715f32b59bdc7a8e01f5584ea0bf,[No abstract available],,
Developing a Reflective Model of Collaborative Systems,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976792652&doi=10.1145%2f200968.200970&partnerID=40&md5=6a0744e2ba6b04bdccab0511508097f4,"Recent years have seen a shift in perception of the nature of HCI and interactive systems. As interface work has increasingly become a focus of attention for the social sciences, we have expanded our appreciation of the importance of issues such as work practice, adaptation, and evolution in interactive systems. The reorientation in our view of interactive systems has been accompanied by a call for a new model of design centered around user needs and participation. This article argues that a new process of design is not enough and that the new view necessitates a similar reorientation in the structure of the systems we build. It outlines some requirements for systems that support a deeper conception of interaction and argues that the traditional system design techniques are not suited to creating such systems. Finally, using examples from ongoing work in the design of an open toolkit for collaborative applications, it illustrates how the principles of computational reflection and metaobject protocols can lead us toward a new model based on open abstraction that holds great promise in addressing these issues. © 1995, ACM. All rights reserved.",Collaborative applications; computational reflection; meta-object protocol; open implementations; system architecture,
MASSIVE: A Collaborative Virtual Environment for Teleconferencing,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976795669&doi=10.1145%2f210079.210088&partnerID=40&md5=c7f4005ed982e674efb401ef533bddf0,[No abstract available],,
"Chiron-1: A Software Architecture for User Interface Development, Maintenance, and Run-Time Support",1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976839228&doi=10.1145%2f210181.210182&partnerID=40&md5=126ce8c9aefcfe59f5a5711f174a7aba,"The Chiron-1 user interface system demonstrates key techniques that enable a strict separation of an application from its user interface. These techniques include separating the control-flow aspects of the application and user interface: they are concurrent and may contain many threads. Chiron also separates windowing and look-and-feel issues from dialogue and abstract presentation decisions via mechanisms employing a client-server architecture. To separate application code from user interface code, user interface agents called artists are attached to instances of application abstract data types 1995. Operations on ADTs within the application implicitly trigger user interface activities within the artists. Multiple artists can be attached to ADTs, providing multiple views and alternative forms of access and manipulation by either a single user or by multiple users. Each artist and the application run in separate threads of control. Artists maintain the user interface by making remote calls to an abstract depiction hierarchy in the Chiron server, insulting the user interface code from the specifics of particular windowing systems and toolkits. The Chiron server and clients execute in separate processes. The client-server architecture also supports multilingual systems: mechanisms are demonstrated that support clients written in programming languages other than that of the server while nevertheless supporting object-oriented server concepts. The system has been used in several universities and research and development projects. It is available by anonymous ftp. © 1995, ACM. All rights reserved.",artists; client-server; concurrency; event-based integration; user interface architectures,
Introduction to the Special Issue on Virtual Reality Software and Technology,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976668320&doi=10.1145%2f210079.214028&partnerID=40&md5=a01d10469b210d650ac24ba0f066c28b,[No abstract available],,
An Approach to Natural Gesture in Virtual Environments,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976695784&doi=10.1145%2f210079.210080&partnerID=40&md5=06f4226811d2de15b0052127388c49e0,"This article presents research—an experiment and the resulting prototype—on a method for treating gestural input so that it can be used for multimodal applications, such as interacting with virtual environments. This method involves the capture and use of natural, empty-hand gestures that are made during conventional descriptive utterances. Users are allowed to gesture in a normal continuous manner, rather than being restricted to a small set of discrete gestural commands as in most other systems. The gestures are captured and analyzed into a higher-level description. This description can be used by an application-specific interpreter to understand the gestural input in its proper context. Having a gesture analyzer of this sort enables natural gesture input to any appropriate application. © 1995, ACM. All rights reserved.",Design; Experimentation; Gesture; Human Factors; input methods; multimodal; natural interaction; Performance,
Coupling the User Interfaces of a Multiuser Program,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976806476&doi=10.1145%2f200968.200969&partnerID=40&md5=dd13b3a59607e3aa040f2d1d5d040059,"We have developed a new model for coupling the user interfaces of a multiuser program. It is based on an interaction model and a user interface framework that allow users and programmers, respectively, to view applications as editors of data. It consists of a semantics model, a specification model, and an implementation model for coupling. The semantics model determines 1995 which properties of interaction entities created for a user are shared with corresponding interaction entities created for other users and (2) when changes made by a user to a property of an interaction entity are communicated to other users sharing it. It divides the properties of an interaction entity into multiple coupling sets and allows users to share different coupling sets independently. It supports several criteria for choosing when a change made by a user to a shared property is communicated to other users. These criteria include how structurally complete the change is, how correct it is, and the time at which it was made. The specification model determines how users specify the desired semantics of coupling. It associates interaction entities with inheritable coupling attributes, allows multiple users to specify values of these attributes, and does a runtime matching of the coupling attributes specified by different users to derive the coupling among their user interfaces. The implementation model determines how multiuser programs implement user-customizable coupling. It divides the task of implementing the coupling between system-provided modules and application programs. The modules support automatically a predefined semantics and specification model that can be extended by the programs. We have implemented the coupling model as part of a system called Suite. This paper describes and motivates the model using the concrete example of Suite, discusses how aspects of it can be implemented in other systems, compares it with related work, discusses its shortcomings, and suggests directions for future work. © 1995, ACM. All rights reserved.",collaboration; computer-supported cooperative work; groupware; structure editors; user interface management systems,
Taking Steps: The Influence of a Walking Technique on Presence in Virtual Reality,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976767581&doi=10.1145%2f210079.210084&partnerID=40&md5=408fa7b653a808985ebf10b31b3d9ad9,[No abstract available],,
User Interface Software Tools,1995,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960095694&doi=10.1145%2f200968.200971&partnerID=40&md5=6b829e987a454457ac6cc418dd230a52,"Almost as long as there have been user interfaces, there have been special software systems and tools to help design and implement the user interface software. Many of these tools have demonstrated significant productivity gains for programmers, and have become important commercial products. Others have proven less successful at supporting the kinds of user interfaces people want to build. This article discusses the different kinds of user interface software tools, and investigates why some approaches have worked and others have not. Many examples of commercial and research systems are included. Finally, current research directions and open issues in the field are discussed. © 1995, ACM. All rights reserved.",interface builders; toolkits; user interface development environments; user interface software,
HyperActive: Extending an Open Hypermedia Architecture to Support Agency,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976740373&doi=10.1145%2f198425.198428&partnerID=40&md5=71e1c2a4702b78697392f964af26bc56,"Agency and hypermedia have both been suggested as powerful means to cope with future information management and human-computer interaction requirements. However, research projects have included interface agents only marginally in the context of hypermedia systems. This article proposes a set of criteria for characterizing interface agents and offers a perspective view of ongoing research in the field using those criteria as a framework. The need to provide a supporting infrastructure that facilitates testing and experimentation of interface agents is stressed. The article describes an existing open hypermedia architecture and introduces an extended architecture that includes provisions to support the development and operation of interface agents. A prototype instantiating this system architecture is presented, as well as an initial assessment of the potential and requirements of interface agents in a hypermedia environment. © 1994, ACM. All rights reserved.",agent-aware hyperbases; HyperActive; interface agents; open hypermedia systems,
Reaching for Objects in VR Displays: Lag and Frame Rate,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976783616&doi=10.1145%2f198425.198426&partnerID=40&md5=be3f9f2121568267eb27130ac36f7ffe,"This article reports the results from three experimental studies of reaching behavior in a head-coupled stereo display system with a hand-tracking subsystem for object selection. It is found that lag in the head-tracking system is relatively unimportant in predicting performance, whereas lag in the hand-tracking system is critical. The effect of hand lag can be modeled by means of a variation on Fitts' Law with the measured system lag introduced as a multiplicative variable to the Fitts' Law index of difficulty. This means that relatively small lags can cause considerable degradation in performance if the targets are small. Another finding is that errors are higher for movement in and out of the screen, as compared to movements in the plane of the screen, and there is a small 1994 time penalty for movement in the Z direction in all three experiments. Low frame rates cause a degradation in performance; however, this can be attributed to the lag which is caused by low frame rates, particularly if double buffering is used combined with early sampling of the hand-tracking device. © 1994, ACM. All rights reserved.",Fitts' Law; Haptics; virtual reality,
A Framework for Undoing Actions in Collaborative Systems,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976854245&doi=10.1145%2f198425.198427&partnerID=40&md5=1c83f40ae3aaecc5ac59c08e92ec7952,"The ability to undo operations is a standard feature in most single-user interactive applications. We propose a general framework for implementing undo in collaborative systems. The framework allows users to reverse their own changes individually, taking into account the possibility of conflicts between different users' operations that may prevent an undo. The proposed framework has been incorporated into DistEdit, a toolkit for building group text editors. Based on our experience with DistEdit's undo facilities, we discuss several issues that need to be taken into account in using the framework, in order to ensure that a reasonable undo behavior is provided to users. We show that the framework is also applicable to single-user systems, since the operations to undo can be selected not just on the basis of who performed them, but by any appropriate criterion, such as the document region in which the operations occurred or the time interval in which the operations were carried out. © 1994, ACM. All rights reserved.",Computer-supported cooperative work; concurrency control; DistEdit; groupware; selective undo; state recovery; undo; user recovery,
A Review and Taxonomy of Distortion-Oriented Presentation Techniques,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976833679&doi=10.1145%2f180171.180173&partnerID=40&md5=fd8f5d8829777b6c4d4bff8e9dd6f6ab,"One of the common problems associated with large computer-based information systems is the relatively small window through which an information space can be viewed. Increasing interest in recent years has been focused on the development of distortion-oriented presentation techniques to address this problem. However, the growing number of new terminologies and techniques developed have caused considerable confusion to the graphical user interface designer, consequently making the comparison of these presentation techniques and generalization of empirical results of experiments with them very difficult, if not impossible. This article provides a taxonomy of distortion-oriented techniques which demonstrates clearly their underlying relationships. A unified theory is presented to reveal their roots and origins. Issues relating to the implementation and performance of these techniques are also discussed. © 1994, ACM. All rights reserved.",bifocal displays; distortion-oriented presentation; fisheye views; focus + context techniques; graphical interfaces; information visualization; Perspective Wall; presentation techniques,
A Selective Undo Mechanism for Graphical User Interfaces Based on Command Objects,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976657125&doi=10.1145%2f196699.196721&partnerID=40&md5=4b84bcaed60d120f307c05e27ef769b6,"It is important to provide a recovery operation for applications with a graphical user interface. A restricted linear undo mechanism can conveniently be implemented using object-oriented techniques. Although linear undo provides an arbitrarily long history, it is not possible to undo isolated commands from the history without undoing all following commands. Various undo models have been proposed to overcome this limitation, but they all ignore the problem that in graphical user interfaces a previous user action might not have a sensible interpretation in another state. Selective undo introduced here can undo isolated commands by copying them into the current state “if that is meaningful.” Furthermore, the semantics of selective undo are argued to be more natural for the user, because the mechanism only looks at the command to undo and the current state and does not depend on the history in between. The user interface for selective undo can also be implemented generically. Such a generic implementation is able to provide a consistent recovery mechanism in arbitrary applications. © 1994, ACM. All rights reserved.",command objects; groupware; undo,
What Do Groups Need? A Proposed Set of Generic Groupware Requirements,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976652410&doi=10.1145%2f196699.196715&partnerID=40&md5=f33d09f8e99d9b7591684dd69c68857f,[No abstract available],Collaboration; collaborative work; computer-supported cooperative work(CSCW); Design; group decision support systems(GDSS); group support systems(GSS); groupware; Human Factors; Theory,
Integrating pointer variables into one-way constraint models,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976665846&doi=10.1145%2f180171.180174&partnerID=40&md5=f1417e2a5a444a5b59cc4ad1e6683fd2,"Pointer variables have long been considered useful for constructing and manipulating data structures in traditional programming languages. This article discusses how pointer variables can be integrated into one-way constraint models and indicates how these constraints can be usefully employed in user interfaces. Pointer variables allow constraints to model a wide array of dynamic application behavior, simplify the implementation of structured objects and demonstrational systems, and improve the storage and efficiency of constraint-based applications. This article presents two incremental algorithms—one lazy and one eager— for solving constraints with pointer variables. Both algorithms are capable of handling 1994 arbitrary systems of one-way constraints, including constraints that involve cycles, and (2) editing models that allow multiple changes between calls to the constraint solver. These algorithms are fault tolerant in that they can handle and recover gracefully from formulas that crash due to programmer error. Constraints that use pointer variables have been implemented in a comprehensive user interface toolkit, Garnet, and our experience with applications written in Garnet have proven the usefulness of pointer variable constraints. Many large-scale applications have been implemented using these constraints. © 1994, ACM. All rights reserved.",constraints; development tools; Garnet; incremental algorithms,
The Rendezvous Architecture and Language for Constructing Multiuser Applications,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976808279&doi=10.1145%2f180171.180172&partnerID=40&md5=58a23ddcd6dec1ec3514c2954d107a0a,"When people have meetings or discussions, frequently they use conversational props: physical models, drawings, or other concrete representations of information used to enhance the exchange of information. If the participants are geographically separated, it is difficult to make effective use of props since each physical prop can only exist in one place. Computer applications that allow two or more users to simultaneously view and manipulate the same data can be used to augment human-to-human telecommunication. We have built the Rendezvous system is similar to many UIMSs or user interface toolkits in that it is intended to simplify the construction of graphical direct-manipulation interfaces. It goes beyond these systems by adding functionality to support the construction of multiuser applications. Based on experience with several large applications built with the Rendezvous system, we believe that it is useful for building conversational props and other computer-supported cooperative work 1994 applications. We present a list of required features of conversational props, some example applications built with the Rendezvous system, and a description of the Rendezvous system. © 1994, ACM. All rights reserved.",constraint maintenance; CSCW; synchronous groupware; UIMS,
Toward Visual Debugging: Integrating Algorithm Animation Capabilities Within a Source-Level Debugger,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976814947&doi=10.1145%2f196699.196702&partnerID=40&md5=695b6fd5b9c454cbd6a61c1c85863267,"Much of the recent research in software visualization has been polarized toward two opposite domains. In one domain that we call data structure and program visualization, low-level canonical views of program structures are generated automatically. These types of views, which do not require programmer input or intervention, can be useful for testing and debugging software. Often, however, their generic, low-level views are not expressive enough to convey adequately how a program functions. In the second domain called algorithm animation, designers handcraft abstract, application-specific views that are useful for program understanding and teaching. Unfortunately, since algorithm animation development typically requires time-consuming design with a graphics package, it will not be used for debugging, where timeliness is a necessity. However, we speculate that the application-specific nature of algorithm animation views could be a valuable debugging aid for software developers as well, if only the views could be easy and rapid to create. We have developed a system called Lens that occupies a unique niche between the two domains discussed above and explores the capabilities that such a system may offer. Lens allows programmers to build rapidly 1994 algorithm animation-style program views without requiring any sophisticated graphics knowledge and without using textual coding. Lens also is integrated with a system debugger to promote iterative design and exploration. © 1994, ACM. All rights reserved.",algorithm animation; debugging; programming environments; software visualization; user interfaces,
Organizational Obstacles to Interface Design and Development: Two Participant-Observer Studies,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-70049094095&doi=10.1145%2f174630.174633&partnerID=40&md5=89dea189f5a79bf00f2ccde3b718692c,"The development of human-computer interfaces was studied in two large software product development organizations. Researchers joined development projects for approximately one month and participated in interface design while concurrently interviewing other project participants and employees, recording activity in meetings and on electronic networks, and otherwise observing the process. The two organizations differed in their approaches to development, and, in each case, the approach differed in practice from the model supported by the organizational structure. Development practices blocked the successful application of accepted principles of interface design. The obstacles to effective design that results from people noticing and being affected by interface changes, and a lack of communication among those sharing responsibility for different aspects of the interface. © 1994, ACM. All rights reserved.",,
Split Menus: Effectively Using Selection Frequency to Organize Menus,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343269137&doi=10.1145%2f174630.174632&partnerID=40&md5=8dcf6a99a2402d831d0ef46d1460cd7c,"When some items in a menu are selected more frequently than others, as is often the case, designers or individual users may be able to speed performance and improve preference ratings by placing several high-frequency items at the top of the menu. Design guidelines for split menus were developed and applied. Split menus were implemented and tested in two in situ usability studies and a controlled experiment. In the usability studies performance times were reduced by 17 to 58% depending on the site and menus. In the controlled experiment split menus were significantly faster than alphabetic menus and yielded significantly higher subjective preferences. A possible resolution to the continuing debate among cognitive theorists about predicting menu selection times is offered. We conjecture and offer evidence that, at least when selecting items from pull-down menus, a logarithmic model applies to familiar 1994 items, and a linear model to unfamiliar (low-frequency) items. © 1994, ACM. All rights reserved.",Human-Computer Interaction; menus; selection frequency; split menus; user interface,
Integrality and Separability of Input Devices,1994,ACM Transactions on Computer-Human Interaction (TOCHI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976672490&doi=10.1145%2f174630.174631&partnerID=40&md5=a1fdd70d9520f64c85f29e0f8dd0c8da,"Current input device taxonomies and other frameworks typically emphasize the mechanical structure of input devices. We suggest that selecting an appropriate input device for an interactive task requires looking beyond the physical structure of devices to the deeper perceptual structure of the task, the device, and the interrelationship between the perceptual structure of the task and the control properties of the device. We affirm that perception is key to understanding performance of multidimensional input devices on multidimensional tasks. We have therefore extended the theory of processing of percetual structure to graphical interactive tasks and to the control structure of input devices. This allows us to predict task and device combinations that lead to better performance and hypothesize that performance is improved when the perceptual structure of the task matches the control structure of the device. We conducted an experiment in which subjects performed two tasks with different perceptual structures, using two input devices with correspondingly different control structures, a three-dimensional tracker and a mouse. We analyzed both speed and accuracy, as well as the trajectories generated by subjects as they used the unconstrained three-dimensional tracker to perform each task. The result support our hypothesis and confirm the importance of matching the perceptual structure of the task and the control structure of the input device. © 1994, ACM. All rights reserved.",gesture input; input devices; integrality; interaction techniques; perceptual space; Polhemus tracker; separability,
