Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
A Systematic Analysis of the Capital One Data Breach: Critical Lessons Learned,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146431354&doi=10.1145%2f3546068&partnerID=40&md5=f972dd2d0d419986a34e8c3a3bb25cb5,"The 2019 Capital One data breach was one of the largest data breaches impacting the privacy and security of personal information of over a 100 million individuals. In most reports about a cyberattack, you will often hear that it succeeded because a single employee clicked on a link in a phishing email or forgot to patch some software, making it seem like an isolated, one-off, trivial problem involving maybe one person, committing a mistake or being negligent. But that is usually not the complete story. By ignoring the related managerial and organizational failures, you are leaving in place the conditions for the next breach. Using our Cybersafety analysis methodology, we identified control failures spanning control levels, going from rather technical issues up to top management, the Board of Directors, and Government regulators. In this analysis, we reconstruct the Capital One hierarchical cyber safety control structure, identify what parts failed and why, and provide recommendations for improvements. This work demonstrates how to discover the true causes of security failures in complex information systems and derive systematic cybersecurity improvements that likely apply to many other organizations. It also provides an approach that individuals can use to evaluate and better secure their organizations.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Capital One breach; cybersafety; cybersecurity; privacy; STAMP,Data privacy; Capital one breach; Cyber security; Cyber-attacks; Cyber-safety; Large data; Personal information; Privacy; Privacy and security; STAMP; Systematic analysis; Cybersecurity
Assessment Framework for the Identification and Evaluation of Main Features for Distributed Usage Control Solutions,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139925817&doi=10.1145%2f3561511&partnerID=40&md5=73a2e3870560cd078532ab51d84cc0d9,"Data exchange between organizations is becoming an increasingly significant issue due to the great opportunities it presents. However, there is great reluctance to share if data sovereignty is not provided. Providing it calls for not only access control but also usage control implemented in distributed systems. Access control is a research field where there has been a great deal of work, but usage control, especially implemented in distributed systems as Distributed Usage Control (DUC), is a very new field of research that presents great challenges. Moreover, little is known about what challenges must really be faced and how they must be addressed. This is evidenced by the fact that existing research has focused non-specifically on different features of DUC, which are not formalized. Therefore, the path for the development of DUC solutions is unclear and it is difficult to analyze the scope of data sovereignty attained by the wide range of DUC solutions. In this context, this article is based on an initial in-depth analysis of DUC related work. In it, the challenges posed by DUC in terms of data sovereignty and the features that must be provided to address them are identified and analyzed for the first time. Based on these features, an initial DUC framework is proposed to assess in a practical and unified way the extent to which DUC solutions provide data sovereignty. Finally, the assessment framework is applied to compare the scopes of the most widespread DUC solutions and identify their limitations.  © 2022 Association for Computing Machinery.",Data exchange; data sovereignty; Distributed Usage Control; IDSA UPL; LUCON; MYDATA,Access control; Laws and legislation; Control solutions; Data sovereignty; Distributed systems; Distributed usage control; Identification and evaluation; IDSA UPL; LUCON; MYDATA; Research fields; Usage control; Electronic data interchange
"Contact Discovery in Mobile Messengers: Low-cost Attacks, Quantitative Analyses, and Efficient Mitigations",2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146438716&doi=10.1145%2f3546191&partnerID=40&md5=9d6a90a667d296bc9252166df0822206,"Contact discovery allows users of mobile messengers to conveniently connect with people in their address book. In this work, we demonstrate that severe privacy issues exist in currently deployed contact discovery methods and propose suitable mitigations. Our study of three popular messengers (WhatsApp, Signal, and Telegram) shows that large-scale crawling attacks are (still) possible. Using an accurate database of mobile phone number prefixes and very few resources, we queried 10 % of US mobile phone numbers for WhatsApp and 100 % for Signal. For Telegram, we find that its API exposes a wide range of sensitive information, even about numbers not registered with the service. We present interesting (cross-messenger) usage statistics, which also reveal that very few users change the default privacy settings. Furthermore, we demonstrate that currently deployed hashing-based contact discovery protocols are severely broken by comparing three methods for efficient hash reversal. Most notably, we show that with the password cracking tool ""JTR,""we can iterate through the entire worldwide mobile phone number space in < 150 s on a consumer-grade GPU. We also propose a significantly improved rainbow table construction for non-uniformly distributed input domains that is of independent interest. Regarding mitigations, we most notably propose two novel rate-limiting schemes: our incremental contact discovery for services without server-side contact storage strictly improves over Signal's current approach while being compatible with private set intersection, whereas our differential scheme allows even stricter rate limits at the overhead for service providers to store a small constant-size state that does not reveal any contact information.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",crawling; hash reversal; Mobile contact discovery; PSI; rainbow table,Costs; Crawling; Hash reversal; Large-scales; Low-costs; Mobile contact discovery; Mobile contacts; Phone number; Privacy issue; PSI; Rainbow tables; Cellular telephones
What Users Want From Cloud Deletion and the Information They Need: A Participatory Action Study,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146427555&doi=10.1145%2f3546578&partnerID=40&md5=ce176cc256f1356a8d04d5e713a97381,"Current cloud deletion mechanisms fall short in meeting users' various deletion needs. They assume all data is deleted the same way - data is temporally removed (or hidden) from users' cloud accounts before being completely deleted. This assumption neglects users' desire to have data completely deleted instantly or their preference to have it recoverable for a more extended period. To date, these preferences have not been explored. To address this gap, we conducted a participatory study with four groups of active cloud users (five subjects per group). We examined their deletion preferences and the information they require to aid deletion. In particular, we explored how users want to delete cloud data and identify what information about cloud deletion they consider essential, the time it should be made available to them, and the communication channel that should be used. We show that cloud deletion preferences are complex and multi-dimensional, varying between subjects and groups. Information about deletion should be within reach when needed, for instance, be part of deletion controls. Based on these findings, we discuss the implications of our study in improving the current deletion mechanism to accommodate these preferences. © 2022 Copyright held by the owner/author(s).",cloud computing; cloud deletion; cloud deletion mechanisms; cloud storage; data deletion; Deletion; deletion preferences; participatory design; preferences; user studies,Cloud deletion; Cloud deletion mechanism; Cloud storages; Cloud-computing; Data deletion; Deletion; Deletion preference; Participatory design; Preference; User study; Digital storage
Secure and Reliable Network Updates,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146421588&doi=10.1145%2f3556542&partnerID=40&md5=692e6378cc93a1fb2767d372d21c137b,"Software-defined wide area networking (SD-WAN) enables dynamic network policy control over a large distributed network via network updates. To be practical, network updates must be consistent (i.e., free of transient errors caused by updates to multiple switches), secure (i.e., only be executed when sent from valid controllers), and reliable (i.e., function despite the presence of faulty or malicious members in the control plane), while imposing only minimal overhead on controllers and switches. We present SERENE: a protocol for secure and reliable network updates for SD-WAN environments. In short: Consistency is provided through the combination of an update scheduler and a distributed transactional protocol. Security is preserved by authenticating network events and updates, the latter with an adaptive threshold cryptographic scheme. Reliability is provided by replicating the control plane and making it resilient to a dynamic adversary by using a distributed ledger as a controller failure detector. We ensure practicality by providing a mechanism for scalability through the definition of independent network domains and exploiting the parallelism of network updates both within and across domains. We formally define SERENE's protocol and prove its safety with regards to event-linearizability. Extensive experiments show that SERENE imposes minimal switch burden and scales to large networks running multiple network applications all requiring concurrent network updates, imposing at worst a 16% overhead on short-lived flow completion and negligible overhead on anticipated normal workloads.  © 2022 Association for Computing Machinery.",fault tolerance; Software defined networking,Controllers; Internet protocols; Network security; Software defined networking; Wide area networks; Control planes; Distributed networks; Dynamic network; Network policy; Policy control; Practical networks; Reliable Networks; Secure networks; Software-defined networkings; Transient errors; Fault tolerance
Industrial Control Systems Security via Runtime Enforcement,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146424193&doi=10.1145%2f3546579&partnerID=40&md5=9d75362012cc62052101e406dfff688a,"With the advent of Industry 4.0, industrial facilities and critical infrastructures are transforming into an ecosystem of heterogeneous physical and cyber components, such as programmable logic controllers, increasingly interconnected and therefore exposed to cyber-physical attacks, i.e., security breaches in cyberspace that may adversely affect the physical processes underlying industrial control systems. In this article, we propose a formal approach based on runtime enforcement to ensure specification compliance in networks of controllers, possibly compromised by colluding malware that may locally tamper with actuator commands, sensor readings, and inter-controller communications. Our approach relies on an ad-hoc sub-class of Ligatti et al.'s edit automata to enforce controllers represented in Hennessy and Regan's Timed Process Language. We define a synthesis algorithm that, given an alphabet of observable actions and a timed correctness property e, returns a monitor that enforces the property e during the execution of any (potentially corrupted) controller with alphabet, and complying with the property e. Our monitors do mitigation by correcting and suppressing incorrect actions of corrupted controllers and by generating actions in full autonomy when the controller under scrutiny is not able to do so in a correct manner. Besides classical requirements, such as transparency and soundness, the proposed enforcement enjoys deadlock- and diverge-freedom of monitored controllers, together with scalability when dealing with networks of controllers. Finally, we test the proposed enforcement mechanism on a non-trivial case study, taken from the context of industrial water treatment systems, in which the controllers are injected with different malware with different malicious goals.  © 2022 Association for Computing Machinery.",ICS security; mitigation; PLC malware; runtime enforcement,Control systems; Cybersecurity; Intelligent control; Malware; Process control; Programmable logic controllers; Control system security; Exposed to; ICS security; Industrial control systems; Industrial facilities; Malwares; Mitigation; PLC malware; Property; Runtime enforcements; Controllers
A Novel Cross-Network Embedding for Anchor Link Prediction with Social Adversarial Attacks,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139277307&doi=10.1145%2f3548685&partnerID=40&md5=20694d3af1842281e57462c4d30a5746,"Anchor link prediction across social networks plays an important role in multiple social network analysis. Traditional methods rely heavily on user privacy information or high-quality network topology information. These methods are not suitable for multiple social networks analysis in real-life. Deep learning methods based on graph embedding are restricted by the impact of the active privacy protection policy of users on the graph structure. In this paper, we propose a novel method which neutralizes the impact of users' evasion strategies. First, graph embedding with conditional estimation analysis is used to obtain a robust embedding vector space. Secondly, cross-network features space for supervised learning is constructed via the constraints of cross-network feature collisions. The combination of robustness enhancement and cross-network feature collisions constraints eliminate the impact of evasion strategies. Extensive experiments on large-scale real-life social networks demonstrate that the proposed method significantly outperforms the state-of-the-art methods in terms of precision, adaptability, and robustness for the scenarios with evasion strategies.  © 2022 Association for Computing Machinery.",adversarial attacks; anchor link prediction; graph embedding; Social network,Deep learning; Forecasting; Graph embeddings; Network embeddings; Adversarial attack; Anchor link prediction; Cross networks; Evasion strategy; Graph embeddings; Link prediction; Network embedding; Network features; Social network; Social Network Analysis; Vector spaces
Differentially Private Real-Time Release of Sequential Data,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146425312&doi=10.1145%2f3544837&partnerID=40&md5=318713d7929059da7617389a6f765902,"Many data analytics applications rely on temporal data, generated (and possibly acquired) sequentially for online analysis. How to release this type of data in a privacy-preserving manner is of great interest and more challenging than releasing one-time, static data. Because of the (potentially strong) temporal correlation within the data sequence, the overall privacy loss can accumulate significantly over time; an attacker with statistical knowledge of the correlation can be particularly hard to defend against. An idea that has been explored in the literature to mitigate this problem is to factor this correlation into the perturbation/noise mechanism. Existing work, however, either focuses on the offline setting (where perturbation is designed and introduced after the entire sequence has become available), or requires a priori information on the correlation in generating perturbation. In this study we propose an approach where the correlation is learned as the sequence is generated, and is used for estimating future data in the sequence. This estimate then drives the generation of the noisy released data. This method allows us to design better perturbation and is suitable for real-time operations. Using the notion of differential privacy, we show this approach achieves high accuracy with lower privacy loss compared to existing methods.  © 2022 Association for Computing Machinery.",Differential privacy; sequential data,Digital storage; Privacy-preserving techniques; Data analytics; Data sequences; Differential privacies; On-line analysis; Privacy preserving; Real- time; Sequential data; Static datum; Temporal correlations; Temporal Data; Data Analytics
DeviceWatch: A Data-Driven Network Analysis Approach to Identifying Compromised Mobile Devices with Graph-Inference,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146432666&doi=10.1145%2f3558767&partnerID=40&md5=0fba3d0adfb7847e10a0fe1fd8fa885c,"We propose to identify compromised mobile devices from a network administrator's point of view. Intuitively, inadvertent users (and thus their devices) who download apps through untrustworthy markets are often lured to install malicious apps through in-app advertisements or phishing. We thus hypothesize that devices sharing similar apps would have a similar likelihood of being compromised, resulting in an association between a compromised device and its apps. We propose to leverage such associations to identify unknown compromised devices using the guilt-by-association principle. Admittedly, such associations could be relatively weak as it is hard, if not impossible, for an app to automatically download and install other apps without explicit user initiation. We describe how we can magnify such associations by carefully choosing parameters when applying graph-based inferences. We empirically evaluate the effectiveness of our approach on real datasets provided by a major mobile service provider. Specifically, we show that our approach achieves nearly 98% AUC (area under the ROC curve) and further detects as many as 6 ∼ 7 times of new compromised devices not covered by the ground truth by expanding the limited knowledge on known devices. We show that the newly detected devices indeed present undesirable behavior in terms of leaking private information and accessing risky IPs and domains. We further conduct in-depth analysis of the effectiveness of graph inferences to understand the unique structure of the associations between mobile devices and their apps, and its impact on graph inferences, based on which we propose how to choose key parameters.  © 2022 Association for Computing Machinery.",Compromised device; graph inference; mobile traffic analysis,Analysis approach; Compromized device; Data driven; Graph inference; Guilt by associations; Mobile traffic; Mobile traffic analyse; Network administrator; Phishing; Traffic analysis; Graphic methods
Pump Up Password Security! Evaluating and Enhancing Risk-Based Authentication on a Real-World Large-Scale Online Service,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146434449&doi=10.1145%2f3546069&partnerID=40&md5=9ed7af8fc55d7bcc057ecc237b3336d5,"Risk-based authentication (RBA) aims to protect users against attacks involving stolen passwords. RBA monitors features during login, and requests re-authentication when feature values widely differ from those previously observed. It is recommended by various national security organizations, and users perceive it more usable than and equally secure to equivalent two-factor authentication. Despite that, RBA is still used by very few online services. Reasons for this include a lack of validated open resources on RBA properties, implementation, and configuration. This effectively hinders the RBA research, development, and adoption progress. To close this gap, we provide the first long-term RBA analysis on a real-world large-scale online service. We collected feature data of 3.3 million users and 31.3 million login attempts over more than 1 year. Based on the data, we provide (i) studies on RBA's real-world characteristics plus its configurations and enhancements to balance usability, security, and privacy; (ii) a machine learning-based RBA parameter optimization method to support administrators finding an optimal configuration for their own use case scenario; (iii) an evaluation of the round-trip time feature's potential to replace the IP address for enhanced user privacy; and (iv) a synthesized RBA dataset to reproduce this research and to foster future RBA research. Our results provide insights on selecting an optimized RBA configuration so that users profit from RBA after just a few logins. The open dataset enables researchers to study, test, and improve RBA for widespread deployment in the wild. © 2022 Copyright held by the owner/author(s).",big data analysis; large-scale online services; Risk-based authentication,Big data; National security; Risk assessment; Statistical tests; Big data analyse; Feature values; Large-scale online service; Large-scales; On-line service; Password security; Re authentications; Real-world; Risk-based; Risk-based authentication; Authentication
What is Beautiful is Secure,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135033821&doi=10.1145%2f3533047&partnerID=40&md5=4bc4edb51a5c924e06dd32acb4b5e7f7,"Visual appeal has been shown to influence perceptions of usability and credibility, and we hypothesize that something similar is happening with user judgments of website security: What is beautiful is secure. Web certificates provide reliable information about a website's level of security, presented in browser interfaces. Users should use this to inform their trust decisions online, but evidence from laboratory studies and real-world usage suggests that they do not. We conducted two studies - one in lab, and one online - in which participants view and interact with websites with high and low visual appeal, and various security levels, and then make security-related judgments. In both studies, participants consistently rated visually appealing websites as more secure, and indicated they would be more likely to enter sensitive information into visually appealing websites - even when they were less secure. Our results provide evidence that users rely on visual appeal when making security and trust decisions on websites. We discuss how these results may be used to help users. © 2022 Association for Computing Machinery.",Aesthetics; cybersecurity; human-computer interaction; perceived usability; visual appeal; web certificates,Cybersecurity; Human computer interaction; Browser interfaces; Cyber security; Esthetic; In browsers; Perceived usability; Trust decisions; User judgements; Visual appeals; Web certificate; Website securities; Websites
HotFuzz: Discovering Temporal and Spatial Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135056364&doi=10.1145%2f3532184&partnerID=40&md5=8411f47dfb9393bac825547fd2a8224e,"Fuzz testing repeatedly assails software with random inputs in order to trigger unexpected program behaviors, such as crashes or timeouts, and has historically revealed serious security vulnerabilities. In this article, we present HotFuzz, a framework for automatically discovering Algorithmic Complexity (AC) time and space vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high resource utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values in both the temporal and spatial domains. © 2022 Association for Computing Machinery.",algorithmic complexity; denial-of-service; dynamic analysis; Fuzz testing; micro-fuzzing,Denial-of-service attack; Genetic algorithms; Java programming language; Libraries; Network security; Software testing; Algorithmic complexity; Denial of Service; Dynamics analysis; Fuzz Testing; Java library; Java objects; Micro-fuzzing; Program behavior; Random input; Temporal and spatial; Computational complexity
Valued Authorization Policy Existence Problem: Theory and Experiments,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135026932&doi=10.1145%2f3528101&partnerID=40&md5=eaea1ad7a5b2fcdb3a69495db148af62,"Recent work has shown that many problems of satisfiability and resiliency in workflows may be viewed as special cases of the authorization policy existence problem (APEP), which returns an authorization policy if one exists and ""No""otherwise. However, in many practical settings it would be more useful to obtain a ""least bad""policy than just a ""No,""where ""least bad""is characterized by some numerical value indicating the extent to which the policy violates the base authorization relation and constraints. Accordingly, we introduce the Valued APEP, which returns an authorization policy of minimum weight, where the (non-negative) weight is determined by the constraints violated by the returned solution.We then establish a number of results concerning the parameterized complexity of Valued APEP. We prove that the problem is fixed-parameter tractable (FPT) if the set of constraints satisfies two restrictions, but is intractable if only one of these restrictions holds. (Most constraints known to be of practical use satisfy both restrictions.) Our analysis is based on the novel concept of a user profile.We also introduce a new type of resiliency problem in the context of workflow satisfiability, show how it can be addressed using Valued APEP, and use this to build a set of benchmark instances for Valued APEP. We describe two different formulations of this problem using mixed integer programming and report the results of computational experiments which solve the problem using these formulations as input to a general-purpose solver. Our results show that the formulation which employs the user profile concept, has FPT-like running time and usually significantly outperforms our naive formulation of the problem. © 2022 Association for Computing Machinery.",Access control; authorization policy existence problem; resiliency problems; workflow satisfiability,Authorization; Benchmarking; Formal logic; Integer programming; Authorization policy; Authorization policy existence problem; Existence problems; Minimum weight; Numerical values; Resiliency problem; Satisfiability; User's profiles; Work-flows; Workflow satisfiability; User profile
Hidden in Plain Sight: Exploring Privacy Risks of Mobile Augmented Reality Applications,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135088589&doi=10.1145%2f3524020&partnerID=40&md5=f8305b019eb6d0add713bc2438e2cc62,"Mobile augmented reality systems are becoming increasingly common and powerful, with applications in such domains as healthcare, manufacturing, education, and more. This rise in popularity is thanks in part to the functionalities offered by commercially available vision libraries such as ARCore, Vuforia, and Google's ML Kit; however, these libraries also give rise to the possibility of a hidden operations threat, that is, the ability of a malicious or incompetent application developer to conduct additional vision operations behind the scenes of an otherwise honest AR application without alerting the end-user. In this article, we present the privacy risks associated with the hidden operations threat and propose a framework for application development and runtime permissions targeted specifically at preventing the execution of hidden operations. We follow this with a set of experimental results, exploring the feasibility and utility of our system in differentiating between user-expectation-compliant and non-compliant AR applications during runtime testing, for which preliminary results demonstrate accuracy of up to 71%. We conclude with a discussion of open problems in the areas of software testing and privacy standards in mobile AR systems. © 2022 Association for Computing Machinery.",Augmented reality; mobile system security; user privacy,Libraries; mHealth; Software testing; AR application; Augmented reality applications; Augmented reality systems; Healthcare manufacturing; Mobile augmented reality; Mobile system security; Mobile systems; Privacy risks; System security; User privacy; Augmented reality
FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135096760&doi=10.1145%2f3544746&partnerID=40&md5=6b88cec4f0493c9f9d5a9ba48a62f17b,"As advances in Deep Neural Networks (DNNs) demonstrate unprecedented levels of performance in many critical applications, their vulnerability to attacks is still an open question. We consider evasion attacks at testing time against Deep Learning in constrained environments, in which dependencies between features need to be satisfied. These situations may arise naturally in tabular data or may be the result of feature engineering in specific application domains, such as threat detection in cyber security. We propose a general iterative gradient-based framework called FENCE for crafting evasion attacks that take into consideration the specifics of constrained domains and application requirements. We apply it against Feed-Forward Neural Networks trained for two cyber security applications: network traffic botnet classification and malicious domain classification, to generate feasible adversarial examples. We extensively evaluate the success rate and performance of our attacks, compare their improvement over several baselines, and analyze factors that impact the attack success rate, including the optimization objective and the data imbalance. We show that with minimal effort (e.g., generating 12 additional network connections), an attacker can change the model's prediction from the Malicious class to Benign and evade the classifier. We show that models trained on datasets with higher imbalance are more vulnerable to our FENCE attacks. Finally, we demonstrate the potential of performing adversarial training in constrained domains to increase the model resilience against these evasion attacks. © 2022 Association for Computing Machinery.",Adversarial machine learning; constrained environment; domain classification; evasion attacks; feed-forward neural networks; network traffic botnet classification,Botnet; Deep neural networks; Feedforward neural networks; Fences; Network security; Adversarial machine learning; Botnets; Constrained environment; Domain classification; Evasion attack; Feed forward neural net works; Machine-learning; Network traffic; Network traffic botnet classification; Performance; Cybersecurity
Accountable Private Set Cardinality for Distributed Measurement,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135046755&doi=10.1145%2f3477531&partnerID=40&md5=549e8c426e8104d1c3319f3edf515109,"We introduce cryptographic protocols for securely and efficiently computing the cardinality of set union and set intersection. Our private set-cardinality protocols (PSC) are designed for the setting in which a large set of parties in a distributed system makes observations, and a small set of parties with more resources and higher reliability aggregates the observations. PSC allows for secure and useful statistics gathering in privacy-preserving distributed systems. For example, it allows operators of anonymity networks such as Tor to securely answer the questions: How many unique users are using the network? and How many hidden services are being accessed?We prove the correctness and security of PSC in the Universal Composability framework against an active adversary that compromises all but one of the aggregating parties. Although successful output cannot be guaranteed in this setting, PSC either succeeds or terminates with an abort, and we furthermore make the adversary accountable for causing an abort by blaming at least one malicious party. We also show that PSC prevents adaptive corruption of the data parties from revealing past observations, which prevents them from being victims of targeted compromise, and we ensure safe measurements by making outputs differentially private.We present a proof-of-concept implementation of PSC and use it to demonstrate that PSC operates with low computational overhead and reasonable bandwidth. It can count tens of thousands of unique observations from tens to hundreds of data-collecting parties while completing within hours. PSC is thus suitable for daily measurements in a distributed system. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",privacy-preserving measurement; Secure computation,Privacy-preserving techniques; Cardinalities; Cryptographic protocols; Distributed measurements; Distributed systems; Privacy preserving; Privacy-preserving measurement; Resource reliability; Secure computation; Set cardinality; Set intersection; Network security
"PRShare: A Framework for Privacy-preserving, Interorganizational Data Sharing",2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135016328&doi=10.1145%2f3531225&partnerID=40&md5=1856818e54910a957bb83a31e16ab5b9,"We consider the task of interorganizational data sharing, in which data owners, data clients, and data subjects have different and sometimes competing privacy concerns. One real-world scenario in which this problem arises concerns law-enforcement use of phone-call metadata: The data owner is a phone company, the data clients are law-enforcement agencies, and the data subjects are individuals who make phone calls. A key challenge in this type of scenario is that each organization uses its own set of proprietary intraorganizational attributes to describe the shared data; such attributes cannot be shared with other organizations. Moreover, data-access policies are determined by multiple parties and may be specified using attributes that are not directly comparable with the ones used by the owner to specify the data.We propose a system architecture and a suite of protocols that facilitate dynamic and efficient interorganizational data sharing, while allowing each party to use its own set of proprietary attributes to describe the shared data and preserving the confidentiality of both data records and proprietary intraorganizational attributes. We introduce the novel technique of Attribute-Based Encryption with Oblivious Attribute Translation (OTABE), which plays a crucial role in our solution. This extension of attribute-based encryption uses semi-trusted proxies to enable dynamic and oblivious translation between proprietary attributes that belong to different organizations; it supports hidden access policies, direct revocation, and fine-grained, data-centric keys and queries. We prove that our OTABE-based framework is secure in the standard model and provide two real-world use cases. © 2022 Association for Computing Machinery.",Attribute-based encryption; privacy-preserving data sharing,Privacy-preserving techniques; Telephone sets; Access policies; Attribute-based encryptions; Data client; Data Sharing; Data subjects; Inter-organizational; Phone calls; Privacy preserving; Privacy-preserving data sharing; Shared data; Network architecture
Dynamic Binary Translation for SGX Enclaves,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135030122&doi=10.1145%2f3532862&partnerID=40&md5=99090b62a3628ddde857716ac99c0dd5,"Enclaves, such as those enabled by Intel SGX, offer a hardware primitive for shielding user-level applications from the OS. While enclaves are a useful starting point, code running in the enclave requires additional checks whenever control or data is transferred to/from the untrusted OS. The enclave-OS interface on SGX, however, can be extremely large if we wish to run existing unmodified binaries inside enclaves. This article presents Ratel, a dynamic binary translation engine running inside SGX enclaves on Linux. Ratel offers complete interposition, the ability to interpose on all executed instructions in the enclave and monitor all interactions with the OS. Instruction-level interposition offers a general foundation for implementing a large variety of inline security monitors in thefuture.We take a principled approach in explaining why complete interposition on SGX is challenging. We draw attention to five design decisions in SGX that create fundamental trade-offs between performance and ensuring complete interposition, and we explain how to resolve them in the favor of complete interposition. To illustrate the utility of the Ratel framework, we present the first attempt to offer binary compatibility with existing software on SGX. We report that Ratel offers binary compatibility with over 200 programs we tested, including micro-benchmarks and real applications, such as Linux shell utilities. Runtimes for two programming languages, namely, Python and R, tested with standard benchmarks work out-of-the-box on Ratel without any specialized handling. © 2022 Copyright held by the owner/author(s).",compatibility; complete interposition; dynamic binary translation; dynamorio; enclaves; instrumentation; lift and shift; porting; SGX design restrictions; TEEs; trusted computing; Trusted execution environments,Application programs; Benchmarking; Economic and social effects; Python; Trusted computing; Compatibility; Complete interposition; Design restriction; Dynamic binary translation; Dynamorio; Enclave; Instrumentation; Lift and shift; Porting; SGX design restriction; TEE; Trusted execution environments; Linux
Privacy Analysis of Query-Set-Size Control,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135030532&doi=10.1145%2f3532774&partnerID=40&md5=6644126581c097a42e31fcceda60a1e8,"The publication of user data for statistical analysis and research can be extremely beneficial for both academic and commercial uses, such as statistical research and recommendation systems. To maintain user privacy when such a publication occurs many databases employ anonymization techniques, either on the query results or the data itself. In this article, we examine and analyze the privacy offered when using the query-set-size control method for aggregate queries over a data structures representing various topologies. We focus on the mathematical queries of minimum, maximum, median, and average and show some query types that may be used to extract hidden information. We prove some combinations of these queries will maintain a measurable level of privacy even when using multiple queries. We offer a privacy probability measure, indicating the probability of an attacker to obtain information defined as sensitive by utilizing legitimate queries over such a system. Our results are mathematically proven and backed by simulations using vehicular network data based on the TAPASCologne project. © 2022 Association for Computing Machinery.",anonymity; Privacy; privacy measure; query-set-size-control; vehicular network,Data privacy; Anonymity; Commercial use; Privacy; Privacy analysis; Privacy measures; Query-set-size-control; Size-control; Statistical research; User data; Vehicular networks; Query processing
In the Land of MMUs: Multiarchitecture OS-Agnostic Virtual Memory Forensics,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135084592&doi=10.1145%2f3528102&partnerID=40&md5=19296ae45d665b3a63d69e0db4b47bf1,"The first step required to perform any analysis of a physical memory image is the reconstruction of the virtual address spaces, which allows translating virtual addresses to their corresponding physical offsets. However, this phase is often overlooked, and the challenges related to it are rarely discussed in the literature. Practical tools solve the problem by using a set of custom heuristics tailored on a very small number of well-known operating systems (OSs) running on few architectures.In this article, we look for the first time at all the different ways the virtual to physical translation can be operated in 10 different CPU architectures. In each case, we study the inviolable constraints imposed by the memory management unit that can be used to build signatures to recover the required data structures from memory without any knowledge about the running OS. We build a proof-of-concept tool to experiment with the extraction of virtual address spaces showing the challenges of performing an OS-agnostic virtual to physical address translation in real-world scenarios. We conduct experiments on a large set of 26 different OSs and a use case on a real hardware device. Finally, we show a possible usage of our technique to retrieve information about user space processes running on an unknown OS without any knowledge of its internals. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Memory forensics; MMU; OS-agnostic forensics; virtual memory,Computer forensics; Information management; Memory management units; Physical addresses; CPU architecture; Memory forensics; MMU; Operating system-agnostic forensic; Physical memory; Proof of concept; Real-world scenario; Virtual address space; Virtual memory; Virtual-to-physical address translations; Virtual addresses
EI-MTD: Moving Target Defense for Edge Intelligence against Adversarial Attacks,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133722828&doi=10.1145%2f3517806&partnerID=40&md5=bc19f672f8affdd4e182a0c71dad799f,"Edge intelligence has played an important role in constructing smart cities, but the vulnerability of edge nodes to adversarial attacks becomes an urgent problem. A so-called adversarial example can fool a deep learning model on an edge node for misclassification. Due to the transferability property of adversarial examples, an adversary can easily fool a black-box model by a local substitute model. Edge nodes in general have limited resources, which cannot afford a complicated defense mechanism like that on a cloud data center. To address the challenge, we propose a dynamic defense mechanism, namely EI-MTD. The mechanism first obtains robust member models of small size through differential knowledge distillation from a complicated teacher model on a cloud data center. Then, a dynamic scheduling policy, which builds on a Bayesian Stackelberg game, is applied to the choice of a target model for service. This dynamic defense mechanism can prohibit the adversary from selecting an optimal substitute model for black-box attacks. We also conduct extensive experiments to evaluate the proposed mechanism, and results show that EI-MTD could protect edge intelligence effectively against adversarial attacks in black-box settings.  © 2022 Association for Computing Machinery.",Adversarial examples; Bayesian Stackelberg game; differential knowledge distillation; dynamic scheduling,Deep learning; Dynamics; Network security; Scheduling; Adversarial example; Bayesian stackelberg games; Black boxes; Cloud data centers; Defence mechanisms; Differential knowledge distillation; Dynamic scheduling; Edge intelligence; Edge nodes; Moving target defense; Distillation
Computation on Encrypted Data Using Dataflow Authentication,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133697996&doi=10.1145%2f3513005&partnerID=40&md5=62affa1166545a62698f544638661991,"Encrypting data before sending it to the cloud ensures data confidentiality but requires the cloud to compute on encrypted data. Trusted execution environments, such as Intel SGX enclaves, promise to provide a secure environment in which data can be decrypted and then processed. However, vulnerabilities in the executed program give attackers ample opportunities to execute arbitrary code inside the enclave. This code can modify the dataflow of the program and leak secrets via SGX side channels. Fully homomorphic encryption would be an alternative to compute on encrypted data without data leaks. However, due to its high computational complexity, its applicability to general-purpose computing remains limited. Researchers have made several proposals for transforming programs to perform encrypted computations on less powerful encryption schemes. Yet current approaches do not support programs making control-flow decisions based on encrypted data.We introduce the concept of dataflow authentication (DFAuth) to enable such programs. DFAuth prevents an adversary from arbitrarily deviating from the dataflow of a program. Our technique hence offers protections against the side-channel attacks described previously. We implemented two flavors of DFAuth, a Java bytecode-to-bytecode compiler, and an SGX enclave running a small and program-independent trusted code base. We applied DFAuth to a neural network performing machine learning on sensitive medical data and a smart charging scheduler for electric vehicles. Our transformation yields a neural network with encrypted weights, which can be evaluated on encrypted inputs in . Our protected scheduler is capable of updating the encrypted charging plan in approximately 1.06 seconds.  © 2022 Copyright held by the owner/author(s).",authenticated encryption; homomorphic encryption; secure cloud computing; Trusted code base; trusted execution environment,Codes (symbols); Computer software; Metadata; Scheduling; Sensitive data; Side channel attack; Trusted computing; Authenticated encryption; Data confidentiality; Dataflow; Encrypted data; Ho-momorphic encryptions; Homomorphic-encryptions; Neural-networks; Secure cloud computing; Trusted code base; Trusted execution environments; Authentication
Dealing with Security Alert Flooding: Using Machine Learning for Domain-independent Alert Aggregation,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128212903&doi=10.1145%2f3510581&partnerID=40&md5=43437dc850722fb1450e1b763b53e90d,"Intrusion Detection Systems (IDS) secure all kinds of IT infrastructures through automatic detection of malicious activities. Unfortunately, they are known to produce large numbers of alerts that often become overwhelming for manual analysis. Therefore, aggregation methods have been developed for filtering, grouping, and correlating alerts. However, existing techniques either rely on manually defined attack scenarios or require specific alert formats, such as IDMEF that include IP addresses. This makes the application of existing aggregation methods infeasible for alerts from host-based or anomaly-based IDSs that frequently lack such network-related data. In this paper, we therefore present a domain-independent alert aggregation technique. We introduce similarity measures and merging strategies for arbitrary semi-structured alerts and alert groups. Based on these metrics and techniques we propose an incremental procedure for the generation of abstract alert patterns that enable continuous classification of incoming alerts. Evaluations show that our approach is capable of reducing the number of alert groups for human review by around and assigning attack classifiers to the groups with true positive rates of and false positive rates lower than .  © 2022 Copyright held by the owner/author(s).",Alert aggregation; intrusion detection; log data analysis,Machine learning; Network security; Aggregation methods; Alert aggregation; Domain independents; Floodings; Intrusion Detection Systems; Intrusion-Detection; Log data; Log data analyse; Machine-learning; Security alerts; Intrusion detection
SoK: A Modularized Approach to Study the Security of Automatic Speech Recognition Systems,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133682430&doi=10.1145%2f3510582&partnerID=40&md5=969477277c5fbf093378afb951f178a2,"With the wide use of Automatic Speech Recognition (ASR) in applications such as human machine interaction, simultaneous interpretation, audio transcription, and so on, its security protection becomes increasingly important. Although recent studies have brought to light the weaknesses of popular ASR systems that enable out-of-band signal attack, adversarial attack, and so on, and further proposed various remedies (signal smoothing, adversarial training, etc.), a systematic understanding of ASR security (both attacks and defenses) is still missing, especially on how realistic such threats are and how general existing protection could be. In this article, we present our systematization of knowledge for ASR security and provide a comprehensive taxonomy for existing work based on a modularized workflow. More importantly, we align the research in this domain with that on security in Image Recognition System (IRS), which has been extensively studied, using the domain knowledge in the latter to help understand where we stand in the former. Generally, both IRS and ASR are perceptual systems. Their similarities allow us to systematically study existing literature in ASR security based on the spectrum of attacks and defense solutions proposed for IRS, and pinpoint the directions of more advanced attacks and the directions potentially leading to more effective protection in ASR. In contrast, their differences, especially the complexity of ASR compared with IRS, help us learn unique challenges and opportunities in ASR security. Particularly, our experimental study shows that transfer attacks across ASR models are feasible, even in the absence of knowledge about models (even their types) and training data.  © 2022 Association for Computing Machinery.",Adversarial attacks; machine learning security; speech system security,Domain Knowledge; Image recognition; Speech recognition; Adversarial attack; Automatic speech recognition; Automatic speech recognition system; Image recognition system; Machine learning security; Machine-learning; Modularized; Speech system security; Speech systems; System security; Machine learning
Information Leakage Games: Exploring Information as a Utility Function,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133679953&doi=10.1145%2f3517330&partnerID=40&md5=38e477e773ca1b885af1b0cdcaea5ffa,"A common goal in the areas of secure information flow and privacy is to build effective defenses against unwanted leakage of information. To this end, one must be able to reason about potential attacks and their interplay with possible defenses. In this article, we propose a game-theoretic framework to formalize strategies of attacker and defender in the context of information leakage, and provide a basis for developing optimal defense methods. A novelty of our games is that their utility is given by information leakage, which in some cases may behave in a non-linear way. This causes a significant deviation from classic game theory, in which utility functions are linear with respect to players' strategies. Hence, a key contribution of this work is the establishment of the foundations of information leakage games. We consider two kinds of games, depending on the notion of leakage considered. The first kind, the QIF-games, is tailored for the theory of quantitative information flow. The second one, the DP-games, corresponds to differential privacy.  © 2022 Copyright held by the owner/author(s).",convex-concave optimization; differential privacy; game theory; Information leakage; quantitative information flow,Concave optimization; Convex-concave optimization; Differential privacies; Game-theoretic; Information leakage; Information privacy; Potential attack; Quantitative information flows; Secure information flow; Utility functions; Game theory
Privacy-Preserving Decision Trees Training and Prediction,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133727452&doi=10.1145%2f3517197&partnerID=40&md5=85455855faf838e132c830c19676faff,"In the era of cloud computing and machine learning, data has become a highly valuable resource. Recent history has shown that the benefits brought forth by this data driven culture come at a cost of potential data leakage. Such breaches have a devastating impact on individuals and industry, and lead the community to seek privacy preserving solutions. A promising approach is to utilize Fully Homomorphic Encryption () to enable machine learning over encrypted data, thus providing resiliency against information leakage. However, computing over encrypted data incurs a high computational overhead, thus requiring the redesign of algorithms, in an ""-friendly""manner, to maintain their practicality.In this work we focus on the ever-popular tree based methods, and propose a new privacy-preserving solution to training and prediction for trees over data encrypted with homomorphic encryption. Our solution employs a low-degree approximation for the step-function together with a lightweight interactive protocol, to replace components of the vanilla algorithm that are costly over encrypted data. Our protocols for decision trees achieve practical usability demonstrated on standard UCI datasets encrypted with fully homomorphic encryption. In addition, the communication complexity of our protocols is independent of the tree size and dataset size in prediction and training, respectively, which significantly improves on prior works.1  © 2022 Copyright held by the owner/author(s).",decision trees; Fully homomorphic encryption; prediction; privacy; secure outsourcing; training,Approximation algorithms; Forecasting; History; Machine learning; Privacy-preserving techniques; Cloud-computing; Data driven; Encrypted data; Fully homomorphic encryption; Learning data; Machine-learning; Privacy; Privacy preserving; Privacy preserving solutions; Secure outsourcing; Decision trees
Generating Quality Threat Intelligence Leveraging OSINT and a Cyber Threat Unified Taxonomy,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133662198&doi=10.1145%2f3530977&partnerID=40&md5=28536cad84d1a4820be6e6335bb809bd,"Today's threats use multiple means of propagation, such as social engineering, email, and application vulnerabilities, and often operate in different phases, such as single device compromise, lateral network movement, and data exfiltration. These complex threats rely on advanced persistent threats supported by well-advanced tactics for appearing unknown to traditional security defenses. As organizations realize that attacks are increasing in size and complexity, cyber threat intelligence (TI) is growing in popularity and use. This trend followed the evolution of advanced persistent threats, as they require a different level of response that is more specific to the organization. TI can be obtained via many formats, with open-source intelligence one of the most common, and using threat intelligence platforms (TIPs) that aid organizations to consume, produce, and share TI. TIPs have multiple advantages that enable organizations to quickly bootstrap the core processes of collecting, analyzing, and sharing threat-related information. However, current TIPs have some limitations that prevent their mass adoption. This article proposes AECCP, a platform that addresses some of the TIPs limitations. AECCP improves quality TI by classifying it accordingly a single unified taxonomy, removing the information with low value, enriching it with valuable information from open-source intelligence sources, and aggregating it for complementing information associated with the same threat. AECCP was validated and evaluated with three datasets of events and compared with two other platforms, showing that it can generate quality TI automatically and help security analysts analyze security incidents in less time.  © 2022 Association for Computing Machinery.",automated TI classification; Cybersecurity; Indicators of compromise (IoCs); Open ource intelligence (OSINT); Quality threat intelligence (TI); Threat intelligence platforms (TIP),Complex networks; Taxonomies; Automated threat intelligence classification; Cyber security; Cyber threats; Indicator of compromize; Open ource intelligence (OSINT); Open source intelligence; Quality threat intelligence; Social applications; Social engineering; Threat intelligence platform; Cybersecurity
Learning Relationship-Based Access Control Policies from Black-Box Systems,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133703610&doi=10.1145%2f3517121&partnerID=40&md5=d6c0de8e246569000d415525ba1ded1b,"Access control policies are crucial in securing data in information systems. Unfortunately, often times, such policies are poorly documented, and gaps between their specification and implementation prevent the system users, and even its developers, from understanding the overall enforced policy of a system. To tackle this problem, we propose the first of its kind systematic approach for learning the enforced authorizations from a target system by interacting with and observing it as a black box. The black-box view of the target system provides the advantage of learning its overall access control policy without dealing with its internal design complexities. Furthermore, compared to the previous literature on policy mining and policy inference, we avoid exhaustive exploration of the authorization space by minimizing our observations. We focus on learning relationship-based access control (ReBAC) policy, and show how we can construct a deterministic finite automaton (DFA) to formally characterize such an enforced policy. We theoretically analyze our proposed learning approach by studying its termination, correctness, and complexity. Furthermore, we conduct extensive experimental analysis based on realistic application scenarios to establish its cost, quality of learning, and scalability in practice.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",black box; formal analysis; model learning; Relationship-based access control,Authorization; Quality control; Access control policies; Black box system; Black boxes; Black-box views; Design complexity; Formal analysis; Internal design; Model learning; Relationship-based access control; Target systems; Learning systems
Differentially Private k-Nearest Neighbor Missing Data Imputation,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133667267&doi=10.1145%2f3507952&partnerID=40&md5=27f2b1c31b42c8c87b5335cfb97951f5,"Using techniques employing smooth sensitivity, we develop a method for-nearest neighbor missing data imputation with differential privacy. This requires bounding the number of data incomplete tuples that can have their data complete ""donor""changed by making a single addition or deletion to the dataset. The multiplicity of a single individual's impact on an imputed dataset necessarily means our mechanisms require the addition of more noise than mechanisms that ignore missing data, but we show empirically that this is significantly outweighed by the bias reduction from imputing missing data.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Differential privacy; private data cleaning; smooth sensitivity; statistical disclosure limitation,Data privacy; Data cleaning; Differential privacies; Missing data; Missing data imputations; Nearest-neighbour; Number of datum; Private data; Private data cleaning; Smooth sensitivity; Statistical disclosure limitations; k-nearest neighbors
InkFiltration: Using Inkjet Printers for Acoustic Data Exfiltration from Air-Gapped Networks,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133700833&doi=10.1145%2f3510583&partnerID=40&md5=4f1875b8e3d5aa0019df716213687662,"Printers have become ubiquitous in modern office spaces, and their placement in these spaces been guided more by accessibility than security. Due to the proximity of printers to places with potentially high-stakes information, the possible misuse of these devices is concerning. We present a previously unexplored covert channel that effectively uses the sound generated by printers with inkjet technology to exfiltrate arbitrary sensitive data (unrelated to the apparent content of the document being printed) from an air-gapped network. We also discuss a series of defense techniques that can make these devices invulnerable to covert manipulation.The proposed covert channel works by malware installed on a computer with access to a printer, injecting certain imperceptible patterns into all documents that applications on the computer send to the printer. These patterns can control the printing process without visibly altering the original content of a document, and generate acoustic signals that a nearby acoustic recording device, such as a smartphone, can capture and decode. To prove and analyze the capabilities of this new covert channel, we carried out tests considering different types of document layouts and distances between the printer and recording device. We achieved a bit error ratio less than 5% and an average bit rate of approximately 0.5 bps across all tested printers at distances up to 4 m, which is sufficient to extract tiny bits of information.  © 2022 Copyright held by the owner/author(s).",air-gap; covert channel; data exfiltration; Inkjet printer; side-channel attacks,Malware; Office buildings; Printing presses; Sensitive data; Side channel attack; Acoustic data; Air-gaps; Covert channels; Data exfiltration; Ink jet technology; Ink-jet printers; Office space; Recording devices; Sensitive datas; Side-channel attacks; Bit error rate
MOTION-A Framework for Mixed-Protocol Multi-Party Computation,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133718120&doi=10.1145%2f3490390&partnerID=40&md5=5021d236a4b84222635920037c59d7c4,"We present MOTION, an efficient and generic open-source framework for mixed-protocol secure multi-party computation (MPC). MOTION is built in a user-friendly, modular, and extensible way, intended to be used as a tool in MPC research and to increase adoption of MPC protocols in practice. Our framework incorporates several important engineering decisions such as full communication serialization, which enables MPC over arbitrary messaging interfaces and removes the need of owning network sockets. MOTION also incorporates several performance optimizations that improve the communication complexity and latency, e.g., better online round complexity of precomputed correlated Oblivious Transfer (OT).We instantiate our framework with protocols for N parties and security against up to passive corruptions: the MPC protocols of Goldreich-Micali-Wigderson (GMW) in its arithmetic and Boolean version and OT-based BMR (Ben-Efraim et al., CCS'16), as well as novel and highly efficient conversions between them, including a non-interactive conversion from BMR to arithmetic GMW.MOTION is highly efficient, which we demonstrate in our experiments. Compared to secure evaluation of AES-128 with parties in a high-latency network with OT-based BMR, we achieve a 16 better throughput of 16 AES evaluations per second using BMR. With this, we show that BMR is much more competitive than previously assumed. For parties and full-threshold protocols in a LAN, MOTION is-faster than the previous best passively secure implementation from the MP-SPDZ framework, and-faster than the actively secure SCALE-MAMBA framework. Finally, we show that our framework is highly efficient for privacy-preserving neural network inference.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",efficiency; hybrid protocols; outsourcing; Secure multi-party computation,Network security; Outsourcing; Privacy-preserving techniques; Engineering decisions; Hybrid protocols; Modulars; Multi-party computation protocols; Multiparty computation; Network sockets; Oblivious transfer; Open source frameworks; Secure multi-party computation; User friendly; Complex networks
Risk Prediction of IoT Devices Based on Vulnerability Analysis,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133729261&doi=10.1145%2f3510360&partnerID=40&md5=7a22ca8430203d9a789db0dbcab3a506,"Internet of Things (IoT) devices are becoming more widespread not only in areas such as smart homes and smart cities but also in research and office environments. The sheer number, heterogeneity, and limited patch availability provide significant challenges for the security of both office networks and the Internet in general. The systematic estimation of device risks, which is essential for mitigation decisions, is currently a skill-intensive task that requires expertise in network vulnerability scanning, as well as manual effort in firmware binary analysis.This article introduces SAFER,1 the Security Assessment Framework for Embedded-device Risks, which enables a semi-automated risk assessment of IoT devices in any network. SAFER combines information from network device identification and automated firmware analysis to estimate the current risk associated with the device. Based on past vulnerability data and vendor patch intervals for device models, SAFER extrapolates those observations into the future using different automatically parameterized prediction models. Based on that, SAFER also estimates an indicator for future security risks. This enables users to be aware of devices exposing high risks in the future.One major strength of SAFER over other approaches is its scalability, achieved through significant automation. To demonstrate this strength, we apply SAFER in the network of a large multinational organization, to systematically assess the security level of hundreds of IoT devices on large-scale networks.Results indicate that SAFER successfully identified 531 out of 572 devices leading to a device identification rate of 92.83 %, analyzed 825 firmware images, and predicted the current and future security risk for 240 devices.  © 2022 Copyright held by the owner/author(s).",CERN; device identification; firmware analysis; future risk; IoT; risk prediction; safer network; security risk assessment; vulnerability analysis,Automation; Firmware; Forecasting; Intelligent buildings; Network security; Risk analysis; Risk assessment; Risk perception; 'current; CERN; Device identification; Firmware analyse; Future risk; Risk predictions; Safe network; Security risk assessments; Security risks; Vulnerability analysis; Internet of things
Constrained Proximity Attacks on Mobile Targets,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133720673&doi=10.1145%2f3498543&partnerID=40&md5=5fb67fcf00ddcd2fa99aee2cf76eda52,"Proximity attacks allow an adversary to uncover the location of a victim by repeatedly issuing queries with fake location data. These attacks have been mostly studied in scenarios where victims remain static and there are no constraints that limit the actions of the attacker. In such a setting, it is not difficult for the attacker to locate a particular victim and quantifying the effort for doing so is straightforward. However, it is far more realistic to consider scenarios where potential victims present a particular mobility pattern. In this article, we consider abstract (constrained and unconstrained) attacks on services that provide location information on other users in the proximity. We derive strategies for constrained and unconstrained attackers, and show that when unconstrained they can practically achieve success with theoretically optimal effort. We then propose a simple yet effective constraint that may be employed by a proximity service (for example, running in the cloud or using a suitable two-party protocol) as a countermeasure to increase the effort for the attacker several orders of magnitude both in simulated and real-world cases.  © 2022 Association for Computing Machinery.",Location privacy; mobility pattern; proximity attacks; quantification,Abstracting; Effective constraints; Location data; Location information; Location privacy; Mobile targets; Mobility pattern; Proximity attack; Proximity service; Quantification; Simple++; Location
A Deep Dive Inside DREBIN: An Explorative Analysis beyond Android Malware Detection Scores,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130845494&doi=10.1145%2f3503463&partnerID=40&md5=a619ea19f3f5bdced393cccf897e550d,"Machine learning advances have been extensively explored for implementing large-scale malware detection. When reported in the literature, performance evaluation of machine learning based detectors generally focuses on highlighting the ratio of samples that are correctly or incorrectly classified, overlooking essential questions on why/how the learned models can be demonstrated as reliable. In the Android ecosystem, several recent studies have highlighted how evaluation setups can carry biases related to datasets or evaluation methodologies. Nevertheless, there is little work attempting to dissect the produced model to provide some understanding of its intrinsic characteristics. In this work, we fill this gap by performing a comprehensive analysis of a state-of-the-art Android malware detector, namely DREBIN, which constitutes today a key reference in the literature. Our study mainly targets an in-depth understanding of the classifier characteristics in terms of (1) which features actually matter among the hundreds of thousands that DREBIN extracts, (2) whether the high scores of the classifier are dependent on the dataset age, and (3) whether DREBIN's explanations are consistent within malware families, among others. Overall, our tentative analysis provides insights into the discriminatory power of the feature set used by DREBIN to detect malware. We expect our findings to bring about a systematisation of knowledge for the community.  © 2022 Copyright held by the owner/author(s).",Android malware detection; DREBIN; machine learning; SVM,Android (operating system); Classification (of information); Mobile security; Support vector machines; Android malware; Android malware detection; Classifieds; Deep dives; DREBIN; Large-scales; Machine-learning; Malware detection; Performances evaluation; SVM; Android malware
Terminator: A Secure Coprocessor to Accelerate Real-Time AntiViruses Using Inspection Breakpoints,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133712559&doi=10.1145%2f3494535&partnerID=40&md5=49a603a70a00abbe4afc80d9fabc4da5,"AntiViruses (AVs) are essential to face the myriad of malware threatening Internet users. AVs operate in two modes: on-demand checks and real-time verification. Software-based real-time AVs intercept system and function calls to execute AV's inspection routines, resulting in significant performance penalties as the monitoring code runs among the suspicious code. Simultaneously, dark silicon problems push the industry to add more specialized accelerators inside the processor to mitigate these integration problems. In this article, we propose Terminator, an AV-specific coprocessor to assist software AVs by outsourcing their matching procedures to the hardware, thus saving CPU cycles and mitigating performance degradation. We designed Terminator to be flexible and compatible with existing AVs by using YARA and ClamAVrules. Our experiments show that our approach can save up to 70 million CPU cycles per rule when outsourcing on-demand checks for matching typical, unmodified YARA rules against a dataset of 30 thousand in-the-wild malware samples. Our proposal eliminates the AV's need for blocking the CPU to perform full system checks, which can now occur in parallel. We also designed a new inspection breakpoint mechanism that signals to the coprocessor the beginning of a monitored region, allowing it to scan the regions in parallel with their execution. Overall, our mechanism mitigated up to 44% of the overhead imposed to execute and monitor the SPEC benchmark applications in the most challenging scenario.  © 2022 Association for Computing Machinery.",antivirus; coprocessor; Malware,Benchmarking; Codes (symbols); Coprocessor; Hardware security; Outsourcing; Anti virus; Breakpoint; Co-processors; CPU cycles; Internet users; Malwares; Matchings; On demands; Real- time; Secure coprocessor; Malware
Improving Unlinkability of Attribute-based Authentication through Game Theory,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133702369&doi=10.1145%2f3501260&partnerID=40&md5=acf2f4398e97a4b829664fceae620963,"This article first formalizes the problem of unlinkable attribute-based authentication in the system where each user possesses multiple assertions and uses them interchangeably. Currently, there are no recommendations for optimal usage of assertions in such authentication systems. To mitigate this issue, we use conditional entropy to measure the uncertainty for a Relying Party who attempts to link observed assertions with user labels. Conditional entropy is the function of usage statistics for all assertions in the system. Personal decisions made by the users about the usage of assertions contribute to these statistics. This collective effect from all the users impacts the unlinkability of authentication and must be studied using game theory. We specify several instances of the game where context information that is provided to the users differs. Through game theory and based on conditional entropy, we demonstrate how each user optimizes usage for the personal set of assertions. In the experiment, we substantiate the advantage of the proposed rational decision-making approaches: Unlinkability that we obtain under Nash equilibrium is higher than in the system where users authenticate using their assertions at random. We finally propose an algorithm that calculates equilibrium and assists users with the selection of assertions. This manifests that described techniques can be executed in realistic settings. This does not require modification of existing authentication protocols and can be implemented in platform-independent identity agents. As a use case, we describe how our technique can be used in Digital Credential Wallets: We suggest that unlinkability of authentication can be improved for Verifiable Credentials.  © 2022 Association for Computing Machinery.",Attribute-based authentication; digital credential wallets; game theory; unlinkability; verifiable credentials,Authentication; Decision making; Entropy; Attribute-based; Attribute-based authentication; Authentication systems; Conditional entropy; Digital credential wallet; Digital credentials; Uncertainty; Unlinkability; User labels; Verifiable credential; Game theory
So Near and Yet So Far-Symbolic Verification of Distance-Bounding Protocols,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133676093&doi=10.1145%2f3501402&partnerID=40&md5=5b5191598369ad6dcdd8e699a8d4936b,"The continuous adoption of Near Field Communication (NFC) tags offers many new applications whose security is essential (e.g., contactless payments). In order to prevent flaws and attacks, we develop in this article a framework allowing us to analyse the underlying security protocols, taking into account the location of the agents and the transmission delay when exchanging messages. We propose two reduction results to render automatic verification possible relying on the existing verification tool ProVerif. Our first result allows one to consider a unique topology to catch all possible attacks. The second result simplifies the security analysis when considering Terrorist fraud. Then, based on these results, we perform a comprehensive case study analysis (27 protocols), in which we obtain new proofs of security for some protocols and detect attacks on some others.  © 2022 Association for Computing Machinery.",distance-bounding protocols; Formal verification; physical proximity; symbolic model,Near field communication; Network security; % reductions; Contactless payment; Distance-bounding protocols; Near-field communication; New applications; Physical proximity; Security protocols; Symbolic modeling; Symbolic verification; Transmission delays; Formal verification
Formal Modelling and Automated Trade-off Analysis of Enforcement Architectures for Cryptographic Access Control in the Cloud,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123979726&doi=10.1145%2f3474056&partnerID=40&md5=cfa4300ce1041cf25e60bef255bf82da,"To facilitate the adoption of cloud by organizations, Cryptographic Access Control (CAC) is the obvious solution to control data sharing among users while preventing partially trusted Cloud Service Providers (CSP) from accessing sensitive data. Indeed, several CAC schemes have been proposed in the literature. Despite their differences, available solutions are based on a common set of entities-e.g., a data storage service or a proxy mediating the access of users to encrypted data-that operate in different (security) domains-e.g., on-premise or the CSP. However, the majority of these CAC schemes assumes a fixed assignment of entities to domains; this has security and usability implications that are not made explicit and can make inappropriate the use of a CAC scheme in certain scenarios with specific trust assumptions and requirements. For instance, assuming that the proxy runs at the premises of the organization avoids the vendor lock-in effect but may give rise to other security concerns (e.g., malicious insiders attackers).To the best of our knowledge, no previous work considers how to select the best possible architecture (i.e., the assignment of entities to domains) to deploy a CAC scheme for the trust assumptions and requirements of a given scenario. In this article, we propose a methodology to assist administrators in exploring different architectures for the enforcement of CAC schemes in a given scenario. We do this by identifying the possible architectures underlying the CAC schemes available in the literature and formalizing them in simple set theory. This allows us to reduce the problem of selecting the most suitable architectures satisfying a heterogeneous set of trust assumptions and requirements arising from the considered scenario to a decidable Multi-objective Combinatorial Optimization Problem (MOCOP) for which state-of-the-art solvers can be invoked. Finally, we show how we use the capability of solving the MOCOP to build a prototype tool assisting administrators to preliminarily perform a ""What-if""analysis to explore the trade-offs among the various architectures and then use available standards and tools (such as TOSCA and Cloudify) for automated deployment in multiple CSPs. © 2021 Association for Computing Machinery.",architecture; Cryptographic access control; optimization,Access control; Cloud security; Combinatorial optimization; Cryptography; Economic and social effects; Trusted computing; Access control schemes; Cloud service providers; Combinatorial optimization problems; Cryptographic access controls; Enforcement architectures; Formal modeling; Multiobjective combinatorial optimization; Optimisations; Trade-off analysis; Trust assumptions; Digital storage
Vulnerabilities of Unattended Face Verification Systems to Facial Components-based Presentation Attacks: An Empirical Study,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124012806&doi=10.1145%2f3491199&partnerID=40&md5=5f5918eedb9b4432bc8104a6987eeda6,"As face presentation attacks (PAs) are realistic threats for unattended face verification systems, face presentation attack detection (PAD) has been intensively investigated in past years, and the recent advances in face PAD have significantly reduced the success rate of such attacks. In this article, an empirical study on a novel and effective face impostor PA is made. In the proposed PA, a facial artifact is created by using the most vulnerable facial components, which are optimally selected based on the vulnerability analysis of different facial components to impostor PAs. An attacker can launch a face PA by presenting a facial artifact on his or her own real face. With a collected PA database containing various types of artifacts and presentation attack instruments (PAIs), the experimental results and analysis show that the proposed PA poses a more serious threat to face verification and PAD systems compared with the print, replay, and mask PAs. Moreover, the generalization ability of the proposed PA and the vulnerability analysis with regard to commercial systems are also investigated by evaluating unknown face verification and real-world PAD systems. It provides a new paradigm for the study of face PAs. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Face verification; facial components; presentation attack; presentation attack detection,Attack detection; Component based; Detection system; Empirical studies; Face Verification; Face verification systems; Facial components; Presentation attack; Presentation attack detection; Vulnerability analysis; Face recognition
AutoProfile: Towards Automated Profile Generation for Memory Analysis,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123980754&doi=10.1145%2f3485471&partnerID=40&md5=9385d6162ea455071459ac5d020e72f3,"Despite a considerable number of approaches that have been proposed to protect computer systems, cyber-criminal activities are on the rise and forensic analysis of compromised machines and seized devices is becoming essential in computer security.This article focuses on memory forensics, a branch of digital forensics that extract artifacts from the volatile memory. In particular, this article looks at a key ingredient required by memory forensics frameworks: a precise model of the OS kernel under analysis, also known as profile. By using the information stored in the profile, memory forensics tools are able to bridge the semantic gap and interpret raw bytes to extract evidences from a memory dump.A big problem with profile-based solutions is that custom profiles must be created for each and every system under analysis. This is especially problematic for Linux systems, because profiles are not generic: they are strictly tied to a specific kernel version and to the configuration used to build the kernel. Failing to create a valid profile means that an analyst cannot unleash the true power of memory forensics and is limited to primitive carving strategies.For this reason, in this article we present a novel approach that combines source code and binary analysis techniques to automatically generate a profile from a memory dump, without relying on any non-public information. Our experiments show that this is a viable solution and that profiles reconstructed by our framework can be used to run many plugins, which are essential for a successful forensics investigation. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",linux kernel; Memory forensics; memory forensics profile,Computer crime; Computer forensics; Cybersecurity; Electronic crime countermeasures; Linux; Semantics; Criminal activities; Cyber criminals; Forensic analysis; Linux kernel; Memory analysis; Memory forensic profile; Memory forensics; Precise modeling; Volatile memory; Digital storage
A Novel Hybrid Approach for Multi-Dimensional Data Anonymization for Apache Spark,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124035554&doi=10.1145%2f3484945&partnerID=40&md5=f5a35f5aa26f0665cb08e77aef9f4084,"Multi-dimensional data anonymization approaches (e.g., Mondrian) ensure more fine-grained data privacy by providing a different anonymization strategy applied for each attribute. Many variations of multi-dimensional anonymization have been implemented on different distributed processing platforms (e.g., MapReduce, Spark) to take advantage of their scalability and parallelism supports. According to our critical analysis on overheads, either existing iteration-based or recursion-based approaches do not provide effective mechanisms for creating the optimal number of and relative size of resilient distributed datasets (RDDs), thus heavily suffer from performance overheads. To solve this issue, we propose a novel hybrid approach for effectively implementing a multi-dimensional data anonymization strategy (e.g., Mondrian) that is scalable and provides high-performance. Our hybrid approach provides a mechanism to create far fewer RDDs and smaller size partitions attached to each RDD than existing approaches. This optimal RDD creation and operations approach is critical for many multi-dimensional data anonymization applications that create tremendous execution complexity. The new mechanism in our proposed hybrid approach can dramatically reduce the critical overheads involved in re-computation cost, shuffle operations, message exchange, and cache management. © 2021 Association for Computing Machinery.",data anonymization; Mondrian; multi-dimensional data; resilient distributed dataset (RDD); Spark,Clustering algorithms; MapReduce; Anonymization; Data anonymization; Fine grained; Hybrid approach; Mondrian; Multi dimensional; Multidimensional data; Performance; Resilient distributed dataset; Data privacy
Optimally Efficient Multi-party Fair Exchange and Fair Secure Multi-party Computation,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124042523&doi=10.1145%2f3477530&partnerID=40&md5=9914ab496ec83a4a8ad82c4fda718e6e,"Multi-party fair exchange (MFE) and fair secure multi-party computation (fair SMPC) are under-studied fields of research, with practical importance. In particular, we consider MFE scenarios where at the end of the protocol, either every participant receives every other participant's item, or no participant receives anything. We analyze the case where a trusted third party (TTP) is optimistically available, although we emphasize that the trust put on the TTP is only regarding the fairness, and our protocols preserve the privacy of the exchanged items against the TTP. In the fair SMPC case, we prove that a malicious TTP can only harm fairness, but not security.We construct an asymptotically optimal multi-party fair exchange protocol that requires a constant number of rounds (in comparison to linear) and O(n2) messages (in comparison to cubic), where n is the number of participating parties. In our protocol, we enable the parties to efficiently exchange any item that can be efficiently put into a verifiable encryption (e.g., signatures on a contract). We show how to apply this protocol on top of any SMPC protocol to achieve fairness with very little overhead (independent of the circuit size). We then generalize our protocol to efficiently handle any exchange topology (participants exchange items with arbitrary other participants). Our protocol guarantees fairness in its strongest sense: even if all n-1 other participants are malicious and colluding with each other, the fairness is still guaranteed. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",fair computation; Multi-party fair exchange; optimistic model; secure multi-party computation,Computational efficiency; Network security; Asymptotically optimal; Fair computation; Fair exchange; Multi-party fair exchange; Multi-party fair exchange protocols; Optimistic model; Optimistics; Practical importance; Secure multi-party computation; Trusted third parties; Cryptography
Secure Selections on Encrypted Multi-writer Streams,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124029832&doi=10.1145%2f3485470&partnerID=40&md5=2126090d14ec50533bab8ecb8dccc284,"Performing searches over encrypted data is a very current and active area. Several efficient solutions have been provided for the single-writer scenario in which all sensitive data originate with one party (the Data Owner) that encrypts and uploads the data to a public repository. Subsequently, the Data Owner accesses the encrypted data through a Query Processor, which has direct access to the public encrypted repository. Motivated by the recent trend in pervasive data collection, we depart from this model and consider a multi-writer scenario in which the data originate with several and mutually untrusted parties, the Data Sources. In this new scenario, the Data Owner provides public parameters so that each Data Source can add encrypted items to the public encrypted stream; moreover, the Data Owner keeps some related secret information needed to generate tokensso that different Query Sources can decrypt different subsets of the encrypted stream, as specified by corresponding access policies.We propose security model for this problem that we call Secure Selective Stream(SSS) and give a secure construction for it based on hard problems in Pairing-Based Cryptography. The cryptographic core of our construction is a new primitive, Amortized Orthogonality Encryption, that is crucial for the efficiency of the proposed implementation for SSS. © 2021 Association for Computing Machinery.",encrypted multi-writer data; functional encryption; Secure search,'current; Active area; Data-source; Encrypted data; Encrypted multi-writer data; Functional encryptions; Public repositories; Query processor; Secure search; Sensitive datas; Public key cryptography
C3PO: Cloud-based Confidentiality-preserving Continuous Query Processing,2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124016630&doi=10.1145%2f3472717&partnerID=40&md5=b5987c9893842d8741d8399f5909b898,"With the advent of the Internet of things (IoT), billions of devices are expected to continuously collect and process sensitive data (e.g., location, personal health factors). Due to the limited computational capacity available on IoT devices, the current de facto model for building IoT applications is to send the gathered data to the cloud for computation. While building private cloud infrastructures for handling large amounts of data streams can be expensive, using low-cost public (untrusted) cloud infrastructures for processing continuous queries including sensitive data leads to strong concerns over data confidentiality.This article presents C3PO, a confidentiality-preserving, continuous query processing engine, that leverages the public cloud. The key idea is to intelligently utilize partially homomorphic and property-preserving encryption to perform as many computationally intensive operations as possible-without revealing plaintext-in the untrusted cloud. C3PO provides simple abstractions to the developer to hide the complexities of applying complex cryptographic primitives, reasoning about the performance of such primitives, deciding which computations can be executed in an untrusted tier, and optimizing cloud resource usage. An empirical evaluation with several benchmarks and case studies shows the feasibility of our approach. We consider different classes of IoT devices that differ in their computational and memory resources (from a Raspberry Pi 3 to a very small device with a Cortex-M3 microprocessor) and through the use of optimizations, we demonstrate the feasibility of using partially homomorphic and property-preserving encryption on IoT devices. © 2021 Association for Computing Machinery.",cloud computing; confidentiality; IoT; stream processing,Costs; Cryptography; Query processing; Search engines; Cloud infrastructures; Cloud-based; Cloud-computing; Confidentiality; Continuous query processing; Health factors; Personal health; Property-preserving; Sensitive datas; Stream processing; Internet of things
Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116399529&doi=10.1145%2f3473039&partnerID=40&md5=40fd1ec9bc90fba4ac39362454b06e7b,"Recent work has shown that adversarial Windows malware samples - referred to as adversarial EXEmples in this article - can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that does not only encompass and generalize previous attacks against machine-learning models, but also includes three novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable file format. These attacks, named Full DOS, Extend, and Shift, inject the adversarial payload by respectively manipulating the DOS header, extending it, and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box scenarios, achieving a better tradeoff in terms of evasion rate and size of the injected payload, while also enabling evasion of models that have been shown to be robust to previous attacks. To facilitate reproducibility of our findings, we open source our framework and all the corresponding attack implementations as part of the secml-malware Python library. We conclude this work by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts directly into the learning process.  © 2021 ACM.",Adversarial examples; evasion; malware detection; semantics-invariant manipulations,Domain Knowledge; Machine learning; Malware; Adversarial example; Evasion; Experimental evaluation; Machine-learning; Malware detection; Malwares; Non-functional; On-machines; Semantic-invariant manipulation; Static code analysis; Semantics
Large-scale and Robust Code Authorship Identification with Deep Feature Learning,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116507382&doi=10.1145%2f3461666&partnerID=40&md5=6dc64c3c12f12abbb3c1c7b80bbcde66,"Successful software authorship de-anonymization has both software forensics applications and privacy implications. However, the process requires an efficient extraction of authorship attributes. The extraction of such attributes is very challenging, due to various software code formats from executable binaries with different toolchain provenance to source code with different programming languages. Moreover, the quality of attributes is bounded by the availability of software samples to a certain number of samples per author and a specific size for software samples. To this end, this work proposes a deep Learning-based approach for software authorship attribution, that facilitates large-scale, format-independent, language-oblivious, and obfuscation-resilient software authorship identification. This proposed approach incorporates the process of learning deep authorship attribution using a recurrent neural network, and ensemble random forest classifier for scalability to de-anonymize programmers. Comprehensive experiments are conducted to evaluate the proposed approach over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1,987 public repositories on GitHub. The results of our work show high accuracy despite requiring a smaller number of samples per author. Experimenting with source-code, our approach allows us to identify 8,903 GCJ authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Using the real-world dataset, we achieved an identification accuracy of 94.38% for 745 C programmers on GitHub. Moreover, the proposed approach is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g., C, C++, Java, and Python), and authors writing in mixed languages (e.g., Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g., using C Tigress) with an accuracy of 93.42% for a set of 120 authors. Experimenting with executable binaries, our approach achieves 95.74% for identifying 1,500 programmers of software binaries. Similar results were obtained when software binaries are generated with different compilation options, optimization levels, and removing of symbol information. Moreover, our approach achieves 93.86% for identifying 1,500 programmers of obfuscated binaries using all features adopted in Obfuscator-LLVM tool.  © 2021 ACM.",deep learning identification; program features; Software authorship identification; software forensics,Application programs; C++ (programming language); Decision trees; Extraction; Java programming language; Mapping; Open source software; Recurrent neural networks; Authorship identification; Deep learning identification; Executables; Large-scales; Learning identifications; Number of samples; Program feature; Software authorship identification; Software forensics; Source codes; Python
#PrettyFlyForAWiFi: Real-world Detection of Privacy Invasion Attacks by Drones,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116484028&doi=10.1145%2f3473672&partnerID=40&md5=68bb89c8e3cfc50ff2f595461e189e0d,"Drones are becoming increasingly popular for hobbyists and recreational use. But with this surge in popularity comes increased risk to privacy as the technology makes it easy to spy on people in otherwise-private environments, such as an individual's home. An attacker can fly a drone over fences and walls to observe the inside of a house, without having physical access. Existing drone detection systems require specialist hardware and expensive deployment efforts, making them inaccessible to the general public. In this work, we present a drone detection system that requires minimal prior configuration and uses inexpensive commercial off-the-shelf hardware to detect drones that are carrying out privacy invasion attacks. We use a model of the attack structure to derive statistical metrics for movement and proximity that are then applied to received communications between a drone and its controller. We test our system in real-world experiments with two popular consumer drone models mounting privacy invasion attacks using a range of flight patterns. We are able both to detect the presence of a drone and to identify which phase of the privacy attack was in progress while being resistant to false positives from other mobile transmitters. For line-of-sight approaches using our kurtosis-based method, we are able to detect all drones at a distance of 6 m, with the majority of approaches detected at 25 m or farther from the target window without suffering false positives for stationary or mobile non-drone transmitters.  © 2021 ACM.",drone detection; drones; privacy invasion; Uav,Drones; Transmitters; Commercial off-the-shelf hardwares; Detection system; False positive; Flight patterns; General publics; Privacy Attacks; Privacy invasions; Real world experiment; Real-world; Uav; Aircraft detection
Exploitation Techniques for Data-oriented Attacks with Existing and Potential Defense Approaches,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116462429&doi=10.1145%2f3462699&partnerID=40&md5=1da35adfb172c8ae6a2e358ee77ce343,"Data-oriented attacks manipulate non-control data to alter a program's benign behavior without violating its control-flow integrity. It has been shown that such attacks can cause significant damage even in the presence of control-flow defense mechanisms. However, these threats have not been adequately addressed. In this survey article, we first map data-oriented exploits, including Data-Oriented Programming (DOP) and Block-Oriented Programming (BOP) attacks, to their assumptions/requirements and attack capabilities. Then, we compare known defenses against these attacks, in terms of approach, detection capabilities, overhead, and compatibility. It is generally believed that control flows may not be useful for data-oriented security. However, data-oriented attacks (especially DOP attacks) may generate side effects on control-flow behaviors in multiple dimensions (i.e., incompatible branch behaviors and frequency anomalies). We also characterize control-flow anomalies caused by data-oriented attacks. In the end, we discuss challenges for building deployable data-oriented defenses and open research questions.  © 2021 ACM.",BOP; branch correlation; Data-oriented attacks; DOP; frequency anomaly,Block-oriented programming; Branch correlation; Control data; Control-flow; Control-flow integrities; Data-oriented attack; Data-oriented programming; Defence mechanisms; Exploitation techniques; Frequency anomaly; Network security
On the Security of Smartphone Unlock PINs,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116464501&doi=10.1145%2f3473040&partnerID=40&md5=aae6c1fab4b9c3e890c3dca201d25eda,"In this article, we provide the first comprehensive study of user-chosen four- and six-digit PINs (n=1705}) collected on smartphones with participants being explicitly primed for device unlocking. We find that against a throttled attacker (with 10, 30, or 100 guesses, matching the smartphone unlock setting), using six-digit PINs instead of four-digit PINs provides little to no increase in security and surprisingly may even decrease security. We also study the effects of blocklists, where a set of ""easy to guess""PINs is disallowed during selection. Two such blocklists are in use today by iOS, for four digits (274 PINs) as well as six digits (2,910 PINs). We extracted both blocklists and compared them with six other blocklists, three for each PIN length. In each case, we had a small (four-digit: 27 PINs; six-digit: 29 PINs), a large (four-digit: 2,740 PINs; six-digit: 291,000 PINs), and a placebo blocklist that always excluded the first-choice PIN. For four-digit PINs, we find that the relatively small blocklist in use today by iOS offers little to no benefit against a throttled guessing attack. Security gains are only observed when the blocklist is much larger. In the six-digit case, we were able to reach a similar security level with a smaller blocklist. As the user frustration increases with the blocklists size, developers should employ a blocklist that is as small as possible while ensuring the desired security.Based on our analysis, we recommend that for four-digit PINs a blocklist should contain the 1,000 most popular PINs to provide the best balance between usability and security and for six-digit PINs the 2,000 most popular PINs should be blocked.  © 2021 Owner/Author.",authentication; blocklist; mobile; PIN; Security; smartphone; usability,Mobile security; Blocklist; Guessing attacks; Matchings; Mobile; PIN; Security; Security level; Smart phones; Usability and security; Smartphones
"Design, Development, and Evaluation of a Cybersecurity, Privacy, and Digital Literacy Game for Tweens",2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116439444&doi=10.1145%2f3469821&partnerID=40&md5=e12290253009a968988a0bc287d3d7c5,"Tweens are avid users of digital media, which exposes them to various online threats. Teachers are primarily expected to teach children safe online behaviours, despite not necessarily having the required training or classroom tools to support this education. Using the theory of procedural rhetoric and established game design principles, we designed a classroom-based cybersecurity, privacy, and digital literacy game for tweens that has since been deployed to over 300 Canadian elementary schools. The game, A Day in the Life of the JOs, teaches children about 25 cybersecurity, privacy, and digital literacy topics and allows them to practice what they have learned in a simulated environment. We employed a user-centered design process to create the game, iteratively testing its design and effectiveness with children and teachers through five user studies (with a total of 63 child participants and 21 teachers). Our summative evaluation with children showed that the game improved their cybersecurity, privacy, and digital literacy knowledge and behavioural intent and was positively received by them. Our summative evaluation with teachers also showed positive results. Teachers liked that the game represented the authentic experiences of children on digital media and that it aligned with their curriculum requirements; they were interested in using it in their classrooms. In this article, we discuss our process and experience of designing a production quality game for children and provide evidence of its effectiveness with both children and teachers.  © 2021 ACM.",classrooms; educational game; teachers; tweens; usable privacy; Usable security; user education,Curricula; Digital storage; Personnel training; User centered design; Classroom; Cyber security; Design development; Digital literacies; Educational game; Teachers'; Tween; Usable privacy; Usable security; User education; Cybersecurity
Flexible Mechanisms for Remote Attestation,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116478344&doi=10.1145%2f3470535&partnerID=40&md5=7696abfd47511d99a930352390233c15,"Remote attestation consists of generating evidence of a system's integrity via measurements and reporting the evidence to a remote party for appraisal in a form that can be trusted. The parties that exchange information must agree on formats and protocols. We assert there is a large variety of patterns of interactions among appraisers and attesters of interest. Therefore, it is important to standardize on flexible mechanisms for remote attestation. We make our case by describing scenarios that require the exchange of evidence among multiple parties using a variety of message passing patterns. We show cases in which changes in the order of evidence collection result in important differences to what can be inferred by an appraiser. We argue that adding the ability to negotiate the appropriate kind of attestation allows for remote attestations that better adapt to a dynamically changing environment. Finally, we suggest a language-based solution to taming the complexity of specifying and negotiating attestation procedures.  © 2021 ACM.",attestation protocols; layered attestation; Remote attestation,Attestation protocol; Changing environment; Evidence collection; Flexible mechanisms; Layered attestation; Message-passing; Remote attestation; System integrity; Message passing
A Lightweight Privacy-Aware Continuous Authentication Protocol-PACA,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116507354&doi=10.1145%2f3464690&partnerID=40&md5=92cdc2fbad68c94c3520a5b49b111802,"As many vulnerabilities of one-time authentication systems have already been uncovered, there is a growing need and trend to adopt continuous authentication systems. Biometrics provides an excellent means for periodic verification of the authenticated users without breaking the continuity of a session. Nevertheless, as attacks to computing systems increase, biometric systems demand more user information in their operations, yielding privacy issues for users in biometric-based continuous authentication systems. However, the current state-of-the-art privacy technologies are not viable or costly for the continuous authentication systems, which require periodic real-time verification. In this article, we introduce a novel, lightweight, privacy-aware, and secure continuous authentication protocol called PACA. PACA is initiated through a password-based key exchange (PAKE) mechanism, and it continuously authenticates users based on their biometrics in a privacy-aware manner. Then, we design an actual continuous user authentication system under the proposed protocol. In this concrete system, we utilize a privacy-aware template matching technique and a wearable-assisted keystroke dynamics-based continuous authentication method. This provides privacy guarantees without relying on any trusted third party while allowing the comparison of noisy user inputs (due to biometric data) and yielding an efficient and lightweight protocol. Finally, we implement our system on an Apple smartwatch and perform experiments with real user data to evaluate the accuracy and resource consumption of our concrete system.  © 2021 ACM.",authentication; biometrics; Continuous; matching; privacy-aware; secure; template,Biometrics; Concretes; Continuous time systems; Cryptography; Real time systems; Template matching; Authentication protocols; Authentication systems; Breakings; Concrete system; Continuous; Continuous authentications; Matchings; Privacy aware; Secure; Template; Authentication
Maat: Automatically Analyzing VirusTotal for Accurate Labeling and Effective Malware Detection,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116409452&doi=10.1145%2f3465361&partnerID=40&md5=c506946782f3975da017b23a04604b84,"The malware analysis and detection research community relies on the online platform VirusTotal to label Android apps based on the scan results of around 60 antiviral scanners. Unfortunately, there are no standards on how to best interpret the scan results acquired from VirusTotal, which leads to the utilization of different threshold-based labeling strategies (e.g., if 10 or more scanners deem an app malicious, it is considered malicious). While some of the utilized thresholds may be able to accurately approximate the ground truths of apps, the fact that VirusTotal changes the set and versions of the scanners it uses makes such thresholds unsustainable over time. We implemented a method, Maat, that tackles these issues of standardization and sustainability by automatically generating a Machine Learning (ML)-based labeling scheme, which outperforms threshold-based labeling strategies. Using the VirusTotal scan reports of 53K Android apps that span 1 year, we evaluated the applicability of Maat's Machine Learning (ML)-based labeling strategies by comparing their performance against threshold-based strategies. We found that such ML-based strategies (a) can accurately and consistently label apps based on their VirusTotal scan reports, and (b) contribute to training ML-based detection methods that are more effective at classifying out-of-sample apps than their threshold-based counterparts.  © 2021 ACM.",Android security; machine learning; malware detection,Machine learning; Malware; Mobile security; Scanning; Android apps; Android securities; Antivirals; Labeling strategy; Labelings; Machine-learning; Malware analysis; Malware detection; Online platforms; Research communities; Android (operating system)
Towards Better Understanding of User Authorization Query Problem via Multi-variable Complexity Analysis,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124691781&doi=10.1145%2f3450768&partnerID=40&md5=31b55ed758723dd182cc7a24cb19c17f,"User authorization queries in the context of role-based access control have attracted considerable interest in the past 15 years. Such queries are used to determine whether it is possible to allocate a set of roles to a user that enables the user to complete a task, in the sense that all the permissions required to complete the task are assigned to the roles in that set. Answering such a query, in general, must take into account a number of factors, including, but not limited to, the roles to which the user is assigned and constraints on the sets of roles that can be activated. Answering such a query is known to be NP-hard. The presence of multiple parameters and the need to find efficient and exact solutions to the problem suggest that a multi-variate approach will enable us to better understand the complexity of the user authorization query problem (UAQ). In this article, we establish a number of complexity results for UAQ. Specifically, we show the problem remains hard even when quite restrictive conditions are imposed on the structure of the problem. Our fixed-parameter tractable (FPT) results show that we have to use either a parameter with potentially quite large values or quite a restricted version of UAQ. Moreover, our second FPT algorithm is complex and requires sophisticated, state-of-the-art techniques. In short, our results show that it is unlikely that all variants of UAQ that arise in practice can be solved reasonably quickly in general.  © 2021 ACM.",parameterized complexity; representative families; User authorization query; W-hardness,Complexity analysis; Multi variables; Multiple parameters; NP-hard; Number of factors; Parameterized complexity; Representative family; Role-based Access Control; User authorization query; W-hardness; Authorization
Optimal Packet Camouflage Against Traffic Analysis,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110461883&doi=10.1145%2f3442697&partnerID=40&md5=98fae47ff596413acbb612a85cee1fa3,"Research has proved that supposedly secure encrypted network traffic is actually threatened by privacy and security violations from many aspects. This is mainly due to flow features leaking evidence about user activity and data content. Currently, adversaries can use statistical traffic analysis to create classifiers for network applications and infer users' sensitive data. In this article, we propose a system that optimally prevents traffic feature leaks. In our first algorithm, we model the packet length probability distribution of the source app to be protected and that of the target app that the source app will resemble. We define a model that mutates the packet lengths of a source app to those lengths from the target app having similar bin probability. This would confuse a classifier by identifying a mutated source app as the target app. In our second obfuscation algorithm, we present an optimized scheme resulting in a trade-off between privacy and complexity overhead. For this reason, we propose a mathematical model for network obfuscation. We formulate analytically the problem of selecting the target app and the length from the target app to mutate to. Then, we propose an algorithm to solve it dynamically. Extensive evaluation of the proposed models, on real app traffic traces, shows significant obfuscation efficiency with relatively acceptable overhead. We were able to reduce a classification accuracy from 91.1% to 0.22% using the first algorithm, with 11.86% padding overhead. The same classification accuracy was reduced to 1.76% with only 0.73% overhead using the second algorithm.  © 2021 ACM.",anonymization; Internet traffic classification; Machine learning; obfuscation; packet length modeling; side-channel information; traffic padding,Classification (of information); Cost reduction; Economic and social effects; Probability distributions; Anonymization; Classification accuracy; Internet traffic classifications; Length modelling; Obfuscation; Packet length; Packet length modeling; Side-channel information; Traffic analysis; Traffic padding; Machine learning
The Android Platform Security Model,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105122644&doi=10.1145%2f3448609&partnerID=40&md5=4e27c62ba1c033887850cd224667b785,"Android is the most widely deployed end-user focused operating system. With its growing set of use cases encompassing communication, navigation, media consumption, entertainment, finance, health, and access to sensors, actuators, cameras, or microphones, its underlying security model needs to address a host of practical threats in a wide variety of scenarios while being useful to non-security experts. The model needs to strike a difficult balance between security, privacy, and usability for end users, assurances for app developers, and system performance under tight hardware constraints. While many of the underlying design principles have implicitly informed the overall system architecture, access control mechanisms, and mitigation techniques, the Android security model has previously not been formally published. This article aims to both document the abstract model and discuss its implications. Based on a definition of the threat model and Android ecosystem context in which it operates, we analyze how the different security measures in past and current Android implementations work together to mitigate these threats. There are some special cases in applying the security model, and we discuss such deliberate deviations from the abstract model. © 2021 Owner/Author.",Android; informal model; operating system; security,Access control; Android (operating system); Health risks; Privacy by design; Abstract modeling; Access control mechanism; Android platforms; Android securities; Hardware constraints; Media consumption; Mitigation techniques; System architectures; Mobile security
A Multi-view Approach to Preserve Privacy and Utility in Network Trace Anonymization,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105180772&doi=10.1145%2f3439732&partnerID=40&md5=fce4e2a35971d65e5acad2986e580f3f,"As network security monitoring grows more sophisticated, there is an increasing need for outsourcing such tasks to third-party analysts. However, organizations are usually reluctant to share their network traces due to privacy concerns over sensitive information, e.g., network and system configuration, which may potentially be exploited for attacks. In cases where data owners are convinced to share their network traces, the data are typically subjected to certain anonymization techniques, e.g., CryptoPAn, which replaces real IP addresses with prefix-preserving pseudonyms. However, most such techniques either are vulnerable to adversaries with prior knowledge about some network flows in the traces or require heavy data sanitization or perturbation, which may result in a significant loss of data utility. In this article, we aim to preserve both privacy and utility through shifting the trade-off from between privacy and utility to between privacy and computational cost. The key idea is for the analysts to generate and analyze multiple anonymized views of the original network traces: Those views are designed to be sufficiently indistinguishable even to adversaries armed with prior knowledge, which preserves the privacy, whereas one of the views will yield true analysis results privately retrieved by the data owner, which preserves the utility. We formally analyze the privacy of our solution and experimentally evaluate it using real network traces provided by a major ISP. The experimental results show that our approach can significantly reduce the level of information leakage (e.g., less than 1% of the information leaked by CryptoPAn) with comparable utility. © 2021 ACM.",CryptoPAn; Network trace anonymization; semantic attacks,Chromium compounds; Economic and social effects; Privacy by design; Computational costs; Data utilities; Information leakage; Prior knowledge; Privacy concerns; Security monitoring; Sensitive informations; System configurations; Network security
A Large-Scale Analysis of the Semantic Password Model and Linguistic Patterns in Passwords,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105181731&doi=10.1145%2f3448608&partnerID=40&md5=29a32d2b92e257492fc20c5e82f5142c,"In this article, we present a thorough evaluation of semantic password grammars. We report multifactorial experiments that test the impact of sample size, probability smoothing, and linguistic information on password cracking. The semantic grammars are compared with state-of-the-art probabilistic context-free grammar (PCFG) and neural network models, and tested in cross-validation and A vs. B scenarios. We present results that reveal the contributions of part-of-speech (syntactic) and semantic patterns, and suggest that the former are more consequential to the security of passwords. Our results show that in many cases PCFGs are still competitive models compared to their latest neural network counterparts. In addition, we show that there is little performance gain in training PCFGs with more than 1 million passwords. We present qualitative analyses of four password leaks (Mate1, 000webhost, Comcast, and RockYou) based on trained semantic grammars, and derive graphical models that capture high-level dependencies between token classes. Finally, we confirm the similarity inferences from our qualitative analysis by examining the effectiveness of grammars trained and tested on all pairs of leaks. © 2021 ACM.",Password guessing; PCFG; probabilistic context-free grammars; semantics,Context free grammars; Neural networks; Semantics; Competitive models; Large-scale analysis; Linguistic information; Linguistic patterns; Neural network model; Probabilistic context free grammars; Qualitative analysis; Semantic grammars; Authentication
Two-factor Password-authenticated Key Exchange with End-to-end Security,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105208034&doi=10.1145%2f3446807&partnerID=40&md5=7a12820eefa2835a0a15f25464830512,"We present a secure two-factor authentication (TFA) scheme based on the user's possession of a password and a crypto-capable device. Security is ""end-to-end""in the sense that the attacker can attack all parts of the system, including all communication links and any subset of parties (servers, devices, client terminals), can learn users' passwords, and perform active and passive attacks, online and offline. In all cases the scheme provides the highest attainable security bounds given the set of compromised components. Our solution builds a TFA scheme using any Device-enhanced Password-authenticated Key Exchange (PAKE), defined by Jarecki et al., and any Short Authenticated String (SAS) Message Authentication, defined by Vaudenay. We show an efficient instantiation of this modular construction, which utilizes any password-based client-server authentication method, with or without reliance on public-key infrastructure. The security of the proposed scheme is proven in a formal model that we formulate as an extension of the traditional PAKE model. We also report on a prototype implementation of our schemes, including TLS-based and PKI-free variants, as well as several instantiations of the SAS mechanism, all demonstrating the practicality of our approach. Finally, we present a usability study evaluating the viability of our protocol contrasted with the traditional PIN-based TFA approach in terms of efficiency, potential for errors, user experience, and security perception of the underlying manual process. © 2021 ACM.",Authentication; passwords; two factor authentication,Modular construction; Public key cryptography; User experience; End-to-end security; Message authentication; Password authenticated key exchanges (PAKE); Password-authenticated key exchange; Prototype implementations; Public key infrastructure; Two factor authentication; Usability studies; Authentication
Friendly Fire: Cross-app Interactions in IoT Platforms,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105177440&doi=10.1145%2f3444963&partnerID=40&md5=48a9753065cae75ff7b22f1e05a5fced,"IoT platforms enable users to connect various smart devices and online services via reactive apps running on the cloud. These apps, often developed by third-parties, perform simple computations on data triggered by external information sources and actuate the results of computations on external information sinks. Recent research shows that unintended or malicious interactions between the different (even benign) apps of a user can cause severe security and safety risks. These works leverage program analysis techniques to build tools for unveiling unexpected interference across apps for specific use cases. Despite these initial efforts, we are still lacking a semantic framework for understanding interactions between IoT apps. The question of what security policy cross-app interference embodies remains largely unexplored. This article proposes a semantic framework capturing the essence of cross-app interactions in IoT platforms. The framework generalizes and connects syntactic enforcement mechanisms to bisimulation-based notions of security, thus providing a baseline for formulating soundness criteria of these enforcement mechanisms. Specifically, we present a calculus that models the behavioral semantics of a system of apps executing concurrently, and use it to define desirable semantic policies targeting the security and safety of IoT apps. To demonstrate the usefulness of our framework, we define and implement static analyses for enforcing cross-app security and safety, and prove them sound with respect to our semantic conditions. We also leverage real-world apps to validate the practical benefits of our tools based on the proposed enforcement mechanisms. © 2021 ACM.",Cloud-based IoT platform; cross-app interference; IoT application security,Calculations; Semantics; Static analysis; Behavioral semantics; Enforcement mechanisms; External informations; On-line service; Program analysis; Recent researches; Security policy; Semantic framework; Internet of things
Privacy-preserving Dynamic Symmetric Searchable Encryption with Controllable Leakage,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105145109&doi=10.1145%2f3446920&partnerID=40&md5=11606835f60ae180288c424472238e86,"Searchable Encryption (SE) is a technique that allows Cloud Service Providers to search over encrypted datasets without learning the content of queries and records. In recent years, many SE schemes have been proposed to protect outsourced data. However, most of them leak sensitive information, from which attackers could still infer the content of queries and records by mounting leakage-based inference attacks, such as the count attack and file-injection attack. In this work, first we define the leakage in searchable encrypted databases and analyse how the leakage is leveraged in existing leakage-based attacks. Second, we propose a Privacy-preserving Multi-cloud based dynamic symmetric SE scheme for relational Database (P-McDb). P-McDb has minimal leakage, which not only ensures confidentiality of queries and records but also protects the search, intersection, and size patterns. Moreover, P-McDb ensures both forward and backward privacy of the database. Thus, P-McDb could resist existing leakage-based attacks, e.g., active file/record-injection attacks. We give security definition and analysis to show how P-McDb hides the aforementioned patterns. Finally, we implemented a prototype of P-McDb and tested it using the TPC-H benchmark dataset. Our evaluation results show that users can get the required records in 2.16 s when searching over 4.1 million records. © 2021 ACM.",controllable leakage; dynamic; multi-cloud; Searchable encryption,Privacy by design; Cloud service providers; Encrypted database; Evaluation results; Forward-and-backward; Relational Database; Searchable encryptions; Security definitions; Sensitive informations; Cryptography
Systematic Mutation-Based Evaluation of the Soundness of Security-Focused Android Static Analysis Techniques,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102099672&doi=10.1145%2f3439802&partnerID=40&md5=e966e0b833da26dec230949924300a60,"Mobile application security has been a major area of focus for security research over the course of the last decade. Numerous application analysis tools have been proposed in response to malicious, curious, or vulnerable apps. However, existing tools, and specifically, static analysis tools, trade soundness of the analysis for precision and performance and are hence soundy. Unfortunately, the specific unsound choices or flaws in the design of these tools is often not known or well documented, leading to misplaced confidence among researchers, developers, and users. This article describes the Mutation-Based Soundness Evaluation (μSE) framework, which systematically evaluates Android static analysis tools to discover, document, and fix flaws, by leveraging the well-founded practice of mutation analysis. We implemented μSE and applied it to a set of prominent Android static analysis tools that detect private data leaks in apps. In a study conducted previously, we used μSE to discover 13 previously undocumented flaws in FlowDroid, one of the most prominent data leak detectors for Android apps. Moreover, we discovered that flaws also propagated to other tools that build upon the design or implementation of FlowDroid or its components. This article substantially extends our μSE framework and offers a new in-depth analysis of two more major tools in our 2020 study; we find 12 new, undocumented flaws and demonstrate that all 25 flaws are found in more than one tool, regardless of any inheritance-relation among the tools. Our results motivate the need for systematic discovery and documentation of unsound choices in soundy tools and demonstrate the opportunities in leveraging mutation testing in achieving this goal. © 2021 ACM.",CryptoPAn; Network trace anonymization; semantic attacks,Android (operating system); Petroleum reservoir evaluation; Security of data; Software testing; Static analysis; Analysis techniques; Android apps; Application analysis; In-depth analysis; Mobile application securities; Mutation analysis; Mutation testing; Security research; Mobile security
Designing Strong Privacy Metrics Suites Using Evolutionary Optimization,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100724066&partnerID=40&md5=c6ca5a38210b40311a26b4621b7f35b0,"The ability to measure privacy accurately and consistently is key in the development of new privacy protections. However, recent studies have uncovered weaknesses in existing privacy metrics, as well as weaknesses caused by the use of only a single privacy metric. Metrics suites, or combinations of privacy metrics, are a promising mechanism to alleviate these weaknesses, if we can solve two open problems: which metrics should be combined and how. In this article, we tackle the first problem, i.e., the selection of metrics for strong metrics suites, by formulating it as a knapsack optimization problem with both single and multiple objectives. Because solving this problem exactly is difficult due to the large number of combinations and many qualities/objectives that need to be evaluated for each metrics suite, we apply 16 existing evolutionary and metaheuristic optimization algorithms. We solve the optimization problem for three privacy application domains: genomic privacy, graph privacy, and vehicular communications privacy. We find that the resulting metrics suites have better properties, i.e., higher monotonicity, diversity, evenness, and shared value range, than previously proposed metrics suites.  © 2021 ACM.",evolutionary optimization; genomics privacy; graph privacy; metrics suites; monotonicity; multiobjective optimization; privacy measurement; Privacy metrics; vehicular privacy,Evolutionary algorithms; Optimization; Evolutionary optimizations; Graph privacies; Knapsack optimization; Meta-heuristic optimizations; Multiple-objectives; Optimization problems; Privacy protection; Vehicular communications; Privacy by design
Exploiting Mixed Binaries,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100771726&partnerID=40&md5=f14d82d26f71760786551562f757cb8f,"Unsafe programming systems are still very popular, despite the shortcomings due to several published memory-corruption vulnerabilities. Toward defending memory corruption, compilers have started to employ advanced software hardening such as Control-flow Integrity (CFI) and SafeStack. However, there is a broad interest for realizing compilers that impose memory safety with no heavy runtime support (e.g., garbage collection). Representative examples of this category are Rust and Go, which enforce memory safety primarily statically at compile time. Software hardening and Rust/Go are promising directions for defending memory corruption, albeit combining the two is questionable. In this article, we consider hardened mixed binaries, i.e., machine code that has been produced from different compilers and, in particular, from hardened C/C++ and Rust/Go (e.g., Mozilla Firefox, Dropbox, npm, and Docker). Our analysis is focused on Mozilla Firefox, which outsources significant code to Rust and is open source with known public vulnerabilities (with assigned CVE). Furthermore, we extend our analysis in mixed binaries that leverage Go, and we derive similar results. The attacks explored in this article do not exploit Rust or Go binaries that depend on some legacy (vulnerable) C/C++ code. In contrast, we explore how Rust/Go compiled code can stand as a vehicle for bypassing hardening in C/C++ code. In particular, we discuss CFI and SafeStack, which are available in the latest Clang. Our assessment concludes that CFI can be completely nullified through Rust or Go code by constructing much simpler attacks than state-of-the-art CFI bypasses.  © 2021 Owner/Author.",CFI; Go; Memory safety; Rust; SafeStack,Codes (symbols); Crime; Hardening; Open source software; Open systems; Program compilers; Web browsers; Advanced softwares; Control-flow integrities; Garbage collection; Memory corruption; Programming system; Runtime support; Software hardenings; State of the art; C++ (programming language)
On Generating Network Traffic Datasets with Synthetic Attacks for Intrusion Detection,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100823426&partnerID=40&md5=71125e2d4ed032406d9e9f2ddf6c4f82,"Most research in the field of network intrusion detection heavily relies on datasets. Datasets in this field, however, are scarce and difficult to reproduce. To compare, evaluate, and test related work, researchers usually need the same datasets or at least datasets with similar characteristics as the ones used in related work. In this work, we present concepts and the Intrusion Detection Dataset Toolkit (ID2T) to alleviate the problem of reproducing datasets with desired characteristics to enable an accurate replication of scientific results. Intrusion Detection Dataset Toolkit (ID2T) facilitates the creation of labeled datasets by injecting synthetic attacks into background traffic. The injected synthetic attacks created by ID2T blend with the background traffic by mimicking the background traffic's properties. This article has three core contributions. First, we present a comprehensive survey on intrusion detection datasets. In the survey, we propose a classification to group the negative qualities found in the datasets. Second, the architecture of ID2T is revised, improved, and expanded in comparison to previous work. The architectural changes enable ID2T to inject recent and advanced attacks, such as the EternalBlue exploit or a peer-to-peer botnet. ID2T's functionality provides a set of tests, known as TIDED, that helps identify potential defects in the background traffic into which attacks are injected. Third, we illustrate how ID2T is used in different use-case scenarios to replicate scientific results with the help of reproducible datasets. ID2T is open source software and is made available to the community to expand its arsenal of attacks and capabilities.  © 2021 ACM.",attack injection; datasets; Intrusion detection systems; synthetic dataset,Classification (of information); Open source software; Open systems; Surveys; Architectural changes; Background traffic; Labeled datasets; Network intrusion detection; Network traffic; Potential defects; Scientific results; Use case scenario; Intrusion detection
Attack Context Embedded Data Driven Trust Diagnostics in Smart Metering Infrastructure,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100828103&partnerID=40&md5=ed19e44841949f0592d25d00f4507630,"Spurious power consumption data reported from compromised meters controlled by organized adversaries in the Advanced Metering Infrastructure (AMI) may have drastic consequences on a smart grid's operations. While existing research on data falsification in smart grids mostly defends against isolated electricity theft, we introduce a taxonomy of various data falsification attack types, when smart meters are compromised by organized or strategic rivals. To counter these attacks, we first propose a coarse-grained and a fine-grained anomaly-based security event detection technique that uses indicators such as deviation and directional change in the time series of the proposed anomaly detection metrics to indicate: (i) occurrence, (ii) type of attack, and (iii) attack strategy used, collectively known asattack context. Leveraging the attack context information, we propose three attack response metrics to the inferred attack context: (a) an unbiased mean indicating a robust location parameter; (b) a median absolute deviation indicating a robust scale parameter; and (c) an attack probability time ratio metric indicating the active time horizon of attacks. Subsequently, we propose a trust scoring model based on Kullback-Leibler (KL) divergence, that embeds the appropriate unbiased mean, the median absolute deviation, and the attack probability ratio metric at runtime to produce trust scores for each smart meter. These trust scores help classify compromised smart meters from the non-compromised ones. The embedding of the attack context, into the trust scoring model, facilitates accurate and rapid classification of compromised meters, even under large fractions of compromised meters, generalize across various attack strategies and margins of false data. Using real datasets collected from two different AMIs, experimental results show that our proposed framework has a high true positive detection rate, while the average false alarm and missed detection rates are much lesser than 10% for most attack combinations for two different real AMI micro-grid datasets. Finally, we also establish fundamental theoretical limits of the proposed method, which will help assess the applicability of our method to other domains.  © 2021 ACM.",Advanced metering infrastructure; anomaly detection; artificial-intelligence-based security; data falsification attacks; data integrity; smart metering; smart-grid security; trust,Advanced metering infrastructures; Anomaly detection; Crime; Electric power measurement; Electric power system control; Electric power transmission networks; Microgrids; Smart meters; Attack strategies; Context information; Directional changes; Electricity theft; Kullback-Leibler divergence; Location parameters; Median absolute deviation; Theoretical limits; Smart power grids
Analyzing Dynamic Code: A Sound Abstract Interpreter for Evil Eval,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100740311&partnerID=40&md5=4ad820e937743f0b59831c7f5daa47c0,"Dynamic languages, such as JavaScript, employ string-to-code primitives to turn dynamically generated text into executable code at run-time. These features make standard static analysis extremely hard if not impossible, because its essential data structures, i.e., the control-flow graph and the system of recursive equations associated with the program to analyze, are themselves dynamically mutating objects. Nevertheless, assembling code at run-time by manipulating strings, such as by eval in JavaScript, has been always strongly discouraged, since it is often recognized that ""eval is evil,""leading static analyzers to not consider such statements or ignoring their effects. Unfortunately, the lack of formal approaches to analyze string-to-code statements pose a perfect habitat for malicious code, that is surely evil and do not respect good practice rules, allowing them to hide malicious intents as strings to be converted to code and making static analyses blind to the real malicious aim of the code. Hence, the need to handle string-to-code statements approximating what they can execute, and therefore allowing the analysis to continue (even in the presence of dynamically generated program statements) with an acceptable degree of precision, should be clear. To reach this goal, we propose a static analysis allowing us to collect string values and to soundly over-approximate and analyze the code potentially executed by a string-to-code statement.  © 2021 ACM.",Abstract interpretation; dynamic languages; static analysis,Data flow analysis; Flow graphs; High level languages; Control flow graphs; Degree of precision; Dynamic languages; Executable codes; Malicious codes; Program statements; Recursive equations; Static analyzers; Static analysis
One Size Does Not Fit All: A Longitudinal Analysis of Brazilian Financial Malware,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100726928&partnerID=40&md5=cc57887526d914b2c8641bfe2e478092,"Malware analysis is an essential task to understand infection campaigns, the behavior of malicious codes, and possible ways to mitigate threats. Malware analysis also allows better assessment of attackers' capabilities, techniques, and processes. Although a substantial amount of previous work provided a comprehensive analysis of the international malware ecosystem, research on regionalized, country-, and population-specific malware campaigns have been scarce. Moving towards addressing this gap, we conducted a longitudinal (2012-2020) and comprehensive (encompassing an entire population of online banking users) study of MS Windows desktop malware that actually infected Brazilian banks' users. We found that the Brazilian financial desktop malware has been evolving quickly: it started to make use of a variety of file formats instead of typical PE binaries, relied on native system resources, and abused obfuscation techniques to bypass detection mechanisms. Our study on the threats targeting a significant population on the ecosystem of the largest and most populous country in Latin America can provide invaluable insights that may be applied to other countries' user populations, especially those in the developing world that might face cultural peculiarities similar to Brazil's. With this evaluation, we expect to motivate the security community/industry to seriously consider a deeper level of customization during the development of next-generation anti-malware solutions, as well as to raise awareness towards regionalized and targeted Internet threats.  © 2021 ACM.",banking; Malware; reverse engineer,Developing countries; Ecosystems; Petroleum reservoir evaluation; Comprehensive analysis; Detection mechanism; Developing world; Longitudinal analysis; Malicious codes; Malware analysis; On-line banking; Security community; Malware
An Extensive Formal Analysis of Multi-factor Authentication Protocols,2021,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100796544&partnerID=40&md5=3d9011a30429ba9ca9ea015ed4891fbd,"Passwords are still the most widespread means for authenticating users, even though they have been shown to create huge security problems. This motivated the use of additional authentication mechanisms in so-called multi-factor authentication protocols. In this article, we define a detailed threat model for this kind of protocol: While in classical protocol analysis attackers control the communication network, we take into account that many communications are performed over TLS channels, that computers may be infected by different kinds of malware, that attackers could perform phishing, and that humans may omit some actions. We formalize this model in the applied pi calculus and perform an extensive analysis and comparison of several widely used protocols - variants of Google 2-step and FIDO's U2F (Yubico's Security Key token). The analysis is completely automated, generating systematically all combinations of threat scenarios for each of the protocols and using the PROVERIF tool for automated protocol analysis. To validate our model and attacks, we demonstrate their feasibility in practice, even though our experiments are run in a laboratory environment. Our analysis highlights weaknesses and strengths of the different protocols. It allows us to suggest several small modifications of the existing protocols that are easy to implement, as well as an extension of Google 2-step that improves security in several threat scenarios.  © 2021 ACM.",detailed threat models; Formal methods; multi-factor authentication; symbolic model,Calculations; Malware; Applied pi calculus; Authentication mechanisms; Automated protocol analysis; Different protocols; Laboratory environment; Multi-factor authentication; Protocol analysis; Security problems; Authentication
The Tip of the Iceberg: On the Merits of Finding Security Bugs,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097512118&doi=10.1145%2f3406112&partnerID=40&md5=3f768922c98244557dea38a35505e881,"In this article, we investigate a fundamental question regarding software security: Is the security of SW releases increasing over time? We approach this question with a detailed analysis of the large body of open-source software packaged in the popular Debian GNU/Linux distribution. Contrary to common intuition, we find no clear evidence that the vulnerability rate of widely used software decreases over time: Even in popular and ""stable""releases, the fixing of bugs does not seem to reduce the rate of newly identified vulnerabilities. The intuitive conclusion is worrisome: Commonly employed development and validation procedures do not seem to scale with the increase of features and complexity - they are only chopping pieces off the top of an iceberg of vulnerabilities. To the best of our knowledge, this is the first investigation into the problem that studies a complete distribution of software, spanning multiple versions. Although we can not give a definitive answer, we show that several popular beliefs also cannot be confirmed given our dataset. We publish our Debian Vulnerability Analysis Framework (DVAF), an automated dataset creation and analysis process, to enable reproduction and further analysis of our results. Overall, we hope our contributions provide important insights into the vulnerability discovery process and help in identifying effective techniques for vulnerability analysis and prevention.  © 2020 ACM.",debian GNU/Linux; Empirical study; vulnerability discovery rate,Cell proliferation; Open systems; Program debugging; Sea ice; Analysis process; GNU/LINUX; Security bugs; Software security; Vulnerability analysis; Vulnerability discovery; Open source software
Exploiting Behavioral Side Channels in Observation Resilient Cognitive Authentication Schemes,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097494299&doi=10.1145%2f3414844&partnerID=40&md5=3b1aa1b00e753d93a0ed80dcb6045e81,"Observation Resilient Authentication Schemes (ORAS) are a class of shared secret challenge-response identification schemes where a user mentally computes the response via a cognitive function to authenticate herself such that eavesdroppers cannot readily extract the secret. Security evaluation of ORAS generally involves quantifying information leaked via observed challenge-response pairs. However, little work has evaluated information leaked via human behavior while interacting with these schemes. A common way to achieve observation resilience is by including a modulus operation in the cognitive function. This minimizes the information leaked about the secret due to the many-to-one map from the set of possible secrets to a given response. In this work, we show that user behavior can be used as a side channel to obtain the secret in such ORAS. Specifically, the user's eye-movement patterns and associated timing information can deduce whether a modulus operation was performed (a fundamental design element) to leak information about the secret. We further show that the secret can still be retrieved if the deduction is erroneous, a more likely case in practice. We treat the vulnerability analytically and propose a generic attack algorithm that iteratively obtains the secret despite the ""faulty""modulus information. We demonstrate the attack on five ORAS and show that the secret can be retrieved with considerably less challenge-response pairs than non-side-channel attacks (e.g., algebraic/statistical attacks). In particular, our attack is applicable on Mod10, a one-time-pad-based scheme, for which no non-side-channel attack exists. We field test our attack with a small-scale eye-tracking user study.  © 2020 ACM.",Cognitive authentication; eyetracking; modulus operation; observation resilient authentication schemes; side-channel attack,Authentication; Behavioral research; Brain; Eye movements; Eye tracking; Iterative methods; Authentication scheme; Challenge response; Challenge-response pair; Cognitive functions; Eye movement patterns; Fundamental design; Identification scheme; Security evaluation; Side channel attack
A Study on the Use of Checksums for Integrity Verification of Web Downloads,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097499078&doi=10.1145%2f3410154&partnerID=40&md5=9486b1ef764150484575f34a3efe7ecc,"App stores provide access to millions of different programs that users can download on their computers. Developers can also make their programs available for download on their websites and host the program files either directly on their website or on third-party platforms, such as mirrors. In the latter case, as users download the software without any vetting from the developers, they should take the necessary precautions to ensure that it is authentic. One way to accomplish this is to check that the published file's integrity verification code - the checksum - matches that (if provided) of the downloaded file. To date, however, there is little evidence to suggest that such a process is effective. Even worse, very few usability studies about it exist. In this article, we provide the first comprehensive study that assesses the usability and effectiveness of the manual checksum verification process. First, by means of an in-situ experiment with 40 participants and eye-tracking technology, we show that the process is cumbersome and error-prone. Second, after a 4-month-long in-the-wild experiment with 134 participants, we demonstrate how our proposed solution - a Chrome extension that verifies checksums automatically - significantly reduces human errors, improves coverage, and has only limited impact on usability. It also confirms that, sadly, only a tiny minority of websites that link to executable files in our sample provide checksums (0.01%), which is a strong call to action for web standards bodies, service providers, and content creators to increase the use of file integrity verification on their properties.  © 2020 Owner/Author.",Checksums; integrity; security; usability; web downloads,Eye tracking; Websites; Chrome extensions; Executable files; Eye tracking technologies; File integrities; In-situ experiments; Integrity verifications; Usability studies; Verification process; Application programs
"""So if Mr Blue Head here clicks the link⋯"" Risk Thinking in Cyber Security Decision Making",2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097502983&doi=10.1145%2f3419101&partnerID=40&md5=18f4657e63bc2c0a050134705fb3c963,"Cyber security decision making is inherently complicated, with nearly every decision having knock-on consequences for an organisation's vulnerability and exposure. This is further compounded by the fact that decision-making actors are rarely security experts and may have an incomplete understanding of the security that the organisation currently has in place. They must contend with a multitude of possible security options that they may only partially understand. This challenge is met by decision makers' risk thinking - their strategies for identifying risks, assessing their severity, and prioritising responses. We study the risk thinking strategies employed by teams of participants in an existing dataset derived from a tabletop cyber-physical systems security game. Our analysis identifies four structural patterns of risk thinking and two reasoning strategies: risk-first and opportunity-first. Our work highlights that risk-first approaches (as prescribed by the likes of NIST-800-53 and ISO 27001) are followed neither substantially nor exclusively when it comes to decision making. Instead, our analysis finds that decision making is affected by the plasticity of teams - that is, the ability to readily switch between ideas and practising both risk-first and opportunity-first reasoning.  © 2020 ACM.",cyber security; cyber security professions; Decision making,Embedded systems; Risk assessment; Security of data; Cyber physical systems (CPSs); Cyber security; Decision makers; Security experts; Structural pattern; Decision making
Adaptive Cyber Defense against Multi-Stage Attacks Using Learning-Based POMDP,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097491449&doi=10.1145%2f3418897&partnerID=40&md5=2d86170938446d8e8118cc0e9607e776,"Growing multi-stage attacks in computer networks impose significant security risks and necessitate the development of effective defense schemes that are able to autonomously respond to intrusions during vulnerability windows. However, the defender faces several real-world challenges, e.g., unknown likelihoods and unknown impacts of successful exploits. In this article, we leverage reinforcement learning to develop an innovative adaptive cyber defense to maximize the cost-effectiveness subject to the aforementioned challenges. In particular, we use Bayesian attack graphs to model the interactions between the attacker and networks. Then we formulate the defense problem of interest as a partially observable Markov decision process problem where the defender maintains belief states to estimate system states, leverages Thompson sampling to estimate transition probabilities, and utilizes reinforcement learning to choose optimal defense actions using measured utility values. The algorithm performance is verified via numerical simulations based on real-world attacks.  © 2020 ACM.",adaptive cyber defense; Reinforcement learning; Thompson sampling,Bayesian networks; Cost effectiveness; Markov processes; Network security; Algorithm performance; Multi-stage attack; Partially observable Markov decision process; Real-world attack; Security risks; Thompson samplings; Transition probabilities; Utility values; Reinforcement learning
NoiSense Print: Detecting Data Integrity Attacks on Sensor Measurements Using Hardware-based Fingerprints,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094644914&doi=10.1145%2f3410447&partnerID=40&md5=0a4fc467d422d74a18a4892b2aeb5534,"Fingerprinting of various physical and logical devices has been proposed for uniquely identifying users or devices of mainstream IT systems such as PCs, laptops, and smart phones. However, the application of such techniques in Industrial Control Systems (ICS) is less explored for reasons such as a lack of direct access to such systems and the cost of faithfully reproducing realistic threat scenarios. This work addresses the feasibility of using fingerprinting techniques in the context of realistic ICS related to water treatment and distribution systems. A model-free sensor fingerprinting scheme (NoiSense) and a model-based sensor fingerprinting scheme (NoisePrint) are proposed. Using extensive experimentation with sensors, it is shown that noise patterns due to microscopic imperfections in hardware manufacturing can uniquely identify sensors with accuracy as high as 97%. The proposed technique can be used to detect physical attacks, such as the replacement of legitimate sensors by faulty or manipulated sensors. For NoisePrint, a combined fingerprint for sensor and process noise is created. The difference (called residual), between expected and observed values, i.e., noise, is used to derive a model of the system. It was found that in steady state the residual vector is a function of process and sensor noise. Data from experiments reveals that a multitude of sensors can be uniquely identified with a minimum accuracy of 90% based on NoisePrint. Also proposed is a novel challenge-response protocol that exposes more powerful cyber-attacks, including replay attacks.  © 2020 ACM.",attack detection; challenge response protocol; CPS security; CPS threat modeling; Cyber physical systems; device fingerprinting; ICS security; machine learning-based intrusion detection; physical attacks; process noise; sensor fingerprinting; sensor noise; sensors security,Network security; Smartphones; Water treatment; Challenge response protocols; Distribution systems; Fingerprinting schemes; Fingerprinting techniques; Industrial control systems; Residual vectors; Sensor measurements; Threat scenarios; Palmprint recognition
Following Passive DNS Traces to Detect Stealthy Malicious Domains Via Graph Inference,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091908456&doi=10.1145%2f3401897&partnerID=40&md5=fb70bc9f20bb535f467e09da61c26a4f,"Malicious domains, including phishing websites, spam servers, and command and control servers, are the reason for many of the cyber attacks nowadays. Thus, detecting them in a timely manner is important to not only identify cyber attacks but also take preventive measures. There has been a plethora of techniques proposed to detect malicious domains by analyzing Domain Name System (DNS) traffic data. Traditionally, DNS acts as an Internet miscreant's best friend, but we observe that the subtle traces in DNS logs left by such miscreants can be used against them to detect malicious domains. Our approach is to build a set of domain graphs by connecting ""related""domains together and injecting known malicious and benign domains into these graphs so that we can make inferences about the other domains in the domain graphs. A key challenge in building these graphs is how to accurately identify related domains so that incorrect associations are minimized and the number of domains connected from the dataset is maximized. Based on our observations, we first train two classifiers and then devise a set of association rules that assist in linking domains together. We perform an in-depth empirical analysis of the graphs built using these association rules on passive DNS data and show that our techniques can detect many more malicious domains than the state-of-the-art.  © 2020 ACM.",domain association; graph inference; Malicious domains; passive DNS,Association rules; Command and control systems; Computer crime; Crime; Graphic methods; Information dissemination; Network security; Command and control; Cyber-attacks; Domain name system; Empirical analysis; In-buildings; Phishing websites; Preventive measures; State of the art; Internet protocols
The Seven Deadly Sins of the HTML5 WebAPI,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091934077&doi=10.1145%2f3403947&partnerID=40&md5=0728d23010d51c32355bf8090f4cfff1,"Modern smartphone sensors can be leveraged for providing novel functionality and greatly improving the user experience. However, sensor data can be misused by privacy-invasive or malicious entities. Additionally, a wide range of other attacks that use mobile sensor data have been demonstrated; while those attacks have typically relied on users installing malicious apps, browsers have eliminated that constraint with the deployment of HTML5 WebAPI. In this article, we conduct a comprehensive evaluation of the multifaceted threat that mobile web browsing poses to users by conducting a large-scale study of mobile-specific HTML5 WebAPI calls across more than 183K of the most popular websites. We build a novel testing infrastructure consisting of actual smartphones on top of a dynamic Android app analysis framework, allowing us to conduct an end-to-end exploration. In detail, our system intercepts and tracks data access in real time, from the WebAPI JavaScript calls down to the Android system calls. Our study reveals the extent to which websites are actively leveraging the WebAPI for collecting sensor data, with 2.89% of websites accessing at least one sensor. To provide a comprehensive assessment of the risks of this emerging practice, we create a taxonomy of sensor-based attacks from prior studies and present an in-depth analysis by framing our collected data within that taxonomy. We find that 1.63% of websites can carry out at least one attack and emphasize the need for a standardized policy across all browsers and the ability for users to control what sensor data each website can access.  © 2020 ACM.",Android; browser guidelines; mobile HTML5; mobile sensors; sensor attack taxonomy; WebAPI,HTML; Risk assessment; Smartphones; Taxonomies; User experience; Websites; Analysis frameworks; Android systems; Comprehensive assessment; Comprehensive evaluation; In-depth analysis; Large-scale studies; Malicious entity; Mobile web browsing; Android (operating system)
"On the Security and Usability Implications of Providing Multiple Authentication Choices on Smartphones: The More, the Beter?",2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091924929&doi=10.1145%2f3410155&partnerID=40&md5=f399220ab7d0fe57c15f49483e45e28e,"The latest smartphones have started providing multiple authentication options including PINs, patterns, and passwords (knowledge based), as well as face, fingerprint, iris, and voice identification (biometric-based). In this article, we conducted two user studies to investigate how the convenience and security of unlocking phones are influenced by the provision of multiple authentication options. In a task-based user study with 52 participants, we analyze how participants choose an option to unlock their smartphone in daily life. The user study results demonstrate that providing multiple biometric-based authentication choices does not really influence convenience, because fingerprint had monopolistic dominance in the usage of unlock methods (111 of a total of 115 unlock trials that used a biometric-based authentication factor) due to users' habitual behavior and fastness in unlocking phones. However, convenience was influenced by the provision of both knowledge-based and biometric-based authentication categories, as biometric-based authentication options were used in combination with knowledge-based authentication options - pattern was another frequently used unlock method. Our findings were confirmed and generalized through a follow-up survey with 327 participants. First, knowledge-based and biometric-based authentication options are used interchangeably. Second, providing multiple authentication options for knowledge-based authentication may influence convenience - both PINs (55.7%) and patterns (39.2%) are quite evenly used. Last, in contrast to knowledge-based authentication, providing multiple authentication choices for biometric-based authentication has less influence on choosing unlock options - fingerprint scanner is the most frequently used option (134 of 187 unlock methods used among biometric-based authentication options).  © 2020 ACM.",biometric authentication; Multiple authentication options; password,Biometrics; Knowledge based systems; Mobile security; Smartphones; Surveys; Biometric based authentication; Fingerprint scanners; Habitual behavior; Knowledge based; Knowledge-based authentication; Multiple authentications; Security and usabilities; Voice identification; Authentication
Efficient Authorization of Graph-database Queries in an Attribute-supporting ReBAC Model,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091920339&doi=10.1145%2f3401027&partnerID=40&md5=fb69e213e7e145a00b0ba0e6f431ccd4,"Neo4j is a popular graph database that offers two versions: an enterprise edition and a community edition. The enterprise edition offers customizable Role-based Access Control features through custom developed procedures, while the community edition does not offer any access control support. Being a graph database, Neo4j appears to be a natural application for Relationship-Based Access Control (ReBAC), an access control paradigm where authorization decisions are based on relationships between subjects and resources in the system (i.e., an authorization graph). In this article, we present AReBAC, an attribute-supporting ReBAC model for Neo4j that provides finer-grained access control by operating over resources instead of procedures. AReBAC employs Nano-Cypher, a declarative policy language based on Neo4j's Cypher query language, the result of which allows us to weave database queries with access control policies and evaluate both simultaneously. Evaluating the combined query and policy produces a result that (i) matches the search criteria, and (ii) the requesting subject is authorized to access. AReBAC is accompanied by the algorithms and their implementation required for the realization of the presented ideas, including GP-Eval, a query evaluation algorithm. We also introduce Live-End Backjumping (LBJ), a backtracking scheme that provides a significant performance boost over conflict-directed backjumping for evaluating queries. As demonstrated in our previous work, the original version of GP-Eval already performs significantly faster than the Neo4j's Cypher evaluation engine. The optimized version of GP-Eval, which employs LBJ, further improves the performance significantly, thereby demonstrating the capabilities of the technique.  © 2020 ACM.",attributes; graph database; graph patterns; live-end backjumping; nano-cypher; Neo4j; Relationship-based access control,Graph Databases; Query languages; Query processing; Access control policies; Authorization decision; Conflict-directed backjumping; Database queries; Policy language; Query evaluation algorithm; Role-based Access Control; Search criterion; Access control
Code Renewability for Native Software Protection,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091935522&doi=10.1145%2f3404891&partnerID=40&md5=e0f5b32aa70c82e17b6a4d44c90b83d8,"Software protection aims at safeguarding assets embedded in software by preventing and delaying reverse engineering and tampering attacks. This article presents an architecture and supporting tool flow to renew parts of native applications dynamically. Renewed and diversified code and data belonging to either the original application or to linked-in protections are delivered from a secure server to a client on demand. This results in frequent changes to the software components when they are under attack, thus making attacks harder. By supporting various forms of diversification and renewability, novel protection combinations become available and existing combinations become stronger. The prototype implementation is evaluated on several industrial use cases.  © 2020 ACM.",diversification; Man-at-the-end attacks; online protection; security server; software updates,Reverse engineering; Industrial use case; On demands; Prototype implementations; Software component; Software protection; Supporting tool; Tampering attacks; Codes (symbols)
Proactively Identifying Emerging Hacker Threats from the Dark Web,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091933720&doi=10.1145%2f3409289&partnerID=40&md5=567e69508adf7512313922edabb4541b,"Cybersecurity experts have appraised the total global cost of malicious hacking activities to be $450 billion annually. Cyber Threat Intelligence (CTI) has emerged as a viable approach to combat this societal issue. However, existing processes are criticized as inherently reactive to known threats. To combat these concerns, CTI experts have suggested proactively examining emerging threats in the vast, international online hacker community. In this study, we aim to develop proactive CTI capabilities by exploring online hacker forums to identify emerging threats in terms of popularity and tool functionality. To achieve these goals, we create a novel Diachronic Graph Embedding Framework (D-GEF). D-GEF operates on a Graph-of-Words (GoW) representation of hacker forum text to generate word embeddings in an unsupervised manner. Semantic displacement measures adopted from diachronic linguistics literature identify how terminology evolves. A series of benchmark experiments illustrate D-GEF's ability to generate higher quality than state-of-the-art word embedding models (e.g., word2vec) in tasks pertaining to semantic analogy, clustering, and threat classification. D-GEF's practical utility is illustrated with in-depth case studies on web application and denial of service threats targeting PHP and Windows technologies, respectively. We also discuss the implications of the proposed framework for strategic, operational, and tactical CTI scenarios. All datasets and code are publicly released to facilitate scientific reproducibility and extensions of this work.  © 2020 ACM.",Cyber threat intelligence; deep learning; diachronic linguistics; graph convolutions; graph embeddings; hacker forums; ransomware; text graphs,Benchmarking; Classification (of information); Embeddings; Personal computing; Security of data; Semantics; Benchmark experiments; Denial of Service; Graph embeddings; Hacker communities; Reproducibilities; State of the art; Threat classifications; WEB application; Computer crime
Privado: Privacy-preserving Group-based Advertising Using Multiple Independent Social Network Providers,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090450775&doi=10.1145%2f3386154&partnerID=40&md5=5f9f804c2ad6c4bc3e6113d882c86f1c,"Online Social Networks (OSNs) offer free storage and social networking services through which users can communicate personal information with one another. The personal information of the users collected by the OSN provider comes with privacy problems when being monetized for advertising purposes. To protect user privacy, existing studies propose utilizing data encryption that immediately prevents OSNs from monetizing users data and hence leaves secure OSNs with no convincing commercial model. To address this problem, we propose Privado as a privacy-preserving group-based advertising mechanism to be integrated into secure OSNs to re-empower monetizing ability. Privado is run by N servers, each provided by an independent provider. User privacy is protected against an active malicious adversary controlling N - 1 providers, all the advertisers, and a large fraction of the users. We base our design on the group-based advertising notion to protect user privacy, which is not possible in the personalized variant. Our design also delivers advertising transparency; the procedure of identifying target customers is operated solely by the OSN servers without getting users and advertisers involved. We carry out experiments to examine the advertising running time under various number of servers and group sizes. We also argue about the optimum number of servers with respect to user privacy and advertising running time. © 2020 ACM.",active adversary; advertising; malicious adversary; online social networks; privacy; privacy-preserving advertising; Unlinkability,Cryptography; Digital storage; Marketing; Social networking (online); Storage as a service (STaaS); Commercial models; Malicious adversaries; Network provider; Online social networks (OSNs); Optimum Number of Servers; Personal information; Privacy preserving; Social networking services; Data privacy
The System That CriedWolf: Sensor Security Analysis of Wide-area Smoke Detectors for Critical Infrastructure,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090474403&doi=10.1145%2f3393926&partnerID=40&md5=ada26bb16bd95571263a0123eff897b8,"Fire alarm and signaling systems are a networked system of fire detectors, fire control units, automated fire extinguishers, and fire notification appliances. Malfunction of these safety-critical cyber-physical systems may lead to chaotic evacuations, property damage, and even loss of human life. Therefore, reliability is one of the most crucial factors for fire detectors. Indeed, even a single report of a fire cannot be ignored, considering the importance of early fire detection and suppression. In this article, we show that wide-area smoke detectors, which are globally installed in critical infrastructures such as airports, sports facilities, and auditoriums, have significant vulnerabilities in terms of reliability; one can remotely and stealthily induce false fire alarms and suppress real fire alarms with a minimal attacker capability using simple equipment. The practicality and generalizability of these vulnerabilities has been assessed based on the demonstration of two types of sensor attacks on two commercial off-the-shelf optical beam smoke detectors from different manufacturers. Further, the practical considerations of building stealthy attack equipment has been analyzed, and an extensive survey of almost all optical beam smoke detectors on the market has been conducted. In addition, we show that the current standards of the fire alarm network connecting the detector and a control unit exacerbate the problem, making it impossible or very difficult to mitigate the threats we found. Finally, we discuss hardware- and software-based possible countermeasures for both wide-area smoke detectors and the fire alarm network; the effectiveness of one of the countermeasures is experimentally evaluated. © 2020 ACM.",cyber-physical system; fire alarm and signaling system; safety-critical system; sensing and actuation system; Sensor attack; sensor security,Critical infrastructures; Embedded systems; Fire extinguishers; Fires; Networked control systems; Public works; Smoke; Smoke detectors; Wide area networks; Fire control unit; Hardware and software; Networked systems; Notification appliances; Optical beams; Property damage; Sensor securities; Signaling systems; Fire alarm systems
Quantum Leap and Crash,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090431618&doi=10.1145%2f3398726&partnerID=40&md5=6d37ef0dd3a4a4138761e1aed6141a88,"Random numbers are essential for cryptography and scientific simulation. Generating truly random numbers for cryptography can be a slow and expensive process. Quantum physics offers a variety of promising solutions to this challenge, proposing sources of entropy that may be genuinely unpredictable, based on the inherent randomness of certain physical phenomena. These properties have been employed to design Quantum Random Number Generators (QRNGs), some of which are commercially available. In this work, we present the first published analysis of the Quantis family of QRNGs (excluding AIS-31 models), designed and manufactured by ID Quantique (IDQ). Our study also includes Comscire's PQ32MU QRNG, and two online services: the Australian National University's (ANU) QRNG, and the Humboldt Physik generator. Each QRNG is analysed using five batteries of statistical tests: Dieharder, National Institute of Standards and Technology (NIST) SP800-22, Ent, Tuftests and TestU01, as part of our thorough examination of their output. Our analysis highlights issues with current certification schemes, which largely rely on NIST SP800-22 and Diehard tests of randomness. We find that more recent tests of randomness identify issues in the output of QRNG, highlighting the need for mandatory post-processing even for low-security usage of random numbers sourced from QRNGs. © 2020 ACM.",cryptography; entropy; Quantum random number generation; statistical analysis,Automatic identification; Cryptography; Number theory; Random processes; Australian National University; National Institute of Standards and Technology; Physical phenomena; Post processing; Quantum physics; Quantum random number generators; Scientific simulations; Tests of randomness; Random number generation
Key Negotiation Downgrade Attacks on Bluetooth and Bluetooth Low Energy,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090475013&doi=10.1145%2f3394497&partnerID=40&md5=af7c7c9b2ccfc0d6d127871d6970141f,"Bluetooth (BR/EDR) and Bluetooth Low Energy (BLE) are pervasive wireless technologies specified in the Bluetooth standard. The standard includes key negotiation protocols used to generate long-term keys (during pairing) and session keys (during secure connection establishment). In this work, we demonstrate that the key negotiation protocols of Bluetooth and BLE are vulnerable to standard-compliant entropy downgrade attacks. In particular, we show how an attacker can downgrade the entropy of any Bluetooth session key to 1 byte, and of any BLE long-term key and session key to 7 bytes. Such low entropy values enable the attacker to brute-force Bluetooth long-term keys and BLE long-term and session keys, and to break all the security guarantees promised by Bluetooth and BLE. As a result of our attacks, an attacker can decrypt all the ciphertext and inject valid ciphertext in any Bluetooth and BLE network. Our key negotiation downgrade attacks are conducted remotely, do not require access to the victims' devices, and are stealthy to the victims. As the attacks are standard-compliant, they are effective regardless of the usage of the strongest Bluetooth and BLE security modes (including Secure Connections), the Bluetooth version, and the implementation details of the devices used by the victims. We successfully attack 38 Bluetooth devices (32 unique Bluetooth chips) and 19 BLE devices from different vendors, using all the major versions of the Bluetooth standard. Finally, we present effective legacy compliant and non-legacy compliant countermeasures to mitigate our key negotiation downgrade attacks. © 2020 ACM.",BLE; bluetooth; downgrade attack; key negotiation; KNOB attack; Security,Cryptography; Entropy; Security of data; Bluetooth chip; Bluetooth device; Bluetooth low energies (BLE); Bluetooth low energies (BTLE); Bluetooth standards; Long-term keys; Negotiation protocol; Pervasive wireless technologies; Bluetooth
Formal Analysis of Mobile Multi-Factor Authentication with Single Sign-On Login,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090464517&doi=10.1145%2f3386685&partnerID=40&md5=78b5feac75baa933b21f02a6c1226cc5,"Over the last few years, there has been an almost exponential increase in the number of mobile applications that deal with sensitive data, such as applications for e-commerce or health. When dealing with sensitive data, classical authentication solutions based on username-password pairs are not enough, and multi-factor authentication solutions that combine two or more authentication factors of different categories are required instead. Even if several solutions are currently used, their security analyses have been performed informally or semiformally at best, and without a reference model and a precise definition of the multi-factor authentication property. This makes a comparison among the different solutions both complex and potentially misleading. In this article, we first present the design of two reference models for native applications based on the requirements of two real-world use-case scenarios. Common features between them are the use of one-time password approaches and the support of a single sign-on experience. Then, we provide a formal specification of our threat model and the security goals, and discuss the automated security analysis that we performed. Our formal analysis validates the security goals of the two reference models we propose and provides an important building block for the formal analysis of different multi-factor authentication solutions. © 2020 ACM.",eID card; OAuth; OpenID Connect; SATMC,Authentication; Mobile commerce; Security systems; Authentication solutions; Exponential increase; Mobile applications; Multi-factor authentication; One time passwords; Precise definition; Reference modeling; Security analysis; Factor analysis
Measuring and Analysing the Chain of Implicit Trust: A Study of Third-party Resources Loading,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085618175&doi=10.1145%2f3380466&partnerID=40&md5=6f142808a3ce29f1fceae8844c267145,"The web is a tangled mass of interconnected services, whereby websites import a range of external resources from various third-party domains. The latter can also load further resources hosted on other domains. For each website, this creates a dependency chain underpinned by a form of implicit trust between the first-party and transitively connected third parties. The chain can only be loosely controlled as first-party websites often have little, if any, visibility on where these resources are loaded from. This article performs a large-scale study of dependency chains in the web to find that around 50% of first-party websites render content that they do not directly load. Although the majority (84.91%) of websites have short dependency chains (below three levels), we find websites with dependency chains exceeding 30. Using VirusTotal, we show that 1.2% of these third parties are classified as suspicious - although seemingly small, this limited set of suspicious third parties have remarkable reach into the wider ecosystem. We find that 73% of websites under-study load resources from suspicious third parties, and 24.8% of first-party webpages contain at least three third parties classified as suspicious in their dependency chain. By running sandboxed experiments, we observe a range of activities with the majority of suspicious JavaScript codes downloading malware. © 2020 ACM.",experiments; javascript; Measurement; sandbox; third party resources; web of trust; web security and privacy,Computer viruses; Dependency chains; External resources; Implicit trusts; Javascript; Large-scale studies; Third parties; Websites
Using Generative Adversarial Networks to Break and Protect Text Captchas,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085590553&doi=10.1145%2f3378446&partnerID=40&md5=3aba184ec410d3be9f38fd4c5a9ef18e,"Text-based CAPTCHAs remains a popular scheme for distinguishing between a legitimate human user and an automated program. This article presents a novel genetic text captcha solver based on the generative adversarial network. As a departure from prior text captcha solvers that require a labor-intensive and time-consuming process to construct, our scheme needs significantly fewer real captchas but yields better performance in solving captchas. Our approach works by first learning a synthesizer to automatically generate synthetic captchas to construct a base solver. It then improves and fine-tunes the base solver using a small number of labeled real captchas. As a result, our attack requires only a small set of manually labeled captchas, which reduces the cost of launching an attack on a captcha scheme. We evaluate our scheme by applying it to 33 captcha schemes, of which 11 are currently used by 32 of the top-50 popular websites. Experimental results demonstrate that our scheme significantly outperforms four prior captcha solvers and can solve captcha schemes where others fail. As a countermeasure, we propose to add imperceptible perturbations onto a captcha image. We demonstrate that our countermeasure can greatly reduce the success rate of the attack. © 2020 ACM.",authentication; generative adversarial networks; security; Text captchas; transfer learning,Adversarial networks; CAPTCHAs; Human users; Labor intensive; Electronic mail filters
"Build It, Break It, Fix It: Contesting Secure Development",2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085616963&doi=10.1145%2f3383773&partnerID=40&md5=d28133d55d8088230cc3a43e4fae26cb,"Typical security contests focus on breaking or mitigating the impact of buggy systems. We present the Build-it, Break-it, Fix-it (BIBIFI) contest, which aims to assess the ability to securely build software, not just break it. In BIBIFI, teams build specified software with the goal of maximizing correctness, performance, and security. The latter is tested when teams attempt to break other teams' submissions. Winners are chosen from among the best builders and the best breakers. BIBIFI was designed to be open-ended - teams can use any language, tool, process, and so on, that they like. As such, contest outcomes shed light on factors that correlate with successfully building secure software and breaking insecure software. We ran three contests involving a total of 156 teams and three different programming problems. Quantitative analysis from these contests found that the most efficient build-it submissions used C/C++, but submissions coded in a statically type safe language were 11× less likely to have a security flaw than C/C++ submissions. Break-it teams that were also successful build-it teams were significantly better at finding security bugs. © 2020 ACM.",Contest; education; engineering; security; software,Programming problem; Secure software; Security bugs; Security flaws; Type-safe languages; C++ (programming language)
The Security of Lazy Users in Out-of-Band Authentication,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085595507&doi=10.1145%2f3377849&partnerID=40&md5=ba3dd6394da73f7f3268aff7ff6975b5,"Faced with the threats posed by man-in-the-middle attacks, messaging platforms rely on ""out-of-band"" authentication, assuming that users have access to an external channel for authenticating one short value. For example, assuming that users recognizing each other's voice can authenticate a short value, Telegram and WhatApp ask their users to compare 288-bit and 200-bit values, respectively. The existing protocols, however, do not take into account the plausible behavior of users who may be ""lazy"" and only compare parts of these values (rather than their entirety). Motivated by such a security-critical user behavior, we study the security of lazy users in out-of-band authentication. We start by showing that both the protocol implemented by WhatsApp and the statistically optimal protocol of Naor, Segev, and Smith (CRYPTO'06) are completely vulnerable to man-in-the-middle attacks when the users consider only a half of the out-of-band authenticated value. In this light, we put forward a framework that captures the behavior and security of lazy users. Our notions of security consider both statistical security and computational security, and for each flavor we derive a lower bound on the tradeoff between the number of positions that are considered by the lazy users and the adversary's forgery probability. Within our framework, we then provide two authentication protocols. First, in the statistical setting, we present a transformation that converts any out-of-band authentication protocol into one that is secure even when executed by lazy users. Instantiating our transformation with a new refinement of the protocol of Naor et al. results in a protocol whose tradeoff essentially matches our lower bound in the statistical setting. Then, in the computational setting, we show that the computationally optimal protocol of Vaudenay (CRYPTO'05) is secure even when executed by lazy users - and its tradeoff matches our lower bound in the computational setting. © 2020 ACM.",cryptographic protocols; End-to-end encryption; key exchange; messaging,Behavioral research; Network security; Authentication protocols; Computational security; Computational settings; Man in the middle attacks; Optimal protocols; Security-critical; Statistical securities; User behaviors; Authentication
A Case for Feedforward Control with Feedback Trim to Mitigate Time Transfer Attacks,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085609408&doi=10.1145%2f3382503&partnerID=40&md5=380883a99e4aa029541796ee313492d8,"We propose a new clock synchronization architecture for systems under time transfer attacks. Facilitated by a feedforward control with feedback trim - based clock adjustment, coupled with packet filtering and frequency shaping techniques, our proposed architecture bounds the clock errors in the presence of a powerful network attacker capable of attacking packets between a master and a client. A key advantage is consistent measurements, timely coordination, and synchronized actuation in distributed systems. In contrast, current time synchronization architectures behave poorly under attacks due to assumptions that the network is benign and delays are symmetric. The usage of feedback controllers aggravates poor performance. We provide an architecture that is indifferent to delays and eases the integration to traditional protocols. We implement a delay attack - resistant precision time protocol and validate the results on a hardware-supported testbed. © 2020 ACM.",Feedback control; precision time protocol; two-way time transfer,Clocks; Feedback; Feedforward control; Synchronization; Attack resistants; Clock Synchronization; Distributed systems; Feedback controller; Network attackers; Precision time protocols; Proposed architectures; Time synchronization; Network architecture
"Discriminative power of typing features on desktops, tablets, and phones for user identification",2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079511847&doi=10.1145%2f3377404&partnerID=40&md5=0e0ede3bdb7172cd8ccd933561b86971,"Research in Keystroke-Dynamics (KD) has customarily focused on temporal features without considering context to generate user templates that are used in authentication. Additionally, work on KD in hand-held devices such as smart-phones and tablets have shown that these features alone do not perform satisfactorily for authentication. In this work, we analyze the discriminatory power of the most-used conventional features found in the literature, propose a set of context-sensitive or word-specific features, and analyze the discriminatory power of proposed features using their classification results. To perform these tasks, we use the keystroke data consisting of over 650K keystrokes, collected from 20 unique users during different activities on desktops, tablets, and phones, over a span of two months. On an average, each user made 12.5K, 9K, and 10K keystrokes on desktop, tablet, and phone, respectively. We find that the conventional features are not highly discriminatory on desktops and are only marginally better on hand-held devices for user identification. By using information of the context, a subset (derived after analysis) of our proposed word-specific features offers superior discrimination among users on all devices. We find that a majority of the classifiers, built using these features, perform user identification well with accuracies in the range of 90% to 97%, average precision and recall values of 0.914 and 0.901, respectively, on balanced test samples in 10-fold cross validation. We also find that proposed features work best on hand-held devices. This work calls for a shift from using conventional KD features to a set of context-sensitive or word-specific KD features that take advantage of known information such as context. © 2020 Association for Computing Machinery.",Context-sensitive features; Desktop; Discriminative power; Keystroke dynamics; Phone; Tablet; Typing,Authentication; Hand held computers; Smartphones; Context sensitive; Desktop; Discriminative power; Keystroke dynamics; Phone; Tablet; Typing; Classification (of information)
The dilemma of user engagement in privacy notices: Effects of interaction modes and habituation on user attention,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079765446&doi=10.1145%2f3372296&partnerID=40&md5=3a0da25eef07609884d26c9eac3d2a42,"Privacy notices and consent forms are the means of conveying privacy policy information to users. In Europe, a valid consent needs to be confirmed by a clear affirmative action. Despite previous research, it is not yet clear whether user engagement with consent forms via different types of interactions for confirming consent may play a significant role in effectively drawing user attention to the content, even after repeated exposure. We investigate, in a laboratory study, how different types of interactions that engage users with consent forms differ in terms of their effectiveness, efficiency, and user satisfaction. In addition, we examine if and how habituation affects user attention and satisfaction, and the time they spend on giving their consent. We conducted a controlled experiment with 80 participants in four different groups where people either were engaged actively with the policy content via Drag and Drop (DAD), Swipe, or Checkboxes, or were not actively engaged with the content (as the control condition) in a first-exposure phase and in a habituation phase. We measured user attention to consent forms along multiple dimensions, including direct, objective measurements and indirect, self-reported measures. Our results show that the different types of interactions may affect user attention to certain parts of policy information. In particular, the DAD action results in significantly more user attention to the data items compared to other groups. However, with repeated exposure to consent forms, the difference disappears. We conclude that user engagement with policy content needs to be designed with care, so that attention to substantial policy information is increased and not negatively affected. © 2020 Copyright held by the owner/author(s).",Affirmative actions; Attention to policy information; Habituation; Informed consent; Privacy notices,Affirmative actions; Attention to policy information; Controlled experiment; Habituation; Informed consent; Laboratory studies; Multiple dimensions; Objective measurement
A multi-server ORAM framework with constant client bandwidth blowup,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079478371&doi=10.1145%2f3369108&partnerID=40&md5=122d85e69c75b2e4086c03926119d5fd,"Oblivious Random Access Machine (ORAM) allows a client to hide the access pattern when accessing sensitive data on a remote server. It is known that there exists a logarithmic communication lower bound on any passive ORAM construction, where the server only acts as the storage service. This overhead, however, was shown costly for some applications. Several active ORAM schemes with server computation have been proposed to overcome this limitation. However, they mostly rely on costly homomorphic encryptions, whose performance is worse than passive ORAM. In this article, we propose S3ORAM, a new multi-server ORAM framework, which features O(1) client bandwidth blowup and low client storage without relying on costly cryptographic primitives. Our key idea is to harness Shamir Secret Sharing and a multi-party multiplication protocol on applicable binary tree-ORAM paradigms. This strategy allows the client to instruct the server(s) to perform secure and efficient computation on his/her behalf with a low intervention thereby, achieving a constant client bandwidth blowup and low server computational overhead. Our framework can also work atop a general kary tree ORAM structure (k ≥ 2). We fully implemented our framework, and strictly evaluated its performance on a commodity cloud platform (Amazon EC2). Our comprehensive experiments confirmed the efficiency of S3ORAM framework, where it is approximately 10× faster than the most efficient passive ORAM (i.e., Path-ORAM) for a moderate network bandwidth while being three orders of magnitude faster than active ORAM with O(1) bandwidth blowup (i.e., Onion-ORAM). We have open-sourced the implementation of our framework for public testing and adaptation. © 2020 Association for Computing Machinery.",ORAM; Privacy-enhancing technologies; Secret sharing,Bandwidth; Binary trees; Cryptography; Digital storage; Computational overheads; Cryptographic primitives; Ho-momorphic encryptions; ORAM; Privacy enhancing technologies; Random access machines; Secret sharing; Three orders of magnitude; Network architecture
Mimicry attacks on smartphone keystroke authentication,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079494527&doi=10.1145%2f3372420&partnerID=40&md5=a19ef8ae7075333a91a75140c4ddd95a,"Keystroke behaviour-based authentication employs the unique typing behaviour of users to authenticate them. Recent such proposals for virtual keyboards on smartphones employ diverse temporal, contact, and spatial features to achieve over 95% accuracy. Consequently, they have been suggested as a second line of defense with text-based password authentication. We show that a state-of-the-art keystroke behaviour-based authentication scheme is highly vulnerable against mimicry attacks. While previous research used training interfaces to attack physical keyboards, we show that this approach has limited effectiveness against virtual keyboards. This is mainly due to the large number of diverse features that the attacker needs to mimic for virtual keyboards. We address this challenge by developing an augmented reality-based app that resides on the attacker's smartphone and leverages computer vision and keystroke data to provide real-time guidance during password entry on the victim's phone. In addition, we propose an audiovisual attack in which the attacker overlays transparent film printed with spatial pointers on the victim's device and uses audio cues to match the temporal behaviour of the victim. Both attacks require neither tampering or installing software on the victim's device nor specialized hardware. We conduct experiments with 30 users to mount over 400 mimicry attacks. We show that our methods enable an attacker to mimic keystroke behaviour on virtual keyboards with little effort. We also demonstrate the extensibility of our augmented reality-based technique by successfully mounting mimicry attacks on a swiping behaviour-based continuous authentication system. © 2020 Association for Computing Machinery.",Augmented reality; Authentication; Behavioural biometrics; Mimicry attacks; Spoofing attacks,Augmented reality; Computer keyboards; Smartphones; Authentication scheme; Continuous authentications; Mimicry attacks; Password authentication; Specialized hardware; Spoofing attacks; Temporal behaviour; Transparent films; Authentication
CrowdPrivacy: Publish more useful data with less privacy exposure in crowdsourced location-based services,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079478212&doi=10.1145%2f3375752&partnerID=40&md5=d2ce245e8947bc78ab634c5776e8669e,"Location-based services (LBSs) typically crowdsource geo-tagged data from mobile users. Collecting more data will generally improve the utility for LBS providers; however, it also leads to more privacy exposure of users' mobility patterns. Although the tension between data utility and user privacy has been recognized, there lacks a solution that determines how much data to collect-in both spatial and temporal domains-is the “best” for both mobile users and the service provider. This article proposes a strategy toward making an optimal tradeoff such that a user submits data only if her mobility privacy will not be compromised and the data utility of the LBS provider will be sufficiently improved. To this end, we first define and formulate a concept called privacy exposure, which incorporates both the spatial distribution and the temporal transition of a user's activity points. Second, we define and quantify data utility in terms of spatial repetitions and temporal closeness among data based on an economic principle. Then, we propose a PRivacy-preserving and UTility-Enhancing Crowdsourcing (PRUTEC) algorithm to determine, on behalf of each mobile user, whether a newly sensed piece of data should be submitted to the LBS provider. Our simulation demonstrates that PRUTEC improves the data utility of the service provider with a much less amount of data to collect and reduces privacy exposure for mobile users while collecting useful data continuously. © 2020 Association for Computing Machinery.",Crowdsourcing; Cyber-physical systems; Location-based services; Participatory sensing; Privacy preservation; Smart cities,Crowdsourcing; Cyber Physical System; Data acquisition; Data privacy; Embedded systems; Location; Smart city; Telecommunication services; Economic principle; Optimal tradeoffs; Participatory Sensing; Privacy preservation; Privacy preserving; Service provider; Temporal domain; Users' mobility; Location based services
A formal approach to physics-based attacks in cyber-physical systems,2020,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079484543&doi=10.1145%2f3373270&partnerID=40&md5=fec7da6fc6c87d5014ee8efba080df24,"We apply formal methods to lay and streamline theoretical foundations to reason about Cyber-Physical Systems (CPSs) and physics-based attacks, i.e., attacks targeting physical devices. We focus on a formal treatment of both integrity and denial of service attacks to sensors and actuators of CPSs, and on the timing aspects of these attacks. Our contributions are fourfold. (1) We define a hybrid process calculus to model both CPSs and physics-based attacks. (2) We formalise a threat model that specifies MITM attacks that can manipulate sensor readings or control commands to drive a CPS into an undesired state; we group these attacks into classes and provide the means to assess attack tolerance/vulnerability with respect to a given class of attacks, based on a proper notion of most powerful physics-based attack. (3) We formalise how to estimate the impact of a successful attack on a CPS and investigate possible quantifications of the success chances of an attack. (4) We illustrate our definitions and results by formalising a non-trivial running example in Uppaal SMC, the statistical extension of the Uppaal model checker; we use Uppaal SMC as an automatic tool for carrying out a static security analysis of our running example in isolation and when exposed to three different physics-based attacks with different impacts. © 2020 Association for Computing Machinery.",Attack impact; Attack tolerance/ vulnerability; Cyber-physical system security; Formal security analysis; Process calculi,Calculations; Cyber Physical System; Embedded systems; Formal methods; Model checking; Network security; Security systems; Statistical Physics; Attack impact; Attack tolerances; Cyber-physical system securities; Formal security analysis; Process calculi; Denial-of-service attack
Skype & type: Keyboard eavesdropping in voice-over-IP,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076998082&doi=10.1145%2f3365366&partnerID=40&md5=e7be7d30ea1f7f5b572e2b4cf3e15369,"Voice-over-IP (VoIP) software are among the most widely spread and pervasive software, counting millions of monthly users. However, we argue that people ignore the drawbacks of transmitting information along with their voice, such as keystroke sounds-as such sound can reveal what someone is typing on a keyboard. In this article, we present and assess a new keyboard acoustic eavesdropping attack that involves VoIP, called Skype & Type (S&T). Unlike previous attacks, S&T assumes a weak adversary model that is very practical in many real-world settings. Indeed, S&T is very feasible, as it does not require (i) the attacker to be physically close to the victim (either in person or with a recording device) and (ii) precise profiling of the victim's typing style and keyboard; moreover, it can work with a very small amount of leaked keystrokes. We observe that leakage of keystrokes during a VoIP call is likely, as people often ""multi-task"" during such calls. As expected, VoIP software acquires and faithfully transmits all sounds, including emanations of pressed keystrokes, which can include passwords and other sensitive information. We show that one very popular VoIP software (Skype) conveys enough audio information to reconstruct the victim's input-keystrokes typed on the remote keyboard. Our results demonstrate that, given some knowledge on the victim's typing style and keyboard model, the attacker attains top-5 accuracy of 91.7% in guessing a random key pressed by the victim. This work extends previous results on S&T, demonstrating that our attack is effective with many different recording devices (such as laptop microphones, headset microphones, and smartphones located in proximity of the target keyboard), diverse typing styles and speed, and is particularly threatening when the victim is typing in a known language. © 2019 Association for Computing Machinery.",Input devices; Keystroke sounds; Supervised machine learning,Internet telephony; Microphones; Security systems; Supervised learning; Adversary modeling; Audio information; Eavesdropping attacks; Input devices; Real world setting; Recording devices; Sensitive informations; Supervised machine learning; Voice/data communication systems
Will they use it or not? Investigating software developers' intention to follow privacy engineering methodologies,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075625891&doi=10.1145%2f336422&partnerID=40&md5=060d1bd082cbc4561aab5e486153444c,"With the increasing concerns over privacy in software systems, there is a growing enthusiasm to develop methods to support the development of privacy aware software systems. Inadequate privacy in software system designs could result in users losing their sensitive data, such as health information and financial information, which may cause financial and reputation loss. Privacy Engineering Methodologies (PEMs) are introduced into the software development processes with the goal of guiding software developers to embed privacy into the systems they design. However, for PEMs to be successful it is imperative that software developers have a positive intention to use PEMs. Otherwise, developers may attempt to bypass the privacy methodologies or use them partially and hence develop software systems that may not protect user privacy appropriately. To investigate the factors that affect software developers' behavioural intention to follow PEMs, in this article, we conducted a study with 149 software developers. Findings of the study show that the usefulness of the PEM to the developers' existing work to be the strongest determinant that affects software developers' intention to follow PEMs. Moreover, the compatibility of the PEM with their way of work and how the PEM demonstrates its results when used were also found to be significant. These findings provide important insights in understanding the behaviour of software developers and how they perceive PEMs. The findings could be used to assist organisations and researchers to deploy PEMs and design PEMs that are positively accepted by software developers. © 2019 Association for Computing Machinery.",Privacy engineering; Software development; Technology acceptance,Computer software; Software engineering; Behavioural intentions; Financial information; Health informations; Privacy engineerings; Software developer; Software development process; Software system designs; Technology acceptance; Software design
Malicious overtones: Hunting data theft in the frequency domain with one-class learning,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075632672&doi=10.1145%2f3360469&partnerID=40&md5=3017246a1d8d26fee9153f779dab2173,"A method for detecting electronic data theft from computer networks is described, capable of recognizing patterns of remote exfiltration occurring over days to weeks. Normal traffic flow data, in the form of a host's ingress and egress bytes over time, is used to train an ensemble of one-class learners. The detection ensemble is modular, with individual classifiers trained on different traffic features thought to characterize malicious data transfers. We select features that model the egress to ingress byte balance over time, periodicity, short timescale irregularity, and density of the traffic. The features are most efficiently modeled in the frequency domain, which has the added benefit that variable duration flows are transformed to a fixed-size feature vector, and by sampling the frequency space appropriately, long-duration flows can be tested. When trained on days or weeks worth of traffic from individual hosts, our ensemble achieves a low false-positive rate (<2%) on a range of different system types. Simulated exfiltration samples with a variety of different timing and data characteristics were generated and used to test ensemble performance on different kinds of systems: When trained on a client workstation's external traffic, the ensemble was generally successful at detecting exfiltration that is not simultaneously ingress-heavy, connection-sparse, and of short duration-a combination that is not optimal for attackers seeking to transfer large amounts of data. Remote exfiltration is more difficult to detect from egress-heavy systems, like web servers, with normal traffic exhibiting timing characteristics similar to a wide range of exfiltration types. © 2019 Copyright held by the owner/author(s).",Data exfiltration; One-class learning,Crime; Data transfer; Frequency domain analysis; Vector spaces; Data characteristics; Data exfiltration; Ensemble performance; False positive rates; Individual classifiers; Large amounts of data; One-class learning; Timing characteristics; Feature extraction
Resilient privacy protection for location-based services through decentralization,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073114023&doi=10.1145%2f3319401&partnerID=40&md5=6b17e643c1df0e25d13f123e023ec610,"Location-Based Services (LBSs) provide valuable services, with convenient features for mobile users. However, the location and other information disclosed through each query to the LBS erodes user privacy. This is a concern especially because LBS providers can be honest-but-curious, collecting queries and tracking users' whereabouts and infer sensitive user data. This motivated both centralized and decentralized location privacy protection schemes for LBSs: anonymizing and obfuscating LBS queries to not disclose exact information, while still getting useful responses. Decentralized schemes overcome disadvantages of centralized schemes, eliminating anonymizers, and enhancing users' control over sensitive information. However, an insecure decentralized system could create serious risks beyond private information leakage. More so, attacking an improperly designed decentralized LBS privacy protection scheme could be an effective and low-cost step to breach user privacy. We address exactly this problem, by proposing security enhancements for mobile data sharing systems. We protect user privacy while preserving accountability of user activities, leveraging pseudonymous authentication with mainstream cryptography. We show our scheme can be deployed with off-the-shelf devices based on an experimental evaluation of an implementation in a static automotive testbed. © 2019 Association for Computing Machinery.",Honest-but-curious; Location privacy; Pseudonymous authentication,Authentication; Location; Telecommunication services; Decentralized system; Experimental evaluation; Honest-but-curious; Location privacy; Location privacy protection; Off-the-shelf devices; Security enhancements; Sensitive informations; Location based services
Analytical models for the scalability of dynamic group-key agreement protocols and secure file sharing systems,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073112254&doi=10.1145%2f3342998&partnerID=40&md5=7ac5188278ea45404e2581d6a328ad90,"Dynamic group key agreement protocols are cryptographic primitives to provide secure group communications in decentralized and dynamic networks. Such protocols provide additional operations to update the group key while adding new participants into the group and removing existing participants from the group without re-executing the protocol from the beginning. However, the lack of scalability emerges as one of the most significant issues of dynamic group key agreement protocols when the number of participants in the group increases. For instance, frequent participant join requests for large groups may cause an effect similar to a Distributed Denial of Service (DDoS) attack and violate the system availability due to the increase in group key update time. Therefore, analyzing the scalability of dynamic group key agreement protocols is crucial to detect conditions where the system becomes unavailable. In this article, we propose an analytical performance model to evaluate the scalability of dynamic group key agreement protocols by using queueing models. We also extend our performance model for evaluating the scalability of secure file sharing systems that utilize group key agreement protocols. Moreover, we present a demonstrative use case to show the applicability of our performance model on an example group key agreement protocol and a secure file sharing system. © 2019 Association for Computing Machinery.",Dynamic Group-Key; Performance Model,Denial-of-service attack; Distributed computer systems; Queueing theory; Scalability; Analytical performance model; Cryptographic primitives; Distributed denial of service attack; Dynamic groups; File-sharing system; Group Key Agreement protocols; Performance Model; Secure group communications; Network security
DADS: Decentralized attestation for device swarms,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069542029&doi=10.1145%2f3325822&partnerID=40&md5=ce7d771a38a4413c54ad23c2a94ec2d9,"We present a novel scheme called Decentralized Attestation for Device Swarms (DADS), which is, to the best of our knowledge, the first to accomplish decentralized attestation in device swarms. Device swarms are smart, mobile, and interconnected devices that operate in large numbers and are likely to be part of emerging applications in Cyber-Physical Systems (CPS) and Industrial Internet of Things (IIoTs). Swarm devices process and exchange safety, privacy, and mission-critical information. Thus, it is important to have a good code verification technique that scales to device swarms and establishes trust among collaborating devices. DADS has several advantages over current state-of-the-art swarm attestation techniques: It is decentralized, has no single point of failure, and can handle changing topologies after nodes are compromised. DADS assures system resilience to node compromise/failure while guaranteeing only devices that execute genuine code remain part of the group. We conduct performance measurements of communication, computation, memory, and energy using the TrustLite embedded systems architecture in OMNeT++ simulation environment. We show that the proposed approach can significantly reduce communication cost and is very efficient in terms of computation, memory, and energy requirements. We also analyze security and show that DADS is very effective and robust against various attacks. © 2019 Association for Computing Machinery.",Decentralized attestation; Dynamic networks; Remote attestation; Security; Swarm attestation,Decentralized attestation; Dynamic network; Remote attestation; Security; Swarm attestation; Embedded systems
Database audit workload prioritization via game theory,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069779135&doi=10.1145%2f3323924&partnerID=40&md5=e253c5622f4e8413fb9bd2c4b552fffc,"The quantity of personal data that is collected, stored, and subsequently processed continues to grow rapidly. Given its sensitivity, ensuring privacy protections has become a necessary component of database management. To enhance protection, a number of mechanisms have been developed, such as audit logging and alert triggers, which notify administrators about suspicious activities. However, this approach is limited. First, the volume of alerts is often substantially greater than the auditing capabilities of organizations. Second, strategic attackers can attempt to disguise their actions or carefully choose targets, thus hide illicit activities. In this article, we introduce an auditing approach that accounts for adversarial behavior by (1) prioritizing the order in which types of alerts are investigated and (2) providing an upper bound on how much resource to allocate for each type. Specifically, we model the interaction between a database auditor and attackers as a Stackelberg game. We show that even a highly constrained version of such problem is NP-Hard. Then, we introduce a method that combines linear programming, column generation, and heuristic searching to derive an auditing policy. On the synthetic data, we perform an extensive evaluation on the approximation degree of our solution with the optimal one. The two real datasets, (1) 1.5 months of audit logs from Vanderbilt University Medical Center and (2) a publicly available credit card application dataset, are used to test the policy-searching performance. The findings demonstrate the effectiveness of the proposed methods for searching the audit strategies, and our general approach significantly outperforms non-game-theoretic baselines. © 2019 Association for Computing Machinery.",Anomaly detection; Data privacy; Database auditing; Game theory,Anomaly detection; Data privacy; Database systems; Heuristic algorithms; Heuristic methods; Linear programming; Statistical tests; Approximation degrees; Column generation; Database management; Medical center; Privacy protection; Searching performance; Stackelberg Games; Vanderbilt University; Game theory
A general framework for adversarial examples with objectives,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069523656&doi=10.1145%2f3317611&partnerID=40&md5=a2adc24e8482daa2fa41f27c11b2e045,"Images perturbed subtly to be misclassified by neural networks, called adversarial examples, have emerged as a technically deep challenge and an important concern for several application domains. Most research on adversarial examples takes as its only constraint that the perturbed images are similar to the originals. However, real-world application of these ideas often requires the examples to satisfy additional objectives, which are typically enforced through custom modifications of the perturbation process. In this article, we propose adversarial generative nets (AGNs), a general methodology to train a generator neural network to emit adversarial examples satisfying desired objectives. We demonstrate the ability of AGNs to accommodate a wide range of objectives, including imprecise ones difficult to model, in two application domains. In particular, we demonstrate physical adversarial examples—eyeglass frames designed to fool face recognition—with better robustness, inconspicuousness, and scalability than previous approaches, as well as a new attack to fool a handwritten-digit classifier. © 2019 Copyright held by the owner/author(s).",Adversarial examples; Face recognition; Machine learning; Neural networks,Character recognition; Learning systems; Neural networks; Adversarial examples; Eyeglass frames; General methodologies; Handwritten digit; Real-world; Face recognition
GPLadd: Quantifying trust in government and commercial systems a game-theoretic approach,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069473564&doi=10.1145%2f3326283&partnerID=40&md5=b169d5c467b30842e1bcd652a149ca3a,"Trust in a microelectronics-based system can be characterized as the level of confidence that a system is free of subversive alterations made during system development, or that the development process of a system has not been manipulated by a malicious adversary. Trust in systems has become an increasing concern over the past decade. This article presents a novel game-theoretic framework, called GPLADD (Graph-based Probabilistic Learning Attacker and Dynamic Defender), for analyzing and quantifying system trustworthiness at the end of the development process, through the analysis of risk of development-time system manipulation. GPLADD represents attacks and attacker-defender contests over time. It treats time as an explicit constraint and allows incorporating the informational asymmetries between the attacker and defender into analysis. GPLADD includes an explicit representation of attack steps via multi-step attack graphs, attacker and defender strategies, and player actions at different times. GPLADD allows quantifying the attack success probability over time and the attacker and defender costs based on their capabilities and strategies. This ability to quantify different attacks provides an input for evaluation of trust in the development process. We demonstrate GPLADD on an example attack and its variants. We develop a method for representing success probability for arbitrary attacks and derive an explicit analytic characterization of success probability for a specific attack. We present a numeric Monte Carlo study of a small set of attacks, quantify attack success probabilities, attacker and defender costs, and illustrate the options the defender has for limiting the attack success and improving trust in the development process. © 2019 Association for Computing Machinery.",Attack; Attack graphs; Attacker; Cyber security; Defender; Deterrence; Game theory; GPLADD; Nash equilibrium; Optimal policy; Optimization; Physical security; PLADD; Probability theory; Security; Stochastic process; Trust,Graphic methods; Microelectronics; Network security; Optimization; Random processes; Risk analysis; Risk assessment; Stochastic systems; Attack; Attack graph; Attacker; Cyber security; Defender; Deterrence; GPLADD; Nash equilibria; Optimal policies; Physical security; PLADD; Probability theory; Security; Trust; Game theory
A usability study of four secure email tools using paired participants,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065788833&doi=10.1145%2f3313761&partnerID=40&md5=f6ac902618d8e7df07cf519ac2158228,"Secure email is increasingly being touted as usable by novice users, with a push for adoption based on recent concerns about government surveillance. To determine whether secure email is ready for grassroots adoption, we employ a laboratory user study that recruits pairs of novice users to install and use several of the latest systems to exchange secure messages. We present both quantitative and qualitative results from 28 pairs of novices as they use Private WebMail (Pwm), Tutanota, and Virtru and 10 pairs of novices as they use Mailvelope. Participants report being more at ease with this type of study and better able to cope with mistakes since both participants are “on the same page.” We find that users prefer integrated solutions over depot-based solutions and that tutorials are important in helping first-time users. Finally, our results demonstrate that Pretty Good Privacy using manual key management is still unusable for novice users, with 9 of 10 participant pairs failing to complete the study. © 2019 Association for Computing Machinery.",Grassroots adoption; Paired participants; PGP; Secure email,First-time user; Grassroots adoption; Integrated solutions; Key management; Paired participants; Pretty good privacy; Secure messages; Usability studies; Electronic mail
Mamadroid: Detecting android malware by building Markov chains of behavioral models (extended version),2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065793613&doi=10.1145%2f3313391&partnerID=40&md5=e0ed155b74de230c99ba2db709fa2a40,"As Android has become increasingly popular, so has malware targeting it, thus motivating the research community to propose different detection techniques. However, the constant evolution of the Android ecosystem, and of malware itself, makes it hard to design robust tools that can operate for long periods of time without the need for modifications or costly re-training. Aiming to address this issue, we set to detect malware from a behavioral point of view, modeled as the sequence of abstracted API calls. We introduce MaMaDroid, a static-analysis-based system that abstracts app's API calls to their class, package, or family, and builds a model from their sequences obtained from the call graph of an app as Markov chains. This ensures that the model is more resilient to API changes and the features set is of manageable size. We evaluate MaMaDroid using a dataset of 8.5K benign and 35.5K malicious apps collected over a period of 6 years, showing that it effectively detects malware (with up to 0.99 F-measure) and keeps its detection capabilities for long periods of time (up to 0.87 F-measure 2 years after training). We also show that MaMaDroid remarkably overperforms DroidAPIMiner, a state-of-the-art detection system that relies on the frequency of (raw) API calls. Aiming to assess whether MaMaDroid's effectiveness mainly stems from the API abstraction or from the sequencing modeling, we also evaluate a variant of it that uses frequency (instead of sequences), of abstracted API calls. We find that it is not as accurate, failing to capture maliciousness when trained on malware samples that include API calls that are equally or more frequently used by benign apps. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Android; Malware detection; Static analysis,Abstracting; Computer crime; Malware; Markov processes; Static analysis; Android; Behavioral model; Detection capability; Detection system; Extended versions; Malware detection; Research communities; State of the art; Android (operating system)
Tractor beam: Safe-hijacking of consumer drones with adaptive GPS spoofing,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065759655&doi=10.1145%2f3309735&partnerID=40&md5=5d9709bfcd9497dfbf52dac88dfa76c6,"The consumer drone market is booming. Consumer drones are predominantly used for aerial photography; however, their use has been expanding because of their autopilot technology. Unfortunately, terrorists have also begun to use consumer drones for kamikaze bombing and reconnaissance. To protect against such threats, several companies have started “anti-drone” services that primarily focus on disrupting or incapacitating drone operations. However, the approaches employed are inadequate, because they make any drone that has intruded stop and remain over the protected area. We specify this issue by introducing the concept of safe-hijacking, which enables a hijacker to expel the intruding drone from the protected area remotely. As a safe-hijacking strategy, we investigated whether consumer drones in the autopilot mode can be hijacked via adaptive GPS spoofing. Specifically, as consumer drones activate GPS fail-safe and change their flight mode whenever a GPS error occurs, we performed black- and white-box analyses of GPS fail-safe flight mode and the following behavior after GPS signal recovery of existing consumer drones. Based on our analyses results, we developed a taxonomy of consumer drones according to these fail-safe mechanisms and designed safe-hijacking strategies for each drone type. Subsequently, we applied these strategies to four popular drones: DJI Phantom 3 Standard, DJI Phantom 4, Parrot Bebop 2, and 3DR Solo. The results of field experiments and software simulations verified the efficacy of our safe-hijacking strategies against these drones and demonstrated that the strategies can force them to move in any direction with high accuracy. © 2019 Association for Computing Machinery.",Anti-drone; Drone; Fail-safe; GPS spoofing,Aerial photography; Air navigation; Antennas; Conservation; Drones; Environmental protection; Phantoms; Signal reconstruction; Tractors (agricultural); Fail safes; Fail-safe mechanism; Field experiment; Flight modes; GPS signals; High-accuracy; Protected areas; Software simulation; Consumer behavior
Using episodic memory for user authentication,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065777120&doi=10.1145%2f3308992&partnerID=40&md5=e0cbc8f446d72299ed5bf39b9efc4457,"Passwords are widely used for user authentication, but they are often difficult for a user to recall, easily cracked by automated programs, and heavily reused. Security questions are also used for secondary authentication. They are more memorable than passwords, because the question serves as a hint to the user, but they are very easily guessed. We propose a new authentication mechanism, called “life-experience passwords (LEPs).” Sitting somewhere between passwords and security questions, an LEP consists of several facts about a user-chosen life event-such as a trip, a graduation, a wedding, and so on. At LEP creation, the system extracts these facts from the user's input and transforms them into questions and answers. At authentication, the system prompts the user with questions and matches the answers with the stored ones. We show that question choice and design make LEPs much more secure than security questions and passwords, while the question-answer format promotes low password reuse and high recall. Specifically, we find that: (1) LEPs are 109-1014 × stronger than an ideal, randomized, eight-character password; (2) LEPs are up to 3× more memorable than passwords and on par with security questions; and (3) LEPs are reused half as often as passwords. While both LEPs and security questions use personal experiences for authentication, LEPs use several questions that are closely tailored to each user. This increases LEP security against guessing attacks. In our evaluation, only 0.7% of LEPs were guessed by casual friends, and 9.5% by family members or close friends-roughly half of the security question guessing rate. On the downside, LEPs take around 5× longer to input than passwords. So, these qualities make LEPs suitable for multi-factor authentication at high-value servers, such as financial or sensitive work servers, where stronger authentication strength is needed. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",And Phrases: Authentication; Password; Security question; Template; Usability,Authentication mechanisms; Multi-factor authentication; Password; Personal experience; Security question; Template; Usability; User authentication; Authentication
Introducing the temporal dimension to memory forensics,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065127371&doi=10.1145%2f3310355&partnerID=40&md5=98c35a8c2922115fe7104a9ecfb8781d,"Kickstarted by the Digital Forensic Research Workshop (DFRWS) conference in 2005, modern memory analysis is now one of most active areas of computer forensics and it mostly focuses on techniques to locate key operating system data structures and extract high-level information. These techniques work on the assumption that the information inside a memory dump is consistent and the copy of the physical memory was obtained in an atomic operation. Unfortunately, this is seldom the case in real investigations, where software acquisition tools record information while the rest of the system is running. Thus, since the content of the memory is changing very rapidly, the resulting memory dump may contain inconsistent data. While this problem is known, its consequences are unclear and often overlooked. Unfortunately, errors can be very subtle and can affect the results of an analysis in ways that are difficult to detect. In this article, we argue that memory forensics should also consider the time in which each piece of data was acquired. This new temporal dimension provides a preliminary way to assess the reliability of a given result and opens the door to new research directions that can minimize the effect of the acquisition time or detect inconsistencies. To support our hypothesis, we conducted several experiments to show that inconsistencies are very frequent and can negatively impact an analysis. We then discuss modifications we made to popular memory forensic tools to make the temporal dimension explicit during the analysis and to minimize its effect by resorting to a locality-based acquisition. © 2019 Association for Computing Machinery.",Atomicity; Memory acquisition; Memory forensics; Temporal dimension,Computer operating systems; Atomicity; Forensic research; High-level information; Memory acquisitions; Memory forensics; Record information; Software acquisition; Temporal dimensions; Computer forensics
Anchor: Logically centralized security for software-defined networks,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062371265&doi=10.1145%2f3301305&partnerID=40&md5=50e93925ea3dee231002fc558fc99203,"Software-defined networking (SDN) decouples the control and data planes of traditional networks, logically centralizing the functional properties of the network in the SDN controller. While this centralization brought advantages such as a faster pace of innovation, it also disrupted some of the natural defenses of traditional architectures against different threats. The literature on SDN has mostly been concerned with the functional side, despite some specific works concerning non-functional properties such as security or dependability. Though addressing the latter in an ad-hoc, piecemeal way may work, it will most likely lead to efficiency and effectiveness problems. We claim that the enforcement of non-functional properties as a pillar of SDN robustness calls for a systemic approach. We further advocate, for its materialization, the reiteration of the successful formula behind SDN: 'logical centralization'. As a general concept, we propose anchor, a subsystem architecture that promotes the logical centralization of non-functional properties. To show the effectiveness of the concept, we focus on security in this article: we identify the current security gaps in SDNs and we populate the architecture middleware with the appropriate security mechanisms in a global and consistent manner. Essential security mechanisms provided by anchor include reliable entropy and resilient pseudo-random generators, and protocols for secure registration and association of SDN devices. We claim and justify in the article that centralizing such mechanisms is key for their effectiveness by allowing us to define and enforce global policies for those properties; reduce the complexity of controllers and forwarding devices; ensure higher levels of robustness for critical services; foster interoperability of the nonfunctional property enforcement mechanisms; and promote the security and resilience of the architecture itself. We discuss design and implementation aspects, and we prove and evaluate our algorithms and mechanisms, including the formalisation of the main protocols and the verification of their core security properties using the Tamarin prover. © 2019 Association for Computing Machinery.",Advanced security properties; Attack prevention; Communications overhead; Control plane; IDVV; Mininet; Network device registration and association; Non-functional properties; Open vSwitch (OVS); OpenFlow; Perfect forward secrecy; Post-compromise recovery; Post-compromise security; Post-quantum secure; PRG; Robust pseudo-random generator; Ryu; SDN; Security; Software-defined networking; Source of strong entropy,Controllers; Entropy; Interoperability; Middleware; Network architecture; Quantum cryptography; Robustness (control systems); Software defined networking; Attack prevention; Control planes; IDVV; Mininet; Network devices; Non functional properties; Open vswitch; Openflow; Perfect forward secrecy; Post quantum; Post-compromise security; Pseudorandom generators; Security; Security properties; Network security
Safe and efficient implementation of a security system on ARM using intra-level privilege separation,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062343285&doi=10.1145%2f3309698&partnerID=40&md5=335bcaa5599e3249c0c466a9538c421b,"Security monitoring has long been considered as a fundamental mechanism to mitigate the damage of a security attack. Recently, intra-level security systems have been proposed that can efficiently and securely monitor system software without any involvement of more privileged entity. Unfortunately, there exists no full intra-level security system that can universally operate at any privilege level on ARM. However, as malware and attacks increase against virtually every level of privileged software including an OS, a hypervisor, and even the highest privileged software armored by TrustZone, we have been motivated to develop an intra-level security system, named Hilps. Hilps realizes true intra-level scheme in all these levels of privileged software on ARM by elaborately exploiting a new hardware feature of ARM's latest 64-bit architecture, called TxSZ, that enables elastic adjustment of the accessible virtual address range. Furthermore, Hilps newly supports the sandbox mechanism that provides security tools with individually isolated execution environments, thereby minimizing security threats from untrusted security tools. We have implemented a prototype of Hilps on a real machine. The experimental results demonstrate that Hilps is quite promising for practical use in real deployments. © 2019 Association for Computing Machinery.",Isolation; Privilege separation; Security system,Malware; Security systems; Virtual addresses; 64-bit architectures; Efficient implementation; Execution environments; Fundamental mechanisms; Hardware features; Isolation; Security attacks; Security monitoring; ARM processors
Hybrid private record linkage: Separating differentially private synopses from matching records,2019,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065214645&doi=10.1145%2f3318462&partnerID=40&md5=56537a7a6fd8e5092c33a33d61ba5e91,"Private record linkage protocols allow multiple parties to exchange matching records, which refer to the same entities or have similar values, while keeping the non-matching ones secret. Conventional protocols are based on computationally expensive cryptographic primitives and therefore do not scale. To address these scalability issues, hybrid protocols have been proposed that combine differential privacy techniques with secure multiparty computation techniques. However, a drawback of such protocols is that they disclose to the parties both the matching records and the differentially private synopses of the datasets involved in the linkage. Consequently, differential privacy is no longer always satisfied. To address this issue, we propose a novel framework that separates the private synopses from the matching records. The two parties do not access the synopses directly, but still use them to efficiently link records. We theoretically prove the security of our framework under the state-of-the-art privacy notion of differential privacy for record linkage (DPRL). In addition, we develop a simple but effective strategy for releasing private synopses. Extensive experimental results show that our framework is superior to the existing methods in terms of efficiency. © 2019 Association for Computing Machinery.",Differential privacy; Record linkage; Secure multiparty computation,Cryptography; Cryptographic primitives; Differential privacies; Hybrid protocols; Record linkage; Scalability issue; Secure multi-party computation; State of the art; Data handling
ISOTOP: Auditing virtual networks isolation across cloud layers in OpenStack,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055839839&doi=10.1145%2f3267339&partnerID=40&md5=58e21e2d6eb0d43cd192ceff2b9bee9c,"Multi-tenancy in the cloud is a double-edged sword. While it enables cost-effective resource sharing, it increases security risks for the hosted applications. Indeed, multiplexing virtual resources belonging to different tenants on the same physical substrate may lead to critical security concerns such as cross-tenants data leakage and denial of service. Particularly, virtual networks isolation failures are among the foremost security concerns in the cloud. To remedy these, automated tools are needed to verify security mechanisms compliance with relevant security policies and standards. However, auditing virtual networks isolation is challenging due to the dynamic and layered nature of the cloud. Particularly, inconsistencies in network isolation mechanisms across cloud-stack layers, namely, the infrastructure management and the implementation layers, may lead to virtual networks isolation breaches that are undetectable at a single layer. In this article, we propose an offline automated framework for auditing consistent isolation between virtual networks in OpenStack-managed cloud spanning over overlay and layer 2 by considering both cloud layers’ views. To capture the semantics of the audited data and its relation to consistent isolation requirement, we devise a multi-layered model for data related to each cloud-stack layer’s view. Furthermore, we integrate our auditing system into OpenStack, and present our experimental results on assessing several properties related to virtual network isolation and consistency. Our results show that our approach can be successfully used to detect virtual network isolation breaches for large OpenStack-based data centers in reasonable time. © 2018 Association for Computing Machinery.",Cloud; Compliance verification; Consistency; Network isolation; OpenStack; Security; Virtual infrastructure,Clouds; Compliance control; Compliant mechanisms; Cost effectiveness; Denial-of-service attack; Platform as a Service (PaaS); Regulatory compliance; Semantics; Compliance verification; Consistency; Network isolation; Openstack; Security; Virtual infrastructures; Network security
Technological and human factors of malware attacks: A computer security clinical trial approach,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053380585&doi=10.1145%2f3210311&partnerID=40&md5=b8c9ddc05d68d1122a1a34fa35f70881,"The success (or failure) of malware attacks depends upon both technological and human factors. The most security-conscious users are susceptible to unknown vulnerabilities, and even the best security mechanisms can be circumvented as a result of user actions. Although there has been significant research on the technical aspects of malware attacks and defence, there has been much less research on how users interact with both malware and current malware defences. This article describes a field study designed to examine the interactions between users, antivirus (AV) software, and malware as they occur on deployed systems. In a fashion similar to medical studies that evaluate the efficacy of a particular treatment, our experiment aimed to assess the performance of AV software and the human risk factors of malware attacks. The 4-month study involved 50 home users who agreed to use laptops that were instrumented to monitor for possible malware attacks and gather data on user behaviour. This study provided some very interesting, non-intuitive insights into the efficacy of AV software and human risk factors. AV performance was found to be lower under real-life conditions compared to tests conducted in controlled conditions. Moreover, computer expertise, volume of network usage, and peer-to-peer activity were found to be significant correlates of malware attacks. We assert that this work shows the viability and the merits of evaluating security products, techniques, and strategies to protect systems through long-term field studies with greater ecological validity than can be achieved through other means. © 2018 ACM",Antivirus; Clinical trial; Computer security; Malware; Risk factors,Behavioral research; Computer crime; Computer software; Distributed computer systems; Human engineering; Peer to peer networks; Risk assessment; Security of data; Security systems; Anti virus; Clinical trial; Computer expertise; Controlled conditions; Ecological validity; Risk factors; Security mechanism; Security products; Malware
"VULCON: A system for vulnerability prioritization, mitigation, and management",2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053387665&doi=10.1145%2f3196884&partnerID=40&md5=72cd3390c967ebe2ee243146be96a8cd,"Vulnerability remediation is a critical task in operational software and network security management. In this article, an effective vulnerability management strategy, called VULCON (VULnerability CONtrol), is developed and evaluated. The strategy is based on two fundamental performance metrics: (1) time-to-vulnerability remediation (TVR) and (2) total vulnerability exposure (TVE). VULCON takes as input real vulnerability scan reports, metadata about the discovered vulnerabilities, asset criticality, and personnel resources. VULCON uses a mixed-integer multiobjective optimization algorithm to prioritize vulnerabilities for patching, such that the above performance metrics are optimized subject to the given resource constraints. VULCON has been tested on multiple months of real scan data from a cyber-security operations center (CSOC). Results indicate an overall TVE reduction of 8.97% when VULCON optimizes a realistic security analyst workforce's effort. Additionally, VULCON demonstrates that it can determine monthly resources required to maintain a target TVE score. As such, VULCON provides valuable operational guidance for improving vulnerability response processes in CSOCs. © 2018 ACM",Cyber-security analysts; Cyber-security operations center (CSOC); Management; Multiobjective optimization; Structured vulnerability response programs; Vulnerability triage,Integer programming; Management; Multiobjective optimization; Personnel; Cyber security; Multi-objective optimization algorithms; Network security management; Operational guidance; Vulnerability management; Vulnerability prioritization; Vulnerability remediations; Vulnerability triage; Network security
Verifiable graph processing,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061293715&doi=10.1145%2f3233181&partnerID=40&md5=4a936c671d00da38d3bf007762010958,"We consider a scenario in which a data owner outsources storage of a large graph to an untrusted server; the server performs computations on this graph in response to queries from a client (whether the data owner or others), and the goal is to ensure verifiability of the returned results. Applying generic verifiable computation (VC) would involve compiling each graph computation to a circuit or a RAM program and would incur large overhead, especially in the proof-computation time. In this work, we address the above by designing, building, and evaluating Alitheia, a VC system tailored for graph queries such as computing shortest paths, longest paths, and maximum flows. The underlying principle of Alitheia is to minimize the use of generic VC techniques by leveraging various algorithmic approaches specific for graphs. This leads to both theoretical and practical improvements. Asymptotically, it improves the complexity of proof computation by at least a logarithmic factor. On the practical side, our system achieves significant performance improvements over current state-of-the-art VC systems (up to a 10-orders-of-magnitude improvement in proof-computation time, and a 99.9% reduction in server storage), while scaling to 200,000-node graphs. © 2018 Association for Computing Machinery.",Cloud computing; Graph processing; Verifiable computation,Cloud computing; Flow graphs; Random access storage; Algorithmic approach; Computation time; Graph processing; Shortest path; State of the art; Underlying principles; Untrusted server; Verifiability; Graph theory
A video-based attack for android pattern lock,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053409675&doi=10.1145%2f3230740&partnerID=40&md5=443c64a64c5d2cfacb903ddcf0977622,"Pattern lock is widely used for identification and authentication on Android devices. This article presents a novel video-based side channel attack that can reconstruct Android locking patterns from video footage filmed using a smartphone. As a departure from previous attacks on pattern lock, this new attack does not require the camera to capture any content displayed on the screen. Instead, it employs a computer vision algorithm to track the fingertip movement trajectory to infer the pattern. Using the geometry information extracted from the tracked fingertip motions, the method can accurately infer a small number of (often one) candidate patterns to be tested by an attacker. We conduct extensive experiments to evaluate our approach using 120 unique patterns collected from 215 independent users. Experimental results show that the proposed attack can reconstruct over 95% of the patterns in five attempts. We discovered that, in contrast to most people's belief, complex patterns do not offer stronger protection under our attacking scenarios. This is demonstrated by the fact that we are able to break all but one complex patterns (with a 97.5% success rate) as opposed to 60% of the simple patterns in the first attempt. We demonstrate that this video-side channel is a serious concern for not only graphical locking patterns but also PIN-based passwords, as algorithms and analysis developed from the attack can be easily adapted to target PIN-based passwords. As a countermeasure, we propose to change the way the Android locking pattern is constructed and used. We show that our proposal can successfully defeat this video-based attack. We hope the results of this article can encourage the community to revisit the design and practical use of Android pattern lock. © 2018 ACM",Authentication mechanism; Fingertip movement; Object tracking; Pattern lock; Sensitive information; Video-based attack,Android (operating system); Authentication; Image processing; Locks (fasteners); Authentication mechanisms; Fingertip movement; Object Tracking; Sensitive informations; Video-based attack; Side channel attack
Efficient privacy-preserving matrix factorization for recommendation via fully homomorphic encryption,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053386776&doi=10.1145%2f3212509&partnerID=40&md5=4ae6088f4fbd397ad0ab7236e42c8ce7,"There are recommendation systems everywhere in our daily life. The collection of personal data of users by a recommender in the system may cause serious privacy issues. In this article, we propose the first privacy-preserving matrix factorization for recommendation using fully homomorphic encryption. Our protocol performs matrix factorization over encrypted users' rating data and returns encrypted outputs so that the recommendation system learns nothing on rating values and resulting user/item profiles. Furthermore, the protocol provides a privacy-preserving method to optimize the tuning parameters that can be a business benefit for the recommendation service providers. To overcome the performance degradation caused by the use of fully homomorphic encryption, we introduce a novel data structure to perform computations over encrypted vectors, which are essential for matrix factorization, through secure two-party computation in part. Our experiments demonstrate the efficiency of our protocol. © 2018 ACM",Gradient descent; Homomorphic encryption; Matrix factorization; Privacy-preserving recommendation,Data privacy; Factorization; Matrix algebra; Recommender systems; Business benefits; Fully homomorphic encryption; Gradient descent; Ho-momorphic encryptions; Matrix factorizations; Performance degradation; Privacy preserving; Secure two-party computations; Cryptography
Data usage control for distributed systems,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057594673&doi=10.1145%2f3183342&partnerID=40&md5=7d0352318e51d5e1b705229a3d920ea2,"Data usage control enables data owners to enforce policies over how their data may be used after they have been released and accessed. We address distributed aspects of this problem, which arise if the protected data reside within multiple systems. We contribute by formalizing, implementing, and evaluating a fully decentralized system that (i) generically and transparently tracks protected data across systems, (ii) propagates data usage policies along, and (iii) efficiently and preventively enforces policies in a decentralized manner. The evaluation shows that (i) dataflow tracking and policy propagation achieve a throughput of 21-54% of native execution and (ii) decentralized policy enforcement outperforms a centralized approach in many situations. © 2018 ACM",Data protection; Data usage control; Dataflow tracking; Distributed systems; Policy enforcement; Privacy; Security,Data privacy; Data usage; Dataflow; Distributed systems; Policy enforcement; Security; Network security
The password life cycle,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056478918&doi=10.1145%2f3183341&partnerID=40&md5=9e9275703eb6b9f77f5c288a37dc6110,"Managing passwords is a difficult task for users, who must create, remember, and keep track of large numbers of passwords. In this work, we investigated users' coping strategies for password management. Through a series of interviews, we identified a “life cycle” of password use and find that users' central task in coping with their passwords is rationing their effort to best protect their important accounts. We followed up this work by interviewing experts about their password management practices and found that experts rely on the same kinds of coping strategies as non-experts, but that their increased situation awareness of security allows them to better ration their effort into protecting their accounts. Finally, we conducted a survey study to explore how the life cycle model generalizes to the larger population and find that the life cycle and rationing patterns can be seen in the broader population, but that survey respondents were less likely to characterize security management as a challenging task. © 2018 ACM",Authentication; Coping strategies; Usable security,Authentication; Surveys; Coping strategies; Keep track of; Life cycle model; Non-experts; Password management; Security management; Situation awareness; Usable security; Life cycle
FIMCE: A fully isolated micro-computing environment for multicore systems,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057588591&doi=10.1145%2f3195181&partnerID=40&md5=0a1cd46edb7d903cd4966134d2e36a54,"Virtualization-based memory isolation has been widely used as a security primitive in various security systems to counter kernel-level attacks. In this article, our in-depth analysis on this primitive shows that its security is significantly undermined in the multicore setting when other hardware resources for computing are not enclosed within the isolation boundary. We thus propose to construct a fully isolated micro-computing environment (FIMCE) as a new primitive. By virtue of its architectural niche, FIMCE not only offers stronger security assurance than its predecessor, but also features a flexible and composable environment with support for peripheral device isolation, thus greatly expanding the scope of applications. In addition, FIMCE can be integrated with recent technologies such as Intel Software Guard Extensions (SGX) to attain even stronger security guarantees. We have built a prototype of FIMCE with a bare-metal hypervisor. To show the benefits of using FIMCE as a building block, we have also implemented four applications which are difficult to construct using the existing memory isolation method. Experiments with these applications demonstrate that FIMCE imposes less than 1% overhead on single-threaded applications, while the maximum performance loss on multithreaded applications is bounded by the degree of parallelism at the processor level. © 2017 ACM",Hypervisor; Isolation; Multicore platform; Virtualization,Virtualization; Computing environments; Degree of parallelism; Hypervisor; Isolation; Multi-core platforms; Multi-threaded application; Scope of application; Security primitives; Virtual reality
Amandroid: A precise and general inter-component data flow analysis framework for security vetting of android apps,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056846817&doi=10.1145%2f3183575&partnerID=40&md5=4513cbfaf2e724ae3083fe668b343a9d,"We present a new approach to static analysis for security vetting of Android apps and a general framework called Amandroid. Amandroid determines points-to information for all objects in an Android app component in a flow and context-sensitive (user-configurable) way and performs data flow and data dependence analysis for the component. Amandroid also tracks inter-component communication activities. It can stitch the component-level information into the app-level information to perform intra-app or inter-app analysis. In this article, (a) we show that the aforementioned type of comprehensive app analysis is completely feasible in terms of computing resources with modern hardware, (b) we demonstrate that one can easily leverage the results from this general analysis to build various types of specialized security analyses-in many cases the amount of additional coding needed is around 100 lines of code, and (c) the result of those specialized analyses leveraging Amandroid is at least on par and often exceeds prior works designed for the specific problems, which we demonstrate by comparing Amandroid's results with those of prior works whenever we can obtain the executable of those tools. Since Amandroid's analysis directly handles inter-component control and data flows, it can be used to address security problems that result from interactions among multiple components from either the same or different apps. Amandroid's analysis is sound in that it can provide assurance of the absence of the specified security problems in an app with well-specified and reasonable assumptions on Android runtime system and its library. © 2018 ACM",Android app security analysis; ICC (inter-component communication); Static analysis,Android (operating system); C (programming language); Data flow analysis; Data transfer; Security systems; Static analysis; Communication activities; Computing resource; Data dependence analysis; ICC (inter-component communication); Multiple components; Security analysis; Security problems; Specific problems; Mobile security
Security evaluation of a banking fraud analysis system,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057581588&doi=10.1145%2f3178370&partnerID=40&md5=94b53434efe562bd67549e16b23226db,"The significant growth of banking fraud, fueled by the underground economy of malware, has raised the need for effective detection systems. Therefore, in the last few years, banks have upgraded their security to protect transactions from fraud. State-of-the-art solutions detect fraud as deviations from customers' spending habits. To the best of our knowledge, almost all existing approaches do not provide an in-depth model's granularity and security analysis against elusive attacks. In this article, we examine Banksealer, a decision support system for banking fraud analysis that evaluates the influence on detection performance of the granularity at which spending habits are modeled and its security against evasive attacks. First, we compare user-centric modeling, which builds a model for each user, with system-centric modeling, which builds a model for the entire system, from the point of view of detection performance. Then, we assess the robustness of Banksealer against malicious attackers that are aware of the structure of the models in use. To this end, we design and implement a proof-of-concept attack tool that performs mimicry attacks, emulating a sophisticated attacker that cloaks frauds to avoid detection. We experimentally confirm the feasibility of such attacks, their cost, and the effort required by an attacker in order to perform them. In addition, we discuss possible countermeasures. We provide a comprehensive evaluation on a large real-world dataset obtained from one of the largest Italian banks. © 2018 ACM",Fraud and anomaly detection; Mimicry attack; Online banking; Spending pattern granularity analysis,Artificial intelligence; Crime; Decision support systems; Economics; Large dataset; Malware; Analysis system; Anomaly detection; Detection performance; Fraud detection; Malwares; Mimicry attack; On-line banking; Security evaluation; Spending pattern granularity analyse; Spending patterns; Anomaly detection
KISt: Kernel-informed socket transport for ToR,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061275361&doi=10.1145%2f3278121&partnerID=40&md5=399290def7d0e90186fd99fcb1b8aff3,"Tor's growing popularity and user diversity has resulted in network performance problems that are not well understood, though performance is understood to be a significant factor in Tor's security. A large body of work has attempted to solve performance problems without a complete understanding of where congestion occurs in Tor. In this article, we first study congestion in Tor at individual relays as well as along the entire end-to-end Tor path and find that congestion occurs almost exclusively in egress kernel socket buffers. We then analyze Tor's socket interactions and discover two major contributors to Tor's congestion: Tor writes sockets sequentially, and Tor writes as much as possible to each socket. To improve Tor's performance, we design, implement, and test KIST: a new socket management algorithm that uses real-time kernel information to dynamically compute the amount to write to each socket while considering all circuits of all writable sockets when scheduling cells. We find that, in the medians, KIST reduces circuit congestion by more than 30%, reduces network latency by 18%, and increases network throughput by nearly 10%. We also find that client and relay performance with KIST improves as more relays deploy it and as network load and packet loss rates increase. We analyze the security of KIST and find an acceptable performance and security tradeoff, as it does not significantly affect the outcome of well-known latency, throughput, and traffic correlation attacks. KIST has been merged and configured as the default socket scheduling algorithm in Tor version 0.3.2.1-alpha (released September 18, 2017) and became stable in Tor version 0.3.2.9 (released January 9, 2018). While our focus is Tor, our techniques and observations should help analyze and improve overlay and application performance, both for security applications and in general. © ACM 2018.",,Scheduling; Scheduling algorithms; Acceptable performance; Application performance; Correlation attack; Network latencies; Network throughput; Packet loss rates; Performance problems; Security application; Network security
Characterizing the security of the SMS ecosystem with public gateways,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061292789&doi=10.1145%2f3268932&partnerID=40&md5=bfe80e57842f64f2b14b6d218c55590c,"Recent years have seen the Short Message Service (SMS) become a critical component of the security infrastructure, assisting with tasks including identity verification and second-factor authentication. At the same time, this messaging infrastructure has become dramatically more open and connected to public networks than ever before. However, the implications of this openness, the security practices of benign services, and the malicious misuse of this ecosystem are not well understood. In this article, we provide a comprehensive longitudinal study to answer these questions, analyzing over 900,000 text messages sent to public online SMS gateways over the course of 28 months. From this data, we uncover the geographical distribution of spam messages, study SMS as a transmission medium of malicious content, and find that changes in benign and malicious behaviors in the SMS ecosystem have been minimal during our collection period. The key takeaways of this research show many services sending sensitive security-based messages through an unencrypted medium, implementing low entropy solutions for one-use codes, and behaviors indicating that public gateways are primarily used for evading account creation policies that require verified phone numbers. This latter finding has significant implications for combating phone-verified account fraud and demonstrates that such evasion will continue to be difficult to detect and prevent. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Multifactor authentication; SMS; SMS abuse; SMS spam,Authentication; Ecosystems; Entropy; Gateways (computer networks); Geographical distribution; Network security; Samarium; Telephone sets; Text messaging; Critical component; Identity verification; Longitudinal study; Malicious behavior; Multi-factor authentication; Security infrastructure; Short message services; Transmission medium; Mobile security
Analysis of reflexive eye movements for fast replay-resistant biometric authentication,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061259304&doi=10.1145%2f3281745&partnerID=40&md5=89df05643bd8be1451598b0aaf6a6a24,"Eye tracking devices have recently become increasingly popular as an interface between people and consumer-grade electronic devices. Due to the fact that human eyes are fast, responsive, and carry information unique to an individual, analyzing person's gaze is particularly attractive for rapid biometric authentication. Unfortunately, previous proposals for gaze-based authentication systems either suffer from high error rates or requires long authentication times. We build on the fact that some eye movements can be reflexively and predictably triggered and develop an interactive visual stimulus for elicitation of reflexive eye movements that support the extraction of reliable biometric features in a matter of seconds, without requiring any memorization or cognitive effort on the part of the user. As an important benefit, our stimulus can be made unique for every authentication attempt and thus incorporated in a challenge-response biometric authentication system. This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public. We thoroughly analyze various system parameters and evaluate the performance and security guarantees under several different attack scenarios. The results show that our system matches or surpasses existing gaze-based authentication methods in achieved equal error rates (6.3%) while achieving significantly lower authentication times (5s). © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Challenge-response biometrics; Eye movement biometrics; Reflexive eye movements; User authentication,Authentication; Biometrics; Eye tracking; Authentication methods; Authentication systems; Biometric authentication; Biometric authentication system; Biometric features; Challenge response; Eye tracking devices; User authentication; Eye movements
A close look at a daily dataset of malware samples,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061194256&doi=10.1145%2f3291061&partnerID=40&md5=67748c9a962c87588833dcf05062741f,"The number of unique malware samples is growing out of control. Over the years, security companies have designed and deployed complex infrastructures to collect and analyze this overwhelming number of samples. As a result, a security company can collect more than 1M unique files per day only from its different feeds. These are automatically stored and processed to extract actionable information derived from static and dynamic analysis. However, only a tiny amount of this data is interesting for security researchers and attracts the interest of a human expert. To the best of our knowledge, nobody has systematically dissected these datasets to precisely understand what they really contain. The security community generally discards the problem because of the alleged prevalence of uninteresting samples. In this article, we guide the reader through a step-by-step analysis of the hundreds of thousands Windows executables collected in one day from these feeds. Our goal is to show how a company can employ existing state-of-the-art techniques to automatically process these samples and then perform manual experiments to understand and document what is the real content of this gigantic dataset. We present the filtering steps, and we discuss in detail how samples can be grouped together according to their behavior to support manual verification. Finally, we use the results of this measurement experiment to provide a rough estimate of both the human and computer resources that are required to get to the bottom of the catch of the day. © 2019 Copyright held by the owner/author(s).",Classification; Malware; Measurement; Prioritization,Classification (of information); Computer crime; Measurement; Security systems; Complex infrastructures; Computer resources; Measurement experiments; Prioritization; Security community; State-of-the-art techniques; Static and dynamic analysis; Step-by-step analysis; Malware
Alpha-beta privacy,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061215377&doi=10.1145%2f3289255&partnerID=40&md5=076457c84c7d7ad7e27d01cb30ea9459,"The formal specification of privacy goals in symbolic protocol models has proved to be not quite trivial so far. The most widely used approach in formal methods is based on the static equivalence of frames in the applied pi-calculus, basically asking whether or not the intruder is able to distinguish two given worlds. But then a subtle question emerges: How can we be sure that we have specified all pairs of worlds to properly reflect our intuitive privacy goal? To address this problem, we introduce in this article a novel and declarative way to specify privacy goals, called (α, β)-privacy. This new approach is based on specifying two formulae α and β in first-order logic with Herbrand universes, where α reflects the intentionally released information and β includes the actual cryptographic (""technical"") messages the intruder can see. Then (α, β)-privacy means that the intruder cannot derive any ""nontechnical"" statement from β that he cannot derive from α already. We describe by a variety of examples how this notion can be used in practice. Even though (α, β)-privacy does not directly contain a notion of distinguishing between worlds, there is a close relationship to static equivalence of frames that we investigate formally. This allows us to justify (and criticize) the specifications that are currently used in verification tools and obtain a decision procedure for a large fragment of (α, β)-privacy. © 2019 Association for Computing Machinery.",Frames; Herbrand logic; Model theory; Privacy; Static equivalence; Voting,Calculations; Computer circuits; Data privacy; Formal logic; Frames; Herbrand logic; Model theory; Static equivalence; Voting; Formal specification
Kernel protection against just-in-time code reuse,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061229708&doi=10.1145%2f3277592&partnerID=40&md5=7dd9cc00392ba635a689face5b601e57,"                             The abundance of memory corruption and disclosure vulnerabilities in kernel code necessitates the deployment of hardening techniques to prevent privilege escalation attacks. As stricter memory isolation mechanisms between the kernel and user space become commonplace, attackers increasingly rely on code reuse techniques to exploit kernel vulnerabilities. Contrary to similar attacks in more restrictive settings, as in web browsers, in kernel exploitation, non-privileged local adversaries have great flexibility in abusing memory disclosure vulnerabilities to dynamically discover, or infer, the location of code snippets in order to construct code-reuse payloads. Recent studies have shown that the coupling of code diversification with the enforcement of a “read XOR execute” (R                             ∧                             X) memory safety policy is an effective defense against the exploitation of userland software, but so far this approach has not been applied for the protection of the kernel itself. In this article, we fill this gap by presenting kR                             ∧                             X: a kernel-hardening scheme based on execute-only memory and code diversification. We study a previously unexplored point in the design space, where a hypervisor or a super-privileged component is not required. Implemented mostly as a set of GCC plugins, kR                             ∧                             X is readily applicable to x86 Linux kernels (both 32b and 64b) and can benefit from hardware support (segmentation on x86, MPX on x86-64) to optimize performance. In full protection mode, kR                             ∧                             X incurs a low runtime overhead of 4.04%, which drops to 2.32% when MPX is available, and 1.32% when memory segmentation is in use.                          © Copyright held by the owner/author(s). Publication rights licensed to ACM.",Code diversification; Execute-only memory,Hardening; Linux; Web browsers; Code diversification; Design spaces; Hardware supports; Just in time; Memory corruption; Memory isolation; Memory safety; Runtime overheads; Codes (symbols)
GyrosFinger: Fingerprinting drones for location tracking based on the outputs of MEMS gyroscopes,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042617779&doi=10.1145%2f3177751&partnerID=40&md5=de2f9a8ad5f461f6d0925446003e7af3,"Drones are widely used for various purposes such as delivery, aerial photography, and surveillance. Considering the increasing drone-related services, tracking the locations of drones can cause security threats such as escaping from drone surveillance, disturbing drone-related services, and capturing drones. For wirelessly monitoring the status of drones, telemetry is used, and this status information contains various data such as latitude and longitude, calibrated sensor outputs, and sensor offsets. Because most of the telemetry implementation supports neither authentication nor encryption, an attacker can obtain the status information of the drones by using an appropriate wireless communication device such as software-defined radio. While the attacker knows the locations of the drones from the status information, this information is not sufficient for tracking drones because the status information does not include any identity information that can bind the identity of the drone with its location. In this article, we propose a fingerprinting method for drones in motion for the binding of the identity of the drone with its location. Our fingerprinting method is based on the sensor outputs included in the status information, i.e., the offsets of micro-electro mechanical systems (MEMS) gyroscope, an essential sensor for maintaining the attitude of drones. We found that the offsets of MEMS gyroscopes are different from each other because of manufacturing mismatches, and the offsets of five drones obtained through their telemetry are distinguishable and constant during their flights. To evaluate the performance of our fingerprinting method on a larger scale, we collected the offsets from 70 stand-alone MEMS gyroscopes to generate fingerprints. Our experimental results show that, when using the offsets of three and two axes calculated from 128 samples of the raw outputs per axis as fingerprints, the F-scores of the proposed method reach 98.78% and 94.47%, respectively. The offsets collected after a month are also fingerprinted with F-scores of 96.58% and 78.45% under the same condition, respectively. The proposed fingerprinting method is effective, robust, and persistent. Additionally, unless the MEMS gyroscope is not replaced, our fingerprinting method can be used for drone tracking even when the target drones are flying. © 2018 ACM.",Device fingerprinting; MEMS gyroscope; Security; Sensor,Aerial photography; Antennas; Authentication; Bins; Cryptography; Gyroscopes; Location; MEMS; Palmprint recognition; Sensors; Software radio; Target drones; Telemetering equipment; Unmanned aerial vehicles (UAV); Wireless telecommunication systems; Device fingerprinting; Fingerprinting methods; Implementation support; MEMS gyroscope; Micro  electromechanical system (MEMS); Security; Software-defined radios; Wireless communication devices; Aircraft detection
FOSSIL: A resilient and efficient system for identifying FOSS functions in Malware binaries,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042626945&doi=10.1145%2f3175492&partnerID=40&md5=4700e38acca338a550677f7873de2ea9,"Identifying free open-source software (FOSS) packages on binaries when the source code is unavailable is important for many security applications, such as malware detection, software infringement, and digital forensics. This capability enhances both the accuracy and the efficiency of reverse engineering tasks by avoiding false correlations between irrelevant code bases. Although the FOSS package identification problem belongs to the field of software engineering, conventional approaches rely strongly on practical methods in data mining and database searching. However, various challenges in the use of these methods prevent existing function identification approaches from being effective in the absence of source code. To make matters worse, the introduction of obfuscation techniques, the use of different compilers and compilation settings, and software refactoring techniques has made the automated detection of FOSS packages increasingly difficult. With very few exceptions, the existing systems are not resilient to such techniques, and the exceptions are not sufficiently efficient. To address this issue, we propose FOSSIL, a novel resilient and efficient system that incorporates three components. The first component extracts the syntactical features of functions by considering opcode frequencies and applying a hidden Markov model statistical test. The second component applies a neighborhood hash graph kernel to random walks derived from control-flow graphs, with the goal of extracting the semantics of the functions. The third component applies z-score to the normalized instructions to extract the behavior of instructions in a function. The components are integrated using a Bayesian network model, which synthesizes the results to determine the FOSS function. The novel approach of combining these components using the Bayesian network has produced stronger resilience to code obfuscation. We evaluate our system on three datasets, including real-world projects whose use of FOSS packages is known, malware binaries for which there are security and reverse engineering reports purporting to describe their use of FOSS, and a large repository of malware binaries. We demonstrate that our system is able to identify FOSS packages in real-world projects with a mean precision of 0.95 and with a mean recall of 0.85. Furthermore, FOSSIL is able to discover FOSS packages in malware binaries that match those listed in security and reverse engineering reports. Our results show that modern malware binaries contain 0.10–0.45 of FOSS packages. © 2018 Copyright is held by the owner/author(s).",Binary code analysis; Free software packages; Function fingerprinting; Malicious code analysis,Application programs; Bayesian networks; Binary codes; Codes (symbols); Computer crime; Data mining; Digital forensics; Flow graphs; Hidden Markov models; Malware; Markov processes; Open systems; Reverse engineering; Search engines; Semantics; Software engineering; Bayesian network models; Binary code analysis; Conventional approach; Free open source softwares; Function identification; Identification problem; Malicious-code analysis; Security application; Open source software
Abstract non-interference: A unifying framework for weakening information-flow,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042584366&doi=10.1145%2f3175660&partnerID=40&md5=d3923c6bf776ccef83936ea64872d3af,"Non-interference happens when some elements of a dynamic system do not interfere, i.e., do not affect, other elements in the same system. Originally introduced in language-based security, non-interference means that the manipulation of private information has no effect on public observations of data. In this article, we introduce abstract non-interference as a weakening of non-interference by abstract interpretation. Abstract noninterference is parametric on which private information we want to protect and which are the observational capabilities of the external observer, i.e., what the attacker can observe of a computation and of the data manipulated during the computation. This allows us to model a variety of situations in information-flow security, where the security of a system can be mastered by controlling the degree of precision of the strongest harmless attacker and the properties that are potentially leaked in case of successful attack. © 2018 ACM.",Abstract domains; Abstract interpretation; Closure operators; Language-based security; Non-interference; Program analysis; Semantics,Model checking; Security of data; Semantics; Abstract domains; Abstract interpretations; Closure operators; Language-based security; Non interference; Program analysis; Abstracting
Scalable private set intersection based on ot extension,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040312203&doi=10.1145%2f3154794&partnerID=40&md5=3b66dc9d388c8be80d47a9d82799a4b8,"Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing any information about items that are not in the intersection. It is one of the best studied applications of secure computation and many PSI protocols have been proposed. However, the variety of existing PSI protocols makes it difficult to identify the solution that performs best in a respective scenario, especially since they were not compared in the same setting. In addition, existing PSI protocols are several orders of magnitude slower than an insecure naive hashing solution, which is used in practice. In this article, we review the progress made on PSI protocols and give an overview of existing protocols in various security models. We then focus on PSI protocols that are secure against semi-honest adversaries and take advantage of the most recent efficiency improvements in Oblivious Transfer (OT) extension, propose significant optimizations to previous PSI protocols, and suggest a new PSI protocol whose runtime is superior to that of existing protocols. We compare the performance of the protocols, both theoretically and experimentally, by implementing all protocols on the same platform, give recommendations on which protocol to use in a particular setting, and evaluate the progress on PSI protocols by comparing them to the currently employed insecure naive hashing protocol. We demonstrate the feasibility of our new PSI protocol by processing two sets with a billion elements each. © 2018 ACM.",Anonymity and untraceability; Privacy-preserving protocols; Pseudonymity,Cryptography; Efficiency improvement; Oblivious transfer; Orders of magnitude; Privacy-preserving protocols; Pseudonymity; Secure computation; Semi-honest adversaries; Un traceabilitys; Data privacy
Attribute inference attacks in online social networks,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040311888&doi=10.1145%2f3154793&partnerID=40&md5=7d7ce5315935512ebea9e48653cf9095,"We propose new privacy attacks to infer attributes (e.g., locations, occupations, and interests) of online social network users. Our attacks leverage seemingly innocent user information that is publicly available in online social networks to infer missing attributes of targeted users. Given the increasing availability of (seemingly innocent) user information online, our results have serious implications for Internet privacy-private attributes can be inferred from users' publicly available data unless we take steps to protect users from such inference attacks. To infer attributes of a targeted user, existing inference attacks leverage either the user's publicly available social friends or the user's behavioral records (e.g., the web pages that the user has liked on Facebook, the apps that the user has reviewed on Google Play), but not both. As we will show, such inference attacks achieve limited success rates. However, the problem becomes qualitatively different if we consider both social friends and behavioral records. To address this challenge, we develop a novel model to integrate social friends and behavioral records, and design new attacks based on our model. We theoretically and experimentally demonstrate the effectiveness of our attacks. For instance, we observe that, in a real-world large-scale dataset with 1.1 million users, our attack can correctly infer the cities a user lived in for 57% of the users; via confidence estimation, we are able to increase the attack success rate to over 90% if the attacker selectively attacks half of the users. Moreover, we show that our attack can correctly infer attributes for significantly more users than previous attacks. © 2018 ACM.",Attribute inference; Privacy attack; Social-behavior-attribute network,Behavioral research; Online systems; Websites; Attribute inference; Confidence estimation; Inference attacks; Internet privacy; Large-scale dataset; On-line social networks; Privacy Attacks; Social behavior; Social networking (online)
Enhancing branch monitoring for security purposes: From control flow integrity to malware analysis and debugging,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040309978&doi=10.1145%2f3152162&partnerID=40&md5=00579960ad473f6cc87542de7d52a808,"Malware and code-reuse attacks are the most significant threats to current systems operation. Solutions developed to countermeasure them have their weaknesses exploited by attackers through sandbox evasion and antidebug crafting. To address such weaknesses, we propose a framework that relies on the modern processors' branch monitor feature to allow us to analyze malware while reducing evasion effects. The use of hardware assistance aids in increasing stealthiness, a key feature for debuggers, as modern software (malicious or benign) may be antianalysis armored. We achieve stealthier code execution control by using the branch monitor hardware's inherent interrupt capabilities, keeping the code under execution intact. Previous works on branch monitoring have already addressed the ROP attack problem but require code injection and/or are limited in their capture window size. Therefore, we also propose a ROP detector without these limitations. © 2018 ACM.",Branch monitor; Debug; Malware; ROP,Codes (symbols); Computer crime; Hardware; Program debugging; Anti-analysis; Code execution; Code injection; Control-flow integrities; Debug; Key feature; Malware analysis; Modern processors; Malware
Utilizing performance counters for compromising public key ciphers,2018,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040313573&doi=10.1145%2f3156015&partnerID=40&md5=793e7b10860b43ebacc5fc120942b211,"Hardware performance counters (HPCs) are useful artifacts for evaluating the performance of software implementations. Recently, HPCs have been made more convenient to use without requiring explicit kernel patches or superuser privileges. However, in this article, we highlight that the information revealed by HPCs can be also exploited to attack standard implementations of public key algorithms. In particular, we analyze the vulnerability due to the event branch miss leaked via the HPCs during execution of the target ciphers.We present an iterative attack that targets the key bits of 1,024-bit RSA and 256-bit ECC, whereas in the offline phase, the system's underlying branch predictor is approximated by a theoretical predictor in the literature. Subsimulations are performed corresponding to each bit guess to classify the message space into distinct partitions based on the event branch misprediction and the target key bit value. In the online phase, branch mispredictions obtained from the hardware performance monitors on the target system reveal the secret key bits.We also theoretically prove that the probability of success of the attack is equivalent to the accurate modeling of the theoretical predictor to the underlying system predictor. In addition, we propose an improved version of the attack that requires fewer branch misprediction traces from the HPCs to recover the secret. Experimentations using both attack strategies have been provided on Intel Core 2 Duo, Core i3, and Core i5 platforms for 1,024-bit implementation of RSA and 256-bit scalar multiplication over the secp256r1 curve followed by results on the effect of change of parameters on the success rate. The attack can successfully reveal the exponent bits and thus seeks attention to model secure branch predictors such that it inherently prevents information leakage. © 2018 ACM.",Architecture security; Branch misprediction; Hardware performance counters; Public key cipher; Side channel,Cryptography; Hardware; Iterative methods; Side channel attack; Branch misprediction; Hardware performance counters; Hardware performance monitors; Probability of success; Public key cipher; Scalar multiplication; Side-channel; Software implementation; Public key cryptography
Implementing support for pointers to private data in a general-purpose secure multi-party compiler,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040038504&doi=10.1145%2f3154600&partnerID=40&md5=a0fbeeba62572882f64f85e66c446c76,"Recent compilers allow a general-purpose program (written in a conventional programming language) that handles private data to be translated into a secure distributed implementation of the corresponding functionality. The resulting program is then guaranteed to provably protect private data using secure multi-party computation techniques. The goals of such compilers are generality, usability, and efficiency, but the complete set of features of a modern programming language has not been supported to date by the existing compilers. In particular, recent compilers PICCO and the two-party ANSI C compiler strive to translate any C program into its secure multi-party implementation, but they currently lack support for pointers and dynamic memory allocation, which are important components of many C programs. In this work, we mitigate the limitation and add support for pointers to private data and consequently dynamic memory allocation to the PICCO compiler, enabling it to handle a more diverse set of programs over private data. Because doing so opens up a new design space, we investigate the use of pointers to private data (with known as well as private locations stored in them) in programs and report our findings. Aside from dynamic memory allocation, we examine other important topics associated with common pointer use such as reference by pointer/address, casting, and building various data structures in the context of secure multi-party computation. This results in enabling the compiler to automatically translate a user program that uses pointers to private data into its distributed implementation that provably protects private data throughout the computation. We empirically evaluate the constructions and report on the performance of representative programs. © 2017 ACM.",C compiler; Dynamic memory management; Oblivious data structures; Pointers to private data; Secret sharing; Secure multi-party computation,C (programming language); Computer programming languages; Data communication equipment; Data privacy; Data structures; Information management; Memory architecture; Storage allocation (computer); Translation (languages); C compilers; Dynamic memory management; Private data; Secret sharing; Secure multi-party computation; Program compilers
Handling anti-virtual machine techniques in malicious software,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038913966&doi=10.1145%2f3139292&partnerID=40&md5=9237b5b90f15bbf343f84c37a95c170c,"Malware analysis relies heavily on the use of virtual machines (VMs) for functionality and safety. There are subtle differences in operation between virtual and physical machines. Contemporary malware checks for these differences and changes its behavior when it detects a VM presence. These anti-VM techniques hinder malware analysis. Existing research approaches to uncover differences between VMs and physical machines use randomized testing, and thus cannot guarantee completeness. In this article, we propose a detect-and-hide approach, which systematically addresses anti-VM techniques in malware. First,we propose cardinal pill testing-a modification of red pill testing that aims to enumerate the differences between a given VMand a physical machine through carefully designed tests. Cardinal pill testing finds five times more pills by running 15 times fewer tests than red pill testing.We examine the causes of pills and find that, while the majority of them stem from the failure of VMs to follow CPU specifications, a small number stem from under-specification of certain instructions by the Intel manual. This leads to divergent implementations in different CPU and VM architectures. Cardinal pill testing successfully enumerates the differences that stem from the first cause. Finally, we propose VM Cloak-a WinDbg plug-in which hides the presence of VMs from malware. VM Cloak monitors each execute malware command, detects potential pills, and at runtime modifies the command's outcomes to match those that a physical machine would generate. We implemented VM Cloak and verified that it successfully hides VM presence from malware. © 2017 ACM.",assembly; reverse engineering; System security; virtual machine testing,Assembly; Computer crime; Network security; Pelletizing; Reverse engineering; Specifications; Virtual machine; Malware analysis; Plug-ins; Research approach; Runtimes; System security; Underspecification; Malware
Server Location Verification (SLV) and server location pinning: Augmenting TLS authentication,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038929154&doi=10.1145%2f3139294&partnerID=40&md5=14520ad351d53be8df395d2ccd0de6c0,"We introduce the first known mechanism providing realtime server location verification. Its uses include enhancing server authentication by enabling browsers to automatically interpret server location information. We describe the design of this new measurement-based technique, Server Location Verification (SLV), and evaluate it using PlanetLab. We explain how SLV is compatible with the increasing trends of geographically distributed content dissemination over the Internet, without causing any new interoperability conflicts. Additionally, we introduce the notion of (verifiable) server location pinning (conceptually similar to certificate pinning) to support SLV, and evaluate their combined impact using a server-authentication evaluation framework. The results affirm the addition of new security benefits to the existing TLS-based authentication mechanisms. We implement SLV through a location verification service, the simplest version of which requires no server-side changes. We also implement a simple browser extension that interacts seamlessly with the verification infrastructure to obtain realtime server location-verification results. © 2017 ACM.",internet measurements; location-based authentication; Server authentication; SSL/TLS,Authentication; Authentication mechanisms; Distributed content; Evaluation framework; Internet measurement; Location based; Location verification; Server authentication; SSL/TLS; Location
Differentially Private K-Means Clustering and a Hybrid Approach to Private Optimization,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033237444&doi=10.1145%2f3133201&partnerID=40&md5=df7ce08492c6e6812b8d7dffe81fe235,"K-means clustering is a widely used clustering analysis technique in machine learning. In this article, we study the problem of differentially private k-means clustering. Several state-of-the-art methods follow the single-workload approach, which adapts an existing machine-learning algorithm by making each step private. However, most of them do not have satisfactory empirical performance. In this work, we develop techniques to analyze the empirical error behaviors of one of the state-of-the-art single-workload approaches, DPLloyd, which is a diferentially private version of the Lloyd algorithm for k-means clustering. Based on the analysis, we propose an improvement of DPLloyd. We also propose a new algorithm for k-means clustering from the perspective of the noninteractive approach, which publishes a synopsis of the input dataset and then runs k-means on synthetic data generated from the synopsis. We denote this approach by EUGkM. After analyzing the empirical error behaviors of EUGkM, we further propose a hybrid approach that combines our DPLloyd improvement and EUGkM. Results from extensive and systematic experiments support our analysis and demonstrate the effectiveness of the DPLloyd improvement, EUGkM, and the hybrid approach. © 2017 ACM.",Differential privacy; K-means clustering; Private data publishing,Artificial intelligence; Learning algorithms; Learning systems; Optimization; Clustering analysis; Differential privacies; Empirical performance; K-means clustering; Private data; State of the art; State-of-the-art methods; Systematic experiment; Clustering algorithms
Pareto optimal security resource allocation for Internet of Things,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033215808&doi=10.1145%2f3139293&partnerID=40&md5=d82490be949c37f062ceb9aa465569d3,"In many Internet of Thing (IoT) application domains security is a critical requirement, because malicious parties can undermine the effectiveness of IoT-based systems by compromising single components and/or communication channels. Thus, a security infrastructure is needed to ensure the proper functioning of such systems even under attack. However, it is also critical that security be at a reasonable resource and energy cost. In this article, we focus on the problem of efficiently and effectively securing IoT networks by carefully allocating security resources in the network area. In particular, given a set of security resources R and a set of attacks to be faced A, our method chooses the subset of R that best addresses the attacks in A, and the set of locations where to place them, that ensure the security coverage of all IoT devices at minimum cost and energy consumption. We model our problem according to game theory and provide a Pareto-optimal solution in which the cost of the security infrastructure, its energy consumption, and the probability of a successful attack are minimized. Our experimental evaluation shows that our technique improves the system robustness in terms of packet delivery rate for different network topologies. Furthermore, we also provide a method for handling the computation of the resource allocation plan for large-scale networks scenarios, where the optimization problem may require an unreasonable amount of time to be solved. We show how our proposed method drastically reduces the computing time, while providing a reasonable approximation of the optimal solution. © 2017 ACM.",Clustering; Internet of things; Pareto analysis; Stochastic allocation,Computation theory; Costs; Energy utilization; Game theory; Internet of things; Optimal systems; Optimization; Pareto principle; Resource allocation; Stochastic systems; Clustering; Experimental evaluation; Internet of Things (IOT); Optimization problems; Pareto analysis; Pareto optimal solutions; Security infrastructure; Stochastic allocation; Network security
"Measuring, characterizing, and detecting facebook like farms",2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030219882&doi=10.1145%2f3121134&partnerID=40&md5=594024285da1a48148be96694dedf579,"Online social networks offer convenient ways to reach out to large audiences. In particular, Facebook pages are increasingly used by businesses, brands, and organizations to connect with multitudes of users worldwide. As the number of likes of a page has become a de-facto measure of its popularity and profitability, an underground market of services artificially inflating page likes (""like farms"") has emerged alongside Facebook's official targeted advertising platform. Nonetheless, besides a fewmedia reports, there is littlework that systematically analyzes Facebook pages' promotion methods. Aiming to fill this gap, we present a honeypotbased comparative measurement study of page likes garnered via Facebook advertising and from popular like farms. First, we analyze likes based on demographic, temporal, and social characteristics and find that some farms seem to be operated by bots and do not really try to hide the nature of their operations, while others follow a stealthier approach, mimicking regular users' behavior. Next, we look at fraud detection algorithms currently deployed by Facebook and show that they do not work well to detect stealthy farms that spread likes over longer timespans and like popular pages to mimic regular users. To overcome their limitations, we investigate the feasibility of timeline-based detection of like farm accounts, focusing on characterizing content generated by Facebook accounts on their timelines as an indicator of genuine versus fake social activity. We analyze a wide range of features extracted from timeline posts, which we group into two main categories: lexical and non-lexical.We find that like farm accounts tend to re-share content more often, use fewer words and poorer vocabulary, and more often generate duplicate comments and likes compared to normal users. Using relevant lexical and non-lexical features, we build a classifier to detect like farms accounts that achieves a precision higher than 99% and a 93% recall. © 2017 ACM.",Like farm detection; Machine learning; Measurement; Social networks,Face recognition; Learning systems; Marketing; Measurements; Comparative measurements; Facebook pages; Fraud detection; Lexical features; On-line social networks; Social activities; Targeted advertising; Timeline-based; Social networking (online)
Fast proxy re-encryption for publish/subscribe systems,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030232215&doi=10.1145%2f3128607&partnerID=40&md5=ac4070e5694eef69c6c661a7eaf7e07c,"We develop two IND-CPA-secure multihop unidirectional Proxy Re-Encryption (PRE) schemes by applying the Ring-LWE (RLWE) key switching approach from the homomorphic encryption literature. Unidirectional PRE is ideal for secure publish-subscribe operations where a publisher encrypts information using a public key without knowing upfront who the subscriber will be and what private key will be used for decryption. The proposed PRE schemes provide a multihop capability, meaning that when PRE-encrypted information is published onto a PRE-enabled server, the server can either delegate access to specific clients or enable other servers the right to delegate access. Our first scheme (which we call NTRU-ABD-PRE) is based on a variant of the NTRU-RLWE homomorphic encryption scheme. Our second and main PRE scheme (which we call BV-PRE) is built on top of the Brakerski-Vaikuntanathan (BV) homomorphic encryption scheme and relies solely on the RLWE assumption. We present an open-source C++ implementation of both schemes and discuss several algorithmic and software optimizations. We examine parameter selection tradeoffs in the context of security, runtime/latency, throughput, ciphertext expansion, memory usage, and multihop capabilities. Our experimental analysis demonstrates that BV-PRE outperforms NTRU-ABD-PRE in both single-hop and multihop settings. The BVPRE scheme has a lower time and space complexity than existing IND-CPA-secure lattice-based PRE schemes and requires small concrete parameters, making the scheme computationally efficient for use on low-resource embedded systems while still providing 100 bits of security. We present practical recommendations for applying the PRE schemes to several use cases of ad hoc information sharing for publish-subscribe operations. © 2017 ACM.",Delegating access control; Lattice encryption; Proxy re-encryption; Software engineering,Access control; C++ (programming language); Computer software; Embedded systems; Open source software; Open systems; Publishing; Software engineering; Computationally efficient; Encrypted informations; Ho-momorphic encryptions; Homomorphic Encryption Schemes; Practical recommendation; Proxy re encryptions; Publish/Subscribe system; Time and space complexity; Cryptography
Long-span program behavior modeling and attack detection,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030228904&doi=10.1145%2f3105761&partnerID=40&md5=50ee848677c2826c2671101f262c2d25,"Intertwined developments between program attacks and defenses witness the evolution of program anomaly detection methods. Emerging categories of program attacks, e.g., non-control data attacks and data-oriented programming, are able to comply with normal trace patterns at local views. This article points out the deficiency of existing program anomaly detection models against new attacks and presents long-span behavior anomaly detection (LAD), a model based on mildly context-sensitive grammar verification. The key feature of LAD is its reasoning of correlations among arbitrary events that occurred in long program traces. It extends existing correlation analysis between events at a stack snapshot, e.g., paired call and ret, to correlation analysis among events that historically occurred during the execution. The proposed method leverages specialized machine learning techniques to probe normal program behavior boundaries in vast high-dimensional detection space. Its two-stage modeling/detection design analyzes event correlation at both binary and quantitative levels. Our prototype successfully detects all reproduced real-world attacks against sshd, libpcre, and sendmail. The detection procedure incurs 0.1 ms to 1.3 ms overhead to profile and analyze a single behavior instance that consists of tens of thousands of function call or system call events. 2017 Copyright is held by the owner/author(s). Publication rights licensed to ACM.",Anomaly detection; Co-occurrence analysis; Contextsensitive grammar; Event frequency correlation; Intrusion detection; Machine learning; Program analysis,Artificial intelligence; Computational grammars; Context sensitive grammars; Correlation methods; Learning systems; Anomaly detection; Anomaly detection methods; Anomaly detection models; Co-occurrence analysis; Frequency correlation; Machine learning techniques; Non-control data attacks; Program analysis; Intrusion detection
"Mo(bile) money, mo(bile) problems: Analysis of branchless banking applications",2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032640527&doi=10.1145%2f3092368&partnerID=40&md5=0ecc2da3ac8a1c62e6c28ea9df00e000,"Mobile money, also known as branchless banking, leverages ubiquitous cellular networks to bring muchneeded financial services to the unbanked in the developing world. These services are often deployed as smartphone apps, and although marketed as secure, these applications are often not regulated as strictly as traditional banks, leaving doubt about the truth of such claims. In this article, we evaluate these claims and perform the first in-depth measurement analysis of branchless banking applications.We first perform an automated analysis of all 46 known Android mobile money apps across the 246 known mobile money providers from 2015.We then perform a comprehensive manual teardown of the registration, login, and transaction procedures of a diverse 15% of these apps. We uncover pervasive vulnerabilities spanning botched certification validation, do-it-yourself cryptography, and other forms of information leakage that allow an attacker to impersonate legitimate users, modify transactions, and steal financial records. These findings show that the majority of these apps fail to provide the protections needed by financial services. In an expanded re-evaluation one year later, we find that these systems have only marginally improved their security. Additionally, we document our experiences working in this sector for future researchers and provide recommendations to improve the security of this critical ecosystem. Finally, through inspection of providers' terms of service, we also discover that liability for these problems unfairly rests on the shoulders of the customer, threatening to Erode trust in branchless banking and hinder efforts for global financial inclusion. © 2017 ACM.",Branchless banking; Mobile money,Body fluids; Developing countries; Electronic money; Finance; Automated analysis; Branchless bankings; Financial inclusions; Financial records; Financial service; Information leakage; Mobile money; Terms of services; Mobile security
Texture to the rescue: Practical paper fingerprinting based on texture patterns,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032641107&doi=10.1145%2f3092816&partnerID=40&md5=1f698aac34e59d4d36aa8fad8d9924b5,"In this article, we propose a novel paper fingerprinting technique based on analyzing the translucent patterns revealed when a light source shines through the paper. These patterns represent the inherent texture of paper, formed by the random interleaving of wooden particles during the manufacturing process. We show that these patterns can be easily captured by a commodity camera and condensed into a compact 2,048-bit fingerprint code. Prominent works in this area (Nature 2005, IEEE S&P 2009, CCS 2011) have all focused on fingerprinting paper based on the paper ""surface."" We are motivated by the observation that capturing the surface alone misses important distinctive features such as the noneven thickness, random distribution of impurities, and different materials in the paper with varying opacities. Through experiments, we demonstrate that the embedded paper texture provides a more reliable source for fingerprinting than features on the surface. Based on the collected datasets, we achieve 0% false rejection and 0% false acceptance rates. We further report that our extracted fingerprints contain 807 degrees of freedom (DoF), which is much higher than the 249 DoF with iris codes (that have the same size of 2,048 bits). The high amount of DoF for texturebased fingerprints makes our method extremely scalable for recognition among very large databases; it also allows secure usage of the extracted fingerprint in privacy-preserving authentication schemes based on error correction techniques. © 2017 ACM.",Biometrics; Counterfeiting; Paper fingerprint; Physical unclonable function,Biometrics; Cryptography; Degrees of freedom (mechanics); Error correction; Hardware security; Impurities; Light sources; Correction techniques; Counterfeiting; False acceptance rate; Fingerprinting techniques; Manufacturing process; Privacy-preserving authentication; Random distribution; Very large database; Data privacy
Sancus 2.0: A low-cost security architecture for IoT devices,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032639589&doi=10.1145%2f3079763&partnerID=40&md5=7190d4e99b8d25033eda89901b7425da,"The Sancus security architecture for networked embedded devices was proposed in 2013 at the USENIX Security conference. It supports remote (even third-party) software installation on devices while maintaining strong security guarantees.More specifically, Sancus can remotely attest to a software provider that a specific software module is running uncompromised and can provide a secure communication channel between software modules and software providers. Software modules can securely maintain local state and can securely interact with other software modules that they choose to trust. Over the past three years, significant experience has been gained with applications of Sancus, and several extensions of the architecture have been investigated-both by the original designers as well as by independent researchers. Informed by these additional research results, this journal version of the Sancus paper describes an improved design and implementation, supporting additional security guarantees (such as confidential deployment) and a more efficient cryptographic core. We describe the design of Sancus 2.0 (without relying on any prior knowledge of Sancus) and develop and evaluate a prototype FPGA implementation. The prototype extends an MSP430 processor with hardware support for the memory access control and cryptographic functionality required to run Sancus. We report on our experience using Sancus in a variety of application scenarios and discuss some important avenues of ongoing and future work. © 2017 ACM.",Embedded systems security; Protected Module Architectures; Software security engineering; Trusted computing,Access control; Cryptography; Embedded systems; Integrated circuit design; Internet of things; Trusted computing; Application scenario; Embedded systems securities; FPGA implementations; Module architecture; Networked embedded devices; Security Architecture; Software installations; Software security; Memory architecture
"Don't trust the cloud, verify: Integrity and consistency for cloud object stores",2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032625319&doi=10.1145%2f3079762&partnerID=40&md5=bce7fdeb6770a400c89e2c5e12dcebe4,"Cloud services have turned remote computation into a commodity and enable convenient online collaboration. However, they require that clients fully trust the service provider in terms of confidentiality, integrity, and availability. Toward reducing this dependency, this article introduces VICOS, a protocol for verification of integrity and consistency for cloud object storage that enables a group of mutually trusting clients to detect data integrity and consistency violations for a cloud object storage service. It aims at services where multiple clients cooperate on data stored remotely on a potentially misbehaving service. VICOS enforces the consistency notion of fork-linearizability, supports wait-free client semantics for most operations, and reduces the computation and communication overhead compared to previous protocols. VICOS is based on a generic authenticated data structure. Moreover, its operations cover the hierarchical name space of a cloud object store, supporting a real-world interface and not only a simplistic abstraction. A prototype of VICOS that works with the key-value store interface of commodity cloud storage services has been implemented, and an evaluation demonstrates its advantage compared to existing systems. © 2017 ACM.",Cloud storage; Data integrity; Fork-linearizability; Wait-freedom,Digital storage; Semantics; Authenticated data structures; Cloud storages; Communication overheads; Data integrity; Linearizability; On-line collaborations; Real-world interface; Wait-freedom; Trusted computing
Efficient attack graph analysis through approximate inference,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645831&doi=10.1145%2f3105760&partnerID=40&md5=a01af4f8835397ef35451e6c62ec6117,"Attack graphs provide compact representations of the attack paths an attacker can follow to compromise network resources from the analysis of network vulnerabilities and topology. These representations are a powerful tool for security risk assessment. Bayesian inference on attack graphs enables the estimation of the risk of compromise to the system's components given their vulnerabilities and interconnections and accounts for multi-step attacks spreading through the system. While static analysis considers the risk posture at rest, dynamic analysis also accounts for evidence of compromise, for example, from Security Information and Event Management software or forensic investigation. However, in this context, exact Bayesian inference techniques do not scale well. In this article, we show how Loopy Belief Propagation-an approximate inference technique-can be applied to attack graphs and that it scales linearly in the number of nodes for both static and dynamic analysis, making such analyses viable for larger networks. We experiment with different topologies and network clustering on synthetic Bayesian attack graphs with thousands of nodes to show that the algorithm's accuracy is acceptable and that it converges to a stable solution. We compare sequential and parallel versions of Loopy Belief Propagation with exact inference techniques for both static and dynamic analysis, showing the advantages and gains of approximate inference techniques when scaling to larger attack graphs. 2017 Copyright is held by the owner/author(s).",Approximate inference; Bayesian networks; Probabilistic graphical models,Bayesian networks; Graph theory; Graphic methods; Inference engines; Risk perception; Static analysis; Topology; Approximate inference; Compact representation; Forensic investigation; Loopy belief propagation; Probabilistic graphical models; Security information and event managements; Security risk assessments; Static and dynamic analysis; Risk assessment
Pulse-response: Exploring human body impedance for biometric recognition,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059278444&doi=10.1145%2f3064645&partnerID=40&md5=96fb617597c4684723da8f7d9bdbe1fd,"Biometric characteristics are often used as a supplementary component in user authentication and identification schemes. Many biometric traits, both physiological and behavioral, offering a wider range of security and stability, have been explored. We propose a new physiological trait based on the human body's electrical response to a square pulse signal, called pulse-response, and analyze how this biometric characteristic can be used to enhance security in the context of two example applications: (1) an additional authentication mechanism in PIN entry systems and (2) a means of continuous authentication on a secure terminal. The pulse-response biometric recognition is effective because each human body exhibits a unique response to a signal pulse applied at the palm of one hand and measured at the palm of the other. This identification mechanism integrates well with other established methods and could offer an additional layer of security, either on a continuous basis or at log-in time.We build a proof-of-concept prototype and perform experiments to assess the feasibility of pulse-response for biometric authentication. The results are very encouraging, achieving an equal error rate of 2% over a static dataset and 9% over a dataset with samples taken over several weeks. We also quantize resistance to attack by estimating individual worst-case probabilities for zero-effort impersonation in different experiments. © 2016 ACM.",Biometric authentication; Biometric recognition; Biometrics; Continuous authentication; Physiological trait; Secure computer terminal; Secure man-machine interaction; Secure PIN entry; user identification,Biometrics; Computer terminals; Cryptography; Physiological models; Physiology; Biometric authentication; Biometric recognition; Continuous authentications; Physiological trait; Secure PIN entry; User identification; Authentication
Evaluating the privacy guarantees of location proximity services,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049838154&doi=10.1145%2f3007209&partnerID=40&md5=dffd2dca7ccc88260e739408eea9b4fc,"Location-based services have become an integral part of everyday life. To address the privacy issues that emerge from the use and sharing of location information, social networks and smartphone applications have adopted location proximity schemes as a means of balancing user privacy with utility. Unfortunately, despite the extensive academic literature on this topic, the schemes that large service providers have adopted are not always designed or implemented correctly, rendering users vulnerable to location-disclosure attacks. Such attacks have recently received major publicity as, in some cases, they even exposed citizens of oppressive regimes to life-threatening risks. In this article, we systematically assess the defenses that popular locationbased services and mobile applications deploy to guard against adversaries seeking to identify a user's location. We provide the theoretical foundations for formalizing the privacy guarantees of currently adopted proximity models, design practical attacks for each case, and prove tight bounds on the number of queries required for carrying out successful attacks in practice. To evaluate the completeness of our approach, we conduct extensive experiments against popular services including Facebook, Foursquare, and Grindr. Our results demonstrate that, even though the aforementioned services implement various privacy-preserving techniques to protect their users, they are still vulnerable to attacks. In particular, we are able to pinpoint Facebook users within 5m of their exact location. For Foursquare and Grindr, users are pinpointed within 15m of their location in 90% of the cases, even with the strictest privacy settings enabled. Our attacks are highly efficient and complete within a few seconds. The severity of our findings was acknowledged by Facebook and Foursquare, both of which have followed our recommendations and adopted our design of a safe proximity scheme in their production systems. As the number of mobile applications offering location functionality will continue to increase, service providers and software developers must be able to assess the privacy guarantees that their services offer. To that end, we discuss viable defenses that can be currently adopted by all major services, and provide an open-source testing framework to be used by researchers and service providers who wish to evaluate the privacy-preserving properties of applications offering proximity functionality. © 2016 ACM.",Location privacy; Location proximity; Location-based services; Spatial cloaking; User discovery attacks,Application programs; Location; Mobile computing; Open source software; Social networking (online); Telecommunication services; Location disclosures; Location information; Location privacy; Mobile applications; Smart-phone applications; Spatial cloaking; Theoretical foundations; User discovery attacks; Location based services
Evaluating the Strength of Genomic Privacy Metrics,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040576809&doi=10.1145%2f3020003&partnerID=40&md5=61221cff7f29bfc14a553f157c1750eb,"The genome is a unique identifier for human individuals. The genome also contains highly sensitive information, creating a high potential for misuse of genomic data (for example, genetic discrimination). In this article, we investigate how genomic privacy can be measured in scenarios where an adversary aims to infer a person's genomic markers by constructing probability distributions on the values of genetic variations. We measured the strength of privacy metrics by requiring that metrics are monotonic with increasing adversary strength and uncovered serious problems with several existing metrics currently used to measure genomic privacy. We provide suggestions on metric selection, interpretation, and visualization and illustrate the work flow using case studies for three real-world diseases. © 2017 ACM.",ARCHER; genomic privacy; Privacy metrics,Genes; Case-studies; Genetic variation; Genomic data; High potential; Metric selections; Privacy metrics; Sensitive informations; Unique identifiers; Probability distributions
Privacy games along location traces: A game-theoretic framework for optimizing location privacy,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041769788&doi=10.1145%2f3009908&partnerID=40&md5=0723c35bb39dedf1d40f824e67eb2538,"The mainstream approach to protecting the privacy of mobile users in location-based services (LBSs) is to alter (e.g., perturb, hide, and so on) the users' actual locations in order to reduce exposed sensitive information. In order to be effective, a location-privacy preservingmechanism must consider both the privacy and utility requirements of each user, as well as the user's overall exposed locations (which contribute to the adversary's background knowledge). In this article, we propose a methodology that enables the design of optimal user-centric location obfuscation mechanisms respecting each individual user's service quality requirements, while maximizing the expected error that the optimal adversary incurs in reconstructing the user's actual trace. A key advantage of a user-centric mechanism is that it does not depend on third-party proxies or anonymizers; thus, it can be directly integrated in the mobile devices that users employ to access LBSs. Our methodology is based on the mutual optimization of user/adversary objectives (maximizing location privacy versus minimizing localization error) formalized as a Stackelberg Bayesian game. This formalization makes our solution robust against any location inference attack, that is, the adversary cannot decrease the user's privacy by designing a better inference algorithm as long as the obfuscation mechanism is designed according to our privacy games. We develop two linear programs that solve the location privacy game and output the optimal obfuscation strategy and its corresponding optimal inference attack. These linear programs are used to design location privacy-preserving mechanisms that consider the correlation between past, current, and future locations of the user, thus can be tuned to protect different privacy objectives along the user's location trace.We illustrate the efficacy of the optimal location privacy-preserving mechanisms obtained with our approach against real location traces, showing their performance in protecting users' different location privacy objectives. © 2016 ACM.",Game theory; Location privacy; Optimization; Utility,Game theory; Inference engines; Linear programming; Location; Optimization; Telecommunication services; User centered design; Back-ground knowledge; Inference algorithm; Localization errors; Location obfuscations; Location privacy; Optimal locations; Sensitive informations; Utility; Location based services
Authentication Challenges in a Global Environment,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020104397&doi=10.1145%2f3007208&partnerID=40&md5=ad0c3a276a2eb31ffb9bbc24e9c95401,"In this article, we address the problem of scaling authentication for naming, routing, and end-entity (EE) certification to a global environment in which authentication policies and users' sets of trust roots vary widely. The current mechanisms for authenticating names (DNSSEC), routes (BGPSEC), and EE certificates (TLS) do not support a coexistence of authentication policies, affect the entire Internet when compromised, cannot update trust root information efficiently, and do not provide users with the ability to make flexible trust decisions. We propose the Scalable Authentication Infrastructure for Next-generation Trust (SAINT), which partitions the Internet into groups with common, local trust roots and isolates the effects of a compromised trust root. SAINT requires groups with direct routing connections to cross-sign each other for authentication purposes, allowing diverse authentication policies while keeping all entities' authentication information globally discoverable. SAINT makes trust root management a central part of the network architecture, enabling trust root updates within seconds and allowing users to make flexible trust decisions. SAINT operates without a significant performance penalty and can be deployed alongside existing infrastructures. © 2017 ACM.",authentication; future internet architectures; Public-key infrastructures,Network architecture; Authentication information; Current mechanisms; Direct routing; Global environment; Performance penalties; Scalable authentication; Trust decisions; Authentication
Toward improved audio CAPTCHAs based on auditory perception and language understanding,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051145457&doi=10.1145%2f2856820&partnerID=40&md5=78d81d30026ed1692e460e07c9f579ad,"A so-called completely automated public Turing test to tell computers and humans apart (CAPTCHA) represents a challenge-response test that is widely used on the Internet to distinguish human users from fraudulent computer programs, often referred to as bots. To enable access for visually impaired users, most Web sites utilize audio CAPTCHAs in addition to a conventional image-based scheme. Recent research has shown that most currently available audio CAPTCHAs are insecure, as they can be broken by means of machine learning at relatively low costs. Moreover, most audio CAPTCHAs suffer from low human success rates that arise from severe signal distortions. This article proposes two different audio CAPTCHA schemes that systematically exploit differences between humans and computers in terms of auditory perception and language understanding, yielding a better trade-off between usability and security as compared to currently available schemes. Furthermore, we provide an elaborate analysis of Google's prominent reCAPTCHA that serves as a baseline setting when evaluating our proposed CAPTCHA designs. © 2016 ACM.",Audio CAPTCHA; Auditory perception; Automatic speech recognition; Humans vs. machines; Language understanding; Speech intelligibility; Web accessibility; Web security,Artificial intelligence; Audition; Economic and social effects; Electronic mail filters; Learning systems; Speech intelligibility; Speech recognition; Websites; Auditory perception; Automatic speech recognition; CAPTCHAs; Language understanding; Web accessibility; WEB security; Network security
Quantifying Interdependent Risks in Genomic Privacy,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049450673&doi=10.1145%2f3035538&partnerID=40&md5=c25dfdf3e26091fb7785ec40292bcbc9,"The rapid progress in human-genome sequencing is leading to a high availability of genomic data. These data is notoriously very sensitive and stable in time, and highly correlated among relatives. In this article, we study the implications of these familial correlations on kin genomic privacy. We formalize the problem and detail efficient reconstruction attacks based on graphical models and belief propagation. With our approach, an attacker can infer the genomes of the relatives of an individual whose genome or phenotype are observed by notably relying on Mendel's Laws, statistical relationships between the genomic variants, and between the genome and the phenotype. We evaluate the effect of these dependencies on privacy with respect to the amount of observed variants and the relatives sharing them. We also study how the algorithmic performance evolves when we take these various relationships into account. Furthermore, to quantify the level of genomic privacy as a result of the proposed inference attack, we discuss possible definitions of genomic privacy metrics, and compare their values and evolution. Genomic data reveals Mendelian disorders and the likelihood of developing severe diseases, such as Alzheimer's. We also introduce the quantification of health privacy, specifically, the measure of how well the predisposition to a disease is concealed from an attacker. We evaluate our approach on actual genomic data from a pedigree and show the threat extent by combining data gathered from a genome-sharing website as well as an online social network. © 2017 ACM.",Genomic privacy; inference; kinship; metrics,Genes; Social networking (online); Belief propagation; Efficient reconstruction; High availability; Highly-correlated; Inference attacks; On-line social networks; Privacy metrics; Statistical relationship; Privacy by design
BLC: Private matrix factorization recommenders via automatic group learning,2017,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028322394&doi=10.1145%2f3041760&partnerID=40&md5=8bdbcc7205cd54c49364e48b51a50a50,We propose a privacy-enhanced matrix factorization recommender that exploits the fact that users can often be grouped together by interest. This allows a form of “hiding in the crowd” privacy. We introduce a novel matrix factorization approach suited to making recommendations in a shared group (or “nym”) setting and the BLC algorithm for carrying out this matrix factorization in a privacy-enhanced manner. We demonstrate that the increased privacy does not come at the cost of reduced recommendation accuracy. © 2017 ACM.,Clustering; Matrix factorization; Privacy; Recommender systems,Data privacy; Matrix algebra; Recommender systems; Clustering; Group learning; Matrix factorizations; Recommendation accuracy; Factorization
On the workflow satisfiability problem with class-independent constraints for hierarchical organizations,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044046327&doi=10.1145%2f2988239&partnerID=40&md5=906a48ed91ef58c2923a37bcad1a9f00,"A workflow specification defines a set of steps, a set of users, and an access control policy. The policy determines which steps a user is authorized to perform and imposes constraints on which sets of users can perform which sets of steps. The workflow satisfiability problem (WSP) is the problem of determining whether there exists an assignment of users to workflow steps that satisfies the policy. Given the computational hardness of WSP and its importance in the context of workflow management systems, it is important to develop algorithms that are as efficient as possible to solve WSP. In this article, we study the fixed-parameter tractability of WSP in the presence of class-independent constraints, which enable us to (1) model security requirements based on the groups to which users belong and (2) generalize the notion of a user-independent constraint. Class-independent constraints are defined in terms of equivalence relations over the set of users. We consider sets of nested equivalence relations because this enables us to model security requirements in hierarchical organizations. We prove that WSP is fixed-parameter tractable (FPT) for class-independent constraints defined over nested equivalence relations and develop an FPT algorithm to solve WSP instances incorporating such constraints. We perform experiments to evaluate the performance of our algorithm and compare it with that of SAT4J, an off-the-shelf pseudo-Boolean SAT solver. The results of these experiments demonstrate that our algorithm significantly outperforms SAT4J for many instances of WSP. © 2016 ACM.",Class-independent constraints; Fixed-parameter tractability; Userindependent constraints; Workflow satisfiability problem,Access control; Computational efficiency; Cryptography; Formal logic; Set theory; Work simplification; Access control policies; Class-independent constraints; Fixed-parameter tractability; Hierarchical organizations; Satisfiability problems; User independents; Workflow management systems; Workflow specification; Equivalence classes
Inhibiting and detecting offline password cracking using ersatzpasswords,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057715270&doi=10.1145%2f2996457&partnerID=40&md5=40a3e54929b3c8ce392c0307c93145c3,"In this work, we present a simple, yet effective and practical scheme to improve the security of stored password hashes, increasing the difficulty to crack passwords and exposing cracking attempts. We utilize a hardware-dependent function (HDF), such as a physically unclonable function (PUF) or a hardware security module (HSM), at the authentication server to inhibit offline password discovery. Additionally, a deception mechanism is incorporated to alert administrators of cracking attempts. Using an HDF to generate password hashes hinders attackers from recovering the true passwords without constant access to theHDF.Our scheme can integrate with legacy systems without needing additional servers, changing the structure of the hashed password file, nor modifying client machines.When using our scheme, the structure of the hashed passwords file, e.g., etc/shadow or etc/master.passwd, will appear no different than traditional hashed password files.1 However, when attackers exfiltrate the hashed password file and attempt to crack it, the passwords they will receive are ErsatzPasswords-""fake passwords."" The ErsatzPasswords scheme is flexible by design, enabling it to be integrated into existing authentication systems without changes to user experience. The proposed scheme is integrated into the pam_unix module as well as two client/server authentication schemes: Lightweight Directory Access Protocol (LDAP) authentication and the Pythia pseudorandom function (PRF) Service [Everspaugh et al. 2015]. The core library to support ErsatzPasswords written in C and Python consists of 255 and 103 lines of code, respectively. The integration of ErsatzPasswords into each explored authentication system required less than 100 lines of additional code. Experimental evaluation of ErsatzPasswords shows an increase in authentication latency on the order of 100ms, which maybe acceptable for real world systems. We also describe a framework for implementing ErsatzPasswords using a Trusted Platform Module (TPM). © 2016 ACM.",,C (programming language); Computer hardware; Hardware; Hardware security; Legacy systems; Authentication latency; Authentication scheme; Authentication servers; Authentication systems; Experimental evaluation; Lightweight Directory Access protocols; Physically unclonable functions; Pseudorandom functions; Authentication
Privacy-preserving publishing of hierarchical data,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028665765&doi=10.1145%2f2976738&partnerID=40&md5=62eed717d323e9252424a94df9adf4a4,"Many applications today rely on storage and management of semi-structured information, for example, XML databases and document-oriented databases. These data often have to be shared with untrusted third parties, which makes individuals' privacy a fundamental problem. In this article, we propose anonymization techniques for privacy-preserving publishing of hierarchical data. We show that the problem of anonymizing hierarchical data poses unique challenges that cannot be readily solved by existing mechanisms. We extend two standards for privacy protection in tabular data (k-anonymity and l-diversity) and apply them to hierarchical data. We present utility-aware algorithms that enforce these definitions of privacy using generalizations and suppressions of data values. To evaluate our algorithms and their heuristics, we experiment on synthetic and real datasets obtained from two universities. Our experiments show that we significantly outperform related methods that provide comparable privacy guarantees. © 2016 ACM.",Anonymity; Complex data; Data privacy; Data publishing; Hierarchical data; K-anonymity; XML,Digital storage; XML; Anonymity; Complex data; Data publishing; Hierarchical data; K-Anonymity; Data privacy
MAC precomputation with applications to secure memory,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057736208&doi=10.1145%2f2943780&partnerID=40&md5=6b1ee13db7f30e1c945343a2e07c9200,"We present Shallow MAC (ShMAC), a fixed-input-length message authentication code that performs most of the computation prior to the availability of the message. Specifically, ShMAC's message-dependent computation is much faster and smaller in hardware than the evaluation of a pseudorandom permutation (PRP) and can be implemented by a small shallow circuit, while its precomputation consists of one PRP evaluation. Amain building block for ShMAC is the notion of strong differential uniformity (SDU), which we introduce and which may be of independent interest. We show an efficient SDU construction built from previously considered differentially uniform functions. Our main motivating application is a system architecture where a hardware-secured processor uses memory controlled by an adversary. We also present in technical detail a novel, efficient approach to encrypting and authenticating memory and discuss the associated tradeoffs, while paying special attention to minimizing hardware costs and the reduction of Dynamic Random Access Memory latency.",MAC precomputation; Message authentication code (MAC); System on a chip; Tamper-resistant hardware,Authentication; Hardware; Hardware security; System-on-chip; Differential uniformity; Dynamic random access memory; Message authentication codes; Pre-computation; Pseudorandom permutation; System architectures; System on a chip; Tamper resistant; Dynamic random access storage
Detection of rogue certificates from trusted certificate authorities using deep neural networks,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042651013&doi=10.1145%2f2975591&partnerID=40&md5=22ffa536b5890244b43bab3c345796b6,"Rogue certificates are valid certificates issued by a legitimate certificate authority (CA) that are nonetheless untrustworthy; yet trusted by web browsers and users. With the current public key infrastructure, there exists a window of vulnerability between the time a rogue certificate is issued and when it is detected. Rogue certificates from recent compromises have been trusted for as long as weeks before detection and revocation. Previous proposals to close this window of vulnerability require changes in the infrastructure, Internet protocols, or end user experience. We present a method for detecting rogue certificates from trusted CAs developed from a large and timely collection of certificates. This method automates classification by building machine-learning models with Deep Neural Networks (DNN). Despite the scarcity of rogue instances in the dataset, DNN produced a classification method that is proven both in simulation and in the July 2014 compromise of the India CCA. We report the details of the classification method and illustrate that it is repeatable, such as with datasets obtained from crawling. We describe the classification performance under our current research deployment. © 2016 ACM.",Certificates; Machine learning,Artificial intelligence; Classification (of information); Learning systems; Public key cryptography; Web browsers; Building machines; Certificate authority; Certificates; Classification methods; Classification performance; End-user experience; Public key infrastructure; Window of vulnerability; Deep neural networks
Efficient and accurate behavior-based tracking of malware-control domains in large ISP networks,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052015736&doi=10.1145%2f2960409&partnerID=40&md5=430049f398a68b795bd604ed6a445dd1,"In this article, we propose Segugio, a novel defense system that allows for efficiently tracking the occurrence of new malware-control domain names in very large ISP networks. Segugio passively monitors the DNS traffic to build a machine-domain bipartite graph representing who is querying what. After labeling nodes in this query behavior graph that are known to be either benign or malware-related, we propose a novel approach to accurately detect previously unknown malware-control domains. We implemented a proof-of-concept version of Segugio and deployed it in large ISP networks that serve millions of users. Our experimental results show that Segugio can track the occurrence of new malwarecontrol domains with up to 94% true positives (TPs) at less than 0.1% false positives (FPs). In addition, we provide the following results: (1) we show that Segugio can also detect control domains related to new, previously unseen malware families, with 85% TPs at 0.1% FPs; (2) Segugio's detection models learned on traffic from a given ISP network can be deployed into a different ISP network and still achieve very high detection accuracy; (3) new malware-control domains can be detected days or even weeks before they appear in a large commercial domain-name blacklist; (4) Segugio can be used to detect previously unknown malwareinfected machines in ISP networks; and (5) we show that Segugio clearly outperforms domain-reputation systems based on Belief Propagation. © 2016 ACM.",Behavioral analysis; Graph mining; malware-control domains,Computer crime; Graph theory; Malware; Behavior-based tracking; Behavioral analysis; Belief propagation; Control domains; Detection accuracy; Graph mining; Proof of concept; Reputation systems; Internet service providers
How to train your browser: Preventing XSS attacks using contextual script fingerprints,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049302781&doi=10.1145%2f2939374&partnerID=40&md5=ec461353f7a3673fe70c29aaf5be80d6,"Cross-Site Scripting (XSS) is one of the most common web application vulnerabilities. It is therefore sometimes referred to as the “buffer overflow of the web.” Drawing a parallel from the current state of practice in preventing unauthorized native code execution (the typical goal in a code injection), we propose a script whitelisting approach to tame JavaScript-driven XSS attacks. Our scheme involves a transparent script interception layer placed in the browser's JavaScript engine. This layer is designed to detect every script that reaches the browser, from every possible route, and compare it to a list of valid scripts for the site or page being accessed; scripts not on the list are prevented from executing. To avoid the false positives caused by minor syntactic changes (e.g., due to dynamic code generation), our layer uses the concept of contextual fingerprints when comparing scripts. Contextual fingerprints are identifiers that represent specific elements of a script and its execution context. Fingerprints can be easily enriched with new elements, if needed, to enhance the proposed method's robustness. The list can be populated by the website's administrators or a trusted third party. To verify our approach, we have developed a prototype and tested it successfully against an extensive array of attacks that were performed on more than 50 real-world vulnerable web applications. We measured the browsing performance overhead of the proposed solution on eight websites that make heavy use of JavaScript. Our mechanism imposed an average overhead of 11.1% on the execution time of the JavaScript engine. When measured as part of a full browsing session, and for all tested websites, the overhead introduced by our layer was less than 0.05%. When script elements are altered or new scripts are added on the server side, a new fingerprint generation phase is required. To examine the temporal aspect of contextual fingerprints, we performed a short-term and a long-term experiment based on the same websites. The former, showed that in a short period of time (10 days), for seven of eight websites, the majority of valid fingerprints stay the same (more than 92% on average). The latter, though, indicated that, in the long run, the number of fingerprints that do not change is reduced. Both experiments can be seen as one of the first attempts to study the feasibility of a whitelisting approach for the web. © 2016 ACM 2471-2566/2016/07-ART2 $15.00",JavaScript; JavaScript engine; Protection mechanisms; XSS,Codes (symbols); Engines; Software prototyping; Websites; Cross-site scripting; Dynamic code generation; Javascript; Long-term experiments; Protection mechanisms; State of practice; Trusted third parties; Web application vulnerability; High level languages
Don't let google know I'm lonely,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040668369&doi=10.1145%2f2937754&partnerID=40&md5=a6457964a799f54ee69c379af7b0ed81,"From buying books to finding the perfect partner, we share our most intimate wants and needs with our favourite online systems. But how far should we accept promises of privacy in the face of personalized profiling? In particular, we ask how we can improve detection of sensitive topic profiling by online systems. We propose a definition of privacy disclosure that we call ε-indistinguishability, from which we construct scalable, practical tools to assess the learning potential from personalized content. We demonstrate our results using openly available resources, detecting a learning rate in excess of 98% for a range of sensitive topics during our experiments. © 2016 ACM 2471-2566/2016/08-ART3 $15.00",Bayesian-inference; Detection; Distinguishability; Privacy; Profiling; Recommender-system; Search,Bayesian networks; Data privacy; Error detection; Inference engines; Recommender systems; Bayesian inference; Distinguishability; Indistinguishability; Learning potential; Personalized content; Privacy disclosures; Profiling; Search; Online systems
Looks Like Eve: Exposing insider threats using eye movement biometrics,2016,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019905462&doi=10.1145%2f2904018&partnerID=40&md5=0b91ff0b3e130d39fe65accdc50708ae,"We introduce a novel biometric based on distinctive eye movement patterns. The biometric consists of 20 features that allow us to reliably distinguish users based on differences in these patterns. We leverage this distinguishing power along with the ability to gauge the users' task familiarity, that is, level of knowledge, to address insider threats. In a controlled experiment, we test how both time and task familiarity influence eye movements and feature stability, and how different subsets of features affect the classifier performance. These feature subsets can be used to tailor the eye movement biometric to different authentication methods and threat models. Our results show that eye movement biometrics support reliable and stable continuous authentication of users. We investigate different approaches in which an attacker could attempt to use inside knowledge to mimic the legitimate user. Our results show that while this advance knowledge is measurable, it does not increase the likelihood of successful impersonation. In order to determine the time stability of our features, we repeat the experiment twice within 2 weeks. The results indicate that we can reliably authenticate users over the entire period. We show that lower sampling rates provided by low-cost hardware pose a challenge, but that reliable authentication is possible even at the rate of 50Hz commonly available with consumer-level devices. In a second set of experiments, we evaluate how our authentication system performs across a variety of real-world tasks, including reading, writing, and web browsing. We discuss the advantages and limitations of our approach in detail and give practical insights on the use of this biometric in a real-world environment. 2016 Copyright is held by the owner/author(s).",Biometrics; Continuous authentication; Metrics,Authentication; Biometrics; Classification (of information); Knowledge management; Authentication methods; Authentication systems; Classifier performance; Continuous authentications; Controlled experiment; Eye movement patterns; Metrics; Real world environments; Eye movements
A Decentralized Private Data Marketplace using Blockchain and Secure Multi-Party Computation,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196316329&doi=10.1145%2f3652162&partnerID=40&md5=4f7db31160de6d30eaaf081cecdbaf60,"Big data has proven to be a very useful tool for companies and users, but companies with larger datasets have ended being more competitive than the others thanks to machine learning or artificial intelligence. Secure multi-party computation (SMPC) allows the smaller companies to jointly train arbitrary models on their private data while assuring privacy, and thus gives data owners the ability to perform what are currently known as federated learning algorithms. Besides, with a blockchain it is possible to coordinate and audit those computations in a decentralized way.In this document, we consider a private data marketplace as a space where researchers and data owners meet to agree the use of private data for statistics or more complex model trainings. This document presents a candidate architecure for a private data marketplace by combining SMPC and a public, general-purpose blockchain. Such a marketplace is proposed as a smart contract deployed in the blockchain, while the privacy preserving computation is held by SMPC. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",blockchain; data economy; distributed computation; edge computing; Multi-party computation,Commerce; Edge computing; Learning algorithms; Machine learning; Privacy-preserving techniques; Block-chain; Data economy; Data marketplaces; Decentralised; Distributed computations; Edge computing; Large datasets; Multiparty computation; Private data; Secure multi-party computation; Blockchain
Toward Robust ASR System against Audio Adversarial Examples using Agitated Logit,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196293558&doi=10.1145%2f3661822&partnerID=40&md5=d85077b538573b77e6cef40e7e5a8e95,"Automatic speech recognition (ASR) systems are vulnerable to audio adversarial examples, which aim at deceiving ASR systems by adding perturbations to benign speech signals. These audio adversarial examples appear indistinguishable from benign audio waves, but the ASR system decodes them as intentional malicious commands. Previous studies have demonstrated the feasibility of such attacks in simulated environments (over-line) and have further showcased the creation of robust physical audio adversarial examples (over-air). Various defense techniques have been proposed to counter these attacks. However, most of them have either failed to handle various types of attacks effectively or have resulted in significant time overhead.In this article, we propose a novel method for detecting audio adversarial examples. Our approach involves feeding both smoothed audio and original audio inputs into the ASR system. Subsequently, we introduce noise to the logits before providing them to the decoder of the ASR. We demonstrate that carefully selected noise can considerably influence the transcription results of audio adversarial examples while having minimal impact on the transcription of benign audio waves. Leveraging this characteristic, we detect audio adversarial examples by comparing the altered transcription, resulting from logit noising, with the original transcription. The proposed method can be easily applied to ASR systems without requiring any structural modifications or additional training. Experimental results indicate that the proposed method exhibits robustness against both over-line and over-air audio adversarial examples, outperforming state-of-the-art detection methods. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",audio adversarial examples detection; Automatic speech recognition system; connectionist temporal classification (CTC); over-line and over-air attack; signal smoothing,Acoustic noise; Audio acoustics; Audio systems; Speech recognition; Air attacks; Audio adversarial example detection; Audio wave; Automatic speech recognition system; Connectionist temporal classification; Over-line and over-air attack; Signal smoothing; Simulated environment; Speech signals; Temporal classification; Decoding
CySecBERT: A Domain-Adapted Language Model for the Cybersecurity Domain,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195315891&doi=10.1145%2f3652594&partnerID=40&md5=8bdc591090a09e742c3d7bb478b9e81c,"The field of cysec is evolving fast. Security professionals are in need of intelligence on past, current and - ideally - upcoming threats, because attacks are becoming more advanced and are increasingly targeting larger and more complex systems. Since the processing and analysis of such large amounts of information cannot be addressed manually, cysec experts rely on machine learning techniques. In the textual domain, pre-trained language models such as Bidirectional Encoder Representations from Transformers (BERT) have proven to be helpful as they provide a good baseline for further fine-tuning. However, due to the domain-knowledge and the many technical terms in cysec, general language models might miss the gist of textual information. For this reason, we create a high-quality dataset1 and present a language model2 specifically tailored to the cysec domain that can serve as a basic building block for cybersecurity systems. The model is compared on 15 tasks: Domain-dependent extrinsic tasks for measuring the performance on specific problems, intrinsic tasks for measuring the performance of the internal representations of the model, as well as general tasks from the SuperGLUE benchmark. The results of the intrinsic tasks show that our model improves the internal representation space of domain words compared with the other models. The extrinsic, domain-dependent tasks, consisting of sequence tagging and classification, show that the model performs best in cybersecurity scenarios. In addition, we pay special attention to the choice of hyperparameters against catastrophic forgetting, as pre-trained models tend to forget the original knowledge during further training. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",cybersecurity BERT; cybersecurity dataset; Language model,Benchmarking; Computational linguistics; Domain Knowledge; Learning systems; 'current; Cyber security; Cybersecurity bidirectional encoder representation from transformer; Cybersecurity dataset; Internal representation; Language model; Large amounts; Performance; Security professionals; Cybersecurity
MRAAC: A Multi-stage Risk-aware Adaptive Authentication and Access Control Framework for Android,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196286408&doi=10.1145%2f3648372&partnerID=40&md5=9fde47f450ce386aca83ead27a295970,"Adaptive authentication enables smartphones and enterprise apps to decide when and how to authenticate users based on contextual and behavioral factors. In practice, a system may employ multiple policies to adapt its authentication mechanisms and access controls to various scenarios. However, existing approaches suffer from contradictory or insecure adaptations, which may enable attackers to bypass the authentication system. Besides, most existing approaches are inflexible and do not provide desirable access controls. We design and build a multi-stage risk-aware adaptive authentication and access control framework (MRAAC), which provides the following novel contributions: Multi-stage: MRAAC organizes adaptation policies in multiple stages to handle different risk types and progressively adapts authentication mechanisms based on context, resource sensitivity, and user authenticity. Appropriate access control: MRAAC provides libraries to enable sensitive apps to manage the availability of their in-app resources based on MRAAC's risk awareness. Extensible: While existing proposals are tailored to cater to a single use case, MRAAC supports a variety of use cases with custom risk models. We exemplify these advantages of MRAAC by deploying it for three use cases: an enhanced version of Android Smart Lock, guest-aware continuous authentication, and corporate app for BYOD. We conduct experiments to quantify the CPU, memory, latency, and battery performance of MRAAC. Our evaluation shows that MRAAC enables various stakeholders (device manufacturers, enterprise and secure app developers) to provide complex adaptive authentication workflows on COTS Android with low processing and battery overhead. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",access control; Adaptive authentication; behavioral biometrics; implicit authentication,Android (operating system); Electric batteries; Mobile security; Risk assessment; Risk perception; Adaptive authentication; Authentication mechanisms; Behavioral factors; Behavioural Biometric; Contextual factors; Control framework; Implicit authentications; Multi-stages; Risk aware; Smart phones; Authentication
AdverSPAM: Adversarial SPam Account Manipulation in Online Social Networks,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196270497&doi=10.1145%2f3643563&partnerID=40&md5=6a436f3fc0a89f34ceb0acd5285aefa2,"In recent years, the widespread adoption of Machine Learning (ML) at the core of complex IT systems has driven researchers to investigate the security and reliability of ML techniques. A very specific kind of threats concerns the adversary mechanisms through which an attacker could induce a classification algorithm to provide the desired output. Such strategies, known as Adversarial Machine Learning (AML), have a twofold purpose: to calculate a perturbation to be applied to the classifier's input such that the outcome is subverted, while maintaining the underlying intent of the original data. Although any manipulation that accomplishes these goals is theoretically acceptable, in real scenarios perturbations must correspond to a set of permissible manipulations of the input, which is rarely considered in the literature. In this article, we present AdverSPAM, an AML technique designed to fool the spam account detection system of an Online Social Network (OSN). The proposed black-box evasion attack is formulated as an optimization problem that computes the adversarial sample while maintaining two important properties of the feature space, namely statistical correlation and semantic dependency. Although being demonstrated in an OSN security scenario, such an approach might be applied in other context where the aim is to perturb data described by mutually related features. Experiments conducted on a public dataset show the effectiveness of AdverSPAM compared to five state-of-the-art competitors, even in the presence of adversarial defense mechanisms. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Adversarial machine learning; evasion attacks; online social networks; spammer detection,E-learning; Machine learning; Network security; Semantics; Adversarial machine learning; Black boxes; Classification algorithm; Detection system; Evasion attack; IT system; Machine learning techniques; Machine-learning; Security and reliabilities; Spammer detections; Social networking (online)
Is Bitcoin Future as Secure as We Think? Analysis of Bitcoin Vulnerability to Bribery Attacks Launched through Large Transactions,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196275875&doi=10.1145%2f3641546&partnerID=40&md5=7ae89ac15704a46e67e887bc08d0e599,"Bitcoin uses blockchain technology to maintain transactions order and provides probabilistic guarantees to prevent double-spending, assuming that an attacker's computational power does not exceed 50% of the network power. In this article, we design a novel bribery attack and show that this guarantee can be hugely undermined. Miners are assumed to be rational in this setup, and they are given incentives that are dynamically calculated. In this attack, the adversary misuses the Bitcoin protocol to bribe miners and maximize their gained advantage. We will reformulate the bribery attack to propose a general mathematical foundation upon which we build multiple strategies. We show that, unlike Whale Attack, these strategies are practical, especially in the future when halvings lower the mining rewards. In the so-called ""guaranteed variable-rate bribing with commitment""strategy, through optimization by Differential Evolution (DE), we show how double-spending is possible in the Bitcoin ecosystem for any transaction whose value is above 218.9BTC, and this comes with 100% success rate. A slight reduction in the success probability, e.g., by 10%, brings the threshold down to 165BTC. If the rationality assumption holds, then this shows how vulnerable blockchain-based systems like Bitcoin are. We suggest a soft fork on Bitcoin to fix this issue at the end. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Bitcoin; blockchain; bribery attack; differential evolution; double-spending; markov chain; security,Bitcoin; Evolutionary algorithms; Markov processes; Optimization; Block-chain; Bribery attack; Computational power; Differential Evolution; Double-spending; Mathematical foundations; Multiple strategy; Network power; Probabilistic guarantees; Security; Blockchain
Combining Cyber Security Intelligence to Refine Automotive Cyber Threats,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195027446&doi=10.1145%2f3644075&partnerID=40&md5=0a08e71de6d2b4c07feeac7d5746a1a5,"Modern vehicles increasingly rely on electronics, software, and communication technologies (cyber space) to perform their driving task. Over-The-Air (OTA) connectivity further extends the cyber space by creating remote access entry points. Accordingly, the vehicle is exposed to security attacks that are able to impact road safety. A profound understanding of security attacks, vulnerabilities, and mitigations is necessary to protect vehicles against cyber threats. While automotive threat descriptions, such as in UN R155, are still abstract, this creates a risk that potential vulnerabilities are overlooked and the vehicle is not secured against them. So far, there is no common understanding of the relationship of automotive attacks, the concrete vulnerabilities they exploit, and security mechanisms that would protect the system against these attacks. In this article, we aim at closing this gap by creating a mapping between UN R155, Microsoft STRIDE classification, Common Attack Pattern Enumeration and Classification (CAPEC), and Common Weakness Enumeration (CWE). In this way, already existing detailed knowledge of attacks, vulnerabilities, and mitigations is combined and linked to the automotive domain. In practice, this refines the list of UN R155 threats and therefore supports vehicle manufacturers, suppliers, and approval authorities to meet and assess the requirements for vehicle development in terms of cybersecurity. Overall, 204 mappings between UN threats, STRIDE, CAPEC attack patterns, and CWE weaknesses were created. We validated these mappings by applying our Automotive Attack Database (AAD) that consists of 361 real-world attacks on vehicles. Furthermore, 25 additional attack patterns were defined based on automotive-related attacks. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",attacks; Automotive security; mitigations; taxonomies; vulnerabilities,Abstracting; Cybersecurity; Mapping; Motor transportation; Vehicle to vehicle communications; Attack; Attack patterns; Automotive security; Automotives; Cyber security; Cyber threats; Cyberspaces; Mitigation; Security attacks; Vulnerability; Vehicles
Non-intrusive Balance Tomography Using Reinforcement Learning in the Lightning Network,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185333441&doi=10.1145%2f3639366&partnerID=40&md5=787f77af8ab5d3fa2389ab77d57baf54,"The Lightning Network (LN) is a second layer system for solving the scalability problem of Bitcoin transactions. In the current implementation of LN, channel capacity (i.e., the sum of individual balances held in the channel) is public information, while individual balances are kept secret for privacy concerns. Attackers may discover a particular balance of a channel by sending multiple fake payments through the channel. Such an attack, however, can hardly threaten the security of the LN system due to its high cost and noticeable intrusions. In this work, we present a novel non-intrusive balance tomography attack, which infers channel balances silently by performing legal transactions between two pre-created LN nodes. To minimize the cost of the attack, we propose an algorithm to compute the optimal payment amount for each transaction and design a path construction method using reinforcement learning to explore the most informative path to conduct the transactions. Finally, we propose two approaches (NIBT-RL and NIBT-RL-β) to accurately and efficiently infer all individual balances using the results of these transactions. Experiments using simulated account balances over actual LN topology show that our method can accurately infer 90% ∼94% of all balances in LN with around 12 USD. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesLightning Network; network tomography; reinforcement learning; security and privacy; system attack,Learning systems; Lightning; Tomography; 'current; Additional key word and phraseslightning network; Key words; Network tomography; Non-intrusive; Reinforcement learnings; Scalability problems; Second layer; Security and privacy; System attack; Reinforcement learning
DeepMark: A Scalable and Robust Framework for DeepFake Video Detection,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185218059&doi=10.1145%2f3629976&partnerID=40&md5=3be7e70c26620276550ead7c817b6fb6,"With the rapid growth of DeepFake video techniques, it becomes increasingly challenging to identify them visually, posing a huge threat to our society. Unfortunately, existing detection schemes are limited to exploiting the artifacts left by DeepFake manipulations, so they struggle to keep pace with the ever-improving DeepFake models. In this work, we propose DeepMark, a scalable and robust framework for detecting DeepFakes. It imprints essential visual features of a video into DeepMark Meta (DMM) and uses it to detect DeepFake manipulations by comparing the extracted visual features with the ground truth in DMM. Therefore, DeepMark is future-proof, because a DeepFake video must aim to alter some visual feature, no matter how ""natural""it looks. Furthermore, DMM also contains a signature for verifying the integrity of the above features. And an essential link to the features as well as their signature is attached with error correction codes and embedded in the video watermark. To improve the efficiency of DMM creation, we also present a threshold-based feature selection scheme and a deduced face detection scheme. Experimental results demonstrate the effectiveness and efficiency of DeepMark on DeepFake video detection under various datasets and parameter settings. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesDeepFake forensics; scalable framework; video metadata,Digital forensics; Efficiency; Error correction; Feature extraction; Additional key word and phrasesdeepfake forensic; Detection scheme; Ground truth; Key words; Rapid growth; Scalable framework; Video detection; Video metadata; Video techniques; Visual feature; Face recognition
Sphinx-in-the-Head: Group Signatures from Symmetric Primitives,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185339723&doi=10.1145%2f3638763&partnerID=40&md5=e5399a27f2b2efc9ca6e9982da96df8a,"Group signatures and their variants have been widely used in privacy-sensitive scenarios such as anonymous authentication and attestation. In this paper, we present a new post-quantum group signature scheme from symmetric primitives. Using only symmetric primitives makes the scheme less prone to unknown attacks than basing the design on newly proposed hard problems whose security is less well-understood. However, symmetric primitives do not have rich algebraic properties, and this makes it extremely challenging to design a group signature scheme on top of them. It is even more challenging if we want a group signature scheme suitable for real-world applications, one that can support large groups and require few trust assumptions. Our scheme is based on MPC-in-the-head non-interactive zero-knowledge proofs, and we specifically design a novel hash-based group credential scheme, which is rooted in the SPHINCS+ signature scheme but with various modifications to make it MPC (multi-party computation) friendly. The security of the scheme has been proved under the fully dynamic group signature model. We provide an implementation of the scheme and demonstrate the feasibility of handling a group size as large as 260. This is the first group signature scheme from symmetric primitives that supports such a large group size and meets all the security requirements. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesGroup signature; hash-based cryptography; post-quantum cryptography,Authentication; Quantum cryptography; Additional key word and phrasesgroup signature; Group signature scheme; Group signatures; Group size; Hash-based cryptography; Key words; Large groups; Multiparty computation; Post quantum cryptography; Symmetrics; Network security
On detecting and measuring exploitable javascript functions in real-world applications,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185252093&doi=10.1145%2f3630253&partnerID=40&md5=bcc7edcac78f89af6f04844f70aee5bd,"JavaScript is often rated as the most popular programming language for the development of both client-side and server-side applications. Because of its popularity, JavaScript has become a frequent target for attackers who exploit vulnerabilities in the source code to take control over the application. To address these JavaScript security issues, such vulnerabilities must be identified first. Existing studies in vulnerable code detection in JavaScript mostly consider package-level vulnerability tracking and measurements. However, such package-level analysis is largely imprecise, as real-world services that include a vulnerable package may not use the vulnerable functions in the package. Moreover, even the inclusion of a vulnerable function may not lead to a security problem if the function cannot be triggered with exploitable inputs. In this article, we develop a vulnerability detection framework that uses vulnerable pattern recognition and textual similarity methods to detect vulnerable functions in real-world JavaScript projects, combined with a static multi-file taint analysis mechanism to further assess the impact of the vulnerabilities on the whole project (i.e., whether the vulnerability can be exploited in a given project). We compose a comprehensive dataset of 1,360 verified vulnerable JavaScript functions using the Snyk vulnerability database and the VulnCode-DB project. From this ground-truth dataset, we build our vulnerable patterns for two common vulnerability types: prototype pollution and Regular Expression Denial of Service (ReDoS). With our framework, we analyze 9,205,654 functions (from 3,000 NPM packages, 1,892 websites and 557 Chrome Web extensions), and detect 117,601 prototype pollution and 7,333 ReDoS vulnerabilities. By further processing all 5,839 findings from NPM packages with our taint analyzer, we verify the exploitability of 290 zero-day cases across 134 NPM packages. In addition, we conduct an in-depth contextual analysis of the findings in 17 popular/critical projects and study the practical security exposure of 20 functions. With our semi-automated vulnerability reporting functionality, we disclosed all verified findings to project owners. We also obtained 25 published CVEs for our findings, 19 of them rated as ""Critical""severity and six rated as ""High""severity. Additionally, we obtained 169 CVEs that are currently ""Reserved""(as of Apr. 2023). As evident from the results, our approach can shift JavaScript vulnerability detection from the coarse package/library level to the function level and thus improve the accuracy of detection and aid timely patching. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesJavaScript security; prototype pollution; Regular Expression Denial of Service; semantic pattern detection; static analysis; taint analysis; vulnerability detection; vulnerable functions,Codes (symbols); Denial-of-service attack; High level languages; Pattern matching; Semantics; Web services; Websites; Zero-day attack; Additional key word and phrasesjavascript security; Denial of Service; Key words; Pattern detection; Prototype pollution; Regular expression denial of service; Regular expressions; Semantic pattern; Semantic pattern detection; Taint analyse; Vulnerability detection; Vulnerable function; Static analysis
Deepfaker: A unified evaluation platform for facial deepfake and detection models,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181950504&doi=10.1145%2f3634914&partnerID=40&md5=f7cc0e3463f622cf5d9a303e6e8fc3e4,"Deepfake data contains realistically manipulated faces - its abuses pose a huge threat to the security and privacy-critical applications. Intensive research from academia and industry has produced many deepfake/detection models, leading to a constant race of attack and defense. However, due to the lack of a unified evaluation platform, many critical questions on this subject remain largely unexplored. How is the anti-detection ability of the existing deepfake models? How generalizable are existing detection models against different deepfake samples? How effective are the detection APIs provided by the cloud-based vendors? How evasive and transferable are adversarial deepfakes in the lab and real-world environment? How do various factors impact the performance of deepfake and detection models?To bridge the gap, we design and implement DEEPFAKER1 a unified and comprehensive deepfake detection evaluation platform. Specifically, DEEPFAKER has integrated 10 state-of-the-art deepfake methods and 9 representative detection methods, while providing a user-friendly interface and modular design that allows for easy integration of new methods. Leveraging DEEPFAKER, we conduct a large-scale empirical study of facial deepfake/detection models and draw a set of key findings: (i) the detection methods have poor generalization on samples generated by different deepfake methods; (ii) there is no significant correlation between anti-detection ability and visual quality of deepfake samples; (iii) the current detection APIs have poor detection performance and adversarial deepfakes can achieve about 70% attack success rate on all cloud-based vendors, calling for an urgent need to deploy effective and robust detection APIs; (iv) the detection methods in the lab are more robust against transfer attacks than the detection APIs in the real-world environment; and (v) deepfake videos may not always be more difficult to detect after video compression. We envision that DEEPFAKER will benefit future research on facial deepfake and detection. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesFacial deepfake; adversarial machine learning; deepfake detection; experimental evaluation,Bridges; Interface states; Machine learning; Additional key word and phrasesfacial deepfake; Adversarial machine learning; Deepfake detection; Detection ability; Detection methods; Detection models; Evaluation platforms; Experimental evaluation; Key words; Machine-learning; Image compression
Uncovering CWE-CVE-CPE Relations with Threat Knowledge Graphs,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185218585&doi=10.1145%2f3641819&partnerID=40&md5=d23831b871aa43d01d4740d514f13f7d,"Security assessment relies on public information about products, vulnerabilities, and weaknesses. So far, databases in these categories have rarely been analyzed in combination. Yet, doing so could help predict unreported vulnerabilities and identify common threat patterns. In this article, we propose a methodology for producing and optimizing a knowledge graph that aggregates knowledge from common threat databases (CVE, CWE, and CPE). We apply the threat knowledge graph to predict associations between threat databases, specifically between products, vulnerabilities, and weaknesses. We evaluate the prediction performance both in closed world with associations from the knowledge graph and in open world with associations revealed afterward. Using rank-based metrics (i.e., Mean Rank, Mean Reciprocal Rank, and Hits@N scores), we demonstrate the ability of the threat knowledge graph to uncover many associations that are currently unknown but will be revealed in the future, which remains useful over different time periods. We propose approaches to optimize the knowledge graph and show that they indeed help in further uncovering associations. We have made the artifacts of our work publicly available.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesVulnerability; knowledge graph; link prediction; threat modeling,Database systems; Knowledge graph; Additional key word and phrasesvulnerability; Key words; Knowledge graphs; Link prediction; Mean-ranks; Open world; Prediction performance; Public information; Security assessment; Threat modeling; Forecasting
OptiClass: An Optimized Classifier for Application Layer Protocols Using Bit Level Signatures,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185266117&doi=10.1145%2f3633777&partnerID=40&md5=24322795f246f5b4be7b3424ee44f759,"Network traffic classification has many applications, such as security monitoring, quality of service, traffic engineering, and so on. For the aforementioned applications, Deep Packet Inspection (DPI) is a popularly used technique for traffic classification because it scrutinizes the payload and provides comprehensive information for accurate analysis of network traffic. However, DPI-based methods reduce network performance because they are computationally expensive and hinder end-user privacy as they analyze the payload. To overcome these challenges, bit-level signatures are significantly used to perform network traffic classification. However, most of these methods still need to improve performance as they perform one-by-one signature matching of unknown payloads with application signatures for classification. Moreover, these methods become stagnant with the increase in application signatures. Therefore, to fill this gap, we propose OptiClass, an optimized classifier for application protocols using bit-level signatures. OptiClass performs parallel application signature matching with unknown flows, which results in faster, more accurate, and more efficient network traffic classification. OptiClass achieves twofold performance gains compared to the state-of-the-art methods. First, OptiClass generates bit-level signatures of just 32 bits for all the applications. This keeps OptiClass swift and privacy-preserving. Second, OptiClass uses a novel data structure called BiTSPLITTER for signature matching for fast and accurate classification. We evaluated the performance of OptiClass on three datasets consisting of twenty application protocols. Experimental results report that OptiClass has an average recall, precision, and F1-score of 97.36%, 97.38%, and 97.37%, respectively, and an average classification speed of 9.08 times faster than five closely related state-of-the-art methods. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesApplication layer protocols; bit level encoding; crown graph; ladder graph; network traces,Cryptography; Internet protocols; Network coding; Network security; Quality of service; Telecommunication traffic; Additional key word and phrasesapplication layer protocol; Bit level; Bit level encoding; Crown graph; Encodings; Key words; Ladder graphs; Layer protocols; Network trace; Network traffic classification; Classification (of information)
Sound-based Two-factor Authentication: Vulnerabilities and Redesign,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185505708&doi=10.1145%2f3632175&partnerID=40&md5=e5ab1f1aa5bf911ed530de4f70a12365,"Reducing the level of user effort involved in traditional two-factor authentication (TFA) constitutes an important research topic. An interesting representative approach, Sound-Proof, leverages ambient sounds to detect the proximity between the second-factor device (phone) and the login terminal (browser), and it eliminates the need for the user to transfer PIN codes. In this article, we identify a weakness of the Sound-Proof system that makes it completely vulnerable to passive ""environment guessing""and active ""environment manipulating""remote attackers and proximity attackers. Addressing these security issues, we propose Listening-Watch, a new TFA mechanism based on a wearable device (watch/bracelet) and active browser-generated random speech sounds. As the user attempts to log in, the browser populates a short random code encoded into speech, and the login succeeds if the watch's audio recording contains this code (decoded using speech recognition) and is similar enough to the browser's audio recording. The remote attacker, who has guessed/manipulated the user's environment, will be defeated, since authentication success relies upon the presence of the random code in watch's recordings. The proximity attacker will also be defeated unless it is extremely close (<50 cm) to the watch, since the wearable microphones are usually designed to capture only nearby sounds (e.g., voice commands). © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesTwo-factor authentication; audio proximity; speech signals; wearable device,Audio acoustics; Audio recordings; Codes (symbols); Speech recognition; Watches; Wearable computers; Additional key word and phrasestwo-factor authentication; Ambient sounds; Audio proximity; Key words; Proof system; Random codes; Research topics; Speech signals; Two factor authentication; Wearable devices; Authentication
Efficient History-Driven Adversarial Perturbation Distribution Learning in Low Frequency Domain,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185316469&doi=10.1145%2f3632293&partnerID=40&md5=46707a10bc360b362ca8acc84f4dde92,"The existence of adversarial image makes us have to doubt the credibility of artificial intelligence system. Attackers can use carefully processed adversarial images to carry out a variety of attacks. Inspired by the theory of image compressed sensing, this paper proposes a new black-box attack, . It uses covariance matrix adaptive evolution strategy (CMA-ES) to learn the distribution of adversarial perturbation in low frequency domain, reducing the dimensionality of solution space. And sep-CMA-ES is used to set the covariance matrix as a diagonal matrix, which further reduces the dimensions that need to be updated for the covariance matrix of multivariate Gaussian distribution learned in attacks, thereby reducing the computational cost of attack. And on this basis, we propose history-driven mean update and current optimal solution-guided improvement strategies to avoid the evolution of distribution to a worse direction. The experimental results show that the proposed can achieve a higher attack success rate with fewer queries on attacking both CNN-based and transformer-based target models under -norm and -norm constraints of perturbation. We also conduct an ablation study and the results show that the proposed improved strategies can effectively reduce the number of visits to the target model when making adversarial examples for hard examples. In addition, our attack is able to make the integrated defense strategy of GRIP-GAN and noise-embedded training ineffective to a certain extent. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesInformation security; adversarial perturbation; black-box attacks; computer vision; deep neural networks,Computation theory; Computer vision; Covariance matrix; Frequency domain analysis; Adaptive evolution; Additional key word and phrasesinformation security; Adversarial perturbation; Black boxes; Black-box attack; Covariance matrices; Evolution strategies; Key words; Low frequency domain; Target model; Deep neural networks
Eyes See Hazy while Algorithms Recognize Who You Are,2024,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185395602&doi=10.1145%2f3632292&partnerID=40&md5=ec63b0e59de37cd91dba473f74cf4e02,"Facial recognition technology has been developed and widely used for decades. However, it has also made privacy concerns and researchers' expectations for facial recognition privacy-preserving technologies. To provide privacy, detailed or semantic contents in face images should be obfuscated. However, face recognition algorithms have to be tailor-designed according to current obfuscation methods, as a result the face recognition service provider has to update its commercial off-the-shelf (COTS) products for each obfuscation method. Meanwhile, current obfuscation methods have no clearly quantified explanation. This paper presents a universal face obfuscation method for a family of face recognition algorithms using global or local structure of eigenvector space. By specific mathematical explanations, we show that the upper bound of the distance between the original and obfuscated face images is smaller than the given recognition threshold. Experiments show that the recognition degradation is 0% for global structure based and 0.3%-5.3% for local structure based, respectively. Meanwhile, we show that even if an attacker knows the whole obfuscation method, he/she has to enumerate all the possible roots of a polynomial with an obfuscation coefficient, which is computationally infeasible to reconstruct original faces. So our method shows a good performance in both privacy and recognition accuracy without modifying recognition algorithms. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesPrivacy preserving; eigenspace; face obfuscation; face recognition,Privacy-preserving techniques; Semantics; 'current; Additional key word and phrasesprivacy preserving; Eigenspaces; Face images; Face obfuscation; Face recognition algorithms; Facial recognition; Global structure; Key words; Local structure; Face recognition
An Experimental Assessment of Inconsistencies in Memory Forensics,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185219426&doi=10.1145%2f3628600&partnerID=40&md5=ee8e83925a5c190b5b305a7459d55916,"Memory forensics is concerned with the acquisition and analysis of copies of volatile memory (memory dumps). Based on an empirical assessment of observable inconsistencies in 360 memory dumps of a running Linux system, we confirm a state of overwhelming inconsistency in memory forensics: almost a third of these dumps had an empty process list and was therefore obviously incomplete. Out of those dumps that were analyzable, almost every second dump showed some form of inconsistency that potentially impacts the interpretation of the dump in a forensic investigation. These results are based on a new way to estimate the level of causal consistency of a memory dump. The factors influencing these inconsistencies are less clear but in general correlate with the level of concurrency (system load and number of threads). © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and Phrases Memory forensics; inconsistencies; memory acquisition; memory analysis,Digital storage; Additional key word and phrase memory forensic; Empirical assessment; Experimental assessment; Inconsistency; Key words; Key-phrase; Memory acquisitions; Memory analysis; Memory forensics; Volatile memory; Computer operating systems
Forward Security with Crash Recovery for Secure Logs,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185266311&doi=10.1145%2f3631524&partnerID=40&md5=27f1dccf68eb23cd2bcb1b5465275abc,"Logging is a key mechanism in the security of computer systems. Beyond supporting important forward security properties, it is critical that logging withstands both failures and intentional tampering to prevent subtle attacks leaving the system in an inconsistent state with inconclusive evidence. We propose new techniques combining forward security with crash recovery for secure log data storage. As the support of specifically forward integrity and the online nature of logging prevent the use of conventional coding, we propose and analyze a coding scheme resolving these unique design constraints. Specifically, our coding enables forward integrity, online encoding, and most importantly a constant number of operations per encoding. It adds a new log item by ing it to k cells of a table. If up to a certain threshold of cells is modified by the adversary, or lost due to a crash, we still guarantee recovery of all stored log items. The main advantage of the coding scheme is its efficiency and compatibility with forward integrity. The key contribution of the paper is the use of spectral graph theory techniques to prove that k is constant in the number n of all log items ever stored and small in practice, e.g., k = 5. Moreover, we prove that to cope with up to modified or lost log items, storage expansion is constant in n and small in practice. For k = 5, the size of the table is only 12% more than the simple concatenation of all n items. We propose and evaluate original techniques to scale the computation cost of recovery to several GBytes of security logs. We instantiate our scheme into an abstract data structure which allows to either detect adversarial modifications to log items or treat modifications like data loss in a system crash. The data structure can recover lost log items, thereby effectively reverting adversarial modifications. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesSecure logging; coding; crash recovery; forward security; tamper evidence,Computation theory; Data structures; Digital storage; Encoding (symbols); Graph theory; Molecular biology; Network security; Signal encoding; Additional key word and phrasessecure logging; Coding; Coding scheme; Crash recoveries; Encodings; Forward security; Key words; Log data; Security properties; Tamper evidence; Recovery
Spoofing Against Spoofing: Toward Caller ID Verification in Heterogeneous Telecommunication Systems,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185335275&doi=10.1145%2f3625546&partnerID=40&md5=3a02b24cca3683b1ae732ae5693cee4d,"Caller ID spoofing is a global industry problem and often acts as a critical enabler for telephone fraud. To address this problem, the Federal Communications Commission has mandated telecom providers in the U.S. to implement STIR/SHAKEN, an industry-driven solution based on digital signatures. STIR/SHAKEN relies on a public key infrastructure (PKI) to manage digital certificates, but scaling up this PKI for the global telecom industry is extremely difficult, if not impossible. Furthermore, it only works with IP-based systems (e.g., SIP), leaving the traditional non-IP systems (e.g., SS7) unprotected. So far the alternatives to the STIR/SHAKEN have not been sufficiently studied. In this article, we propose a PKI-free solution, called Caller ID Verification (CIV). CIV authenticates the caller ID based on a challenge-response process instead of digital signatures, hence requiring no PKI. It supports both IP and non-IP systems. Perhaps counter-intuitively, we show that number spoofing can be leveraged, in conjunction with Dual-tone Multi-frequency, to efficiently implement the challenge-response process, i.e., using spoofing to fight against spoofing. We implement CIV for Voice over Internet Protocol, cellular, and landline phones across heterogeneous networks (SS7/SIP) by only updating the software on the user's phone. This is the first caller ID authentication solution with working prototypes for all three types of telephone systems in the current telecom architecture. Finally, we show how the implementation of CIV can be optimized by integrating it into telecom clouds as a service, which users may subscribe to. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesTelecom fraud; caller ID spoofing; caller ID verification; calling line identification; cellular network; dual tone multi-frequency; public switched telephone network; session initiation protocol; STIR/SHAKEN; voice-over-IP,Crime; Electronic document identification systems; Heterogeneous networks; Internet protocols; Network security; Public key cryptography; Telephone sets; Voice/data communication systems; Additional key word and phrasestelecom fraud; Caller ID; Caller ID spoofing; Caller ID verification; Calling line identification; Cellular network; Dual tone multi-frequency; Key words; Line:identification; Multi frequency; Public switched telephone network; Session Initiation Protocols; STIR/SHAKEN; Voice over IP; Authentication
symbSODA: Configurable and Verifiable Orchestration Automation for Active Malware Deception,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179131450&doi=10.1145%2f3624568&partnerID=40&md5=50bc5e656e4d7a60245c3d0189e0ff13,"Malware is commonly used by adversaries to compromise and infiltrate cyber systems in order to steal sensitive information or destroy critical assets. Active Cyber Deception (ACD) has emerged as an effective proactive cyber defense against malware to enable misleading adversaries by presenting fake data and engaging them to learn novel attack techniques. However, real-time malware deception is a complex and challenging task because (1) it requires a comprehensive understanding of the malware behaviors at technical and tactical levels in order to create the appropriate deception ploys and resources that can leverage this behavior and mislead malware, and (2) it requires a configurable yet provably valid deception planning to guarantee effective and safe real-time deception orchestration.This article presents symbSODA, a highly configurable and verifiable cyber deception system that analyzes real-world malware using multipath execution to discover API patterns that represent attack techniques/tactics critical for deception, enables users to create their own customized deception ploys based on the malware type and objectives, allows for constructing conflict-free Deception Playbooks, and finally automates the deception orchestration to execute the malware inside a deceptive environment. symbSODA extracts Malicious Sub-graphs (MSGs) consisting of WinAPIs from real-world malware and maps them to tactics and techniques using the ATT&CK framework to facilitate the construction of meaningful user-defined deception playbooks.We conducted a comprehensive evaluation study on symbSODA using 255 recent malware samples. We demonstrated that the accuracy of the end-to-end malware deception is 95% on average, with negligible overhead using various deception goals and strategies. Furthermore, our approach successfully extracted MSGs with a 97% recall, and our MSG-to-MITRE mapping achieved a top-1 accuracy of 88.75%. Our study suggests that symbSODA can serve as a general-purpose Malware Deception Factory to automatically produce customized deception playbooks against arbitrary malware behavior. © 2023 held by the owner/author(s). Publication rights licensed to ACM.",Cyber deception; malware; security orchestration; threat intelligence; verification,Cybersecurity; Malware; Cybe deception; Cyber systems; Malware behaviors; Malwares; Real- time; Real-world; Security orchestration; Sensitive informations; Subgraphs; Threat intelligence; Network security
Semi-Supervised Classification of Malware Families Under Extreme Class Imbalance via Hierarchical Non-Negative Matrix Factorization with Automatic Model Selection,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175138816&doi=10.1145%2f3624567&partnerID=40&md5=c41f4a17b701375a4864591a2be1592f,"Identification of the family to which a malware specimen belongs is essential in understanding the behavior of the malware and developing mitigation strategies. Solutions proposed by prior work, however, are often not practicable due to the lack of realistic evaluation factors. These factors include learning under class imbalance, the ability to identify new malware, and the cost of production-quality labeled data. In practice, deployed models face prominent, rare, and new malware families. At the same time, obtaining a large quantity of up-to-date labeled malware for training a model can be expensive. In this article, we address these problems and propose a novel hierarchical semi-supervised algorithm, which we call the HNMFk Classifier, that can be used in the early stages of the malware family labeling process. Our method is based on non-negative matrix factorization with automatic model selection, that is, with an estimation of the number of clusters. With HNMFk Classifier, we exploit the hierarchical structure of the malware data together with a semi-supervised setup, which enables us to classify malware families under conditions of extreme class imbalance. Our solution can perform abstaining predictions, or rejection option, which yields promising results in the identification of novel malware families and helps with maintaining the performance of the model when a low quantity of labeled data is used. We perform bulk classification of nearly 2,900 both rare and prominent malware families, through static analysis, using nearly 388,000 samples from the EMBER-2018 corpus. In our experiments, we surpass both supervised and semi-supervised baseline models with an F1 score of 0.80. © 2023 held by the owner/author(s). Publication rights licensed to ACM.",abstaining prediction; class imbalance; hierarchical; Malware; malware families; model selection; non-negative matrix factorization; reject-option; semi-supervised,Malware; Matrix algebra; Static analysis; Supervised learning; Abstaining prediction; Automatic model selection; Class imbalance; Hierarchical; Malware families; Malwares; Model Selection; Nonnegative matrix factorization; Reject-option; Semi-supervised; Non-negative matrix factorization
Measures of Information Leakage for Incomplete Statistical Information: Application to a Binary Privacy Mechanism,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179122945&doi=10.1145%2f3624982&partnerID=40&md5=2cfb41926b8fe8b1553e1fc50f55d6bd,"Information leakage is usually defined as the logarithmic increment in the adversary's probability of correctly guessing the legitimate user's private data or some arbitrary function of the private data when presented with the legitimate user's publicly disclosed information. However, this definition of information leakage implicitly assumes that both the privacy mechanism and the prior probability of the original data are entirely known to the attacker. In reality, the assumption of complete knowledge of the privacy mechanism for an attacker is often impractical. The attacker can usually have access to only an approximate version of the correct privacy mechanism, computed from a limited set of the disclosed data, for which they can access the corresponding un-distorted data. In this scenario, the conventional definition of leakage no longer has an operational meaning. To address this problem, in this article, we propose novel meaningful information-theoretic metrics for information leakage when the attacker has incomplete information about the privacy mechanism - we call them average subjective leakage, average confidence boost, and average objective leakage, respectively. For the simplest, binary scenario, we demonstrate how to find an optimized privacy mechanism that minimizes the worst-case value of either of these leakages. © 2023 held by the owner/author(s). Publication rights licensed to ACM.",average confidence boost; average objective leakage; Average subjective leakage; data privacy; incomplete information; information leakage,Information theory; Average confidence boost; Average objective leakage; Average subjective leakage; Incomplete information; Information leakage; Legitimate users; Measures of information; Privacy mechanisms; Private data; Statistical information; Data privacy
SAM: Query-efficient Adversarial Attacks against Graph Neural Networks,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179128180&doi=10.1145%2f3611307&partnerID=40&md5=de0d4cdb1470632276736b274e271896,"Recent studies indicate that Graph Neural Networks (GNNs) are vulnerable to adversarial attacks. Particularly, adversarially perturbing the graph structure, e.g., flipping edges, can lead to salient degeneration of GNNs' accuracy. In general, efficiency and stealthiness are two significant metrics to evaluate an attack method in practical use. However, most prevailing graph structure-based attack methods are query intensive, which impacts their practical use. Furthermore, while the stealthiness of perturbations has been discussed in previous studies, the majority of them focus on the attack scenario targeting a single node. To fill the research gap, we present a global attack method against GNNs, Saturation adversarial Attack with Meta-gradient, in this article. We first propose an enhanced meta-learning-based optimization method to obtain useful gradient information concerning graph structural perturbations. Then, leveraging the notion of saturation attack, we devise an effective algorithm to determine the perturbations based on the derived meta-gradients. Meanwhile, to ensure stealthiness, we introduce a similarity constraint to suppress the number of perturbed edges. Thorough experiments demonstrate that our method can effectively depreciate the accuracy of GNNs with a small number of queries. While achieving a higher misclassification rate, we also show that the perturbations developed by our method are not noticeable.  © 2023 held by the owner/author(s). Publication rights licensed to ACM.",Adversarial attack; graph neural network; poisoning attack; topology attack,Graphic methods; Topology; Adversarial attack; Attack methods; Flipping edges; General efficiencies; Graph neural networks; Graph structures; Network accuracy; Poisoning attacks; Practical use; Topology attacks; Graph neural networks
System Auditing for Real-Time Systems,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179124010&doi=10.1145%2f3625229&partnerID=40&md5=52e9f3e55b2c37c10426f7a0524d6186,"System auditing is an essential tool for detecting malicious events and conducting forensic analysis. Although used extensively on general-purpose systems, auditing frameworks have not been designed with consideration for the unique constraints and properties of Real-Time Systems (RTS). System auditing could provide tremendous benefits for security-critical RTS. However, a naive deployment of auditing on RTS could violate the temporal requirements of the system while also rendering auditing incomplete and ineffectual. To ensure effective auditing that meets the computational needs of recording complete audit information while adhering to the temporal requirements of the RTS, it is essential to carefully integrate auditing into the real-time (RT) schedule.This work adapts the Linux Audit framework for use in RT Linux by leveraging the common properties of such systems, such as special purpose and predictability. Ellipsis, an efficient system for auditing RTS, is devised that learns the expected benign behaviors of the system and generates succinct descriptions of the expected activity. Evaluations using varied RT applications show that Ellipsis reduces the volume of audit records generated during benign activity by up to 97.55% while recording detailed logs for suspicious activities. Empirical analyses establish that the auditing infrastructure adheres to the properties of predictability and isolation that are important to RTS. Furthermore, the schedulability of RT tasksets under audit is comprehensively analyzed to enable the safe integration of auditing in RT task schedules. © 2023 held by the owner/author(s). Publication rights licensed to ACM.",cyber-physical systems; model-based reduction; Security auditing,Cyber Physical System; Cybersecurity; Embedded systems; Interactive computer systems; Linux; % reductions; Cybe-physical systems; Cyber-physical systems; Forensic analysis; General-purpose systems; Model-based OPC; Model-based reduction; Property; Real - Time system; Security auditing; Real time systems
TLS-MHSA: An Efficient Detection Model for Encrypted Malicious Traffic based on Multi-Head Self-Attention Mechanism,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179127844&doi=10.1145%2f3613960&partnerID=40&md5=b03d0625ddf959c3005c8d3d8545583e,"In recent years, the use of TLS (Transport Layer Security) protocol to protect communication information has become increasingly popular as users are more aware of network security. However, hackers have also exploited the salient features of the TLS protocol to carry out covert malicious attacks, which threaten the security of network space. Currently, the commonly used traffic detection methods are not always reliable when applied to the problem of encrypted malicious traffic detection due to their limitations. The most significant problem is that these methods do not focus on the key features of encrypted traffic. To address this problem, this study proposes an efficient detection model for encrypted malicious traffic based on transport layer security protocol and a multi-head self-attention mechanism called TLS-MHSA. Firstly, we extract the features of TLS traffic during pre-processing and perform traffic statistics to filter redundant features. Then, we use a multi-head self-attention mechanism to focus on learning key features as well as generate the most important combined features to construct the detection model, thereby detecting the encrypted malicious traffic. Finally, we use a public dataset to verify the effectiveness and efficiency of the TLS-MHSA model, and the experimental results show that the proposed TLS-MHSA model has high precision, recall, F1-measure, AUC-ROC as well as higher stability than seven state-of-the-art detection models.  © 2023 held by the owner/author(s). Publication rights licensed to ACM.",deep learning; encrypted traffic; Intrusion detection; multi-head self-attention,Cryptography; Deep learning; Internet protocols; Intrusion detection; Personal computing; Telecommunication traffic; Attention mechanisms; Deep learning; Detection models; Efficient detection; Encrypted traffic; Intrusion-Detection; Malicious traffic; Multi-head self-attention; Transport layer security; Transport layer security protocols; Network security
Lightbox: Sensor Attack Detection for Photoelectric Sensors via Spectrum Fingerprinting,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179126089&doi=10.1145%2f3615867&partnerID=40&md5=f1ef88ad38f6568d9ece2b2b66bdbef5,"Photoelectric sensors are utilized in a range of safety-critical applications, such as medical devices and autonomous vehicles. However, the public exposure of the input channel of a photoelectric sensor makes it vulnerable to malicious inputs. Several studies have suggested possible attacks on photoelectric sensors by injecting malicious signals. While a few defense techniques have been proposed against such attacks, they could be either bypassed or used for limited purposes.In this study, we propose Lightbox, a novel defense system to detect sensor attacks on photoelectric sensors based on signal fingerprinting. Lightbox uses the spectrum of the received light as a feature to distinguish the attacker's malicious signals from the authentic signal, which is a signal from the sensor's light source. We evaluated Lightbox against (1) a saturation attacker, (2) a simple spoofing attacker, and (3) a sophisticated attacker who is aware of Lightbox and can combine multiple light sources to mimic the authentic light source. Lightbox achieved the overall accuracy over 99% for the saturation attacker and simple spoofing attacker, and robustness against a sophisticated attacker. We also evaluated Lightbox considering various environments such as transmission medium, background noise, and input waveform. Finally, we demonstrate the practicality of Lightbox with experiments using a single-board computer after further reducing the training time. © 2023 held by the owner/author(s). Publication rights licensed to ACM.",neural networks; Photoelectric sensors; signal fingerprinting,Network security; Palmprint recognition; Photoelectricity; Safety engineering; Attack detection; Autonomous Vehicles; Lightbox; Medical Devices; Neural-networks; Photoelectric sensors; Safety critical applications; Signal fingerprinting; Simple++; Spectra's; Light sources
Fraud Detection under Siege: Practical Poisoning Attacks and Defense Strategies,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180149640&doi=10.1145%2f3613244&partnerID=40&md5=1ae22121f0666e642880558fdf3ebf82,"Machine learning (ML) models are vulnerable to adversarial machine learning (AML) attacks. Unlike other contexts, the fraud detection domain is characterized by inherent challenges that make conventional approaches hardly applicable. In this article, we extend the application of AML techniques to the fraud detection task by studying poisoning attacks and their possible countermeasures. First, we present a novel approach for performing poisoning attacks that overcomes the fraud detection domain-specific constraints. It generates fraudulent candidate transactions and tests them against a machine learning-based Oracle, which simulates the target fraud detection system aiming at evading it. Misclassified fraudulent candidate transactions are then integrated into the target detection system's training set, poisoning its model and shifting its decision boundary. Second, we propose a novel approach that extends the adversarial training technique to mitigate AML attacks: During the training phase of the detection system, we generate artificial frauds by modifying random original legitimate transactions; then, we include them in the training set with the correct label. By doing so, we instruct our model to recognize evasive transactions before an attack occurs. Using two real bank datasets, we evaluate the security of several state-of-the-art fraud detection systems by deploying our poisoning attack with different degrees of attacker's knowledge and attacking strategies. The experimental results show that our attack works even when the attacker has minimal knowledge of the target system. Then, we demonstrate that the proposed countermeasure can mitigate adversarial attacks by reducing the stolen amount of money up to 100%.  © 2023 held by the owner/author(s). Publication rights licensed to ACM.",Adversarial machine learning; adversarial training; fraud detection systems; poisoning attacks,Crime; Adversarial machine learning; Adversarial training; Attack strategies; Defense strategy; Detection system; Fraud detection; Fraud detection system; Machine-learning; Poisoning attacks; Training sets; Machine learning
B3: Backdoor Attacks against Black-box Machine Learning Models,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174570905&doi=10.1145%2f3605212&partnerID=40&md5=f4ca0d7cfcb4e521e497cdbf61a59852,"Backdoor attacks aim to inject backdoors to victim machine learning models during training time, such that the backdoored model maintains the prediction power of the original model towards clean inputs and misbehaves towards backdoored inputs with the trigger. The reason for backdoor attacks is that resource-limited users usually download sophisticated models from model zoos or query the models from MLaaS rather than training a model from scratch, thus a malicious third party has a chance to provide a backdoored model. In general, the more precious the model provided (i.e., models trained on rare datasets), the more popular it is with users.In this article, from a malicious model provider perspective, we propose a black-box backdoor attack, named B3, where neither the rare victim model (including the model architecture, parameters, and hyperparameters) nor the training data is available to the adversary. To facilitate backdoor attacks in the black-box scenario, we design a cost-effective model extraction method that leverages a carefully constructed query dataset to steal the functionality of the victim model with a limited budget. As the trigger is key to successful backdoor attacks, we develop a novel trigger generation algorithm that intensifies the bond between the trigger and the targeted misclassification label through the neuron with the highest impact on the targeted label. Extensive experiments have been conducted on various simulated deep learning models and the commercial API of Alibaba Cloud Compute Service. We demonstrate that B3 has a high attack success rate and maintains high prediction accuracy for benign inputs. It is also shown that B3 is robust against state-of-the-art defense strategies against backdoor attacks, such as model pruning and NC.  © 2023 held by the owner/author(s). Publication rights licensed to ACM.",Backdoor attacks; black-box; machine learning models; model extraction attacks,Budget control; Cost effectiveness; Extraction; Learning systems; Query processing; Backdoor attack; Backdoors; Black boxes; Machine learning models; Model extraction; Model extraction attack; Original model; Power; Third parties; Training time; Deep learning
Mechanized Proofs of Adversarial Complexity and Application to Universal Composability,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170691629&doi=10.1145%2f3589962&partnerID=40&md5=e3a9f734f2d30d46357772265eed173a,"In this work, we enhance the EasyCrypt proof assistant to reason about the computational complexity of adversaries. The key technical tool is a Hoare logic for reasoning about computational complexity (execution time and oracle calls) of adversarial computations. Our Hoare logic is built on top of the module system used by EasyCrypt for modeling adversaries. We prove that our logic is sound w.r.t. the semantics of EasyCrypt programs - we also provide full semantics for the EasyCrypt module system, which was lacking previously. We showcase (for the first time in EasyCrypt and in other computer-aided cryptographic tools) how our approach can express precise relationships between the probability of adversarial success and their execution time. In particular, we can quantify existentially over adversaries in a complexity class and express general composition statements in simulation-based frameworks. Moreover, such statements can be composed to derive standard concrete security bounds for cryptographic constructions whose security is proved in a modular way. As a main benefit of our approach, we revisit security proofs of some well-known cryptographic constructions and present a new formalization of universal composability.  Copyright © 2023 held by the owner/author(s).",complexity analysis; formal methods; interactive proof system; Verification of cryptographic primitives,Computer circuits; Cryptography; Formal verification; Semantics; Complexity analysis; Cryptographic primitives; CryptoGraphics; Hoare Logic; Interactive proof system; Mechanized proofs; Module systems; Proof assistant; Universal composability; Verification of cryptographic primitive; Computational complexity
Defending Against Membership Inference Attacks on Beacon Services,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170639749&doi=10.1145%2f3603627&partnerID=40&md5=5b48ced8d90d425a606cb9fc43a6a56f,"Large genomic datasets are created through numerous activities, including recreational genealogical investigations, biomedical research, and clinical care. At the same time, genomic data has become valuable for reuse beyond their initial point of collection, but privacy concerns often hinder access. Beacon services have emerged to broaden accessibility to such data. These services enable users to query for the presence of a particular minor allele in a dataset, and information helps care providers determine if genomic variation is spurious or has some known clinical indication. However, various studies have shown that this process can leak information regarding if individuals are members of the underlying dataset. There are various approaches to mitigate this vulnerability, but they are limited in that they (1) typically rely on heuristics to add noise to the Beacon responses; (2) offer probabilistic privacy guarantees only, neglecting data utility; and (3) assume a batch setting where all queries arrive at once. In this article, we present a novel algorithmic framework to ensure privacy in a Beacon service setting with a minimal number of query response flips. We represent this problem as one of combinatorial optimization in both the batch setting and the online setting (where queries arrive sequentially). We introduce principled algorithms with both privacy and, in some cases, worst-case utility guarantees. Moreover, through extensive experiments, we show that the proposed approaches significantly outperform the state of the art in terms of privacy and utility, using a dataset consisting of 800 individuals and 1.3 million single nucleotide variants.  © 2023 Copyright held by the owner/author(s).",access control; Beacon services; genomic databases; privacy protection,Access control; Clinical research; Combinatorial optimization; Database systems; Genes; Large dataset; Beacon service; Biomedical research; Clinical care; Genomic data; Genomics; Genomics database; Inference attacks; Initial point; Privacy protection; Reuse; Genome
Beyond Gradients: Exploiting Adversarial Priors in Model Inversion Attacks,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170643371&doi=10.1145%2f3592800&partnerID=40&md5=b5b2c724e37f29f1e57428ad4a5b471a,"Collaborative machine learning settings such as federated learning can be susceptible to adversarial interference and attacks. One class of such attacks is termed model inversion attacks, characterised by the adversary reverse-engineering the model into disclosing the training data. Previous implementations of this attack typically only rely on the shared data representations, ignoring the adversarial priors, or require that specific layers are present in the target model, reducing the potential attack surface. In this work, we propose a novel context-agnostic model inversion framework that builds on the foundations of gradient-based inversion attacks, but additionally exploits the features and the style of the data controlled by an in-the-network adversary. Our technique outperforms existing gradient-based approaches both qualitatively and quantitatively across all training settings, showing particular effectiveness against the collaborative medical imaging tasks. Finally, we demonstrate that our method achieves significant success on two downstream tasks: sensitive feature inference and facial recognition spoofing.  Copyright © 2023 held by the owner/author(s).",collaborative image analysis; Federated learning; model inversion,Face recognition; Learning systems; Reverse engineering; Collaborative image analyse; Data representations; Federated learning; Gradient based; Image-analysis; Learning settings; Machine-learning; Model inversion; Shared data; Training data; Medical imaging
Privacy-preserving Resilient Consensus for Multi-agent Systems in a General Topology Structure,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170643581&doi=10.1145%2f3587933&partnerID=40&md5=9f619b1336bef3fa8d4c36cde484c6df,"Recent advances of consensus control have made it significant in multi-agent systems such as in distributed machine learning, distributed multi-vehicle cooperative systems. However, during its application it is crucial to achieve resilience and privacy; specifically, when there are adversary/faulty nodes in a general topology structure, normal agents can also reach consensus while keeping their actual states unobserved.In this article, we modify the state-of-the-art Q-consensus algorithm by introducing predefined noise or well-designed cryptography to guarantee the privacy of each agent state. In the former case, we add specified noise on agent state before it is transmitted to the neighbors and then gradually decrease the value of noise so the exact agent state cannot be evaluated. In the latter one, the Paillier cryptosystem is applied for reconstructing reward function in two consecutive interactions between each pair of neighboring agents. Therefore, multi-agent privacy-preserving resilient consensus (MAPPRC) can be achieved in a general topology structure. Moreover, in the modified version, we reconstruct reward function and credibility function so both convergence rate and stability of the system are improved.The simulation results indicate the algorithms' tolerance for constant and/or persistent faulty agents as well as their protection of privacy. Compared with the previous studies that consider both resilience and privacy-preserving requirements, the proposed algorithms in this article greatly relax the topological conditions. At the end of the article, to verify the effectiveness of the proposed algorithms, we conduct two sets of experiments, i.e., a smart-car hardware platform consisting of four vehicles and a distributed machine learning platform containing 10 workers and a server.  © 2023 Copyright held by the owner/author(s).",multi-agent systems; privacy preserving; Q-consensus; Resilient consensus,Machine learning; Privacy-preserving techniques; System stability; Topology; Consensus control; Cooperative systems; Distributed machine learning; General topology; Multi-vehicles; Privacy preserving; Q-consensus; Resilient consensus; Reward function; Topology structure; Multi agent systems
End-to-End Security for Distributed Event-driven Enclave Applications on Heterogeneous TEEs,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170651773&doi=10.1145%2f3592607&partnerID=40&md5=710bc7ba5349657d097c68825e282eb2,"This article presents an approach to provide strong assurance of the secure execution of distributed event-driven applications on shared infrastructures, while relying on a small Trusted Computing Base. We build upon and extend security primitives provided by Trusted Execution Environments (TEEs) to guarantee authenticity and integrity properties of applications, and to secure control of input and output devices. More specifically, we guarantee that if an output is produced by the application, it was allowed to be produced by the application's source code based on an authentic trace of inputs. We present an integrated open-source framework to develop, deploy, and use such applications across heterogeneous TEEs. Beyond authenticity and integrity, our framework optionally provides confidentiality and a notion of availability, and facilitates software development at a high level of abstraction over the platform-specific TEE layer. We support event-driven programming to develop distributed enclave applications in Rust and C for heterogeneous TEE, including Intel SGX, ARM TrustZone, and Sancus. In this article we discuss the workings of our approach, the extensions we made to the Sancus processor, and the integration of our development model with commercial TEEs. Our evaluation of security and performance aspects show that TEEs, together with our programming model, form a basis for powerful security architectures for dependable systems in domains such as Industrial Control Systems and the Internet of Things, illustrating our framework's unique suitability for a broad range of use cases which combine cloud processing, mobile and edge devices, and lightweight sensing and actuation.  Copyright © 2023 held by the owner/author(s).",distributed systems security; IoT security; Software Development Kit; Trusted Execution,Application programs; Authentication; C (programming language); Distributed computer systems; Network security; Open source software; Open systems; Software design; Trusted computing; Distributed events; Distributed systems security; End-to-end security; Event driven applications; Event-driven; IoT security; Secure execution; Software development kit; Trusted execution; Trusted execution environments; Internet of things
Privacy-preserving Decentralized Federated Learning over Time-varying Communication Graph,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170650153&doi=10.1145%2f3591354&partnerID=40&md5=cc8697fce9c65d2cf5128a61aabd728f,"Establishing how a set of learners can provide privacy-preserving federated learning in a fully decentralized (peer-to-peer, no coordinator) manner is an open problem. We propose the first privacy-preserving consensus-based algorithm for the distributed learners to achieve decentralized global model aggregation in an environment of high mobility, where participating learners and the communication graph between them may vary during the learning process. In particular, whenever the communication graph changes, the Metropolis-Hastings method [69] is applied to update the weighted adjacency matrix based on the current communication topology. In addition, the Shamir's secret sharing (SSS) scheme [61] is integrated to facilitate privacy in reaching consensus of the global model. The article establishes the correctness and privacy properties of the proposed algorithm. The computational efficiency is evaluated by a simulation built on a federated learning framework with a real-world dataset.  Copyright © 2023 held by the owner/author(s).",decentralized aggregation; Federated learning; mobility; privacy,Learning systems; Privacy-preserving techniques; Topology; Communication graphs; Decentralised; Decentralized aggregations; Federated learning; Global models; Mobility; Peer to peer; Privacy; Privacy preserving; Time varying; Computational efficiency
Euler: Detecting Network Lateral Movement via Scalable Temporal Link Prediction,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165542098&doi=10.1145%2f3588771&partnerID=40&md5=61060a6b7eb299f029c0721bf38b211d,"Lateral movement is a key stage of system compromise used by advanced persistent threats. Detecting it is no simple task. When network host logs are abstracted into discrete temporal graphs, the problem can be reframed as anomalous edge detection in an evolving network. Research in modern deep graph learning techniques has produced many creative and complicated models for this task. However, as is the case in many machine learning fields, the generality of models is of paramount importance for accuracy and scalability during training and inference. In this article, we propose a formalized approach to this problem with a framework we call Euler. It consists of a model-agnostic graph neural network stacked upon a model-agnostic sequence encoding layer such as a recurrent neural network. Models built according to the Euler framework can easily distribute their graph convolutional layers across multiple machines for large performance improvements. Additionally, we demonstrate that Euler-based models are as good, or better, than every state-of-the-art approach to anomalous link detection and prediction that we tested. As anomaly-based intrusion detection systems, our models efficiently identified anomalous connections between entities with high precision and outperformed all other unsupervised techniques for anomalous lateral movement detection. Additionally, we show that as a piece of a larger anomaly detection pipeline, Euler models perform well enough for use in real-world systems. With more advanced, yet still lightweight, alerting mechanisms ingesting the embeddings produced by Euler models, precision is boosted from 0.243, to 0.986 on real-world network traffic.  © 2023 ///////Copyright held by the owner/author(s). Publication rights licensed to ACM.",graph neural network; Lateral movement detection; temporal graph,Convolutional neural networks; Graph neural networks; Intrusion detection; Learning systems; Motion estimation; Multilayer neural networks; Recurrent neural networks; Euler's model; Evolving networks; Graph neural networks; Lateral movement; Lateral movement detection; Link prediction; Movement detection; Network hosts; Simple++; Temporal graphs; Anomaly detection
The Multi-User Constrained Pseudorandom Function Security of Generalized GGM Trees for MPC and Hierarchical Wallets,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170649037&doi=10.1145%2f3592608&partnerID=40&md5=bc83efe1199d9c8f16527a9bd20e6eec,"Multi-user (mu) security considers large-scale attackers that, given access to a number of cryptosystem instances, attempt to compromise at least one of them. We initiate the study of mu security of the so-called GGM tree that stems from the pseudorandom generator to pseudorandom function transformation of Goldreich, Goldwasser, and Micali, with a goal to provide references for its recently popularized use in applied cryptography. We propose a generalized model for GGM trees and analyze its mu prefix-constrained pseudorandom function security in the random oracle model. Our model allows to derive concrete bounds and improvements for various protocols, and we showcase on the Bitcoin-Improvement-Proposal standard Bip32 hierarchical wallets and function secret sharing protocols. In both scenarios, we propose improvements with better performance and concrete security bounds at the same time. Compared with the state-of-the-art designs, our SHACAL3- and Keccak-p-based Bip32 variants reduce the communication cost of MPC-based implementations by 73.3% to 93.8%, whereas our AES-based function secret sharing substantially improves mu security while reducing computations by 50%.  Copyright © 2023 held by the owner/author(s).",indistinguishability; Provable security,Applied cryptography; Function transformation; Generalized models; Indistinguishability; Large-scales; Multiusers; Provable security; Pseudo-random functions; Pseudorandom generators; Random Oracle model; Cryptography
A Vulnerability Assessment Framework for Privacy-preserving Record Linkage,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170679780&doi=10.1145%2f3589641&partnerID=40&md5=6436bcf78f5ff998f323f7b97e4928f4,"The linkage of records to identify common entities across multiple data sources has gained increasing interest over the last few decades. In the absence of unique entity identifiers, quasi-identifying attributes such as personal names and addresses are generally used to link records. Due to privacy concerns that arise when such sensitive information is used, privacy-preserving record linkage (PPRL) methods have been proposed to link records without revealing any sensitive or confidential information about these records. Popular PPRL methods such as Bloom filter encoding, however, are known to be susceptible to various privacy attacks. Therefore, a systematic analysis of the privacy risks associated with sensitive databases as well as PPRL methods used in linkage projects is of great importance. In this article we present a novel framework to assess the vulnerabilities of sensitive databases and existing PPRL encoding methods. We discuss five types of vulnerabilities: frequency, length, co-occurrence, similarity, and similarity neighborhood, of both plaintext and encoded values that an adversary can exploit in order to reidentify sensitive plaintext values from encoded data. In an experimental evaluation we assess the vulnerabilities of two databases using five existing PPRL encoding methods. This evaluation shows that our proposed framework can be used in real-world linkage applications to assess the vulnerabilities associated with sensitive databases to be linked, as well as with PPRL encoding methods.  Copyright © 2023 held by the owner/author(s).",Bloom filters; Disclosure risk analysis; multiple match-keys; statistical linkage keys; tabulation hashing; two-step hashing,Data structures; Database systems; Encoding (symbols); Petroleum reservoir evaluation; Privacy-preserving techniques; Risk assessment; Signal encoding; Bloom filters; Disclosure risk; Disclosure risk analyse; Encoding methods; Linkage-encoding; Multiple match-key; Privacy preserving record linkages; Statistical linkage key; Tabulation hashing; Two-step hashing; Risk analysis
Resilience-by-design in Adaptive Multi-agent Traffic Control Systems,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170640046&doi=10.1145%2f3592799&partnerID=40&md5=3e09a3358822fedc7f2526bed252cf60,"Connected and Autonomous Vehicles (CAVs) with their evolving data gathering capabilities will play a significant role in road safety and efficiency applications supported by Intelligent Transport Systems (ITSs), such as Traffic Signal Control (TSC) for urban traffic congestion management. However, their involvement will expand the space of security vulnerabilities and create larger threat vectors. In this article, we perform the first detailed security analysis and implementation of a new cyber-physical attack category carried out by the network of CAVs against Adaptive Multi-Agent Traffic Signal Control (AMATSC), namely, coordinated Sybil attacks, where vehicles with forged or fake identities try to alter the data collected by the AMATSC algorithms to sabotage their decisions. Consequently, a novel, game-theoretic mitigation approach at the application layer is proposed to minimize the impact of such sophisticated data corruption attacks. The devised minimax game model enables the AMATSC algorithm to generate optimal decisions under a suspected attack, improving its resilience. Extensive experimentation is performed on a traffic dataset provided by the city of Montréal under real-world intersection settings to evaluate the attack impact. Our results improved time loss on attacked intersections by approximately 48.9%. Substantial benefits can be gained from the mitigation, yielding more robust adaptive control of traffic across networked intersections.  Copyright © 2023 held by the owner/author(s).",adaptive multi-agent traffic signal control; attack mitigation; connected and autonomous vehicles; coordinated Sybil attack; data corruption attacks; game theory; Intelligent transportation systems; resilience-by-design,Adaptive control systems; Autonomous vehicles; Computer crime; Crime; Cybersecurity; Game theory; Information management; Motor transportation; Multi agent systems; Traffic congestion; Urban transportation; Vector spaces; Adaptive Multi-Agent; Adaptive multi-agent traffic signal control; Attack mitigation; Autonomous Vehicles; Connected and autonomous vehicle; Coordinated sybil attack; Data corruption; Data corruption attack; Intelligent transportation systems; Resilience-by-design; Sybil attack; Traffic signal control; Intelligent systems
Costs and Benefits of Authentication Advice,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170638814&doi=10.1145%2f3588031&partnerID=40&md5=61feebcf2235a903f3861ef1e1bb1c04,"Authentication security advice is given with the goal of guiding users and organisations towards secure actions and practices. In this article, a taxonomy of 270 pieces of authentication advice is created, and a survey is conducted to gather information on the costs associated with following or enforcing the advice. Our findings indicate that security advice can be ambiguous and contradictory, with 41% of the advice collected being contradicted by another source. Additionally, users reported high levels of frustration with the advice and identified high usability costs. The study also found that end-users disagreed with each other 71% of the time about whether a piece of advice was valuable or not. We define a formal approach to identifying security benefits of advice. Our research suggests that cost-benefit analysis is essential in understanding the value of enforcing security policies. Furthermore, we find that organisation investment in security seems to have better payoffs than mechanisms with high costs to users.  © 2023 Copyright held by the owner/author(s).",costs versus benefits; cyber security; password advice; Passwords; security policies,Cost benefit analysis; Cybersecurity; Security systems; Cost and benefits; Cost versus benefit; Cost-benefits analysis; Cyber security; End-users; Formal approach; Password; Password advice; Security advices; Security policy; Authentication
Privacy Policies across the Ages: Content of Privacy Policies 1996-2021,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163573414&doi=10.1145%2f3590152&partnerID=40&md5=0d713f125300d8c9c3c91b0d0295e158,"It is well known that most users do not read privacy policies but almost always tick the box to agree with them. While the length and readability of privacy policies have been well studied and many approaches for policy analysis based on natural language processing have been proposed, existing studies are limited in their depth and scope, often focusing on a small number of data practices at single point in time. In this article, we fill this gap by analyzing the 25-year history of privacy policies using machine learning and natural language processing and presenting a comprehensive analysis of policy contents. Specifically, we collect a large-scale longitudinal corpus of privacy policies from 1996 to 2021 and analyze their content in terms of the data practices they describe, the rights they grant to users, and the rights they reserve for their organizations. We pay particular attention to changes in response to recent privacy regulations such as the GDPR and CCPA. We observe some positive changes, such as reductions in data collection post-GDPR, but also a range of concerning data practices, such as widespread implicit data collection for which users have no meaningful choices or access rights. Our work is an important step toward making privacy policies machine readable on the user side, which would help users match their privacy preferences against the policies offered by web services.  Copyright © 2023 held by the owner/author(s).",BERT; longitudinal study; machine learning; natural language processing; neural networks; Privacy policy,Data acquisition; Learning algorithms; Natural language processing systems; Neural networks; Web services; BERT; Data collection; Data practices; Language processing; Longitudinal study; Machine-learning; Natural language processing; Natural languages; Neural-networks; Privacy policies; Machine learning
PrivExtractor: Toward Redressing the Imbalance of Understanding between Virtual Assistant Users and Vendors,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170651162&doi=10.1145%2f3588770&partnerID=40&md5=9e9021f28ef9aa5a277a445cbb259469,"The use of voice-controlled virtual assistants (VAs) is significant, and user numbers increase every year. Extensive use of VAs has provided the large, cash-rich technology companies who sell them with another way of consuming users' data, providing a lucrative revenue stream. Whilst these companies are legally obliged to treat users' information ""fairly and responsibly,""artificial intelligence techniques used to process data have become incredibly sophisticated, leading to users' concerns that a lack of clarity is making it hard to understand the nature and scope of data collection and use.There has been little work undertaken on a self-contained user awareness tool targeting VAs. PrivExtractor, a novel web-based awareness dashboard for VA users, intends to redress this imbalance of understanding between the data ""processors""and the user. It aims to achieve this using the four largest VA vendors as a case study and providing a comparison function that examines the four companies' privacy practices and their compliance with data protection law.As a result of this research, we conclude that the companies studied are largely compliant with the law, as expected. However, the user remains disadvantaged due to the ineffectiveness of current data regulation that does not oblige the companies to fully and transparently disclose how and when they use, share, or profit from the data. Furthermore, the software tool developed during the research is, we believe, the first that is capable of a comparative analysis of VA privacy with a visual demonstration to increase ease of understanding for the user.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",privacy; Security; voice assistants,Privacy; Revenue streams; Security; Technology companies; User data; User information; User number; Virtual assistants; Voice assistant; Voice-controlled; Security of data
SoK: Human-centered Phishing Susceptibility,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168796893&doi=10.1145%2f3575797&partnerID=40&md5=1bdc8f9f6c2d303c3b6de27cd10befc2,"Phishing is recognized as a serious threat to organizations and individuals. While there have been significant technical advances in blocking phishing attacks, end-users remain the last line of defence after phishing emails reach their email inboxes. Most of the existing literature on this subject has focused on the technical aspects related to phishing. The factors that cause humans to be susceptible to phishing attacks are still not well-understood. To fill this gap, we reviewed the available literature and systematically categorized the phishing susceptibility variables studied. We classify variables based on their temporal scope, which led us to propose a three-stage Phishing Susceptibility Model (PSM) for explaining how humans are vulnerable to phishing attacks. This model reveals several research gaps that need to be addressed to understand and improve protection against phishing susceptibility. Our review also systematizes existing studies by their sample size and generalizability and further suggests a practical impact assessment of the value of studying variables: Some more easily lead to improvements than others. We believe that this article can provide guidelines for future phishing susceptibility research to improve experiment design and the quality of findings.  © 2023 Association for Computing Machinery.",Additional Key Words and PhrasesPhishing susceptibility; human-centered; information security,Computer crime; Security of data; Additional key word and phrasesphishing susceptibility; Blockings; End-users; Human-centered; Inboxes; Key words; Phishing; Phishing attacks; Technical advances; Technical aspects; Electronic mail
Revisiting the Security of Biometric Authentication Systems Against Statistical Attacks,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154588806&doi=10.1145%2f3571743&partnerID=40&md5=74a25bfb3cbddcedc36a0064d7510dfb,"The uniqueness of behavioral biometrics (e.g., voice or keystroke patterns) has been challenged by recent works. Statistical attacks have been proposed that infer general population statistics and target behavioral biometrics against a particular victim. We show that despite their success, these approaches require several attempts for successful attacks against different biometrics due to the different nature of overlap in users' behavior for these biometrics. Furthermore, no mechanism has been proposed to date that detects statistical attacks. In this work, we propose a new hypervolumes-based statistical attack and show that unlike existing methods, it (1) is successful against a variety of biometrics, (2) is successful against more users, and (3) requires fewest attempts for successful attacks. More specifically, across five diverse biometrics, for the first attempt, on average our attack is 18 percentage points more successful than the second best (37% vs. 19%). Similarly, for the fifth attack attempt, on average our attack is 18 percentage points more successful than the second best (67% vs. 49%). We propose and evaluate a mechanism that can detect the more devastating statistical attacks. False rejects in biometric systems are common, and by distinguishing statistical attacks from false rejects, our defense improves usability and security. The evaluation of the proposed detection mechanism shows its ability to detect on average 94% of the tested statistical attacks with an average probability of 3% to detect false rejects as a statistical attack. Given the serious threat posed by statistical attacks to biometrics that are used today (e.g., voice), our work highlights the need for defending against these attacks. © 2023 Association for Computing Machinery.",behavioral biometrics; gait authentication; keystroke authentication; Statistical attacks; voice authentication,Authentication; Population statistics; Behavioural Biometric; Biometric authentication system; Gait authentication; General population; Keystroke authentication; Keystroke patterns; Percentage points; Statistical attacks; User behaviors; Voice authentication; Biometrics
Binsec/Rel: Symbolic Binary Analyzer for Security with Applications to Constant-Time and Secret-Erasure,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154603648&doi=10.1145%2f3563037&partnerID=40&md5=8e17493215a22621d722af5ad7ba2790,"This article tackles the problem of designing efficient binary-level verification for a subset of information flow properties encompassing constant-time and secret-erasure. These properties are crucial for cryptographic implementations but are generally not preserved by compilers. Our proposal builds on relational symbolic execution enhanced with new optimizations dedicated to information flow and binary-level analysis, yielding a dramatic improvement over prior work based on symbolic execution. We implement a prototype, Binsec/Rel, for bug-finding and bounded-verification of constant-time and secret-erasure and perform extensive experiments on a set of 338 cryptographic implementations, demonstrating the benefits of our approach. Using Binsec/Rel, we also automate two prior manual studies on preservation of constant-time and secret-erasure by compilers for a total of 4,148 and 1,156 binaries, respectively. Interestingly, our analysis highlights incorrect usages of volatile data pointer for secret-erasure and shows that scrubbing mechanisms based on volatile function pointers can introduce additional register spilling that might break secret-erasure. We also discovered that gcc -O0 and backend passes of clang introduce violations of constant-time in implementations that were previously deemed secure by a state-of-the-art constant-time verification tool operating at LLVM level, showing the importance of reasoning at binary level. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",binary analysis; Constant-time; information-flow analysis; secret-erasure; symbolic execution,Cryptography; Program compilers; Binary analysis; Constant time; Cryptographic implementation; Flow properties; Information flow analysis; Information flows; Optimisations; Property; Secret-erasure; Symbolic execution; Model checking
Stateful Protocol Composition in Isabelle/HOL,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168796643&doi=10.1145%2f3577020&partnerID=40&md5=9996d5897f4d786f3de5ede23f072c7e,"Communication networks like the Internet form a large distributed system where a huge number of components run in parallel, such as security protocols and distributed web applications. For what concerns security, it is obviously infeasible to verify them all at once as one monolithic entity; rather, one has to verify individual components in isolation. While many typical components like TLS have been studied intensively, there exists much less research on analyzing and ensuring the security of the composition of security protocols. This is a problem since the composition of systems that are secure in isolation can easily be insecure. The main goal of compositionality is thus a theorem of the form: given a set of components that are already proved secure in isolation and that satisfy a number of easy-to-check conditions, then also their parallel composition is secure. Said conditions should of course also be realistic in practice, or better yet, already be satisfied for many existing components. Another benefit of compositionality is that when one would like to exchange a component with another one, all that is needed is the proof that the new component is secure in isolation and satisfies the composition conditions - without having to re-prove anything about the other components. This article has three contributions over previous work in parallel compositionality. First, we extend the compositionality paradigm to stateful systems: while previous approaches work only for simple protocols that only have a local session state, our result supports participants who maintain long-term databases that can be sharedamong several protocols. This includes a paradigm for declassification of shared secrets. This result is in fact so general that it also covers many forms of sequential composition as a special case of stateful parallel composition. Second, our compositionality result is formalized and proved in Isabelle/HOL, providing a strong correctness guarantee of our proofs. This also means that one can prove, without gaps, the security of an entire system in Isabelle/HOL, namely the security of components in isolation and the composition conditions, and thus derive the security of the entire system as an Isabelle theorem. For the components one can also make use of our tool PSPSP that can perform automatic proofs for many stateful protocols. Third, for the compositionality conditions we have also implemented an automated check procedure in Isabelle.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesProtocol composition; Isabelle/HOL; stateful security protocol,Network protocols; Additional key word and phrasesprotocol composition; Compositionality; Condition; Entire system; Isabelle; Isabelle/HOL; Key words; Parallel composition; Security protocols; Stateful security protocol; Network security
VulANalyzeR: Explainable Binary Vulnerability Detection with Multi-task Learning and Attentional Graph Convolution,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160608967&doi=10.1145%2f3585386&partnerID=40&md5=0fbc06ac96c379b74b84d28b995de787,"Software vulnerabilities have been posing tremendous reliability threats to the general public as well as critical infrastructures, and there have been many studies aiming to detect and mitigate software defects at the binary level. Most of the standard practices leverage both static and dynamic analysis, which have several drawbacks like heavy manual workload and high complexity. Existing deep learning-based solutions not only suffer to capture the complex relationships among different variables from raw binary code but also lack the explainability required for humans to verify, evaluate, and patch the detected bugs. We propose VulANalyzeR, a deep learning-based model, for automated binary vulnerability detection, Common Weakness Enumeration-type classification, and root cause analysis to enhance safety and security. VulANalyzeR features sequential and topological learning through recurrent units and graph convolution to simulate how a program is executed. The attention mechanism is integrated throughout the model, which shows how different instructions and the corresponding states contribute to the final classification. It also classifies the specific vulnerability type through multi-task learning as this not only provides further explanation but also allows faster patching for zero-day vulnerabilities. We show that VulANalyzeR achieves better performance for vulnerability detection over the state-of-the-art baselines. Additionally, a Common Vulnerability Exposure dataset is used to evaluate real complex vulnerabilities. We conduct case studies to show that VulANalyzeR is able to accurately identify the instructions and basic blocks that cause the vulnerability even without given any prior knowledge related to the locations during the training phase.  © 2023 Crown in Right of Canada. Publication rights licensed to ACM.",attentional GCNN; Binary vulnerability detection; explainability; multi-task deep learning,Deep learning; Learning systems; Software reliability; Topology; Zero-day attack; Attentional GCNN; Binary vulnerability detection; Explainability; General publics; Multi tasks; Multi-task deep learning; Multitask learning; Software defects; Software vulnerabilities; Vulnerability detection; Convolution
Energy Efficient and Secure Neural Network-based Disease Detection Framework for Mobile Healthcare Network,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170637330&doi=10.1145%2f3585536&partnerID=40&md5=7c3100b2d2ea8432ab0c190f09934b9a,"Adopting mobile healthcare network (MHN) services such as disease detection is fraught with concerns about the security and privacy of the entities involved and the resource restrictions at the Internet of Things (IoT) nodes. Hence, the essential requirements for disease detection services are to (i) produce accurate and fast disease detection without jeopardizing the privacy of health clouds and medical users and (ii) reduce the computational and transmission overhead (energy consumption) of the IoT devices while maintaining the privacy. For privacy preservation of widely used neural network- (NN) based disease detection, existing literature suggests either computationally heavy public key fully homomorphic encryption (FHE), or secure multiparty computation, with a large number of interactions. Hence, the existing privacy-preserving NN schemes are energy consuming and not suitable for resource-constrained IoT nodes in MHN. This work proposes a lightweight, fully homomorphic, symmetric key FHE scheme (SkFhe) to address the issues involved in implementing privacy-preserving NN. Based on SkFhe, widely used non-linear activation functions ReLU and Leaky ReLU are implemented over the encrypted domain. Furthermore, based on the proposed privacy-preserving linear transformation and non-linear activation functions, an energy-efficient, accurate, and privacy-preserving NN is proposed. The proposed scheme guarantees privacy preservation of the health cloud's NN model and medical user's data. The experimental analysis demonstrates that the proposed solution dramatically reduces the overhead in communication and computation at the user side compared to the existing schemes. Moreover, the improved energy efficiency at the user is accomplished with reduced diagnosis time without sacrificing classification accuracy.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",homomorphic encryption; Mobile healthcare network; neural networks; privacy,Chemical activation; Cost reduction; Energy efficiency; Energy utilization; Linear transformations; Network security; Neural networks; Privacy-preserving techniques; Disease detection; Energy efficient; Health clouds; Ho-momorphic encryptions; Homomorphic-encryptions; Mobile healthcare network; Network-based; Neural-networks; Privacy; Privacy preserving; Internet of things
Paralinguistic Privacy Protection at the Edge,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154557675&doi=10.1145%2f3570161&partnerID=40&md5=fb03e293a02c6dddb6bddb3f153c4cf0,"Voice user interfaces and digital assistants are rapidly entering our lives and becoming singular touch points spanning our devices. These always-on services capture and transmit our audio data to powerful cloud services for further processing and subsequent actions. Our voices and raw audio signals collected through these devices contain a host of sensitive paralinguistic information that is transmitted to service providers regardless of deliberate or false triggers. As our emotional patterns and sensitive attributes like our identity, gender, and well-being are easily inferred using deep acoustic models, we encounter a new generation of privacy risks by using these services. One approach to mitigate the risk of paralinguistic-based privacy breaches is to exploit a combination of cloud-based processing with privacy-preserving, on-device paralinguistic information learning and filtering before transmitting voice data.In this article we introduce EDGY, a configurable, lightweight, disentangled representation learning framework that transforms and filters high-dimensional voice data to identify and contain sensitive attributes at the edge prior to offloading to the cloud. We evaluate EDGY's on-device performance and explore optimization techniques, including model quantization and knowledge distillation, to enable private, accurate, and efficient representation learning on resource-constrained devices. Our results show that EDGY runs in tens of milliseconds with 0.2% relative improvement in ""zero-shot""ABX score or minimal performance penalties of approximately 5.95% word error rate (WER) in learning linguistic representations from raw voice signals, using a CPU and a single-core ARM processor without specialized hardware.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Deep Learning; disentangled representation learning; Internet of Things (IoT); model optimization; privacy; speech analysis; voice synthesis; Voice user interface,Deep learning; Digital devices; Distillation; Internet of things; Learning systems; Linguistics; Privacy-preserving techniques; Sensitive data; Speech analysis; Speech processing; User interfaces; Deep learning; Disentangled representation learning; Internet of thing; Model optimization; Paralinguistic; Paralinguistic information; Privacy; Sensitive attribute; Voice data; Voice user interface; Constrained optimization
A Comparison of Systemic and Systematic Risks of Malware Encounters in Consumer and Enterprise Environments,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154559064&doi=10.1145%2f3565362&partnerID=40&md5=83a35d89c707f064bf406ff2a8bb4a84,"Malware is still a widespread problem, and it is used by malicious actors to routinely compromise the security of computer systems. Consumers typically rely on a single AV product to detect and block possible malware infections, while corporations often install multiple security products, activate several layers of defenses, and establish security policies among employees. However, if a better security posture should lower the risk of malware infections, then the actual extent to which this happens is still under debate by risk analysis experts. Moreover, the difference in risks encountered by consumers and enterprises has never been empirically studied by using real-world data.In fact, the mere use of third-party software, network services, and the interconnected nature of our society necessarily exposes both classes of users to undiversifiable risks: Independently from how careful users are and how well they manage their cyber hygiene, a portion of that risk would simply exist because of the fact of using a computer, sharing the same networks, and running the same software.In this work, we shed light on both systemic (i.e., diversifiable and dependent on the security posture) and systematic (i.e., undiversifiable and independent of the cyber hygiene) risk classes. Leveraging the telemetry data of a popular security company, we compare, in the first part of our study, the effects that different security measures have on malware encounter risks in consumer and enterprise environments. In the second part, we conduct exploratory research on systematic risk, investigate the quality of nine different indicators we were able to extract from our telemetry, and provide, for the first time, quantitative indicators of their predictive power.Our results show that even if consumers have a slightly lower encounter rate than enterprises (9.8% vs. 12.0%), the latter do considerably better when selecting machines with an increasingly higher uptime (89% vs. 53%). The two segments also diverge when we separately consider the presence of Adware and Potentially Unwanted Applications (PUA) and the generic samples detected through behavioral signatures: While consumers have an encounter rate for Adware and PUA that is 6 times higher than enterprise machines, those on average match behavioral signatures 2 times more frequently than the counterpart. We find, instead, similar trends when analyzing the age of encountered signatures, and the prevalence of different classes of traditional malware (such as Ransomware and Cryptominers). Finally, our findings show that the amount of time a host is active, the volume of files generated on the machine, the number and reputation of vendors of the installed applications, the host geographical location, and its recurrent infected state carry useful information as indicators of systematic risk of malware encounters. Activity days and hours have a higher influence in the risk of consumers, increasing the odds of encountering malware of 4.51 and 2.65 times. In addition, we measure that the volume of files generated on the host represents a reliable indicator, especially when considering Adware. We further report that the likelihood of encountering Worms and Adware is much higher (on average 8 times in consumers and enterprises) for those machines that already reported this kind of signature in the past.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",consumer malware; cyber-risk assessment; enterprise malware; systematic risk; Systemic risk,Cybersecurity; Malware; Network security; Risk analysis; Telemetering equipment; Behavioral signatures; Consumer malware; Cybe-risk assessment; Enterprise environment; Enterprise malware; Malwares; Risks assessments; Systematic risk; Systemic risks; Risk assessment
Log-related Coding Patterns to Conduct Postmortems of Attacks in Supervised Learning-based Projects,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154619454&doi=10.1145%2f3568020&partnerID=40&md5=f3f3786b9ceb53b85a87cc6b7343de8d,"Adversarial attacks against supervised learninga algorithms, which necessitates the application of logging while using supervised learning algorithms in software projects. Logging enables practitioners to conduct postmortem analysis, which can be helpful to diagnose any conducted attacks. We conduct an empirical study to identify and characterize log-related coding patterns, i.e., recurring coding patterns that can be leveraged to conduct adversarial attacks and needs to be logged. A list of log-related coding patterns can guide practitioners on what to log while using supervised learning algorithms in software projects.We apply qualitative analysis on 3,004 Python files used to implement 103 supervised learning-based software projects. We identify a list of 54 log-related coding patterns that map to six attacks related to supervised learning algorithms. Using Log Assistant to conduct Postmortems for Supervised Learning (LOPSUL), we quantify the frequency of the identified log-related coding patterns with 278 open-source software projects that use supervised learning. We observe log-related coding patterns to appear for 22% of the analyzed files, where training data forensics is the most frequently occurring category. © 2023 Association for Computing Machinery.",adversarial machine learning; Empirical study; forensics; logging,Application programs; Learning algorithms; Open source software; Open systems; Adversarial machine learning; Coding patterns; Empirical studies; Forensic; Machine-learning; Open source software projects; Postmortem analysis; Qualitative analysis; Software project; Training data; Supervised learning
Balancing Security and Privacy in Genomic Range Queries,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168794441&doi=10.1145%2f3575796&partnerID=40&md5=0e311eaae28bd8c0010680fde8160fd0,"Exciting recent advances in genome sequencing, coupled with greatly reduced storage and computation costs, make genomic testing increasingly accessible to individuals. Already today, one's digitized DNA can be easily obtained from a sequencing lab and later used to conduct numerous tests by engaging with a testing facility. Due to the inherent sensitivity of genetic material and the often-proprietary nature of genomic tests, privacy is a natural and crucial issue. While genomic privacy received a great deal of attention within and outside the research community, genomic security has not been sufficiently studied. This is surprising since the usage of fake or altered genomes can have grave consequences, such as erroneous drug prescriptions and genetic test outcomes.Unfortunately, in the genomic domain, privacy and security (as often happens) are at odds with each other. In this article, we attempt to reconcile security with privacy in genomic testing by designing a novel technique for a secure and private genomic range query protocol between a genomic testing facility and an individual user. The proposed technique ensures authenticity and completeness of user-supplied genomic material while maintaining its privacy by releasing only the minimum thereof. To confirm its broad usability, we show how to apply the proposed technique to a previously proposed genomic private substring matching protocol. Experiments show that the proposed technique offers good performance and is quite practical. Furthermore, we generalize the genomic range query problem to sparse integer sets and discuss potential use cases.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesCryptographic protocols; genomic privacy; genomic security; private substring matching; range completeness; range query,Cryptography; Gene encoding; Test facilities; Additional key word and phrasescryptographic protocol; Genomic privacy; Genomic security; Genomics; Key words; Matchings; Private substring matching; Range completeness; Range query; Sub-strings; Genome
Pareto-optimal Defenses for the Web Infrastructure: Theory and Practice,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154600948&doi=10.1145%2f3567595&partnerID=40&md5=43af5845f57b21e21c70828a7e0708f5,"The integrity of the content a user is exposed to when browsing the web relies on a plethora of non-web technologies and an infrastructure of interdependent hosts, communication technologies, and trust relations. Incidents like the Chinese Great Cannon or the MyEtherWallet attack make it painfully clear: the security of end users hinges on the security of the surrounding infrastructure: routing, DNS, content delivery, and the PKI. There are many competing, but isolated proposals to increase security, from the network up to the application layer. So far, researchers have focused on analyzing attacks and defenses on specific layers. We still lack an evaluation of how, given the status quo of the web, these proposals can be combined, how effective they are, and at what cost the increase of security comes. In this work, we propose a graph-based analysis based on Stackelberg planning that considers a rich attacker model and a multitude of proposals from IPsec to DNSSEC and SRI. Our threat model considers the security of billions of users against attackers ranging from small hacker groups to nation-state actors. Analyzing the infrastructure of the Top 5k Alexa domains, we discover that the security mechanisms currently deployed are ineffective and that some infrastructure providers have a comparable threat potential to nations. We find a considerable increase of security (up to 13% protected web visits) is possible at a relatively modest cost, due to the effectiveness of mitigations at the application and transport layer, which dominate expensive infrastructure enhancements such as DNSSEC and IPsec. © 2023 Association for Computing Machinery.",Formal security models; security architectures; web security,Intrusion detection; Network security; Pareto principle; Personal computing; Application layers; Communicationtechnology; Exposed to; Formal security models; Pareto-optimal; Security Architecture; Theory and practice; Web infrastructure; WEB security; Web technologies; Graphic methods
RansomShield: A Visualization Approach to Defending Mobile Systems Against Ransomware,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159758952&doi=10.1145%2f3579822&partnerID=40&md5=6ee76b9b9c5ec1a46934fdb0419e996c,"The unprecedented growth in mobile systems has transformed the way we approach everyday computing. Unfortunately, the emergence of a sophisticated type of malware known as ransomware poses a great threat to consumers of this technology. Traditional research on mobile malware detection has focused on approaches that rely on analyzing bytecode for uncovering malicious apps. However, cybercriminals can bypass such methods by embedding malware directly in native machine code, making traditional methods inadequate. Another challenge that detection solutions face is scalability. The sheer number of malware variants released every year makes it difficult for solutions to efficiently scale their coverage. To address these concerns, this work presents RansomShield, an energy-efficient solution that leverages CNNs to detect ransomware. We evaluate CNN architectures that have been known to perform well on computer vision tasks and examine their suitability for ransomware detection. We show that systematically converting native instructions from Android apps into images using space-filling curve visualization techniques enable CNNs to reliably detect ransomware with high accuracy. We characterize the robustness of this approach across ARM and x86 architectures and demonstrate the effectiveness of this solution across heterogeneous platforms including smartphones and chromebooks. We evaluate the suitability of different models for mobile systems by comparing their energy demands using different platforms. In addition, we present a CNN introspection framework that determines the important features that are needed for ransomware detection. Finally, we evaluate the robustness of this solution against adversarial machine learning (AML) attacks using state-of-the-art Android malware dataset.  © 2023 ////////Copyright held by the owner/author(s). Publication rights licensed to ACM.",Android; convolutional neural networks; energy efficiency; entropy; Hilbert; instruction set architecture; intrusion detection system; machine learning; malware; mobile security; Ransomware; visualization,Android (operating system); Android malware; Computer architecture; Convolutional neural networks; Energy efficiency; Entropy; Intrusion detection; Machine learning; Network architecture; Visualization; Android; Convolutional neural network; Hilbert; Instruction set architecture; Intrusion Detection Systems; Machine-learning; Malware detection; Malwares; Mobile malware; Mobile systems; Mobile security
ThermoSecure: Investigating the Effectiveness of AI-Driven Thermal Attacks on Commonly Used Computer Keyboards,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145874555&doi=10.1145%2f3563693&partnerID=40&md5=e0bff7ee955924edc789b11d46fa2bdb,"Thermal cameras can reveal heat traces on user interfaces, such as keyboards. This can be exploited maliciously to infer sensitive input, such as passwords. While previous work considered thermal attacks that rely on visual inspection of simple image processing techniques, we show that attackers can perform more effective artificial intelligence (AI)-driven attacks. We demonstrate this by presenting the development of ThermoSecure and its evaluation in two user studies (N = 21, N = 16), which reveal novel insights about thermal attacks. We detail the implementation of ThermoSecure and make a dataset of 1,500 thermal images of keyboards with heat traces resulting from input publicly available. Our first study shows that ThermoSecure successfully attacks 6-symbol, 8-symbol, 12-symbol, and 16-symbol passwords with an average accuracy of 92%, 80%, 71%, and 55% respectively, and even higher accuracy when thermal images are taken within 30 seconds. We found that typing behavior significantly impacts vulnerability to thermal attacks: hunt-and-peck typists are more vulnerable than fast typists (92% vs. 83% thermal attack success. respectively, if performed within 30 seconds). The second study showed that keycap material has a statistically significant effect on the effectiveness of thermal attacks: ABS keycaps retain the thermal trace of user presses for a longer period of time, making them more vulnerable to thermal attacks, with a 52% average attack accuracy compared with 14% for keyboards with PBT keycaps. Finally, we discuss how systems can leverage our results to protect from thermal attacks and present 7 mitigation approaches that are based on our results and previous work. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Authentication; deep learning; K-means clustering; Mask R-CNN,Deep learning; Image processing; K-means clustering; User interfaces; Deep learning; ITS evaluation; K-means++ clustering; Mask R-CNN; Simple image processing techniques; Thermal attack; Thermal camera; Thermal images; User study; Visual inspection; Authentication
Security Best Practices: A Critical Analysis Using IoT as a Case Study,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154538233&doi=10.1145%2f3563392&partnerID=40&md5=7f5b3cd548781ceceba88bd10dc58291,"Academic research has highlighted the failure of many Internet of Things (IoT) product manufacturers to follow accepted practices, while IoT security best practices have recently attracted considerable attention worldwide from industry and governments. Given current examples of security advice, confusion is evident from guidelines that conflate desired outcomes with security practices to achieve those outcomes. We explore a surprising lack of clarity, and void in the literature, on what (generically) best practice means, independent of identifying specific individual practices or highlighting failure to follow best practices. We consider categories of security advice, and analyze how they apply over the lifecycle of IoT devices. For concreteness in discussion, we use iterative inductive coding to code and systematically analyze a set of 1,013 IoT security best practices, recommendations, and guidelines collated from industrial, government, and academic sources. Among our findings, of all analyzed items, 68% fail to meet our definition of an (actionable) practice, and 73% of all actionable advice relates to the software development lifecycle phase, highlighting the critical position of manufacturers and developers. We hope that our work provides a basis for the community to better understand best practices, identify and reach consensus on specific practices, and find ways to motivate relevant stakeholders to follow them. © 2023 Association for Computing Machinery.",best practices; device lifecycle; inductive coding; IoT security; security advice,Life cycle; Software design; Academic research; Best practices; Case-studies; Critical analysis; Device lifecycle; Inductive coding; Internet of thing security; Product manufacturers; Security advices; Security Best Practices; Internet of things
Assessing Cyber Risk in Cyber-Physical Systems Using the ATT&CK Framework,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153562841&doi=10.1145%2f3571733&partnerID=40&md5=a75e703e181eb3041d1cca035d20d959,"Autonomous transport is receiving increasing attention, with research and development activities already providing prototype implementations. In this article we focus on Autonomous Passenger Ships (APS), which are being considered as a solution for passenger transport across urban waterways. The ambition of the authors has been to examine the safety and security implications of such a Cyber Physical System (CPS), particularly focusing on threats that endanger the passengers and the operational environment of the APS. Accordingly, the article presents a new risk assessment approach based on a Failure Modes Effects and Criticality Analysis (FMECA) that is enriched with selected semantics and components of the MITRE ATT&CK framework, in order to utilize the encoded common knowledge and facilitate the expression of attacks. Then, the proposed approach is demonstrated through conducting a risk assessment for a communication architecture tailored to the requirements of APSs that were proposed in earlier work. Moreover, we propose a group of graph theory-based metrics for estimating the impact of the identified risks. The use of this method has resulted in the identification of risks and their corresponding countermeasures, in addition to identifying risks with limited existing mitigation mechanisms. The benefits of the proposed approach are the comprehensive, atomic, and descriptive nature of the identified threats, which reduce the need for expert judgment, and the granular impact estimation metrics that reduce the impact of bias. All these features are provided in a semi-automated approach to reduce the required effort and collectively are argued to enrich the design-level risk assessment processes with an updatable industry threat model standard, namely ATT&CK.  © 2023 Copyright held by the owner/author(s).",autonomous ship; Cyber-Physical System; FMECA; MITRE ATT&CK; Risk assessment; safety and security,Cyber Physical System; Cybersecurity; Embedded systems; Graph theory; Group theory; Risk perception; Safety engineering; Semantics; Ships; Autonomous ship; Cybe-physical systems; Cyber-physical systems; Failure modes effects and criticality analysis; MITRE ATT&CK; Passenger ships; Research activities; Research and development; Risks assessments; Safety and securities; Risk assessment
Performance and Usability Evaluation of Brainwave Authentication Techniques with Consumer Devices,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170638166&doi=10.1145%2f3579356&partnerID=40&md5=91161336a9ec6a6f4f36795dd51e8230,"Brainwaves have demonstrated to be unique enough across individuals to be useful as biometrics. They also provide promising advantages over traditional means of authentication, such as resistance to external observability, revocability, and intrinsic liveness detection. However, most of the research so far has been conducted with expensive, bulky, medical-grade helmets, which offer limited applicability for everyday usage. With the aim to bring brainwave authentication and its benefits closer to real world deployment, we investigate brain biometrics with consumer devices. We conduct a comprehensive measurement experiment and user study that compare five authentication tasks on a user sample up to 10 times larger than those from previous studies, introducing three novel techniques based on cognitive semantic processing. Furthermore, we apply our analysis on high-quality open brainwave data obtained with a medical-grade headset, to assess the differences. We investigate both the performance, security, and usability of the different options and use this evidence to elicit design and research recommendations. Our results show that it is possible to achieve Equal Error Rates as low as 7.2% (a reduction between 68-72% with respect to existing approaches) based on brain responses to images with current inexpensive technology. We show that the common practice of testing authentication systems only with known attacker data is unrealistic and may lead to overly optimistic evaluations. With regard to adoption, users call for simpler devices, faster authentication, and better privacy.  © 2023 Copyright held by the owner/author(s).",Brain biometrics; electroencephalogram (EEG); usable security; user authentication,Biometrics; Electroencephalography; Quality control; Semantics; Authentication techniques; Brain biometric; Brain wave; Consumer devices; Electroencephalogram; Medical grades; Performances evaluation; Usability evaluation; Usable security; User authentication; Authentication
A Solicitous Approach to Smart Contract Verification,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154538212&doi=10.1145%2f3564699&partnerID=40&md5=8ffcbee304745c491775b5c7212f3170,"Smart contracts are tempting targets of attacks, as they often hold and manipulate significant financial assets, are immutable after deployment, and have publicly available source code, with assets estimated in the order of millions of dollars being lost in the past due to vulnerabilities. Formal verification is thus a necessity, but smart contracts challenge the existing highly efficient techniques routinely applied in the symbolic verification of software, due to specificities not present in general programming languages. A common feature of existing works in this area is the attempt to reuse off-the-shelf verification tools designed for general programming languages. This reuse can lead to inefficiency and potentially unsound results, as domain translation is required. In this article, we describe a carefully crafted approach that directly models the central aspects of smart contracts natively, going from the contract to its logical representation without intermediary steps. We use the expressive and highly automatable logic of constrained Horn clauses for modeling and instantiate our approach to the Solidity language. A tool implementing our approach, called Solicitous, was developed and integrated into the SMTChecker module of the Solidity compiler solc. We evaluated our approach on an extensive benchmark set containing 22,446 real-world smart contracts deployed on the Ethereum blockchain over a 27-month period. The results show that our approach is able to establish safety of significantly more contracts than comparable, publicly available verification tools, with an order of magnitude increase in the percentage of formally verified contracts.  © 2023 Association for Computing Machinery.",direct modeling; Smart contracts; vulnerability detection,Formal verification; Logic programming; Modeling languages; Program compilers; Common features; Direct modelling; Financial assets; General programming; Reuse; Source codes; Symbolic verification; Verification of softwares; Verification tools; Vulnerability detection; Smart contract
Automated Security Assessments of Amazon Web Services Environments,2023,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154572778&doi=10.1145%2f3570903&partnerID=40&md5=d6a340fd3c4e50bc54e754ebfe85edad,"Migrating enterprises and business capabilities to cloud platforms like Amazon Web Services (AWS) has become increasingly common. However, securing cloud operations, especially at large scales, can quickly become intractable. Customer-side issues such as service misconfigurations, data breaches, and insecure changes are prevalent. Furthermore, cloud-specific tactics and techniques paired with application vulnerabilities create a large and complex search space. Various solutions and modeling languages for cloud security assessments exist. However, no single one appeared sufficiently cloud-centered and holistic. Many also did not account for tactical security dimensions. This article, therefore, presents a domain-specific modeling language for AWS environments. When used to model AWS environments, manually or automatically, the language automatically constructs and traverses attack graphs to assess security. Assessments, therefore, require minimal security expertise from the user. The modeling language was primarily tested on four third-party AWS environments through securiCAD Vanguard, a commercial tool built around the AWS modeling language. The language was validated further by measuring performance on models provided by anonymous end users and a comparison with a similar open source assessment tool. As of March 2020, the modeling language could represent essential AWS structures, cloud tactics, and threats. However, the tests highlighted certain shortcomings. Data collection steps, such as planted credentials, and some missing tactics were obvious. Nevertheless, the issues covered by the DSL were already reminiscent of common issues with real-world precedents. Future additions to attacker tactics and addressing data collection should yield considerable improvements. © 2023 Copyright held by the owner/author(s).",attack graphs; Attack simulation; automatic security assessment; cloud security; domain-specific language; threat modeling,Computer simulation languages; Data acquisition; Problem oriented languages; Web services; Websites; XML; Amazon web services; Attack graph; Attack simulation; Automatic security assessment; Cloud securities; Data collection; Domains specific languages; Security assessment; Threat modeling; Web services environment; Modeling languages
