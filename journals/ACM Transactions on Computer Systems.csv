Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
Arrakis: The operating system is the control plane,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946847648&doi=10.1145%2f2812806&partnerID=40&md5=c8ca7da0f0ab1e6d7fd0a07db21b4010,"Recent device hardware trends enable a new approach to the design of network server operating systems. In a traditional operating system, the kernel mediates access to device hardware by server applications to enforce process isolation as well as network and disk security. We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two. Applications have direct access to virtualized I/O devices, allowing most I/O operations to skip the kernel entirely, while the kernel is reengineered to provide network and disk protection without kernel mediation of every operation. We describe the hardware and software changes needed to take advantage of this new abstraction, and we illustrate its power by showing improvements of 2 to 5× in latency and 9× throughput for a popular persistent NoSQL store relative to a well-tuned Linux implementation. © 2015 ACM.",I/O virtualization; Kernel bypass; SR-IOV,Computer hardware; Network security; Control planes; Disk security; Hardware and software; Kernel bypass; Linux implementation; Network server; New approaches; Server applications; Linux
The RAMCloud storage system,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941005029&doi=10.1145%2f2806887&partnerID=40&md5=a7ed7262a21ef229ceecfc5ef0cf367e,"RAMCloud is a storage system that provides low-latency access to large-scale datasets. To achieve low latency, RAMCloud stores all data in DRAM at all times. To support large capacities (1PB or more), it aggregates the memories of thousands of servers into a single coherent key-value store. RAMCloud ensures the durability of DRAM-based data by keeping backup copies on secondary storage. It uses a uniform log-structured mechanism to manage both DRAM and secondary storage, which results in high performance and efficient memory usage. RAMCloud uses a polling-based approach to communication, bypassing the kernel to communicate directly with NICs; with this approach, client applications can read small objects from any RAMCloud storage server in less than 5μs, durable writes of small objects take about 13.5μs. RAMCloud does not keep multiple copies of data online; instead, it provides high availability by recovering from crashes very quickly (1 to 2 seconds). RAMCloud's crash recovery mechanism harnesses the resources of the entire cluster working concurrently so that recovery performance scales with cluster size. © 2015 ACM. All rights reserved.",Datacenters; Design; Experimentation; Large-scale systems; Low latency; Performance; Reliability; Storage systems,Design; Large dataset; Large scale systems; Recovery; Reliability; Data centers; Experimentation; Low latency; Performance; Storage systems; Dynamic random access storage
SKMD: Single kernel on multiple devices for transparent CPU-GPU collaboration,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940970801&doi=10.1145%2f2798725&partnerID=40&md5=25a2128542ccba2e4ee90ecaa5f0ece2,"Heterogeneous computing on CPUs and GPUs has traditionally used fixed roles for each device: the GPU handles data parallel work by taking advantage of its massive number of cores while the CPU handles non data-parallel work, such as the sequential code or data transfer management. This work distribution can be a poor solution as it underutilizes the CPU, has difficulty generalizing beyond the single CPU-GPU combination, and may waste a large fraction of time transferring data. Further, CPUs are performance competitive with GPUs on many workloads, thus simply partitioning work based on the fixed roles may be a poor choice. In this article, we present the single-kernel multiple devices (SKMD) system, a framework that transparently orchestrates collaborative execution of a single data-parallel kernel across multiple asymmetric CPUs and GPUs. The programmer is responsible for developing a single data-parallel kernel in OpenCL, while the system automatically partitions the workload across an arbitrary set of devices, generates kernels to execute the partial workloads, and efficiently merges the partial outputs together. The goal is performance improvement by maximally utilizing all available resources to execute the kernel. SKMD handles the difficult challenges of exposed data transfer costs and the performance variations GPUs have with respect to input size. On real hardware, SKMD achieves an average speedup of 28% on a system with one multicore CPU and two asymmetric GPUs compared to a fastest device execution strategy for a set of popular OpenCL kernels. © 2015.",Collaboration; Compiler; CPU; GPU; Optimization; Runtime,Data transfer; Graphics processing unit; Optimization; Program processors; Collaboration; Collaborative execution; Compiler; Execution strategies; Heterogeneous computing; Performance variations; Runtimes; Transfer managements; Computer hardware
Shielding applications from an untrusted cloud with Haven,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941008296&doi=10.1145%2f2799647&partnerID=40&md5=3f698ed1f618218b415672818c9bf976,"Today's cloud computing infrastructure requires substantial trust. Cloud users rely on both the provider's staff and its globally distributed software/hardware platform not to expose any of their private data. We introduce the notion of shielded execution, which protects the confidentiality and integrity of a program and its data from the platform on which it runs (i.e., the cloud operator's OS, VM, and firmware). Our prototype, Haven, is the first system to achieve shielded execution of unmodified legacy applications, including SQL Server and Apache, on a commodity OS (Windows) and commodity hardware. Haven leverages the hardware protection of Intel SGX to defend against privileged code and physical attacks such as memory probes, and also addresses the dual challenges of executing unmodified legacy binaries and protecting them from a malicious host. This work motivated recent changes in the SGX specification. © 2015 ACM. All rights reserved.",Cloud security; D.4.6 [operating systems]: Security and protection; D.4.7 [operating systems]: Organization and design; Design; Enclave; Intel SGX; Library OS; Security; Shielded execution; Trusted computing,Computer hardware; Design; Firmware; Hardware; Trusted computing; Windows operating system; Cloud securities; Enclave; Intel SGX; Security; Security and protection; Shielded execution; Distributed computer systems
Efficient control and communication paradigms for coarse-grained spatial architectures,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946081286&doi=10.1145%2f2754930&partnerID=40&md5=8f1307e7db341a1f12f0f8eee533371f,"There has been recent interest in exploring the acceleration of nonvectorizable workloads with spatially programmed architectures that are designed to efficiently exploit pipeline parallelism. Such an architecture faces two main problems: how to efficiently control each processing element (PE) in the system, and how to facilitate inter-PE communication without the overheads of traditional shared-memory coherent memory. In this article, we explore solving these problems using triggered instructions and latency-insensitive channels. Triggered instructions completely eliminate the program counter (PC) and allow programs to transition concisely between states without explicit branch instructions. Latency-insensitive channels allow efficient communication of inter-PE control information while simultaneously enabling flexible code placement and improving tolerance for variable events such as cache accesses. Together, these approaches provide a unified mechanism to avoid overserialized execution, essentially achieving the effect of techniques such as dynamic instruction reordering and multithreading. Our analysis shows that a spatial accelerator using triggered instructions and latency-insensitive channels can achieve 8ï¿½ greater area-normalized performance than a traditional general-purpose processor. Further analysis shows that triggered control reduces the number of static and dynamic instructions in the critical paths by 62% and 64%, respectively, over a PC-style baseline, increasing the performance of the spatial programming approach by 2.0ï¿½. ï¿½ 2015 ACM.",Reconfigurable accelerators; Spatial programming,General purpose computers; Multitasking; Communication paradigm; Control information; Dynamic instructions; Efficient communications; General purpose processors; Pipeline parallelisms; Reconfigurable; Spatial programming; Memory architecture
K2: A mobile operating system for heterogeneous coherence domains,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935029339&doi=10.1145%2f2699676&partnerID=40&md5=2646ee05410be2609c4bfe2fd7a0f74a,"Mobile System-on-Chips (SoC) that incorporate heterogeneous coherence domains promise high energy efficiency to a wide range of mobile applications, yet are difficult to program. To exploit the architecture, a desirable, yet missing capability is to replicate operating system (OS) services over multiple coherence domains with minimum inter-domain communication. In designing such an OS, we set three goals: To ease application development, to simplify OS engineering, and to preserve the current OS performance. To this end, we identify a shared-most OS model for multiple coherence domains: creating per-domain instances of core OS services with no shared state, while enabling other extended OS services to share state across domains. To test the model, we build K2, a prototype OS on the TI OMAP4 SoC, by reusing most of the Linux 3.4 source. K2 presents a single system image to applications with its two kernels running on top of the two coherence domains of OMAP4. The two kernels have independent instances of core OS services, such as page allocation and interrupt management, as coordinated by K2; the two kernels share most extended OS services, such as device drivers, whose state is kept coherent transparently by K2. Despite platform constraints and unoptimized code, K2 improves energy efficiency for light OS workloads by 8x-10x, while incurring less than 9% performance overhead for two device drivers shared between kernels. Our experiences with K2 show that the shared-most model is promising. © 2015 ACM.",Coherence domains; Energy efficiency; Heterogeneous architecture; Mobile,Application programs; Computer operating systems; Microprocessor chips; System-on-chip; Application development; Heterogeneous architectures; High energy efficiency; Interdomain communication; Mobile; Mobile applications; Mobile operating systems; Single system image; Energy efficiency
Fireflies: A secure and scalable membership and gossip service,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930340722&doi=10.1145%2f2701418&partnerID=40&md5=21a8b8e5dc6657ba77cee30db8d5d62f,"An attacker who controls a computer in an overlay network can effectively control the entire overlay network if the mechanism managing membership information can successfully be targeted. This article describes Fireflies, an overlay network protocol that fights such attacks by organizing members in a verifiable pseudorandom structure so that an intruder cannot incorrectly modify the membership views of correct members. Fireflies provides each member with a view of the entire membership, and supports networks with moderate total churn. We evaluate Fireflies using both simulations and PlanetLab to show that Fireflies is a practical approach for secure membership maintenance in such networks.",Byzantine failures; Gossip; Membership management; Overlay network,Network protocols; Overlay networks; Byzantine failures; Gossip; Membership information; Membership management; PlanetLab; Pseudo random; Bioluminescence
A small-footprint accelerator for large-scale neural networks,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930319636&doi=10.1145%2f2701417&partnerID=40&md5=3fedd9051f8f220130da4bf0b90d81e7,"Machine-learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-theart across many applications. As architectures evolve toward heterogeneous multicores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope. Until now, most machine-learning accelerator designs have been focusing on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance, and energy. We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02mm2 and 485mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87?faster, and it can reduce the total energy by 21.08×. The accelerator characteristics are obtained after layout at 65nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications. © 2015 ACM.",Convolutional neural network; Deep learning; Deep neural network; Hardware accelerator,Acceleration; Computational efficiency; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Embedded systems; Learning systems; Accelerator design; Broad application; Hardware accelerators; Heterogeneous Multi-Cores; High throughput; Small footprints; State of the art; Synaptic weight; Learning algorithms
A differential approach to undefined behavior detection,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925253952&doi=10.1145%2f2699678&partnerID=40&md5=ef9f55f1e82effcab7cfe77678c17f84,"This article studies undefined behavior arising in systems programming languages such as C/C++. Undefined behavior bugs lead to unpredictable and subtle systems behavior, and their effects can be further amplified by compiler optimizations. Undefined behavior bugs are present inmany systems, including the Linux kernel and the Postgres database. The consequences range from incorrect functionality to missing security checks. This article proposes a formal and practical approach that finds undefined behavior bugs by finding ""unstable code"" in terms of optimizations that leverage undefined behavior. Using this approach, we introduce a new static checker called STACK that precisely identifies undefined behavior bugs. Applying STACK to widely used systems has uncovered 161 new bugs that have been confirmed and fixed by developers. © 2015 ACM.",Compiler optimizations; Undefined behavior,C (programming language); Computer operating systems; Program compilers; Behavior detection; Compiler optimizations; Differential approach; Linux kernel; Security checks; Undefined behavior; Used systems; Program debugging
Energy-oriented partial desktop virtual machine migration,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925249806&doi=10.1145%2f2699683&partnerID=40&md5=9fc7a2b1ee564e50ece7e73fd2e2dd78,"Modern offices are crowded with personal computers. While studies have shown these to be idle most of the time, they remain powered, consuming up to 60% of their peak power. Hardware-based solutions engendered by PC vendors (e.g., low-power states, Wake-on-LAN) have proved unsuccessful because, in spite of user inactivity, these machines often need to remain network active in support of background applications that maintain network presence. Recent proposals have advocated the use of consolidation of idle desktop Virtual Machines (VMs). However, desktop VMs are often large, requiring gigabytes of memory. Consolidating such VMs creates large network transfers lasting in the order of minutes and utilizes server memory inefficiently. When multiple VMsmigrate concurrently, networks become congested, and the resulting migration latencies are prohibitive.We present partial VM migration, an approach that transparently migrates only the working set of an idle VM. It creates a partial replica of the desktop VMon the consolidation server by copying onlyVM metadata, and it transfers pages to the server on-demand, as the VM accesses them. This approach places desktop PCs in low-power mode when inactive and switches them to running mode when pages are needed by the VM running on the consolidation server. To ensure that desktops save energy, we have developed sleep scheduling and prefetching algorithms, as well as the context-aware selective resume framework, a novel approach to reduce the latency of power mode transition operations in commodity PCs. Jettison, our software prototype of partial VM migration for off-the-shelf PCs, can deliver 44-91% energy savings during idle periods of at least 10 minutes, while providing low migration latencies of about 4 seconds and migrating minimal state that is under an order of magnitude of the VM's memory footprint. © 2015 ACM.",Desktop virtualization; Power management; Virtual machine migration,Energy conservation; Low power electronics; Network security; Personal computers; Power management; Software prototyping; Desktop virtualization; Large networks; Low power modes; Low power state; Memory footprint; Prefetching algorithm; Sleep scheduling; Virtual machine migrations; Virtual machine
"ISA wars: Understanding the relevance of ISA being RISC or CISC to performance, power, and energy on modern architectures",2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925274990&doi=10.1145%2f2699682&partnerID=40&md5=b70267dd8d89989366ba959474eb6466,"RISC versus CISC wars raged in the 1980s when chip area and processor design complexity were the primary constraints and desktops and servers exclusively dominated the computing landscape. Today, energy and power are the primary design constraints and the computing landscape is significantly different: Growth in tablets and smartphones running ARM (a RISC ISA) is surpassing that of desktops and laptops running x86 (a CISC ISA). Furthermore, the traditionally low-power ARM ISA is entering the high-performance server market, while the traditionally high-performance x86 ISA is entering the mobile low-power device market. Thus, the question of whether ISA plays an intrinsic role in performance or energy efficiency is becoming important again, and we seek to answer this question through a detailed measurement-based study on real hardware running real applications. We analyze measurements on seven platforms spanning three ISAs (MIPS, ARM, and x86) over workloads spanning mobile, desktop, and server computing. Our methodical investigation demonstrates the role of ISA in modern microprocessors' performance and energy efficiency. We find that ARM, MIPS, and x86 processors are simply engineering design points optimized for different levels of performance, and there is nothing fundamentally more energy efficient in one ISA class or the other. The ISA being RISC or CISC seems irrelevant. © 2015 ACM.",Energy efficiency; Power; Technology scaling,Commerce; Energy efficiency; Integrated circuit design; Engineering design; Low-power devices; Measurement-based studies; Modern architectures; Modern microprocessor; Power; Real applications; Technology scaling; ARM processors
The scalable commutativity rule: Designing scalable software for multicore processors,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921449778&doi=10.1145%2f2699681&partnerID=40&md5=f46bfa8da8157a874171bd215c6158c5,"What opportunities for multicore scalability are latent in software interfaces, such as system call APIs? Can scalability challenges and opportunities be identified even before any implementation exists, simply by considering interface specifications? To answer these questions, we introduce the scalable commutativity rule: whenever interface operations commute, they can be implemented in a way that scales. This rule is useful throughout the development process for scalablemulticore software, from the interface design through implementation, testing, and evaluation. This article formalizes the scalable commutativity rule. This requires defining a novel form of commutativity, SIM commutativity, that lets the rule apply even to complex and highly stateful software interfaces. We also introduce a suite of software development tools based on the rule. Our COMMUTER tool accepts high-level interface models, generates tests of interface operations that commute and hence could scale, and uses these tests to systematically evaluate the scalability of implementations. We apply COMMUTER to a model of 18 POSIX file and virtual memory system operations. Using the resulting 26,238 scalability tests, COMMUTER highlights Linux kernel problems previously observed to limit application scalability and identifies previously unknown bottlenecks that may be triggered by future workloads or hardware. Finally, we apply the scalable commutativity rule and COMMUTER to the design and implementation sv6, a new POSIX-like operating system. sv6's novel file and virtual memory system designs enable it to scale for 99% of the tests generated by COMMUTER. These results translate to linear scalability on an 80-core x86 machine for applications built on sv6's commutative operations.",Design; Performance; Theory,Application programming interfaces (API); Computer operating systems; Design; Scalability; Software engineering; Software testing; Application scalability; Design and implementations; High level interface; Interface specification; Performance; Software development tools; Theory; Virtual memory systems; Software design
The next 700 BFT protocols,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921499802&doi=10.1145%2f2658994&partnerID=40&md5=c57b57a027b9acebb3052d3e21c97dc0,"We present Abstract (ABortable STate mAChine replicaTion), a new abstraction for designing and reconfiguring generalized replicated state machines that are, unlike traditional state machines, allowed to abort executing a client's request if ""something goes wrong."" Abstract can be used to considerably simplify the incremental development of efficient Byzantine faulttolerant state machine replication (BFT) protocols that are notorious for being difficult to develop. In short, we treat a BFT protocol as a composition of Abstract instances. Each instance is developed and analyzed independently and optimized for specific system conditions. We illustrate the power of Abstract through several interesting examples. We first show how Abstract can yield benefits of a state-of-the-art BFT protocol in a less painful and errorprone manner. Namely, we develop AZyzzyva, a new protocol that mimics the celebrated best-case behavior of Zyzzyva using less than 35% of the Zyzzyva code. To cover worst-case situations, our abstraction enables one to use in AZyzzyva any existing BFT protocol. We then present Aliph, a new BFT protocol that outperforms previous BFT protocols in terms of both latency (by up to 360%) and throughput (by up to 30%). Finally, we present R-Aliph, an implementation of Aliph that is robust, that is, whose performance degrades gracefully in the presence of Byzantine replicas and Byzantine clients. © 2015 ACM.",Algorithms; Design; Fault tolerance; Performance,Algorithms; Design; Fault tolerance; Error prones; Fault-tolerant state; Incremental development; Performance; State machine; State machine replication; State of the art; System conditions; Abstracting
Mechanistic modeling of architectural vulnerability factor,2015,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921480913&doi=10.1145%2f2669364&partnerID=40&md5=017e1a22f765085539bed98efc565fd8,"Reliability to soft errors is a significant design challenge in modern microprocessors owing to an exponential increase in the number of transistors on chip and the reduction in operating voltages with each process generation. Architectural Vulnerability Factor (AVF) modeling using microarchitectural simulators enables architects to make informed performance, power, and reliability tradeoffs. However, such simulators are time-consuming and do not reveal the microarchitectural mechanisms that influence AVF. In this article, we present an accurate first-order mechanistic analytical model to compute AVF, developed using the first principles of an out-of-order superscalar execution. This model provides insight into the fundamental interactions between the workload and microarchitecture that together influence AVF. We use the model to perform design space exploration, parametric sweeps, and workload characterization for AVF. © 2015 ACM.",Design; Methodology; Modeling,Computer architecture; Models; Radiation hardening; Systems analysis; Architectural vulnerability factor; Exponential increase; Mechanistic modeling; Methodology; Microarchitectural mechanism; Modern microprocessor; Reliability tradeoffs; Workload characterization; Design
Scaling performance via self-tuning approximation for graphics engines,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907574061&doi=10.1145%2f2631913&partnerID=40&md5=07de0ff36187b2813a7cb6e781ec0560,"Approximate computing, where computation accuracy is traded off for better performance or higher data throughput, is one solution that can help data processing keep pace with the current and growing abundance of information. For particular domains, such as multimedia and learning algorithms, approximation is commonly used today. We consider automation to be essential to provide transparent approximation, and we show that larger benefits can be achieved by constructing the approximation techniques to fit the underlying hardware. Our target platform is the GPU because of its high performance capabilities and difficult programming challenges that can be alleviated with proper automation. Our approach - SAGE - combines a static compiler that automatically generates a set of CUDA kernels with varying levels of approximation with a runtime system that iteratively selects among the available kernels to achieve speedup while adhering to a target output quality set by the user. The SAGE compiler employs three optimization techniques to generate approximate kernels that exploit the GPU microarchitecture: selective discarding of atomic operations, data packing, and thread fusion. Across a set of machine learning and image processing kernels, SAGE's approximation yields an average of 2.5× speedup with less than 10% quality loss compared to the accurate execution on a NVIDIA GTX 560 GPU. © 2014 ACM.",Approximate computing; Compiler; GPU; Optimization,Approximation algorithms; Computer hardware; Data handling; Graphics processing unit; Image processing; Iterative methods; Optimization; Program compilers; Approximate computing; Approximation techniques; Compiler; Computation accuracy; Micro architectures; Optimization techniques; Performance capability; Selective discarding; Learning algorithms
Approximate storage in solid-state memories,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907582153&doi=10.1145%2f2644808&partnerID=40&md5=681f4eaf5e081f9f9766e14b45211bc3,"Memories today expose an all-or-nothing correctness model that incurs significant costs in performance, energy, area, and design complexity. But not all applications need high-precision storage for all of their data structures all of the time. This article proposes mechanisms that enable applications to store data approximately and shows that doing so can improve the performance, lifetime, or density of solid-state memories. We propose two mechanisms. The first allows errors in multilevel cells by reducing the number of programming pulses used to write them. The second mechanism mitigates wear-out failures and extends memory endurance by mapping approximate data onto blocks that have exhausted their hardware error correction resources. Simulations show that reduced-precision writes in multilevel phase-change memory cells can be 1.7× faster on average and using failed blocks can improve array lifetime by 23% on average with quality loss under 10%. © 2014 ACM.",Approximate computing; Error tolerance; Phase-change memory; Storage,Energy storage; Error correction; Approximate computing; Design complexity; Error tolerance; Phase change memory cells; Programming pulse; Reduced precision; Solid state memory; Wear-out failure; Phase change memory
Energy analysis of hardware and software range partitioning,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907575688&doi=10.1145%2f2638550&partnerID=40&md5=c07170ef033b4cd5a54d2b6190bf258e,"Data partitioning is a critical operation for manipulating large datasets because it subdivides tasks into pieces that are more amenable to efficient processing. It is often the limiting factor in database performance and represents a significant fraction of the overall runtime of large data queries. This article measures the performance and energy of state-of-the-art software partitioners, and describes and evaluates a hardware range partitioner that further improves efficiency. The software implementation is broken into two phases, allowing separate analysis of the partition function computation and data shuffling costs. Although range partitioning is commonly thought to be more expensive than simpler strategies such as hash partitioning, our measurements indicate that careful data movement and optimization of the partition function can allow it to approach the throughput and energy consumption of hash or radix partitioning. For further acceleration, we describe a hardware range partitioner, or HARP, a streaming framework that offers a seamless execution environment for this and other streaming accelerators, and a detailed analysis of a 32nm physical design that matches the throughput of four to eight software threads while consuming just 6.9% of the area and 4.3% of the power of a Xeon core in the same technology generation. © 2014 ACM.",Accelerator; Data partitioning; Microarchitecture; Specialized functional unit; Streaming data,Energy utilization; Hardware; Particle accelerators; Query languages; Data partitioning; Database performance; Execution environments; Functional units; Hardware and software; Micro architectures; Software implementation; Streaming data; Data handling
Market mechanisms for managing datacenters with heterogeneous microarchitectures,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894632438&doi=10.1145%2f2541258&partnerID=40&md5=1769047e8c5c36cbf721f856b01c737c,"Specialization of datacenter resources brings performance and energy improvements in response to the growing scale and diversity of cloud applications. Yet heterogeneous hardware adds complexity and volatility to latency-sensitive applications. A resource allocation mechanism that leverages architectural principles can overcome both of these obstacles. We integrate research in heterogeneous architectures with recent advances in multi-agent systems. Embedding architectural insight into proxies that bid on behalf of applications, a market effectively allocates hardware to applications with diverse preferences and valuations. Exploring a space of heterogeneous datacenter configurations, which mix server-class Xeon and mobile-class Atom processors, we find an optimal heterogeneous balance that improves both welfare and energy-efficiency. We further design and evaluate twelve design points along the Xeon-to-Atom spectrum, and find that a mix of three processor architectures achieves a 12× reduction in response time violations relative to equal-power homogeneous systems. © 2014 ACM 0734-2071/2014/02-ART3 $15.00.",Economic mechanisms; Energy-efficient datacenters; Resource allocation,
Comprehensive Formal Verification of an OS Microkernel,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894634485&doi=10.1145%2f2560537&partnerID=40&md5=a7e9dac3869bc2429b73059c5b15b8a5,"We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel. We discuss the kernel design we used to make its verification tractable. We then describe the functional correctness proof of the kernel's C implementation and we cover further steps that transform this result into a comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary code of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a proof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and an automatic initialiser for user-level systems that connects kernel-level access-control enforcement with reasoning about system behaviour. We summarise these results and show how they integrate to form a coherent overall analysis, backed by machine-checked, end-to-end theorems. The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully formally verified to this degree. It is also the only example of formal proof of this scale that is kept current as the requirements, design and implementation of the system evolve over almost a decade. We report on our experience in maintaining this evolving formally verified code base. © 2014 ACM 0734-2071/2014/02- ART3 $15.00.",Isabelle/HOL; L4; Microkernel; Operating systems; SeL4,
GPUfs: Integrating a File System with GPUs,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894623987&doi=10.1145%2f2553081&partnerID=40&md5=79d333b02fbe9430b968c68d0ece7f0a,"AsGPUhardware becomes increasingly general-purpose, it is quickly outgrowing the traditional, constrained GPU-as-coprocessor programming model. This article advocates for extending standard operating system services and abstractions to GPUs in order to facilitate program development and enable harmonious integration of GPUs in computing systems. As an example, we describe the design and implementation of GPUfs, a software layer which provides operating system support for accessing host files directly from GPU programs. GPUfs provides a POSIX-like API, exploits GPU parallelism for efficiency, and optimizes GPU file access by extending the host CPU's buffer cache into GPU memory. Our experiments, based on a set of real benchmarks adapted to use our file system, demonstrate the feasibility and benefits of the GPUfs approach. For example, a self-contained GPU program that searches for a set of strings throughout the Linux kernel source tree runs over seven times faster than on an eight-core CPU. © 2014 ACM 0734-2071/2014/02-ART3 $15.00.",Accelerators; File systems; GPGPUs; Operating systems; Operating systems design,
Faults in linux 2.6,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904191799&doi=10.1145%2f2619090&partnerID=40&md5=16c81d6f0f454d70d52902a9c5768012,"In August 2011, Linux entered its third decade. Ten years before, Chou et al. published a study of faults found by applying a static analyzer to Linux versions 1.0 through 2.4.1. A major result of their work was that the drivers directory contained up to 7 times more of certain kinds of faults than other directories. This result inspired numerous efforts on improving the reliability of driver code. Today, Linux is used in a wider range of environments, provides a wider range of services, and has adopted a new development and release model. What has been the impact of these changes on code quality? To answer this question, we have transported Chou et al.'s experiments to all versions of Linux 2.6; released between 2003 and 2011. We find that Linux has more than doubled in size during this period, but the number of faults per line of code has been decreasing. Moreover, the fault rate of drivers is now below that of other directories, such as arch. These results can guide further development and research efforts for the decade to come. To allow updating these results as Linux evolves, we define our experimental protocol and make our checkers available. © 2014 ACM.",Fault finding; Linux,Codes (symbols); Computer operating systems; Code quality; Experimental protocols; Fault finding; Fault rates; Line of codes; Research efforts; Static analyzers; Linux
Optimizing the block I/O subsystem for fast storage devices,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904110780&doi=10.1145%2f2619092&partnerID=40&md5=ad4768292ebb4b7138d8649ec54d964d,"Fast storage devices are an emerging solution to satisfy data-intensive applications. They provide high transaction rates for DBMS, low response times for Web servers, instant on-demand paging for applications with large memory footprints, and many similar advantages for performance-hungry applications. In spite of the benefits promised by fast hardware, modern operating systems are not yet structured to take advantage of the hardware's full potential. The software overhead caused by an OS, negligible in the past, adversely impacts application performance, lessening the advantage of using such hardware. Our analysis demonstrates that the overheads from the traditional storage-stack design are significant and cannot easily be overcome without modifying the hardware interface and adding new capabilities to the operating system. In this article, we propose six optimizations that enable an OS to fully exploit the performance characteristics of fast storage devices. With the support of new hardware interfaces, our optimizations minimize per-request latency by streamlining the I/O path and amortize per-request latency by maximizing parallelism inside the device.We demonstrate the impact on application performance through well-known storage benchmarks run against a Linux kernel with a customized SSD. We find that eliminating context switches in the I/O path decreases the software overhead of an I/O request from 20 microseconds to 5 microseconds and a new request merge scheme called Temporal Merge enables the OS to achieve 87% to 100% of peak device performance, regardless of request access patterns or types. Although the performance improvement by these optimizations on a standard SATA-based SSD is marginal (because of its limited interface and relatively high response times), our sensitivity analysis suggests that future SSDs with lower response times will benefit from these changes. The effectiveness of our optimizations encourages discussion between the OS community and storage vendors about future device interfaces for fast storage devices. © 2014 ACM.",Device polling; Extended interface; I/O subsystem; Request batching,Application programs; Hardware; Linux; Virtual storage; Application performance; Data-intensive application; Device performance; Device polling; Hardware interfaces; Performance characteristics; Request batching; Transaction rates; Benchmarking
TaintDroid: An information-flow tracking system for realtime privacy monitoring on smartphones,2014,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904095463&doi=10.1145%2f2619091&partnerID=40&md5=b23a927eb2c18ffeb44c00072ae4a79c,"Today's smartphone operating systems frequently fail to provide users with visibility into how third-party applications collect and share their private data. We address these shortcomings with TaintDroid, an efficient, system-wide dynamic taint tracking and analysis system capable of simultaneously tracking multiple sources of sensitive data. TaintDroid enables realtime analysis by leveraging Android's virtualized execution environment. TaintDroid incurs only 32% performance overhead on a CPU-bound microbenchmark and imposes negligible overhead on interactive third-party applications. Using TaintDroid to monitor the behavior of 30 popular third-party Android applications, in our 2010 study we found 20 applications potentially misused users' private information; so did a similar fraction of the tested applications in our 2012 study. Monitoring the flow of privacy-sensitive data with TaintDroid provides valuable input for smartphone users and security service firms seeking to identify misbehaving applications. © 2014 ACM.",Information-flow tracking; Mobile apps; Privacy monitoring; Smartphones,Signal encoding; Smartphones; Android applications; Dynamic taint tracking; Execution environments; Information flows; Mobile apps; Private information; Real time analysis; Third party application (Apps); Android (operating system)
QoS-aware scheduling in heterogeneous datacenters with paragon,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891749429&doi=10.1145%2f2556583&partnerID=40&md5=72549a711d0c54b0c1b64853e86f2f31,"Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty of matching applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online, and do not scale beyond a few applications. We present Paragon, an online and scalable DC scheduler that is heterogeneity- and interference-aware. Paragon is derived from robust analytical methods, and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown incoming workload with respect to heterogeneity and interference in multiple shared resources. It does so by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. After the initial application placement, Paragon monitors application behavior and adjusts the scheduling decisions at runtime to avoid performance degradations. Additionally, we design ARQ, a multiclass admission control protocol that constrains application waiting time. ARQ queues applications in separate classes based on the type of resources they need and avoids long queueing delays for easy-to-satisfy workloads in highly-loaded scenarios. Paragon scales to tens of thousands of servers and applications with marginal scheduling overheads in terms of time or state. We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious, and least-loaded schedulers only provide similar guarantees for 14%, 11%, and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical. © 2013 ACM.",Cloud computing; Datacenter; Heterogeneity; Interference; QoS; Resource-efficiency; Scheduling,Cloud computing; Quality of service; Wave interference; Admission control protocols; Collaborative filtering techniques; Datacenter; Heterogeneity; Performance degradation; Quality of service (QoS) guarantees; Resource efficiencies; Robust analytical methods; Scheduling
Editorial,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891771571&doi=10.1145%2f2542150.2542151&partnerID=40&md5=16ef070f0a94e49d56f64ae00b1446ad,[No abstract available],,
A programmable memory controller for the DDRx interfacing standards,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891789339&doi=10.1145%2f2534845&partnerID=40&md5=b2fe7ec790857af01b5a720e25a1153a,"Modern memory controllers employ sophisticated address mapping, command scheduling, and power management optimizations to alleviate the adverse effects of DRAM timing and resource constraints on system performance. A promising way of improving the versatility and efficiency of these controllers is to make them programmable-a proven technique that has seen wide use in other control tasks, ranging from DMA scheduling to NAND Flash and directory control. Unfortunately, the stringent latency and throughput requirements of modern DDRx devices have rendered such programmability largely impractical, confining DDRx controllers to fixed-function hardware. This article presents the instruction set architecture (ISA) and hardware implementation of PARDIS, a programmable memory controller that can meet the performance requirements of a high-speed DDRx interface. The proposed controller is evaluated by mapping previously proposed DRAM scheduling, address mapping, refresh scheduling, and power management algorithms onto PARDIS. Simulation results show that the average performance of PARDIS comes within 8% of fixed-function hardware for each of these techniques; moreover, by enabling application-specific optimizations, PARDIS improves system performance by 6 to 17% and reduces DRAM energy by 9 to 22% over four existing memory controllers. © 2013 ACM.",Memory controller; Programmable,Computer architecture; Dynamic random access storage; Energy management; Hardware; Mapping; Scheduling; Application-specific optimizations; Hardware implementations; Instruction set architecture; Memory controller; Performance requirements; Power management algorithms; Programmable; Resource Constraint; Controllers
CORFU: A distributed shared log,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891801598&doi=10.1145%2f2535930&partnerID=40&md5=779794238de3f51c65b953e2548889e2,"CORFU is a global log which clients can append-to and read-from over a network. Internally, CORFU is distributed over a cluster of machines in such a way that there is no single I/O bottleneck to either appends or reads. Data is fully replicated for fault tolerance, and a modest cluster of about 16-32 machines with SSD drives can sustain 1 million 4-KByte operations per second. The CORFU log enabled the construction of a variety of distributed applications that require strong consistency at high speeds, such as databases, transactional key-value stores, replicated state machines, and metadata services. © 2013 ACM.",,Digital storage; Distributed applications; Key-value stores; Metadata services; State machine; Strong consistency; Distributed database systems
Exploring the tradeoffs between programmability and efficiency in data-parallel accelerators,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883579996&doi=10.1145%2f2491464&partnerID=40&md5=de41ee1aeeab9e8341ec6fcc7da13802,"We present a taxonomy and modular implementation approach for data-parallel accelerators, including the MIMD, vector-SIMD, subword-SIMD, SIMT, and vector-thread (VT) architectural design patterns. We introduce Maven, a new VT microarchitecture based on the traditional vector-SIMD microarchitecture, that is considerably simpler to implement and easier to program than previous VT designs. Using an extensive design-space exploration of full VLSI implementations of many accelerator design points, we evaluate the varying tradeoffs between programmability and implementation efficiency among the MIMD, vector-SIMD, and VT patterns on a workload of compiled microbenchmarks and application kernels. We find the vector cores provide greater efficiency than the MIMD cores, even on fairly irregular kernels. Our results suggest that the Maven VT microarchitecture is superior to the traditional vector-SIMD architecture, providing both greater efficiency and easier programmability. © 2013 ACM.",,Commerce; Computer architecture; Design; Efficiency; Space research; Accelerator design; Data parallel; Design space exploration; Micro architectures; Micro-benchmarks; Modular implementation; Programmability; VLSI implementation; Vectors
Protocol responsibility offloading to improve tcp throughput in virtualized environments,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883590327&doi=10.1145%2f2491463&partnerID=40&md5=c13265684de0749f6c7842353444805e,"Virtualization is a key technology that powers cloud computing platforms such as Amazon EC2. Virtual machine (VM) consolidation, where multiple VMs share a physical host, has seen rapid adoption in practice, with increasingly large numbers of VMs per machine and per CPU core. Our investigations, however, suggest that the increasing degree of VM consolidation has serious negative effects on the VMs' TCP performance. As multiple VMs share a given CPU, the scheduling latencies, which can be in the order of tens of milliseconds, substantially increase the typically submillisecond round-trip times (RTTs) for TCP connections in a datacenter, causing significant degradation in throughput. In this article, we propose a lightweight solution, called vPRO, that (a) offloads the VM's TCP congestion control function to the driver domain to improve TCP transmit performance; and (b) offloads TCP acknowledgment functionality to the driver domain to improve the TCP receive performance. Our evaluation of a vPRO prototype on Xen suggests that vPRO substantially improves TCP receive and transmit throughputs with minimal per-packet CPU overhead. We further show that the higher TCP throughput leads to improvement in application-level performance, via experiments with Apache Olio, a Web 2.0 cloud application, and Intel MPI benchmark. © 2013 ACM.",Cloud computing; Datacenters; TCP; Virtualization,Cloud computing; Microprocessor chips; Throughput; Virtual reality; Application-level performance; Cloud applications; Cloud computing platforms; Data centers; TCP; TCP congestion control; Virtualizations; Virtualized environment; Transmission control protocol
Spanner: Google's globally distributed database,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883562045&doi=10.1145%2f2491245&partnerID=40&md5=59e3215ba5123e91f21414787d082ff4,"Spanner is Google's scalable, multiversion, globally distributed, and synchronously replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This article describes how Spanner is structured, its feature set, the rationale underlying various design decisions, and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: nonblocking reads in the past, lockfree snapshot transactions, and atomic schema changes, across all of Spanner. © 2013 ACM.",Concurrency control; Distributed databases; Replication; Time management; Transactions,Computer science; Computer systems; Design decisions; Distributed database; Distributed transaction; Replicated database; Replication; Schema changes; Time management; Transactions; Concurrency control
TritonSort: A balanced and energy-efficient large-scale sorting system,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874817897&doi=10.1145%2f2427631.2427634&partnerID=40&md5=2e7910a7558f05924c5b38dedf812b5f,"We present TritonSort, a highly efficient, scalable sorting system. It is designed to process large datasets, and has been evaluated against as much as 100TB of input data spread across 832 disks in 52 nodes at a rate of 0.938TB/min. When evaluated against the annual Indy GraySort sorting benchmark, TritonSort is 66% better in absolute performance and has over six times the per-node throughput of the previous record holder. When evaluated against the 100TB Indy JouleSort benchmark, TritonSort sorted 9703 records/Joule. In this article, we describe the hardware and software architecture necessary to operate TritonSort at this level of efficiency. Through careful management of system resources to ensure cross-resource balance, we are able to sort data at approximately 80% of the disks' aggregate sequential write speed. We believe the work holds a number of lessons for balanced system design and for scale-out architectures in general. While many interesting systems are able to scale linearly with additional servers, per-server performance can lag behind per-server capacity by more than an order of magnitude. Bridging the gap between high scalability and high performance would enable either significantly less expensive systems that are able to do the same work or provide the ability to address significantly larger problem sets with the same infrastructure. © 2013 ACM.",Balanced systems; Data-intensive computing; Sorting; System optimization,Benchmarking; Sorting; Absolute performance; Balanced system designs; Balanced systems; Careful management; Data-intensive computing; Hardware and software architectures; Scale-out architectures; System optimizations; Information management
Aggressive datacenter power provisioning with batteries,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874832907&doi=10.1145%2f2427631.2427633&partnerID=40&md5=b37f36c5ec78742bd6d087e787848c38,"Datacenters spend $10-25 per watt in provisioning their power infrastructure, regardless of the watts actually consumed. Since peak power needs arise rarely, provisioning power infrastructure for them can be expensive. One can, thus, aggressively underprovision infrastructure assuming that simultaneous peak draw across all equipment will happen rarely. The resulting nonzero probability of emergency events where power needs exceed provisioned capacity, however small, mandates graceful reaction mechanisms to cap the power draw instead of leaving it to disruptive circuit breakers/fuses. Existing strategies for power capping use temporal knobs local to a server that throttle the rate of execution (using power modes), and/or spatial knobs that redirect/migrate excess load to regions of the datacenter with more power headroom. We show these mechanisms to have performance degrading ramifications, and propose an entirely orthogonal solution that leverages existing UPS batteries to temporarily augment the utility supply during emergencies.We build an experimental prototype to demonstrate such power capping on a cluster of 8 servers, each with an individual battery, and implement several online heuristics in the context of different datacenter workloads to evaluate their effectiveness in handling power emergencies. We show that our battery-based solution can: (i) handle emergencies of short durations on its own, (ii) supplement existing reaction mechanisms to enhance their efficacy for longer emergencies, and (iii) create more slack for shifting applications temporarily to nonpeak durations. © 2013 ACM.",Batteries; Cap-ex; Datacenters; Peak power; Peak shaving; Provisioning; Stored energy; UPS,Power supply circuits; Solar cells; Uncertainty analysis; Cap-ex; Data centers; Peak power; Peak shaving; Provisioning; Stored energy; UPS; Uninterruptible power systems
Efficient reuse distance analysis of multicore scaling for loop-based parallel programs,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874865302&doi=10.1145%2f2427631.2427632&partnerID=40&md5=430b3700fb8026ea794848197bb608c2,"Reuse Distance (RD) analysis is a powerful memory analysis tool that can potentially help architects study multicore processor scaling. One key obstacle, however, is that multicore RD analysis requires measuring Concurrent Reuse Distance (CRD) and Private-LRU-stack Reuse Distance (PRD) profiles across threadinterleaved memory reference streams. Sensitivity to memory interleaving makes CRD and PRD profiles architecture dependent, preventing them from analyzing different processor configurations. For loop-based parallel programs, CRD and PRD profiles shift coherently across RD values with core count scaling because interleaving threads are symmetric. Simple techniques can predict such shifting, making the analysis of numerous multicore configurations from a small set of CRD and PRD profiles feasible. Given the ubiquity of parallel loops, such techniques will be extremely valuable for studying future large multicore designs. This article investigates using RD analysis to efficiently analyze multicore cache performance for loopbased parallel programs, making several contributions. First, we provide an in-depth analysis on how CRD and PRD profiles change with core count scaling. Second, we develop techniques to predict CRD and PRD profile scaling, in particular employing reference groups [Zhong et al. 2003] to predict coherent shift, demonstrating 90% or greater prediction accuracy. Third, our CRD and PRD profile analyses define two application parameters with architectural implications: Ccore is the minimum shared cache capacity that ""contains"" locality degradation due to core count scaling, and Cshare is the capacity at which shared caches begin to provide a cache-miss reduction compared to private caches. And fourth, we apply CRD and PRD profiles to analyze multicore cache performance. When combined with existing problem scaling prediction, our techniques can predict shared LLC MPKI (private L2 cache MPKI) to within 10.7% (13.9%) of simulation across 1,728 (1,440) configurations using only 36 measured CRD (PRD) profiles. © 2013 ACM.",Cache performance; Chip multiprocessors; Reuse distance,Computer architecture; Microprocessor chips; Parallel architectures; Application parameters; Cache performance; Chip Multiprocessor; Existing problems; Multi-core processor; Prediction accuracy; Reuse distance; Scaling prediction; Forecasting
Parametric content-based publish/subscribe,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885661509&doi=10.1145%2f2465346.2465347&partnerID=40&md5=f8a90e6a8860c23b263c4c6bafd68cd9,"Content-based publish/subscribe (CPS) is an appealing abstraction for building scalable distributed systems, e.g., message boards, intrusion detectors, or algorithmic stock trading platforms. Recently, CPS extensions have been proposed for location-based services like vehicular networks, mobile social networking, and so on. Although current CPS middleware systems are dynamic in the way they support the joining and leaving of publishers and subscribers, they fall short in supporting subscription adaptations. These are becoming increasingly important across many CPS applications. In algorithmic high frequency trading, for instance, stock price thresholds that are of interest to a trader change rapidly, and gains directly hinge on the reaction time to relevant fluctuations rather than fixed values. In location-aware applications, a subscription is a function of the subscriber location (e.g. GPS coordinates), which inherently changes during motion. The common solution for adapting a subscription consists of a resubscription, where a new subscription is issued and the superseded one canceled. This incurs substantial overhead in CPS middleware systems, and leads to missed or duplicated events during the transition. In this article, we explore the concept of parametric subscriptions for capturing subscription adaptations. We discuss desirable and feasible guarantees for corresponding support, and propose novel algorithms for updating routing mechanisms effectively and efficiently in classic decentralized CPS broker overlay networks. Compared to resubscriptions, our algorithms significantly improve the reaction time to subscription updates without hampering throughput or latency under high update rates. We also propose and evaluate approximation techniques to detect and mitigate pathological cases of high frequency subscription oscillations, which could significantly decrease the throughput of CPS systems thereby affecting other subscribers. We analyze the benefits of our support through implementations of our algorithms in two CPS systems, and by evaluating our algorithms on two different application scenarios. © 2013 ACM.",Content-based; Dynamic; Parametric; Publish/subscribe; Subscription oscillations,Commerce; Distributed database systems; Dynamics; Financial markets; Location; Location based services; Middleware; Network security; Reaction rates; Telecommunication services; Approximation techniques; Content-based; High-frequency trading; Location-aware application; Parametric; Publish/subscribe; Relevant fluctuations; Subscription oscillations; Electronic trading
Optimizing storage performance for VM-based mobile computing,2013,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885607093&doi=10.1145%2f2465346.2465348&partnerID=40&md5=58038436a20706b3bfa28dcac42f3ffc,"This article investigates the transient use of free local storage for improving performance in VM-based mobile computing systems implemented as thick clients on host PCs. We use the term TransientPC systems to refer to these types of systems. The solution we propose, called TransPart, uses the higher-performing local storage of host hardware to speed up performance-critical operations. Our solution constructs a virtual storage device on demand (which we call transient storage) by borrowing free disk blocks from the host's storage. In this article, we present the design, implementation, and evaluation of a TransPart prototype, which requires no modifications to the software or hardware of a host computer. Experimental results confirm that TransPart offers low overhead and startup cost, while improving user experience. © 2013 ACM.",Disk borrowing; File system; Free block borrowing; Mobile computing; Opportunistic mobile computing; Performance optimization; Pervasive computing; Storage; Trans Part; Transient storage; Virtual machine; Virtualization; VM,Energy storage; Mobile computing; Ubiquitous computing; User experience; Virtual storage; Virtualization; Disk borrowing; File systems; Free block borrowing; Performance optimizations; Trans Part; Transient storage; Virtual machine
Quantifying the mismatch between emerging scale-out applications and modern processors,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870520103&doi=10.1145%2f2382553.2382557&partnerID=40&md5=8e69981bffbc5ddfb3284e5cae0ffe56,"Emerging scale-out workloads require extensive amounts of computational resources. However, data centers using modern server hardware face physical constraints in space and power, limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads. In this work, we introduce CloudSuite, a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads, finding that today's predominant processor microarchitecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors, particularly in the organization of instruction and data memory systems and the processor core microarchitecture. Moreover, while today's predominant microarchitecture is inefficient when executing scale-out workloads, we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work, we identify the key microarchitectural needs of scale-out workloads, calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers. © 2012 ACM.",Design; Measurement; Performance,Computational efficiency; Computer architecture; Design; Hardware; Measurements; Benchmark suites; Computational density; Computational resources; Data centers; Data memory; Micro architectures; Modern processors; Performance; Performance counters; Physical constraints; Power efficiency; Processor cores; Server processors; Computer hardware
"Autoscale: Dynamic, robust capacity management for multi-tier data centers",2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870549803&doi=10.1145%2f2382553.2382556&partnerID=40&md5=3ded8d0afef8899910ca0e803c037108,"Energy costs for data centers continue to rise, already exceeding $15 billion yearly. Sadly much of this power is wasted. Servers are only busy 10-30% of the time on average, but they are often left on, while idle, utilizing 60% or more of peak power when in the idle state. We introduce a dynamic capacity management policy, AutoScale, that greatly reduces the number of servers needed in data centers driven by unpredictable, time-varying load, while meeting response time SLAs. AutoScale scales the data center capacity, adding or removing servers as needed. AutoScale has two key features: (i) it autonomically maintains just the right amount of spare capacity to handle bursts in the request rate; and (ii) it is robust not just to changes in the request rate of real-world traces, but also request size and server efficiency. We evaluate our dynamic capacity management approach via implementation on a 38-server multi-tier data center, serving a web site of the type seen in Facebook or Amazon, with a key-value store workload. We demonstrate that AutoScale vastly improves upon existing dynamic capacity management policies with respect to meeting SLAs and robustness. © 2012 ACM.",Data centers; Power management; Resource provisioning,Energy management; Auto-scale; Data centers; Dynamic capacity; Energy cost; Facebook; Key feature; Multi-tier; Peak power; Power managements; Resource provisioning; Robust capacity; Spare capacity; Time varying loads; Digital storage
Bringing virtualization to the x86 architecture with the original VMware workstation,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870556673&doi=10.1145%2f2382553.2382554&partnerID=40&md5=57c71eeb82d24c060504d6da37e8faf8,"This article describes the historical context, technical challenges, and main implementation techniques used by VMware Workstation to bring virtualization to the x86 architecture in 1999. Although virtual machine monitors (VMMs) had been around for decades, they were traditionally designed as part of monolithic, single-vendor architectures with explicit support for virtualization. In contrast, the x86 architecture lacked virtualization support, and the industry around it had disaggregated into an ecosystem, with different vendors controlling the computers, CPUs, peripherals, operating systems, and applications, none of them asking for virtualization. We chose to build our solution independently of these vendors. As a result, VMware Workstation had to deal with new challenges associated with (i) the lack of virtualization support in the x86 architecture, (ii) the daunting complexity of the architecture itself, (iii) the need to support a broad combination of peripherals, and (iv) the need to offer a simple user experience within existing environments. These new challenges led us to a novel combination of well-known virtualization techniques, techniques from other domains, and new techniques. VMware Workstation combined a hosted architecture with a VMM. The hosted architecture enabled a simple user experience and offered broad hardware compatibility. Rather than exposing I/O diversity to the virtual machines, VMware Workstation also relied on software emulation of I/O devices. The VMM combined a trap-and-emulate direct execution engine with a system-level dynamic binary translator to efficiently virtualize the x86 architecture and support most commodity operating systems. By relying on x86 hardware segmentation as a protection mechanism, the binary translator could execute translated code at near hardware speeds. The binary translator also relied on partial evaluation and adaptive retranslation to reduce the overall overheads of virtualization. Written with the benefit of hindsight, this article shares the key lessons we learned from building the original system and from its later evolution. © 2012 ACM.",Dynamic binary translation; Hypervisors; Virtual machine monitors; Virtualization; VMM; X86,Computer hardware; Computer operating systems; Hardware; Program processors; Virtual reality; Dynamic binary translation; Hypervisors; Virtual machine monitors; Virtualizations; VMM; X86; Computer architecture
Fay: Extensible distributed tracing from kernels to clusters,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870561105&doi=10.1145%2f2382553.2382555&partnerID=40&md5=e9e37958e13dccce1c6bd50c340d4323,"Fay is a flexible platform for the efficient collection, processing, and analysis of software execution traces. Fay provides dynamic tracing through use of runtime instrumentation and distributed aggregation within machines and across clusters. At the lowest level, Fay can be safely extended with new tracing primitives, including even untrusted, fully optimized machine code, and Fay can be applied to running user-mode or kernel-mode software without compromising system stability. At the highest level, Fay provides a unified, declarative means of specifying what events to trace, as well as the aggregation, processing, and analysis of those events. We have implemented the Fay tracing platform for Windows and integrated it with two powerful, expressive systems for distributed programming. Our implementation is easy to use, can be applied to unmodified production systems, and provides primitives that allow the overhead of tracing to be greatly reduced, compared to previous dynamic tracing platforms. To show the generality of Fay tracing, we reimplement, in experiments, a range of tracing strategies and several custom mechanisms from existing tracing frameworks. Fay shows that modern techniques for high-level querying and data-parallel processing of disagreggated data streams are well suited to comprehensive monitoring of software execution in distributed systems. Revisiting a lesson from the late 1960s [Deutsch and Grant 1971], Fay also demonstrates the efficiency and extensibility benefits of using safe, statically verified machine code as the basis for low-level execution tracing. Finally, Fay establishes that, by automatically deriving optimized query plans and code for safe extensions, the expressiveness and performance of high-level tracing queries can equal or even surpass that of specialized monitoring tools. © 2012 ACM.",Design; Experimentation; Languages; Measurement; Performance,Design; Experiments; Measurements; Optimization; Query languages; System stability; Trace analysis; Data parallel; Data stream; Distributed programming; Distributed systems; Distributed tracing; Execution tracing; Experimentation; Flexible platforms; Machine codes; Monitoring tools; Performance; Production system; Runtimes; Software execution; Tracing framework; Distributed computer systems
Power limitations and dark silicon challenge the future of multicore,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866339572&doi=10.1145%2f2324876.2324879&partnerID=40&md5=80887306e9f0da3a5104c2b2861ecc59,"Since 2004, processor designers have increased core counts to exploit Moore's Law scaling, rather than focusing on single-core performance. The failure of Dennard scaling, to which the shift to multicore parts is partially a response, may soon limit multicore scaling just as single-core scaling has been curtailed. This paper models multicore scaling limits by combining device scaling, single-core scaling, and multicore scaling to measure the speedup potential for a set of parallel workloads for the next five technology generations. For device scaling, we use both the ITRS projections and a set of more conservative device scaling parameters. To model single-core scaling, we combine measurements from over 150 processors to derive Pareto-optimal frontiers for area/performance and power/performance. Finally, to model multicore scaling, we build a detailed performance model of upper-bound performance and lower-bound core power. The multicore designs we study include single-threaded CPU-like and massively threaded GPU-like multicore chip organizations with symmetric, asymmetric, dynamic, and composed topologies. The study shows that regardless of chip organization and topology, multicore scaling is power limited to a degree not widely appreciated by the computing community. Even at 22 nm (just one year from now), 21% of a fixed-size chip must be powered off, and at 8 nm, this number grows to more than 50%. Through 2024, only 7.9× average speedup is possible across commonly used parallel workloads for the topologies we study, leaving a nearly 24-fold gap from a target of doubled performance per generation. © 2012 ACM.",Dark silicon; Modeling; Multicore; Power; Technology scaling,Models; Topology; Computing community; Device-scaling; Moore's Law; Multi core; Multicore chips; Multicore design; Paper models; Pareto-optimal frontiers; Performance Model; Power; Power limitations; Processor designers; Scaling limits; Single-threaded; Technology scaling; Parallel processing systems
"The design, implementation, and evaluation of cells: A virtual smartphone architecture",2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866316857&doi=10.1145%2f2324876.2324877&partnerID=40&md5=fd59ed179461190803c8cb9109e2a95b,"Smartphones are increasingly ubiquitous, and many users carry multiple phones to accommodate work, personal, and geographic mobility needs. We present Cells, a virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical cellphone in an isolated, secure manner. Cells introduces a usage model of having one foreground virtual phone and multiple background virtual phones. This model enables a new device namespace mechanism and novel device proxies that integrate with lightweight operating system virtualization to multiplex phone hardware across multiple virtual phones while providing native hardware device performance. Cells virtual phone features include fully accelerated 3D graphics, complete power management features, and full telephony functionality with separately assignable telephone numbers and caller ID support. We have implemented a prototype of Cells that supports multiple Android virtual phones on the same phone. Our performance results demonstrate that Cells imposes only modest runtime and memory overhead, works seamlessly across multiple hardware devices including Google Nexus 1 and Nexus S phones, and transparently runs Android applications at native speed without any modifications. © 2012 ACM.",Android; Smartphones; Virtualization,Cells; Cytology; Energy management; Hardware; Robots; Smartphones; Virtual reality; 3D graphics; Android; Caller ID; Cell phone; Hardware devices; Memory overheads; Mobility needs; Namespaces; New devices; Novel devices; Power managements; Runtimes; Telephone numbers; Usage models; Virtualizations; Telephone sets
A file is not a file: Understanding the I/O behavior of apple desktop applications,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866307312&doi=10.1145%2f2324876.2324878&partnerID=40&md5=5de714527e3a800edcf165ede045b4dd,"We analyze the I/O behavior of iBench, a new collection of productivity and multimedia application workloads. Our analysis reveals a number of differences between iBench and typical file-system workload studies, including the complex organization of modern files, the lack of pure sequential access, the influence of underlying frameworks on I/O patterns, the widespread use of file synchronization and atomic operations, and the prevalence of threads. Our results have strong ramifications for the design of next generation local and cloud-based storage systems. © 2012 ACM.",Application performance; File systems; Measurement; Trace study,Computer science; Measurements; Application performance; Atomic operation; Desktop applications; File synchronization; File systems; Multimedia applications; Sequential access; Storage systems; Trace study; Computer systems
A hierarchical thread scheduler and register file for energy-efficient throughput processors,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860598287&doi=10.1145%2f2166879.2166882&partnerID=40&md5=a06dce4b12889d2d7f51f6b9eaf4ed49,"Modern graphics processing units (GPUs) employ a large number of hardware threads to hide both function unit and memory access latency. Extreme multithreading requires a complex thread scheduler as well as a large register file, which is expensive to access both in terms of energy and latency. We present two complementary techniques for reducing energy on massively-threaded processors such as GPUs. First, we investigate a two-level thread scheduler that maintains a small set of active threads to hide ALU and local memory access latency and a larger set of pending threads to hide main memory latency. Reducing the number of threads that the scheduler must consider each cycle improves the scheduler's energy efficiency. Second, we propose replacing the monolithic register file found on modern designs with a hierarchical register file. We explore various trade-offs for the hierarchy including the number of levels in the hierarchy and the number of entries at each level. We consider both a hardware-managed caching scheme and a software-managed scheme, where the compiler is responsible for orchestrating all data movement within the register file hierarchy. Combined with a hierarchical register file, our two-level thread scheduler provides a further reduction in energy by only allocating entries in the upper levels of the register file hierarchy for active threads. Averaging across a variety of real world graphics and compute workloads, the active thread count can be reduced by a factor of 4 with minimal impact on performance and our most efficient three-level software-managed register file hierarchy reduces register file energy by 54%. © 2012 ACM.",Energy efficiency; Multithreading; Register file organization; Throughput computing,Computer graphics; Hardware; Multitasking; Program processors; Scheduling; Caching scheme; Data movements; Energy efficient; Function unit; Graphics processing units; Hardware threads; Local memories; Main memory; Memory access latency; Multi-threading; Number of threads; Register files; Three-level; Throughput computing; Energy efficiency
Fairness via source throttling: A configurable and high-performance fairness substrate for multicore memory systems,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860593743&doi=10.1145%2f2166879.2166881&partnerID=40&md5=3a5396c57d7f387c7657e568c5527e3b,"Cores in chip-multiprocessors (CMPs) share multiple memory subsystem resources. If resource sharing is unfair, some applications can be delayed significantly while others are unfairly prioritized. Previous research proposed separate fairness mechanisms for each resource. Such resource-based fairness mechanisms implemented independently in each resource can make contradictory decisions, leading to low fairness and performance loss. Therefore, a coordinated mechanism that provides fairness in the entire shared memory system is desirable. This article proposes a new approach that provides fairness in the entire shared memory system, thereby eliminating the need for and complexity of developing fairness mechanisms for each resource. Our technique, Fairness via Source Throttling (FST), estimates unfairness in the entire memory system. If unfairness is above a system-software-set threshold, FST throttles down cores causing unfairness by limiting the number of requests they create and the frequency at which they do. As such, our source-based fairness control ensures fairness decisions are made in tandem in the entire memory system. FST enforces thread priorities/weights, and enables system-software to enforce different fairness objectives in the memory system. Our evaluations show that FST provides the best system fairness and performance compared to three systems with state-of-the-art fairness mechanisms implemented in both shared caches and memory controllers. © 2012 ACM.",Chip-multiprocessors; Fairness; Memory system,Memory architecture; Chip Multiprocessor; Fairness; Fairness control; Memory controller; Memory subsystems; Memory systems; Multi core; Performance loss; Resource sharing; Shared cache; Shared memory system; System fairness; Three systems; Cache memory
Leveraging core specialization via os scheduling to improve performance on asymmetric multicore systems,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860593772&doi=10.1145%2f2166879.2166880&partnerID=40&md5=820d138ac7d8486dad712e18018ce211,"Asymmetric multicore processors (AMPs) consist of cores with the same ISA (instruction-set architecture), but different microarchitectural features, speed, and power consumption. Because cores with more complex features and higher speed typically use more area and consume more energy relative to simpler and slower cores, we must use these cores for running applications that experience significant performance improvements from using those features. Having cores of different types in a single system allows optimizing the performance/energy trade-off. To deliver this potential to unmodified applications, the OS scheduler must map threads to cores in consideration of the properties of both. Our work describes a Comprehensive scheduler for Asymmetric Multicore Processors (CAMP) that addresses shortcomings of previous asymmetryaware schedulers. First, previous schedulers catered to only one kind of workload properties that are crucial for scheduling on AMPs; either efficiency or thread-level parallelism (TLP), but not both. CAMP overcomes this limitation showing how using both efficiency and TLP in synergy in a single scheduling algorithm can improve performance. Second, most existing schedulers relying on models for estimating how much faster a thread executes on a ""fast"" vs. ""slow"" core (i.e., the speedup factor) were specifically designed for AMP systems where cores differ only in clock frequency. However, more realistic AMP systems include cores that differ more significantly in their features. To demonstrate the effectiveness of CAMP on more realistic scenarios, we augmented the CAMP scheduler with a model that predicts the speedup factor on a real AMP prototype that closely matches future asymmetric systems. © 2012 ACM.",Asymmetric multicore; Operating systems; Scheduling,Computer architecture; Computer operating systems; Asymmetric multicore; Asymmetric system; Clock frequency; Instruction set architecture; Performance improvements; Realistic scenario; Running applications; Speed-up factors; Thread-level parallelism; Scheduling
"The S2E platform: Design, implementation, and applications",2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859090239&doi=10.1145%2f2110356.2110358&partnerID=40&md5=24e9f2ef4a17c6bfa1ed8c927aa79858,"This article presents S 2E, a platform for analyzing the properties and behavior of software systems, along with its use in developing tools for comprehensive performance profiling, reverse engineering of proprietary software, and automated testing of kernel-mode and user-mode binaries. Conceptually, S 2E is an automated path explorer with modular path analyzers: the explorer uses a symbolic execution engine to drive the target system down all execution paths of interest, while analyzers measure and/or check properties of each such path. S 2E users can either combine existing analyzers to build custom analysis tools, or they can directly use S 2E's APIs. S 2E's strength is the ability to scale to large systems, such as a full Windows stack, using two new ideas: Selective symbolic execution, a way to automatically minimize the amount of code that has to be executed symbolically given a target analysis, and execution consistency models, a way to make principled performance/accuracy trade-offs during analysis. These techniques give S 2E three key abilities: To simultaneously analyze entire families of execution paths instead of just one execution at a time; to perform the analyses in-vivo within a real software stack-user programs, libraries, kernel, drivers, etc.-instead of using abstract models of these layers; and to operate directly on binaries, thus being able to analyze even proprietary software. © 2012 ACM.",Analysis; Profiling; Symbolic execution; Testing,Reverse engineering; Testing; Abstract models; Analysis; Analysis tools; Automated path; Automated testing; Comprehensive performance; Consistency model; Execution paths; In-vivo; Large system; Profiling; Proprietary software; Real softwares; Software systems; Symbolic execution; Target analysis; Target systems; Software testing
Introduction to special issue APLOS 2011,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859050136&doi=10.1145%2f2110356.2110357&partnerID=40&md5=fe5545402e1cf36da8a0bc02069f2202,[No abstract available],,
Improving software diagnosability via log enhancement,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859091978&doi=10.1145%2f2110356.2110360&partnerID=40&md5=2750960871b316457c4cc771dc9de392,"Diagnosing software failures in the field is notoriously difficult, in part due to the fundamental complexity of troubleshooting any complex software system, but further exacerbated by the paucity of information that is typically available in the production setting. Indeed, for reasons of both overhead and privacy, it is common that only the run-time log generated by a system (e.g., syslog) can be shared with the developers. Unfortunately, the ad-hoc nature of such reports are frequently insufficient for detailed failure diagnosis. This paper seeks to improve this situation within the rubric of existing practice. We describe a tool, LogEnhancer that automatically ""enhances"" existing logging code to aid in future post-failure debugging. We evaluate LogEnhancer on eight large, real-world applications and demonstrate that it can dramatically reduce the set of potential root failure causes that must be considered while imposing negligible overheads. © 2012 ACM.",Debugging; Failure diagnostics; Log; Program analysis; Software diagnosability,Computer debugging; Computer science; Computer systems; Complex software systems; Diagnosability; Failure Diagnosis; Failure diagnostics; Log; Program analysis; Real-world application; Runtimes; Software failure; Program debugging
Doubleplay: Parallelizing sequential logging and replay,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859041564&doi=10.1145%2f2110356.2110359&partnerID=40&md5=d6257922ef508c1617e1185d8709f5f3,"Deterministic replay systems record and reproduce the execution of a hardware or software system. In contrast to replaying execution on uniprocessors, deterministic replay on multiprocessors is very challenging to implement efficiently because of the need to reproduce the order of or the values read by shared memory operations performed by multiple threads. In this paper, we present DoublePlay, a new way to efficiently guarantee replay on commodity multiprocessors. Our key insight is that one can use the simpler and faster mechanisms of single-processor record and replay, yet still achieve the scalability offered by multiple cores, by using an additional execution to parallelize the record and replay of an application. DoublePlay timeslices multiple threads on a single processor, then runs multiple time intervals (epochs) of the program concurrently on separate processors. This strategy, which we call uniparallelism, makes logging much easier because each epoch runs on a single processor (so threads in an epoch never simultaneously access the same memory) and different epochs operate on different copies of the memory. Thus, rather than logging the order of shared-memory accesses, we need only log the order in which threads in an epoch are timesliced on the processor. DoublePlay runs an additional execution of the program on multiple processors to generate checkpoints so that epochs run in parallel. We evaluate DoublePlay on a variety of client, server, and scientific parallel benchmarks; with spare cores, DoublePlay reduces logging overhead to an average of 15% with two worker threads and 28% with four threads. © 2012 ACM.",Deterministic replay; Uniparallelism,Multiprocessing systems; Well logging; Deterministic replay; Multiple processors; Multiple threads; Parallel benchmarks; Parallelizing; Record-and-replay; Shared memories; Single processors; Software systems; Time interval; Uniparallelism; Uniprocessors; Program processors
A declarative language approach to device configuration,2012,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859065928&doi=10.1145%2f2110356.2110361&partnerID=40&md5=90325fb210b16fbb24036b650c8ddcef,"C remains the language of choice for hardware programming (device drivers, bus configuration, etc.): it is fast, allows low-level access, and is trusted by OS developers. However, the algorithms required to configure and reconfigure hardware devices and interconnects are becoming more complex and diverse, with the added burden of legacy support, ""quirks,"" and hardware bugs to work around. Even programming PCI bridges in a modern PC is a surprisingly complex problem, and is getting worse as new functionality such as hotplug appears. Existing approaches use relatively simple algorithms, hard-coded in C and closely coupled with low-level register access code, generally leading to suboptimal configurations. We investigate the merits and drawbacks of a new approach: separating hardware configuration logic (algorithms to determine configuration parameter values) from mechanism (programming device registers). The latter we keep in C, and the former we encode in a declarative programming language with constraintsatisfaction extensions. As a test case, we have implemented full PCI configuration, resource allocation, and interrupt assignment in the Barrelfish research operating system, using a concise expression of efficient algorithms in constraint logic programming. We show that the approach is tractable, and can successfully configure a wide range of PCs with competitive runtime cost. Moreover, it requires about half the code of the C-based approach in Linux while offering considerably more functionality. Additionally it easily accommodates adaptations such as hotplug, fixed regions, and quirks. © 2012 ACM.",Constraint logic programming; Eclipse CLP; Hardware programming; PCI configuration,Algorithms; Computer operating systems; Computer peripheral equipment; Hardware; Interfaces (computer); Logic programming; Microcomputers; Complex problems; Configuration parameters; Constraint Logic Programming; Declarative Languages; Declarative programming language; Device configurations; Device Driver; Eclipse CLP; Efficient algorithm; Hardware bug; Hardware configurations; Hardware devices; PCI configuration; Register access; Runtime costs; SIMPLE algorithm; Test case; C (programming language)
EventGuard: A system architecture for securing publish-subscribe networks,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863145281&doi=10.1145%2f2063509.2063510&partnerID=40&md5=662a3c160633d45911101299ad08126f,"Publish-subscribe (pub-sub) is an emerging paradigm for building a large number of distributed systems. A wide area pub-sub system is usually implemented on an overlay network infrastructure to enable information dissemination from publishers to subscribers. Using an open overlay network raises several security concerns such as: confidentiality and integrity, authentication, authorization and Denial-of-Service (DoS) attacks. In this article we present EventGuard, a framework for building secure wide-area pub-sub systems. The EventGuard architecture is comprised of three key components: (1) a suite of security guards that can be seamlessly plugged-into a content-based pub-sub system, (2) a scalable key management algorithm to enforce access control on subscribers, and (3) a resilient pub-sub network design that is capable of scalable routing, handling message dropping-based DoS attacks, and node failures. The design of EventGuard mechanisms aims at providing security guarantees while maintaining the system's overall simplicity, scalability, and performance metrics. We describe an implementation of the EventGuard pub-sub system to show that EventGuard is easily stackable on any content-based pub-sub core. We present detailed experimental results that quantify the overhead of the EventGuard pub-sub system and demonstrate its resilience against various attacks. © 2011 ACM.",Access control; DoS attacks; Performance and scalability; Publish-Subscribe system; Resilient overlay network,Access control; Authentication; Computer crime; Network security; Overlay networks; Publishing; Scalability; Content-based; Denial of service attacks; Distributed systems; DoS attacks; Key component; Key management; Network design; Network infrastructure; Node failure; Performance metrics; Publish-subscribe; Publish-subscribe systems; Resilient overlay networks; Scalable routing; Security guards; System architectures; Various attacks; Wide area; Network architecture
Depot: Cloud storage with minimal trust,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863181209&doi=10.1145%2f2063509.2063512&partnerID=40&md5=06c4d343347a0ec170a63ff95841173e,"This article describes the design, implementation, and evaluation of Depot, a cloud storage system that minimizes trust assumptions. Depot tolerates buggy or malicious behavior by any number of clients or servers, yet it provides safety and liveness guarantees to correct clients. Depot provides these guarantees using a two-layer architecture. First, Depot ensures that the updates observed by correct nodes are consistently ordered under Fork-Join-Causal consistency (FJC). FJC is a slight weakening of causal consistency that can be both safe and live despite faulty nodes. Second, Depot implements protocols that use this consistent ordering of updates to provide other desirable consistency, staleness, durability, and recovery properties. Our evaluation suggests that the costs of these guarantees are modest and that Depot can tolerate faults and maintain good availability, latency, overhead, and staleness even when significant faults occur. © 2011 ACM.",Byzantine fault tolerance; Cloud storage; Fork consistency; Fork-Join-Causal (FJC) consistency,Computer science; Computer systems; Byzantine fault tolerance; Faulty node; Fork consistency; Fork-Join-Causal (FJC) consistency; Liveness; Malicious behavior; Recovery properties; Storage systems; Trust assumptions; Two layers; Fault tolerance
Efficient testing of recovery code using fault injection,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857182468&doi=10.1145%2f2063509.2063511&partnerID=40&md5=66603b9f1f4760de24572fa186826460,"A critical part of developing a reliable software system is testing its recovery code. This code is traditionally difficult to test in the lab, and, in the field, it rarely gets to run; yet, when it does run, it must execute flawlessly in order to recover the system from failure. In this article, we present a library-level fault injection engine that enables the productive use of fault injection for software testing. We describe automated techniques for reliably identifying errors that applications may encounter when interacting with their environment, for automatically identifying high-value injection targets in program binaries, and for producing efficient injection test scenarios. We present a framework for writing precise triggers that inject desired faults, in the form of error return codes and corresponding side effects, at the boundary between applications and libraries. These techniques are embodied in LFI, a new fault injection engine we are distributing http://lfi.epfl.ch. This article includes a report of our initial experience using LFI. Most notably, LFI found 12 serious, previously unreported bugs in the MySQL database server, Git version control system, BIND name server, Pidgin IM client, and PBFT replication system with no developer assistance and no access to source code. LFI also increased recovery-code coverage from virtually zero up to 60% entirely automatically without requiring new tests or human involvement. © 2011 ACM.",Automated testing; Fault injection,Codes (symbols); Software testing; Automated techniques; Automated testing; Critical parts; Fault injection; Fault injection engines; Injection test; MySQL database; Name servers; Program binary; Replication systems; Side effect; Software systems; Source codes; Version control system; Recovery
Scheduling real-time garbage collection on uniprocessors,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052354777&doi=10.1145%2f2003690.2003692&partnerID=40&md5=d67bd1117a4444a6e1020907bac55a16,"Managed languages such as Java and C# are increasingly being considered for hard real-time applications because of their productivity and software engineering advantages. Automatic memory management, or garbage collection, is a key enabler for robust, reusable libraries, yet remains a challenge for analysis and implementation of real-time execution environments. This article comprehensively compares leading approaches to hard real-time garbage collection. There are many design decisions involved in selecting a real-time garbage collection algorithm. For time-based garbage collectors on uniprocessors one must choose whether to use periodic, slack-based or hybrid scheduling. A significant impediment to valid experimental comparison of such choices is that commercial implementations use completely different proprietary infrastructures. We present Minuteman, a framework for experimenting with real-time collection algorithms in the context of a high-performance execution environment for real-time Java. We provide the first comparison of the approaches, both experimentally using realistic workloads, and analytically in terms of schedulability. © 2011 ACM.",Joint scheduling; Real-time garbage collection,Algorithms; Computer software; Real time systems; Refuse collection; Waste disposal; Automatic memory management; Commercial implementation; Design decisions; Execution environments; Experimental comparison; Garbage collection; Garbage collectors; Hard real-time; Hybrid scheduling; Joint scheduling; Real time execution; Real-time collection; Real-time garbage collection; Real-time Java; Reusable library; Schedulability; Uniprocessors; Java programming language
On the design of perturbation-resilient atomic commit protocols for mobile transactions,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052355579&doi=10.1145%2f2003690.2003691&partnerID=40&md5=f2aeb90ad383016c5250e3feb0ee2826,"Distributed mobile transactions utilize commit protocols to achieve atomicity and consistent decisions. This is challenging, as mobile environments are typically characterized by frequent perturbations such as network disconnections and node failures. On one hand environmental constraints onmobile participants and wireless links may increase the resource blocking time of fixed participants. On the other hand frequent node and link failures complicate the design of atomic commit protocols by increasing both the transaction abort rate and resource blocking time. Hence, the deployment of classical commit protocols (such as two-phase commit) does not reasonably extend to distributed infrastructure-based mobile environments driving the need for perturbation-resilient commit protocols. In this article, we comprehensively consider and classify the perturbations of the wireless infrastructurebased mobile environment according to their impact on the outcome of commit protocols and on the resource blocking times. For each identified perturbation class a commit solution is provided. Consolidating these subsolutions, we develop a family of fault-tolerant atomic commit protocols that are tunable to meet the desired perturbation needs and provideminimized resource blocking times and optimized transaction commit rates. The framework is also evaluated using simulations and an actual testbed deployment. © 2011 ACM.",Dependability; Infrastructure-based wireless networks; Mobile database systems; Transaction design,Atoms; Database systems; Class A; Dependability; Environmental constraints; Fault-tolerant; Infrastructure-based wireless networks; Link failures; Mobile database systems; Mobile environments; Mobile transaction; Node failure; Resource blocking; Transaction design; Wireless link; Design
Mobile processors for energy-efficient web search,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052389252&doi=10.1145%2f2003690.2003693&partnerID=40&md5=ef3d58beb6ffc3bd20ec4545e8d0f704,"As cloud and utility computing spreads, computer architects must ensure continued capability growth for the data centers that comprise the cloud. Given megawatt scale power budgets, increasing data center capability requires increasing computing hardware energy efficiency. To increase the data center's capability for work, the work done per Joule must increase. We pursue this efficiency even as the nature of data center applications evolves. Unlike traditional enterprise workloads, which are typically memory or I/O bound, big data computation and analytics exhibit greater compute intensity. This article examines the efficiency of mobile processors as a means for data center capability. In particular, we compare and contrast the performance and efficiency of the Microsoft Bing search engine executing on the mobile-class Atom processor and the server-class Xeon processor. Bing implements statisticalmachine learning to dynamically rank pages, producing sophisticated search results but also increasing computational intensity. While mobile processors are energy-efficient, they exact a price for that efficiency. The Atom is 5× more energy-efficient than the Xeon when comparing queries per Joule. However, search queries on Atom encounter higher latencies, different page results, and diminished robustness for complex queries. Despite these challenges, quality-of-service is maintained for most, common queries. Moreover, as different computational phases of the search engine encounter different bottlenecks, we describe implications for future architectural enhancements, application tuning, and system architectures. After optimizing the Atom server platform, a large share of power and cost go toward processor capability. With optimized Atoms, more servers can fit in a given data center power budget. For a data center with 15MW critical load, Atom-based servers increase capability by 3.2× for Bing. © 2011 ACM.",Energy-efficient data centers; Mobile hardware architectures; Web search,Atoms; Budget control; Cloud computing; Computer hardware; Information retrieval; Optimization; Quality of service; Satellite communication systems; Search engines; User interfaces; Windows operating system; World Wide Web; Architectural enhancement; Complex queries; Computational intensity; Computer architects; Computing hardware; Critical load; Data centers; Data computation; Energy efficient; MicroSoft; Mobile hardware; Mobile processors; Power budgets; Search queries; Search results; Server platform; System architectures; Utility computing; Web searches; Xeon processors; Energy efficiency
"Management of multilevel, multiclient cache hierarchies with application hints",2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956087970&doi=10.1145%2f1963559.1963561&partnerID=40&md5=6a07716401707921e9f3a4dbae2ddbd0,"Multilevel caching, common in many storage configurations, introduces new challenges to traditional cache management: data must be kept in the appropriate cache and replication avoided across the various cache levels. Additional challenges are introduced when the lower levels of the hierarchy are shared by multiple clients. Sharing can have both positive and negative effects. While data fetched by one client can be used by another client without incurring additional delays, clients competing for cache buffers can evict each other's blocks and interfere with exclusive caching schemes. We present a global noncentralized, dynamic and informed management policy for multiple levels of cache, accessed by multiple clients. Our algorithm, MC2, combines local, per client management with a global, system-wide scheme, to emphasize the positive effects of sharing and reduce the negative ones. Our local management scheme, Karma, uses readily available information about the client's future access profile to save the most valuable blocks, and to choose the best replacement policy for them. The global scheme uses the same information to divide the shared cache space between clients, and to manage this space. Exclusive caching is maintained for nonshared data and is disabled when sharing is identified. Previous studies have partially addressed these challenges through minor changes to the storage interface. We show that all these challenges can in fact be addressed by combining minor interface changes with smart allocation and replacement policies. We show the superiority of our approach through comparison to existing solutions, including LRU, ARC, Multi Q, LRU-SP, and Demote, as well as a lower bound on optimal I/O response times. Our simulation results demonstrate better cache performance than all other solutions and up to 87% better performance than LRU on representative workloads. © 2011 ACM.",Cache; Hints; Multilevel,Cache; Cache hierarchies; Cache management; Cache performance; Caching scheme; Hints; Local management; Lower bounds; Management policy; Multi-level caching; Multilevel; Multiple clients; Multiple levels; Positive and negative effect; Positive effects; Replacement policy; Response time; Shared cache; Simulation result; Space between; Information management
DieCast: Testing distributed systems with an accurate scale model,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956098319&doi=10.1145%2f1963559.1963560&partnerID=40&md5=02c8530fef663ce2faa696d12f0e751c,"Large-scale network services can consist of tens of thousands of machines running thousands of unique software configurations spread across hundreds of physical networks. Testing such services for complex performance problems and configuration errors remains a difficult problem. Existing testing techniques, such as simulation or running smaller instances of a service, have limitations in predicting overall service behavior at such scales. Testing large services should ideally be done at the same scale and configuration as the target deployment, which can be technically and economically infeasible. We present DieCast, an approach to scaling network services in which we multiplex all of the nodes in a given service configuration as virtual machines across a much smaller number of physical machines in a test harness. We show how to accurately scale CPU, network, and disk to provide the illusion that each VM matches a machine in the original service in terms of both available computing resources and communication behavior. We present the architecture and evaluation of a system we built to support such experimentation and discuss its limitations. We show that for a variety of services-including a commercial high-performance cluster-based file system-and resource utilization levels, DieCast matches the behavior of the original service while using a fraction of the physical resources. © 2011 ACM.",Network emulation; Virtualization; Xen,Testing; Cluster-based; Communication behavior; Computing resource; Die-cast; Distributed systems; Large-scale network; Network emulation; Network services; Performance problems; Physical network; Physical resources; Resource utilizations; Scale models; Service configuration; Software configuration; Test harness; Testing technique; Virtual machines; Virtualizations; Xen; Software testing
Application-tailored I/O with streamline,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956128397&doi=10.1145%2f1963559.1963562&partnerID=40&md5=8aa114950760693be1fd4844f8e56d70,"Streamline is a stream-based OS communication subsystem that spans from peripheral hardware to userspace processes. It improves performance of I/O-bound applications (such as webservers and streaming media applications) by constructing tailor-made I/O paths through the operating system for each application at runtime. Path optimization removes unnecessary copying, context switching and cache replacement and integrates specialized hardware. Streamline automates optimization and only presents users a clear, concise job control language based on Unix pipelines. For backward compatibility Streamline also presents well known files, pipes and sockets abstractions. Observed throughput improvement over Linux 2.6.24 for networking applications is up to 30-fold, but two-fold is more typical. © 2011 ACM.",I/O buffering; Streams and filters; Zero-copy,Computer operating systems; Media streaming; Optimization; Backward compatibility; Cache replacement; Communication subsystems; Context switching; I/O buffering; Job control languages; Networking applications; Operating systems; Path optimizations; Runtimes; Specialized hardware; Streaming media applications; Streams and filters; Throughput improvement; Web servers; Zero-copy; Computer hardware description languages
The powernap server architecture,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952352441&doi=10.1145%2f1925109.1925112&partnerID=40&md5=cf9cc27b4e5ba7bdbedc5c2b6dc84ff0,"Data center power consumption is growing to unprecedented levels: the EPA estimates U.S. data centers will consume 100 billion kilowatt hours annually by 2011. Much of this energy is wasted in idle systems: in typical deployments, server utilization is below 30%,but idle servers still consume 60% of their peak power draw. Typical idle periods - thoughfrequent - last seconds or less, confounding simple energy-conservation approaches. In this article, we propose PowerNap, an energy-conservation approach where the entire system transitions rapidly between a high-performance active state and a near-zero-power idle statein response to instantaneous load. Rather than requiring fine-grained power-performance states and complex load-proportional operation from individual system components, PowerNapinstead calls for minimizing idle power and transition time, which are simpler optimization goals. Based on the PowerNap concept, we develop requirements and outline mechanisms to eliminate idle power waste in enterprise blade servers. Because PowerNap operates in low-efficiency regions of current blade center power supplies, we introduce the Redundant Array for Inexpensive Load Sharing (RAILS), a power provisioning approach that provides high conversion efficiency across the entire range of PowerNap's power demands. Using utilization traces collected from enterprisescale commercial deployments, we demonstrate that,together, PowerNap and RAILS reduce average server power consumption by 74%. © 2011 ACM.",Power management; Servers,Conversion efficiency; Energy management; Optimization; Satellite communication systems; Servers; Active state; Blade servers; Commercial deployment; Complex loads; Data centers; Entire system; Fine-grained power; High conversion efficiency; Individual systems; Load sharing; Optimization goals; Peak power; Power Consumption; Power demands; Power managements; Power supply; Power waste; Server architecture; Transition time; Zero-power; Energy conversion
SnowFlock: Virtual machine cloning as a first-class cloud primitive,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952351187&doi=10.1145%2f1925109.1925111&partnerID=40&md5=c4fc54465a042d47040423f9fd431be3,"A basic building block of cloud computing is virtualization. Virtual machines (VMs) encapsulate a user's computing environment and efficiently isolate it from that of other users. VMs, however, are large entities, and no clear APIs exist yet to provide users withprogramatic, fine-grained control on short time scales. We present SnowFlock, a paradigm and system for cloud computing that introduces VM cloning as a first-class cloud abstraction. VM cloning exploits the well-understood and effective semantics of UNIX fork. We demonstrate multiple usage models of VM cloning: users can incorporate the primitive in their code, can wrap around existing toolchains via scripting, can encapsulate the API withina parallel programming framework, or can use it to load-balance and self-scale clustered servers. VM cloning needs to be efficient to be usable. It must efficiently transmit VM state in order to avoid cloud I/O bottlenecks. We demonstrate how the semantics of cloningaid us in realizing its efficiency: state is propagated in parallel to multiple VM clones, and is transmitted during runtime, allowing for optimizations that substantially reducethe I/O load. We show detailed microbenchmark results highlighting the efficiency of our optimizations, and macrobenchmark numbers demonstrating the effectiveness of the different usage models of SnowFlock. © 2011 ACM.",Cloud computing; Virtualization,Application programming interfaces (API); Cloning; Computer simulation; Computer systems; Optimization; Parallel programming; Semantics; Basic building block; Clustered server; Computing environments; Fine-grained control; I/O bottleneck; Its efficiencies; Load-balance; Micro-benchmark; Programming framework; Runtimes; Short time scale; Usage models; Virtual machines; Virtualizations; Cloud computing
Seattle: A scalable ethernet architecture for large enterprises,2011,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952346610&doi=10.1145%2f1925109.1925110&partnerID=40&md5=09bf8ce1cfd31b50533aa533b2ad8243,"IP networks today require massive effort to configure and manage. Ethernet is vastly simpler to manage, but does not scale beyond small local area networks. This article describes an alternative network architecture called SEATTLE that achieves the best of both worlds: The scalability of IP combined with the simplicity of Ethernet. SEATTLE provides plug-and-play functionality via flat addressing, while ensuring scalability and efficiencythrough shortest-path routing and hash-based resolution of host information. In contrast to previous work on identity-based routing, SEATTLE ensures path predictability, controllability, and stability, thus simplifying key network-management operations, such as capacity planning, traffic engineering, and troubleshooting. We performed a simulation study driven by real-world traffic traces and network topologies, and used Emulab to evaluate a prototype of our design based on the Click and XORP open-source routing platforms. Our experiments show that SEATTLE efficiently handles network failures and host mobility, whilereducing control overhead and state requirements by roughly two orders of magnitude compared with Ethernet bridging. © 2011 ACM.",Data-center network; Enterprise network; Ethernet; Routing; Scalability,Computer simulation; Electric network topology; Ethernet; Highway engineering; Local area networks; Network management; Planning; Scalability; Capacity planning; Control overhead; Data-center network; Enterprise network; Host mobility; Identity-based; IP networks; Management operation; Network failure; Network topology; Open-source; Orders of magnitude; Plug-and-play functionality; Real-world; Routing; Seattle; Shortest path routing; Simulation studies; Traffic Engineering; Traffic traces; Troubleshooting; Network architecture
Load balancing content-based publish/subscribe systems,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650756638&doi=10.1145%2f1880018.1880020&partnerID=40&md5=5fbd9091c548e38fd616a6fb3217970a,"Distributed content-based publish/subscribe systems suffer from performance degradation and poor scalability caused by uneven load distributions typical in real-world applications. The reason for this shortcoming is the lack of a load balancing scheme. This article proposes a load balancing solution specifically tailored to the needs of content-based publish/subscribe systems that is distributed, dynamic, adaptive, transparent, and accommodates heterogeneity. The solution consists of three key contributions: a load balancing framework, a novel load estimation algorithm, and three offload strategies. A working prototype of our solution is built on an open-sourced contentbased publish/subscribe system and evaluated on PlanetLab, a cluster testbed, and in simulations. Real-life experiment results show that the proposed load balancing solution is efficient with less than 0.2% overhead; effective in distributing and balancing load originating from a single server to all available servers in the network; and capable of preventing overloads to preserve system stability, availability, and quality of service. © 2010 ACM.",Content-based routing; Load balancing; Load estimation; Offload algorithms; PADRES; Publish/subscribe; Subscriber migration; ToPSS,Algorithms; Estimation; Quality of service; Servers; System stability; Content based routing; Load estimation; Load-Balancing; Offload algorithms; PADRES; Publish/subscribe; Subscriber migration; ToPSS; Parallel architectures
Contention-aware scheduling on multicore systems,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650740981&doi=10.1145%2f1880018.1880019&partnerID=40&md5=7b2ea454d21b5380ac614054bf257811,"Contention for shared resources on multicore processors remains an unsolved problem in existing systems despite significant research efforts dedicated to this problem in the past. Previous solutions focused primarily on hardware techniques and software page coloring to mitigate this problem. Our goal is to investigate how and to what extent contention for shared resource can be mitigated via thread scheduling. Scheduling is an attractive tool, because it does not require extra hardware and is relatively easy to integrate into the system. Our study is the first to provide a comprehensive analysis of contention-mitigating techniques that use only scheduling. The most difficult part of the problem is to find a classification scheme for threads, which would determine how they affect each other when competing for shared resources. We provide a comprehensive analysis of such classification schemes using a newly proposed methodology that enables to evaluate these schemes separately from the scheduling algorithm itself and to compare them to the optimal. As a result of this analysis we discovered a classification scheme that addresses not only contention for cache space, but contention for other shared resources, such as the memory controller, memory bus and prefetching hardware. To show the applicability of our analysis we design a new scheduling algorithm, which we prototype at user level, and demonstrate that it performs within 2% of the optimal. We also conclude that the highest impact of contention-aware scheduling techniques is not in improving performance of a workload as a whole but in improving quality of service or performance isolation for individual applications and in optimizing system energy consumption. © 2010 ACM.",Multicore processors; Scheduling; Shared resource contention,Energy utilization; Optimization; Quality of service; Classification scheme; Comprehensive analysis; Contention-aware; Existing systems; Improving performance; Memory bus; Memory controller; Multi-core processor; Multi-core systems; Prefetching; Research efforts; Scheduling techniques; Shared resources; System energy; Thread scheduling; Unsolved problems; User levels; Scheduling algorithms
The SMesh wireless mesh network,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957658767&doi=10.1145%2f1841313.1841314&partnerID=40&md5=5fdfa8a8d8dbc77f135fb4fc37337ae5,"Wireless mesh networks extend the connectivity range of mobile devices by using multiple access points, some of them connected to the Internet, to create a mesh topology and forward packets over multiple wireless hops. However, the quality of service provided by the mesh is impaired by the delays and disconnections caused by handoffs, as clients move within the area covered by multiple access points. We present the architecture and protocols of SMesh, the first transparent wireless mesh system that offers seamless, fast handoff, supporting real-time applications such as interactive VoIP. The handoff and routing logic is done solely by the access points, and therefore connectivity is attainable by any 802.11 device. In SMesh, the entire mesh network is seen by the mobile clients as a single, omnipresent access point, giving the mobile clients the illusion that they are stationary. We use multicast for access points coordination and, during handoff transitions, we usemore than one access point to handle the moving client. SMesh provides a hybrid routing protocol that optimizes routes over wireless and wired links in a multihomed environment. Experimental results on a fully deployed mesh network demonstrate the effectiveness of the SMesh architecture and its intra-domain and inter-domain handoff protocols. © 2010 ACM.",Fast handoff; Interdomain; Intra-domain; Micromobility; Wireless mesh networks,Ad hoc networks; Internet protocols; Internet telephony; Mobile devices; Network architecture; Quality of service; Wireless mesh networks (WMN); Fast handoff; Inter-domain; Intra-domain; Micro-mobility; Wireless mesh; MESH networking
Probabilistic quorum systems in wireless ad hoc networks,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957555574&doi=10.1145%2f1841313.1841315&partnerID=40&md5=4b8edf5f78d93a8ac09dd9139244dc2e,"Quorums are a basic construct in solving many fundamental distributed computing problems. One of the known ways of making quorums scalable and efficient is by weakening their intersection guarantee to being probabilistic. This article explores several access strategies for implementing probabilistic quorums in ad hoc networks. In particular, we present the first detailed study of asymmetric probabilistic biquorum systems, that allow to mix different access strategies and different quorums sizes, while guaranteeing the desired intersection probability. We show the advantages of asymmetric probabilistic biquorum systems in ad hoc networks. Such an asymmetric construction is also useful for other types of networks with nonuniform access costs (e.g, peerto- peer networks). The article includes a formal analysis of these approaches backed up by an extensive simulation-based study. The study explores the impact of various parameters such asB network size, network density, mobility speed, and churn. In particular, we show that one of the strategies that uses random walks exhibits the smallest communication overhead, thus being very attractive for ad hoc networks. © 2010 ACM.",Distributed middleware; Location service; Quorums systems; Random walks; Wireless ad hoc networks,Middleware; Random processes; Wireless ad hoc networks; Biquorum; Communication overheads; Distributed Computing; Distributed middleware; Extensive simulations; Formal analysis; Location service; Network density; Network size; Non-uniform access; Peer-to-Peer networks; Probabilistic quorum system; Probabilistic quorums; Quorums systems; Random Walk; Ad hoc networks
Throughput optimal total order broadcast for cluster environments,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955189448&doi=10.1145%2f1813654.1813656&partnerID=40&md5=a3ed6a70fc45da3d14e0a342e0c05c0a,"Total order broadcast is a fundamental communication primitive that plays a central role in bringing cheap software-based high availability to a wide range of services. This article studies the practical performance of such a primitive on a cluster of homogeneous machines. We present LCR, the first throughput optimal uniform total order broadcast protocol. LCR is based on a ring topology. It only relies on point-to-point inter-process communication and has a linear latency with respect to the number of processes. LCR is also fair in the sense that each process has an equal opportunity of having its messages delivered by all processes. We benchmark a C implementation of LCR against Spread and JGroups, two of the most widely used group communication packages. LCR provides higher throughput than the alternatives, over a large number of scenarios. © 2010 ACM.",Cluster computing; Replication; Software fault-tolerance; Total order broadcast,Computer software; Fading (radio); Fault tolerance; Optimization; Quality assurance; Throughput; Cluster environments; Communication primitives; Equal opportunity; Group communications; High availability; Interprocess communication; Ring topology; Software fault tolerances; Software fault-tolerance; Software-based; Total order broadcast; Cluster computing
Proactive obfuscation,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955177883&doi=10.1145%2f1813654.1813655&partnerID=40&md5=ccd1cb3a9379f622b9fb92ccce0a1ab5,"Proactive obfuscation is a new method for creating server replicas that are likely to have fewer shared vulnerabilities. It uses semantics-preserving code transformations to generate diverse exe- cutables, periodically restarting servers with these fresh versions. The periodic restarts help bound the number of compromised replicas that a service ever concurrently runs, and therefore proactive obfuscation makes an adversary's job harder. Proactive obfuscation was used in implementing two prototypes: a distributed firewall based on state-machine replication and a distributed storage service based on quorum systems. Costs intrinsic to supporting proactive obfuscation in replicated systems were evaluated by measuring the performance of these prototypes. The results show that employing proactive obfuscation adds little to the cost of replica-management protocols. © 2010 ACM.",Byzantine fault tolerance; Distributed systems; Proactive recovery; Quorum systems; State machine approach,Contour followers; Cosine transforms; Distributed computer systems; Fault tolerance; Quality assurance; Servers; Byzantine fault tolerance; Code transformation; Distributed firewall; Distributed storage; Management protocols; Quorum systems; Replicated systems; Server replicas; State machine approaches; State-machine; Fault tolerant computer systems
ACM Transactions on Computer Systems: Editorial,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950836970&doi=10.1145%2f1731060.1731061&partnerID=40&md5=bab5808561bf9cd10eb5d753264df783,[No abstract available],,
DDoS defense by offense,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950831788&doi=10.1145%2f1731060.1731063&partnerID=40&md5=7d1535c5e13dc422998dd419f58352ee,"This article presents the design, implementation, analysis, and experimental evaluation of speak-up, a defense against application-level distributed denial-of-service (DDoS), in which attackers cripple a server by sending legitimate-looking requests that consume computational resources (e.g., CPU cycles, disk). With speak-up, a victimized server encourages all clients, resources permitting, to automatically send higher volumes of traffic. We suppose that attackers are already using most of their upload bandwidth so cannot react to the encouragement. Good clients, however, have spare upload bandwidth so can react to the encouragement with drastically higher volumes of traffic. The intended outcome of this traffic inflation is that the good clients crowd out the bad ones, thereby capturing a much larger fraction of the server's resources than before. We experiment under various conditions and find that speak-up causes the server to spend resources on a group of clients in rough proportion to their aggregate upload bandwidths, which is the intended result. © 2010 ACM.",Bandwidth; Currency; DoS attack,Computer crime; Personnel; Computational resources; CPU cycles; Currency; Distributed Denial of Service; DoS attacks; Experimental evaluation; Bandwidth
Predicting and preventing inconsistencies in deployed distributed systems,2010,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950808422&doi=10.1145%2f1731060.1731062&partnerID=40&md5=a13a415a6bc97655e674acaa7c2badaa,"We propose a new approach for developing and deploying distributed systems, in which nodes predict distributed consequences of their actions and use this information to detect and avoid errors. Each node continuously runs a state exploration algorithm on a recent consistent snapshot of its neighborhood and predicts possible future violations of specified safety properties. We describe a new state exploration algorithm, consequence prediction, which explores causally related chains of events that lead to property violation. This article describes the design and implementation of this approach, termed CrystalBall. We evaluate CrystalBall on RandTree, BulletPrime, Paxos, and Chord distributed system implementations. We identified new bugs in mature Mace implementations of three systems. Furthermore, we show that if the bug is not corrected during system development, CrystalBall is effective in steering the execution away from inconsistent states at runtime. © 2010 ACM.",Consequence prediction; Distributed systems; Enforcing safety properties; Execution steering; Reliability,Detect and avoid; Distributed systems; Enforcing safety properties; New approaches; Possible futures; Runtimes; Safety property; State exploration algorithms; System development; Three systems; Forecasting
Zyzzyva: Speculative Byzantine fault tolerance,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049140718&doi=10.1145%2f1658357.1658358&partnerID=40&md5=ddab6196b5e442b8a26aa46d7c1576f5,"A longstanding vision in distributed systems is to build reliable systems from unreliable components. An enticing formulation of this vision is Byzantine Fault-Tolerant (BFT) state machine replication, in which a group of servers collectively act as a correct server even if some of the servers misbehave or malfunction in arbitrary (Byzantine) ways. Despite this promise, practitioners hesitate to deploy BFT systems, at least partly because of the perception that BFT must impose high overheads. In this article, we present Zyzzyva, a protocol that uses speculation to reduce the cost of BFT replication. In Zyzzyva, replicas reply to a client's request without first running an expensive three-phase commit protocol to agree on the order to process requests. Instead, they optimistically adopt the order proposed by a primary server, process the request, and reply immediately to the client. If the primary is faulty, replicas can become temporarily inconsistent with one another, but clients detect inconsistencies, help correct replicas converge on a single total ordering of requests, and only rely on responses that are consistent with this total order. This approach allows Zyzzyva to reduce replication overheads to near their theoretical minima and to achieve throughputs of tens of thousands of requests per second, making BFT replication practical for a broad range of demanding services. © 2009 ACM.",Byzantine fault tolerance; Output commit; Replication; Speculative execution,Cost reduction; Fault tolerance; Fault tolerant computer systems; Servers; Byzantine fault; Byzantine fault tolerance; Distributed systems; Reliable systems; Speculative execution; State machine replication; Three-phase commit protocols; Total order; Total ordering; Quality assurance
Sinfonia: A new paradigm for building scalable distributed systems,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-73349135291&doi=10.1145%2f1629087.1629088&partnerID=40&md5=a1e6dc41f1aaaf8cf5b748c4b088b090,"We propose a new paradigm for building scalable distributed systems. Our approach does not require dealing with message-passing protocols, a major complication in existing distributed systems. Instead, developers just design and manipulate data structures within our service called Sinfonia. Sinfonia keeps data for applications on a set of memory nodes, each exporting a linear address space. At the core of Sinfonia is a new minitransaction primitive that enables efficient and consistent access to data, while hiding the complexities that arise from concurrency and failures. Using Sinfonia, we implemented two very different and complex applications in a few months: a cluster file system and a group communication service. Our implementations perform well and scale to hundreds of machines.",Distributed systems; Fault tolerance; Scalability; Shared memory; Transactions; Two-phase commit,Data structures; Fault tolerance; Message passing; Model checking; Quality assurance; Scalability; Cluster File Systems; Complex applications; Consistent access; Distributed systems; Group communications; Linear address space; Memory nodes; Shared memories; Fault tolerant computer systems
Selective replication: A lightweight technique for soft errors,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049119339&doi=10.1145%2f1658357.1658359&partnerID=40&md5=dc085bd06adf9d5dba89415767078910,"Soft errors are an important challenge in contemporary microprocessors. Modern processors have caches and large memory arrays protected by parity or error detection and correction codes. However, today's failure rate is dominated by flip flops, latches, and the increasing sensitivity of combinational logic to particle strikes. Moreover, as Chip Multi-Processors (CMPs) become ubiquitous, meeting the FIT budget for new designs is becoming a major challenge. Solutions based on replicating threads have been explored deeply; however, their high cost in performance and energy make them unsuitable for current designs. Moreover, our studies based on a typical configuration for a modern processor show that focusing on the top 5 most vulnerable structures can provide up to 70% reduction in FIT rate. Therefore, full replication may overprotect the chip by reducing the FIT much below budget. We propose Selective Replication, a lightweight-reconfigurable mechanism that achieves a high FIT reduction by protecting the most vulnerable instructions with minimal performance and energy impact. Low performance degradation is achieved by not requiring additional issue slots and reissuing instructions only during the time window between when they are retirable and they actually retire. Coverage can be reconfigured online by replicating only a subset of the instructions (the most vulnerable ones). Instructions' vulnerability is estimated based on the area they occupy and the time they spend in the issue queue. By changing the vulnerability threshold, we can adjust the trade-off between coverage and performance loss. Results for an out-of-order processor configured similarly to Intel Core#8482; Micro-Architecture show that our scheme can achieve over 65% FIT reduction with less than 4% performance degradation with small area and complexity overhead. © 2009 ACM.",AVF prediction; FIT reduction; Redundant multithreading; Soft errors,Budget control; Computer architecture; Degradation; Error correction; Error detection; Microprocessor chips; Program processors; Combinational logic; Energy impact; Error detection and correction codes; Failure rate; High costs; Issue queue; Memory array; Micro architectures; Modern processors; Multi-processors; New design; Out-of-order processors; Performance degradation; Performance loss; Re-configurable; Redundant multithreading; Selective replication; Small area; Soft error; Time windows; Vulnerable structures; Multitasking
Automated anomaly detection and performance modeling of enterprise applications,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-73349094671&doi=10.1145%2f1629087.1629089&partnerID=40&md5=ea62c29fd3df96bc72d75f653bf146e1,"Automated tools for understanding application behavior and its changes during the application lifecycle are essential for many performance analysis and debugging tasks. Application performance issues have an immediate impact on customer experience and satisfaction. A sudden slowdown of enterprise-wide application can effect a large population of customers, lead to delayed projects, and ultimately can result in company financial loss. Significantly shortened time between new software releases further exacerbates the problem of thoroughly evaluating the performance of an updated application. Our thesis is that online performance modeling should be a part of routine application monitoring. Early, informative warnings on significant changes in application performance should help service providers to timely identify and prevent performance problems and their negative impact on the service. We propose a novel framework for automated anomaly detection and application change analysis. It is based on integration of two complementary techniques: (i) a regression-based transaction model that reflects a resource consumption model of the application, and (ii) an application performance signature that provides a compact model of runtime behavior of the application. The proposed integrated framework provides a simple and powerful solution for anomaly detection and analysis of essential performance changes in application behavior. An additional benefit of the proposed approach is its simplicity: It is not intrusive and is based on monitoring data that is typically available in enterprise production environments. The introduced solution further enables the automation of capacity planning and resource provisioning tasks of multitier applications in rapidly evolving IT environments.",Anomaly detection; Capacity planning; Multitier applications; Online algorithms; Performance modeling,Customer satisfaction; Losses; Anomaly detection; Capacity planning; Multi-tier applications; On-line algorithms; Performance Modeling; Automation
A mechanistic performance model for superscalar out-of-order processors,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650312346&doi=10.1145%2f1534909.1534910&partnerID=40&md5=727d2ed1a56f47e9f5f4aacb8a58bde0,"A mechanistic model for out-of-order superscalar processors is developed and then applied to the study of microarchitecture resource scaling. The model divides execution time into intervals separated by disruptive miss events such as branch mispredictions and cache misses. Each type of miss event results in characterizable performance behavior for the execution time interval. By considering an interval's type and length (measured in instructions), execution time can be predicted for the interval. Overall execution time is then determined by aggregating the execution time over all intervals. The mechanistic model provides several advantages over prior modeling approaches, and, when estimating performance, it differs from detailed simulation of a 4-wide out-of-order processor by an average of 7%. The mechanistic model is applied to the general problem of resource scaling in out-of-order superscalar processors. First, we use the model to determine size relationships among microarchitecture structures in a balanced processor design. Second, we use the mechanistic model to study scaling of both pipeline depth and width in balanced processor designs. We corroborate previous results in this area and provide new results. For example, we show that at optimal design points, the pipeline depth times the square root of the processor width is nearly constant. Finally, we consider the behavior of unbalanced, overprovisioned processor designs based on insight gained from the mechanistic model. We show that in certain situations an overprovisioned processor may lead to improved overall performance. Designs where a processor's dispatch width is wider than its issue width are of particular interest. © 2009 ACM.",Analytical modeling; Balanced processor design; Mechanistic modeling; Overprovisioned processor design; Performance modeling; Pipeline depth; Pipeline width; Resource scaling; Superscalar out-of-order processor; Wide front-end dispatch processors,Design; Microprocessor chips; Pipelines; Systems analysis; Uncertainty analysis; Analytical modeling; Balanced processor design; Mechanistic modeling; Overprovisioned processor design; Performance modeling; Pipeline depth; Resource scaling; Superscalar out-of-order processor; Wide front-end dispatch processors; Pipeline processing systems
Practical and low-overhead masking of failures of TCP-based servers,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650462476&doi=10.1145%2f1534909.1534911&partnerID=40&md5=d5c5aceb2093c20d3068bfc479583619,"This article describes an architecture that allows a replicated service to survive crashes without breaking its TCP connections. Our approach does not require modifications to the TCP protocol, to the operating system on the server, or to any of the software running on the clients. Furthermore, it runs on commodity hardware. We compare two implementations of this architecture (one based on primary/backup replication and another based on message logging) focusing on scalability, failover time, and application transparency. We evaluate three types of services: a file server, a Web server, and a multimedia streaming server. Our experiments suggest that the approach incurs low overhead on throughput, scales well as the number of clients increases, and allows recovery of the service in near-optimal time. © 2009 ACM.",Fault-tolerant computing system; Primary/backup approach; TCP/IP,Computer operating systems; Computer science; Internet protocols; Multimedia services; Servers; Transmission control protocol; Commodity hardware; Failover; Fault-tolerant computing system; File servers; Low overhead; Message logging; Multimedia streaming; Operating systems; Optimal time; Primary/backup approach; Replicated services; TCP connections; TCP protocol; TCP/IP; Web servers; Network architecture
"Distributed hash sketches: Scalable, efficient, and accurate cardinality estimation for distributed multisets",2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-60449101900&doi=10.1145%2f1482619.1482621&partnerID=40&md5=44a7b51a3fa8cdb88dd2e07d80bfbe11,"Counting items in a distributed system, and estimating the cardinality of multisets in particular, is important for a large variety of applications and a fundamental building block for emerging Internet-scale information systems. Examples of such applications range from optimizing query access plans in peer-to-peer data sharing, to computing the significance (rank/score) of data items in distributed information retrieval. The general formal problem addressed in this article is computing the network-wide distinct number of items with some property (e.g., distinct files with file name containing spiderman) where each node in the network holds an arbitrary subset, possibly overlapping the subsets of other nodes. The key requirements that a viable approach must satisfy are: (1) scalability towards very large network size, (2) efficiency regarding messaging overhead, (3) load balance of storage and access, (4) accuracy of the cardinality estimation, and (5) simplicity and easy integration in applications. This article contributes the DHS (Distributed Hash Sketches) method for this problem setting: a distributed, scalable, efficient, and accurate multiset cardinality estimator. DHS is based on hash sketches for probabilistic counting, but distributes the bits of each counter across network nodes in a judicious manner based on principles of Distributed Hash Tables, paying careful attention to fast access and aggregation as well as update costs. The article discusses various design choices, exhibiting tunable trade-offs between estimation accuracy, hop-count efficiency, and load distribution fairness. We further contribute a full-fledged, publicly available, open-source implementation of all our methods, and a comprehensive experimental evaluation for various settings. © 2009 ACM.",Distributed cardinality estimation; Distributed data summary structures; Distributed estimation; Distributed information systems; Hash sketches; Peer-to-peer networks and systems,Applications; Estimation; Information services; Information systems; Mobile telecommunication systems; Telecommunication networks; Distributed cardinality estimation; Distributed data summary structures; Distributed estimation; Distributed information systems; Hash sketches; Peer-to-peer networks and systems; Distributed computer systems
Hill-climbing SMT processor resource distribution,2009,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-60449110893&doi=10.1145%2f1482619.1482620&partnerID=40&md5=6e4912848beace52b7a369cd96e16c4d,"The key to high performance in Simultaneous MultiThreaded (SMT) processors lies in optimizing the distribution of shared resources to active threads. Existing resource distribution techniques optimize performance only indirectly. They infer potential performance bottlenecks by observing indicators, like instruction occupancy or cache miss counts, and take actions to try to alleviate them. While the corrective actions are designed to improve performance, their actual performance impact is not known since end performance is never monitored. Consequently, potential performance gains are lost whenever the corrective actions do not effectively address the actual bottlenecks occurring in the pipeline. We propose a different approach to SMT resource distribution that optimizes end performance directly. Our approach observes the impact that resource distribution decisions have on performance at runtime, and feeds this information back to the resource distribution mechanisms to improve future decisions. By evaluating many different resource distributions, our approach tries to learn the best distribution over time. Because we perform learning online, learning time is crucial. We develop a hill-climbing algorithm that quickly learns the best distribution of resources by following the performance gradient within the resource distribution space. We also develop several ideal learning algorithms to enable deeper insights through limit studies. This article conducts an in-depth investigation of hill-climbing SMT resource distribution using a comprehensive suite of 63 multiprogrammed workloads. Our results show hill-climbing outperforms ICOUNT, FLUSH, and DCRA (three existing SMT techniques) by 11.4%, 11.5%, and 2.8%, respectively, under the weighted IPC metric. A limit study conducted using our ideal learning algorithms shows our approach can potentially outperform the same techniques by 19.2%, 18.0%, and 7.6%, respectively, thus demonstrating additional room exists for further improvement. Using our ideal algorithms, we also identify three bottlenecks that limit online learning speed: local maxima, phased behavior, and interepoch jitter. We define metrics to quantify these learning bottlenecks, and characterize the extent to which they occur in our workloads. Finally, we conduct a sensitivity study, and investigate several extensions to improve our hill-climbing technique. © 2009 ACM.",Hill-climbing algorithm; Limit study; SMT processor,Algorithms; Education; Internet; Jitter; Learning systems; Multiprogramming; Pipelines; Surface mount technology; Transmission control protocol; Cache miss; Corrective actions; Hill-climbing; Hill-climbing algorithm; Hill-climbing techniques; In-depth investigations; Learning time; Limit study; Local maximum; On-line learning; Performance bottlenecks; Performance gains; Performance impacts; Processor resources; Resource distribution decisions; Resource distributions; Run-time; Sensitivity studies; Shared resources; Simultaneous multi-threaded processors; SMT processor; Learning algorithms
Vigilante: End-to-end containment of Internet worm epidemics,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59349121868&doi=10.1145%2f1455258.1455259&partnerID=40&md5=05edc0d771ade2433de0a7ceb2051f05,"Worm containment must be automatic because worms can spread too fast for humans to respond. Recent work proposed network-level techniques to automate worm containment; these techniques have limitations because there is no information about the vulnerabilities exploited by worms at the network level. We propose Vigilante, a new end-to-end architecture to contain worms automatically that addresses these limitations. In Vigilante, hosts detect worms by instrumenting vulnerable programs to analyze infection attempts. We introduce dynamic data-flow analysis: a broad-coverage host-based algorithm that can detect unknown worms by tracking the flow of data from network messages and disallowing unsafe uses of this data. We also show how to integrate other host-based detection mechanisms into the Vigilante architecture. Upon detection, hosts generate self-certifying alerts (SCAs), a new type of security alert that can be inexpensively verified by any vulnerable host. Using SCAs, hosts can cooperate to contain an outbreak, without having to trust each other. Vigilante broadcasts SCAs over an overlay network that propagates alerts rapidly and resiliently. Hosts receiving an SCA protect themselves by generating filters with vulnerability condition slicing: an algorithm that performs dynamic analysis of the vulnerable program to identify control-flow conditions that lead to successful attacks. These filters block the worm attack and all its polymorphic mutations that follow the execution path identified by the SCA. Our results show that Vigilante can contain fast-spreading worms that exploit unknown vulnerabilities, and that Vigilante's filters introduce a negligible performance overhead. Vigilante does not require any changes to hardware, compilers, operating systems, or the source code of vulnerable programs; therefore, it can be used to protect current software binaries. © 2008 ACM.",Dynamic data-flow analysis; Program analysis; Self-certifying alerts; Vulnerability condition slicing; Worm containment,Broadcasting; Computer aided language translation; Computer crime; Computer worms; Concurrency control; Dynamic analysis; Pulsatile flow; Dynamic data-flow analysis; Program analysis; Self-certifying alerts; Vulnerability condition slicing; Worm containment; Data flow analysis
Improving peer-to-peer performance through server-side scheduling,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449092129&doi=10.1145%2f1455258.1455260&partnerID=40&md5=80ab980d0f1383faae5b8e4171dcbc9d,"We show how to significantly improve the mean response time seen by both uploaders and downloaders in peer-to-peer data-sharing systems. Our work is motivated by the observation that response times are largely determined by the performance of the peers serving the requested objects, that is, by the peers in their capacity as servers. With this in mind, we take a close look at this server side of peers, characterizing its workload by collecting and examining an extensive set of traces. Using trace-driven simulation, we demonstrate the promise and potential problems with scheduling policies based on shortest-remaining-processing-time (SRPT), the algorithm known to be optimal for minimizing mean response time. The key challenge to using SRPT in this context is determining request service times. In addressing this challenge, we introduce two new estimators that enable predictive SRPT scheduling policies that closely approach the performance of ideal SRPT. We evaluate our approach through extensive single-server and system-level simulation coupled with real Internet deployment and experimentation. © 2008 ACM.",Peer-to-peer; Scheduling; Server-side; Size-based scheduling; SRPT,Response time (computer systems); Servers; Telecommunication networks; Time sharing systems; Mean response time; Peer-to-peer; Peer-to-peer data sharing; Potential problems; Response time; Scheduling policies; Server-side; Service time; Shortest-remaining-processing-time; Size-based scheduling; SRPT; System-level simulations; Trace-driven simulations; Scheduling
Rethink the sync,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-52949104013&doi=10.1145%2f1394441.1394442&partnerID=40&md5=48b0b89d4dfa79e9d4f95844f1981f66,"We introduce external synchrony, a new model for local file I/O that provides the reliability and simplicity of synchronous I/O, yet also closely approximates the performance of asynchronous I/O. An external observer cannot distinguish the output of a computer with an externally synchronous file system from the output of a computer with a synchronous file system. No application modification is required to use an externally synchronous file system. In fact, application developers can program to the simpler synchronous I/O abstraction and still receive excellent performance. We have implemented an externally synchronous file system for Linux, called xsyncfs. Xsyncfs provides the same durability and ordering-guarantees as those provided by a synchronously mounted ext3 file system. Yet even for I/O-intensive benchmarks, xsyncfs performance is within 7% of ext3 mounted asynchronously. Compared to ext3 mounted synchronously, xsyncfs is up to two orders of magnitude faster. © 2008 ACM.",Causality; File systems; Speculative execution; Synchronous I/O,Application developers; Asynchronous I/O; Causality; Excellent performance; External observer; External-; File I/O; File systems; New model; Orders-of-magnitude; Speculative execution; Synchronous I/O; Benchmarking
Adaptive work-stealing with parallelism feedback,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-52949109730&doi=10.1145%2f1394441.1394443&partnerID=40&md5=4ccc4948d967500a04e716d444279750,"Multiprocessor scheduling in a shared multiprogramming environment can be structured as two-level scheduling, where a kernel-level job scheduler allots processors to jobs and a user-level thread scheduler schedules the work of a job on its allotted processors. We present a randomized work-stealing thread scheduler for fork-join multithreaded jobs that provides continual parallelism feedback to the job scheduler in the form of requests for processors. Our A-STEAL algorithm is appropriate for large parallel servers where many jobs share a common multiprocessor resource and in which the number of processors available to a particular job may vary during the job's execution. Assuming that the job scheduler never allots a job more processors than requested by the job's thread scheduler, A-STEAL guarantees that the job completes in near-optimal time while utilizing at least a constant fraction of the allotted processors. We model the job scheduler as the thread scheduler's adversary, challenging the thread scheduler to be robust to the operating environment as well as to the job scheduler's administrative policies. For example, the job scheduler might make a large number of processors available exactly when the job has little use for them. To analyze the performance of our adaptive thread scheduler under this stringent adversarial assumption, we introduce a new technique called trim analysis, which allows us to prove that our thread scheduler performs poorly on no more than a small number of time steps, exhibiting near-optimal behavior on the vast majority. More precisely, suppose that a job has work T1 and span T∞. On a machine with P processors, A-STEAL completes the job in an expected duration of O(T 1/P̃ + T∞ + L lg P) time steps, where L is the length of a scheduling quantum, and P̃ denotes the O(T∞ + L lg P)-trimmed availability. This quantity is the average of the processor availability over all time steps except the O(T∞+L lg P) time steps that have the highest processor availability. When the job's parallelism dominates the trimmed availability, that is, P̃≪ T1/T ∞, the job achieves nearly perfect linear speedup. Conversely, when the trimmed mean dominates the parallelism, the asymptotic running time of the job is nearly the length of its span, which is optimal. We measured the performance of A-STEAL on a simulated multiprocessor system using synthetic workloads. For jobs with sufficient parallelism, our experiments confirm that A-STEAL provides almost perfect linear speedup across a variety of processor availability profiles. We compared A-STEAL with the ABP algorithm, an adaptive work-stealing thread scheduler developed by Arora et al. [1998] which does not employ parallelism feedback. On moderately to heavily loaded machines with large numbers of processors, A-STEAL typically completed jobs more than twice as quickly as ABP, despite being allotted the same number or fewer processors on every step, while wasting only 10 of the processor cycles wasted by ABP. © 2008 ACM.",Adaptive scheduling; Adversary; Instantaneous parallelism; Job scheduling; Multiprocessing; Multiprogramming; Parallel computation; Parallelism feedback; Processor allocation; Randomized algorithm; Space sharing; Span; Thread scheduling; Two-level scheduling,Multiprocessing systems; Multiprogramming; Parallel algorithms; Servers; Trees (mathematics); Adaptive scheduling; Adversary; Instantaneous parallelism; Job scheduler; Job scheduling; Multi-processor scheduling; Multi-threaded; Multiprocessing; Operating environment; Optimal time; Parallel computation; Parallel servers; Parallelism feedback; Processor allocation; Randomized algorithm; Space sharing; Span; Thread scheduling; Two-level scheduling; Scheduling
A stateless approach to connection-oriented protocols,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-52949145950&doi=10.1145%2f1394441.1394444&partnerID=40&md5=b2ec615b9d542b1afdfc75910d46857f,"Traditional operating system interfaces and network protocol implementations force some system state to be kept on both sides of a connection. This state ties the connection to its endpoints, impedes transparent failover, permits denial-of-service attacks, and limits scalability. This article introduces a novel TCP-like transport protocol and a new interface to replace sockets that together enable all state to be kept on one endpoint, allowing the other endpoint, typically the server, to operate without any per-connection state. Called Trickles, this approach enables servers to scale well with increasing numbers of clients, consume fewer resources, and better resist denial-of-service attacks. Measurements on a full implementation in Linux indicate that Trickles achieves performance comparable to TCP/IP, interacts well with other flows, and scales well. Trickles also enables qualitatively different kinds of networked services. Services can be geographically replicated and contacted through an anycast primitive for improved availability and performance. Widely-deployed practices that currently have client-observable side effects, such as periodic server reboots, connection redirection, and failover, can be made transparent, and perform well, under Trickles. The protocol is secure against tampering and replay attacks, and the client interface is backward-compatible, requiring no changes to sockets-based client applications. © 2008 ACM.",Stateless interfaces; Stateless protocols,Computer crime; Computer operating systems; Computer programming languages; Industrial management; Laws and legislation; Servers; Anycast; Client applications; Client interfaces; Denial-of-Service attacks; Fail over; Networked services; Operating system interfaces; Protocol implementations; Replay attacks; Side effects; Stateless interfaces; Stateless protocols; System states; Transport protocol; Telecommunication networks
Bigtable: A distributed storage system for structured data,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-47749140025&doi=10.1145%2f1365815.1365816&partnerID=40&md5=6ecf1e7eca7149122ac0969463fa9a72,"Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this article, we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable. © 2008 ACM.",Large-scale distributed storage,Data storage equipment; Internet; Satellite imagery; Commodity servers; Data layouts; Data modelling; Data size; Distributed storage systems; Dynamic controls; Google Earth; Large sizes; Petabytes (PB); Real-time data; Structured data; Web indexing; Web pages; Data processing
RaWMS - Random walk based lightweight membership service for wireless ad hoc networks,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-47749148120&doi=10.1145%2f1365815.1365817&partnerID=40&md5=12ae9bcb9af84297771f0590d14eee95,"This article presents RaWMS, a novel lightweight random membership service for ad hoc networks. The service provides each node with a partial uniformly chosen view of network nodes. Such a membership service is useful, for example, in data dissemination algorithms, lookup and discovery services, peer sampling services, and complete membership construction. The design of RaWMS is based on a novel reverse random walk (RW) sampling technique. The article includes a formal analysis of both the reverse RW sampling technique and RaWMS and verifies it through a detailed simulation study. In addition, RaWMS is compared both analytically and by simulations with a number of other known methods such as flooding and gossip-based techniques. © 2008 ACM.",Ad hoc networks; Membership service; Random walk,Random processes; Sampling; Wireless telecommunication systems; Data dissemination algorithms; Formal analysis; Hoc networks; Network nodes; Random walk (RW); Sampling techniques; Simulation studies; wireless Ad Hoc networks; Ad hoc networks
A generic component model for building systems software,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-40549141440&doi=10.1145%2f1328671.1328672&partnerID=40&md5=699ca8d7b65d8f9a205cc52f12a4126a,"Component-based software structuring principles are now commonplace at the application level; but componentization is far less established when it comes to building low-level systems software. Although there have been pioneering efforts in applying componentization to systems-building, these efforts have tended to target specific application domains (e.g., embedded systems, operating systems, communications systems, programmable networking environments, or middleware platforms). They also tend to be targeted at specific deployment environments (e.g., standard personal computer (PC) environments, network processors, or microcontrollers). The disadvantage of this narrow targeting is that it fails to maximize the genericity and abstraction potential of the component approach. In this article, we argue for the benefits and feasibility of a generic yet tailorable approach to component-based systems-building that offers a uniform programming model that is applicable in a wide range of systems-oriented target domains and deployment environments. The component model, called OpenCom, is supported by a reflective runtime architecture that is itself built from components. After describing OpenCom and evaluating its performance and overhead characteristics, we present and evaluate two case studies of systems we have built using OpenCom technology, thus illustrating its benefits and its general applicability. © 2008 ACM.",Component-based software; Computer systems implementation,Communication systems; Embedded systems; Mathematical models; Middleware; Personal computers; Component based software; Generic component models; Computer operating systems
High-bandwidth data dissemination for large-scale distributed systems,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-40549120932&doi=10.1145%2f1328671.1328674&partnerID=40&md5=b12541723cfff2dfdbdeefbe57a3f7c6,"This article focuses on the multireceiver data dissemination problem. Initially, IP multicast formed the basis for efficiently supporting such distribution. More recently, overlay networks have emerged to support point-to-multipoint communication. Both techniques focus on constructing trees rooted at the source to distribute content among all interested receivers. We argue, however, that trees have two fundamental limitations for data dissemination. First, since all data comes from a single parent, participants must often continuously probe in search of a parent with an acceptable level of bandwidth. Second, due to packet losses and failures, available bandwidth is monotonically decreasing down the tree. To address these limitations, we present Bullet, a data dissemination mesh that takes advantage of the computational and storage capabilities of end hosts to create a distribution structure where a node receives data in parallel from multiple peers. For the mesh to deliver improved bandwidth and reliability, we need to solve several key problems: (i) disseminating disjoint data over the mesh, (ii) locating missing content, (iii) finding who to peer with (peering strategy), (iv) retrieving data at the right rate from all peers (flow control), and (v) recovering from failures and adapting to dynamically changing network conditions. Additionally, the system should be self-adjusting and should have few user-adjustable parameter settings. We describe our approach to addressing all of these problems in a working, deployed system across the Internet. Bullet outperforms state-of-the-art systems, including BitTorrent, by 25-70% and exhibits strong performance and reliability in a range of deployment settings. In addition, we find that, relative to tree-based solutions, Bullet reduces the need to perform expensive bandwidth probing. © 2008 ACM.",Bandwidth; Overlays; Peer-to-peer,Bandwidth; Communication systems; Distributed computer systems; Large scale systems; Problem solving; Data dissemination; Large-scale distributed systems; Data acquisition
Incrementally parallelizing database transactions with thread-level speculation,2008,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-40549097354&doi=10.1145%2f1328671.1328673&partnerID=40&md5=fac9eaa883a87aeb6a9eebfe8e82729f,"With the advent of chip multiprocessors, exploiting intratransaction parallelism in database systems is an attractive way of improving transaction performance. However, exploiting intratransaction parallelism is difficult for two reasons: first, significant changes are required to avoid races or conflicts within the DBMS; and second, adding threads to transactions requires a high level of sophistication from transaction programmers. In this article we show how dividing a transaction into speculative threads solves both problems - -it minimizes the changes required to the DBMS, and the details of parallelization are hidden from the transaction programmer. Our technique requires a limited number of small, localized changes to a subset of the low-level data structures in the DBMS. Through this method of incrementally parallelizing transactions, we can dramatically improve performance: on a simulated four-processor chip-multiprocessor, we improve the response time by 44 - 66% for three of the five TPC-C transactions, assuming the availability of idle processors. © 2008 ACM.",Chip-multiprocessing; Incremental parallelization; Optimistic concurrency; Thread-level speculation,Parallel processing systems; Problem solving; Program processors; Incremental parallelization; Optimistic concurrency; Thread-level speculation; Database systems
Memory scheduling for modern microprocessors,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049001810&doi=10.1145%2f1314299.1314301&partnerID=40&md5=878701873395ad8038696935f78a7ef6,"The need to carefully schedule memory operations has increased as memory performance has become increasingly important to overall system performance. This article describes the adaptive history-based (AHB) scheduler, which uses the history of recently scheduled operations to provide three conceptual benefits: (1) it allows the scheduler to better reason about the delays associated with its scheduling decisions, (2) it provides a mechanism for combining multiple constraints, which is important for increasingly complex DRAM structures, and (3) it allows the scheduler to select operations so that they match the program's mixture of Reads and Writes, thereby avoiding certain bottlenecks within the memory controller. We have previously evaluated this scheduler in the context of the IBM Power5. When compared with the state of the art, this scheduler improves performance by 15.6%, 9.9%, and 7.6% for the Stream, NAS, and commercial benchmarks, respectively. This article expands our understanding of the AHB scheduler in a variety of ways. Looking backwards, we describe the scheduler in the context of prior work that focused exclusively on avoiding bank conflicts, and we show that the AHB scheduler is superior for the IBM Power5, which we argue will be representative of future microprocessor memory controllers. Looking forwards, we evaluate this scheduler in the context of future systems by varying a number of microarchitectural features and hardware parameters. For example, we show that the benefit of this scheduler increases as we move to multithreaded environments. © 2007 ACM.",Adaptive history-based scheduling; Memory scheduling; Memory system performance,Adaptive systems; Decision theory; Dynamic random access storage; Feature extraction; Scheduling; Storage allocation (computer); Adaptive history-based (AHB) scheduler; Memory scheduling; Memory system performance; Scheduling decisions; Microprocessor chips
Minimizing expected energy consumption in real-time systems through dynamic voltage scaling,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049016851&doi=10.1145%2f1314299.1314300&partnerID=40&md5=d1a0750d58e310dddc8b711a34a57a12,"Many real-time systems, such as battery-operated embedded devices, are energy constrained. A common problem for these systems is how to reduce energy consumption in the system as much as possible while still meeting the deadlines; a commonly used power management mechanism by these systems is dynamic voltage scaling (DVS). Usually, the workloads executed by these systems are variable and, more often than not, unpredictable. Because of the unpredictability of the workloads, one cannot guarantee to minimize the energy consumption in the system. However, if the variability of the workloads can be captured by the probability distribution of the computational requirement of each task in the system, it is possible to achieve the goal of minimizing the expected energy consumption in the system. In this paper, we investigate DVS schemes that aim at minimizing expected energy consumption for frame-based hard real-time systems. Our investigation considers various DVS strategies (i.e., intra-task DVS, inter-task DVS, and hybrid DVS) and both an ideal system model (i.e., assuming unrestricted continuous frequency, well-defined power-frequency relation, and no speed change overhead) and a realistic system model (i.e., the processor provides a set of discrete speeds, no assumption is made on power-frequency relation, and speed change overhead is considered). The highlights of the investigation are two practical DVS schemes: Practical PACE (PPACE) for a single task and Practical Inter-Task DVS (PITDVS2) for general frame-based systems. Evaluation results show that our proposed schemes outperform and achieve significant energy savings over existing schemes. © 2007 ACM.",Dynamic voltage scaling; Power management; Processor acceleration to conserve energy; Real-time,Embedded systems; Energy conservation; Finite difference method; Optimization; Probability; Real time systems; Dynamic voltage scaling (DVS); Embedded devices; Power management; Processor acceleration to conserve energy; Electric power utilization
Labels and event processes in the Asbestos operating system,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049002830&doi=10.1145%2f1314299.1314302&partnerID=40&md5=2183b0cc75dd62e735782bb3e197f8b1,"Asbestos, a new operating system, provides novel labeling and isolation mechanisms that help contain the effects of exploitable software flaws. Applications can express a wide range of policies with Asbestos's kernel-enforced labels, including controls on interprocess communication and system-wide information flow. A new event process abstraction defines lightweight, isolated contexts within a single process, allowing one process to act on behalf of multiple users while preventing it from leaking any single user's data to others. A Web server demonstration application uses these primitives to isolate private user data. Since the untrusted workers that respond to client requests are constrained by labels, exploited workers cannot directly expose user data except as allowed by application policy. The server application requires 1.4 memory pages per user for up to 145,000 users and achieves connection rates similar to Apache, demonstrating that additional security can come at an acceptable cost. © 2007 ACM.",Information flow; Labels; Mandatory access control; Process abstractions; Secure Web servers,Access control; Data reduction; Information dissemination; Process engineering; Servers; Web services; Information flow; Mandatory access control; Process abstractions; Secure Web servers; Computer operating systems
Gossip-based peer sampling,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548273006&doi=10.1145%2f1275517.1275520&partnerID=40&md5=1045950862c3aebcc6ea806d368f5c9a,"Gossip-based communication protocols are appealing in large-scale distributed applications such as information dissemination, aggregation, and overlay topology management. This paper factors out a fundamental mechanism at the heart of all these protocols: the peer-sampling service. In short, this service provides every node with peers to gossip with. We promote this service to the level of a first-class abstraction of a large-scale distributed system, similar to a name service being a first-class abstraction of a local-area system. We present a generic framework to implement a peer-sampling service in a decentralized manner by constructing and maintaining dynamic unstructured overlays through gossiping membership information itself. Our framework generalizes existing approaches and makes it easy to discover new ones. We use this framework to empirically explore and compare several implementations of the peer-sampling service. Through extensive simulation experiments we show that - -although all protocols provide a good quality uniform random stream of peers to each node locally - -traditional theoretical assumptions about the randomness of the unstructured overlays as a whole do not hold in any of the instances. We also show that different design decisions result in severe differences from the point of view of two crucial aspects: load balancing and fault tolerance. Our simulations are validated by means of a wide-area implementation. © 2007 ACM.",Epidemic protocols; Gossip-based protocols; Peer sampling service,Computer aided design; Computer simulation; Dynamic programming; Information dissemination; Network protocols; Sampling; Epidemic protocols; Gossip-based protocols; Peer sampling services; Distributed computer systems
Rx: Treating bugs as allergies - -a safe method to survive software failures,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548235323&doi=10.1145%2f1275517.1275519&partnerID=40&md5=e01634a66b7c984cbcc085391326ccd3,"Many applications demand availability. Unfortunately, software failures greatly reduce system availability. Prior work on surviving software failures suffers from one or more of the following limitations: required application restructuring, inability to address deterministic software bugs, unsafe speculation on program execution, and long recovery time. This paper proposes an innovative safe technique, called Rx, which can quickly recover programs from many types of software bugs, both deterministic and nondeterministic. Our idea, inspired from allergy treatment in real life, is to rollback the program to a recent checkpoint upon a software failure, and then to reexecute the program in a modified environment. We base this idea on the observation that many bugs are correlated with the execution environment, and therefore can be avoided by removing the allergen from the environment. Rx requires few to no modifications to applications and provides programmers with additional feedback for bug diagnosis. We have implemented Rx on Linux. Our experiments with five server applications that contain seven bugs of various types show that Rx can survive six out of seven software failures and provide transparent fast recovery within 0.017 - 0.16 seconds, 21 - 53 times faster than the whole program restart approach for all but one case (CVS). In contrast, the two tested alternatives, a whole program restart approach and a simple rollback and reexecution without environmental changes, cannot successfully recover the four servers (Squid, Apache, CVS, and ypserv) that contain deterministic bugs, and have only a 40% recovery rate for the server (MySQL) that contains a nondeterministic concurrency bug. Additionally, Rx's checkpointing system is lightweight, imposing small time and space overheads. © 2007 ACM.",Availability; Bug; Reliability; Software Failure,Availability; Computer operating systems; Data structures; Program debugging; Software reliability; Supervisory and executive programs; Linux (operating system); Software bugs; Software Failures; Computer system recovery
Experience distributing objects in an SMMP OS,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548348919&doi=10.1145%2f1275517.1275518&partnerID=40&md5=12d77ea80ee8d8aba422ade4be938d7e,"Designing and implementing system software so that it scales well on shared-memory multiprocessors (SMMPs) has proven to be surprisingly challenging. To improve scalability, most designers to date have focused on concurrency by iteratively eliminating the need for locks and reducing lock contention. However, our experience indicates that locality is just as, if not more, important and that focusing on locality ultimately leads to a more scalable system. In this paper, we describe a methodology and a framework for constructing system software structured for locality, exploiting techniques similar to those used in distributed systems. Specifically, we found two techniques to be effective in improving scalability of SMMP operating systems: (i) an object-oriented structure that minimizes sharing by providing a natural mapping from independent requests to independent code paths and data structures, and (ii) the selective partitioning, distribution, and replication of object implementations in order to improve locality. We describe concrete examples of distributed objects and our experience implementing them. We demonstrate that the distributed implementations improve the scalability of operating-system- intensive parallel workloads. © 2007 ACM.",Concurrency; Distribution; Locality; Scalability SMMP,Computer operating systems; Data structures; Integrated circuit layout; Iterative methods; Optimization; Scalability; Lock contention; Methodology; Object implementations; Scalable systems; Interconnection networks
Specifying memory consistency of write buffer multiprocessors,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250201499&doi=10.1145%2f1189736.1189737&partnerID=40&md5=7d689114518c114955541155ad19c223,"Write buffering is one of many successful mechanisms that improves the performance and scalability of multiprocessors. However, it leads to more complex memory system behavior, which cannot be described using intuitive consistency models, such as Sequential Consistency. It is crucial to provide programmers with a specification of the exact behavior of such complex memories. This article presents a uniform framework for describing systems at different levels of abstraction and proving their equivalence. The framework is used to derive and prove correct simple specifications in terms of program-level instructions of the SPARC total store order and partial store order memories. The framework is also used to examine the SPARC relaxed memory order. We show that it is not a memory consistency model that corresponds to any implementation on a multiprocessor that uses write-buffers, even though we suspect that the SPARC version 9 specification of relaxed memory order was intended to capture a general write-buffer architecture. The same technique is used to show that Coherence does not correspond to a write-buffer architecture. A corollary, which follows from the relationship between Coherence and Alpha, is that any implementation of Alpha consistency using write-buffers cannot produce all possible Alpha computations. That is, there are some computations that satisfy the Alpha specification but cannot occur in the given write-buffer implementation. © 2007 ACM.",Alpha; Coherence; Memory consistency framework; Partial store order; Relaxed memory order; Sequential consistency; SPARC multiprocessors; Total store order; Write-buffer architectures,Abstracting; Computational methods; Mathematical models; Scalability; Buffer architectures; Memory consistency framework; Relaxed memory order; Sequential consistency; SPARC multiprocessors; Total store order; Interconnection networks
Concurrent programming without locks,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249721556&doi=10.1145%2f1233307.1233309&partnerID=40&md5=62a418bd143d5fc1b3aeec1a0dc40e39,"Mutual exclusion locks remain the de facto mechanism for concurrency control on shared-memory data structures. However, their apparent simplicity is deceptive: It is hard to design scalable locking strategies because locks can harbor problems such as priority inversion, deadlock, and convoying. Furthermore, scalable lock-based systems are not readily composable when building compound operations. In looking for solutions to these problems, interest has developed in nonblocking systems which have promised scalability and robustness by eschewing mutual exclusion while still ensuring safety. However, existing techniques for building nonblocking systems are rarely suitable for practical use, imposing substantial storage overheads, serializing nonconflicting operations, or requiring instructions not readily available on today's CPUs. In this article we present three APIs which make it easier to develop nonblocking implementations of arbitrary data structures. The first API is a multiword compare-and-swap operation (MCAS) which atomically updates a set of memory locations. This can be used to advance a data structure from one consistent state to another. The second API is a word-based software transactional memory (WSTM) which can allow sequential code to be reused more directly than with MCAS and which provides better scalability when locations are being read rather than being updated. The third API is an object-based software transactional memory (OSTM). OSTM allows a simpler implementation than WSTM, but at the cost of reengineering the code to use OSTM objects. We present practical implementations of all three of these APIs, built from operations available across all of today's major CPU families. We illustrate the use of these APIs by using them to build highly concurrent skip lists and red-black trees. We compare the performance of the resulting implementations against one another and against high-performance lock-based systems. These results demonstrate that it is possible to build useful nonblocking data structures with performance comparable to, or better than, sophisticated lock-based designs. © 2007 ACM.",Concurrency; Lock-free systems; Transactional memory,Computer system recovery; Concurrency control; Concurrent engineering; Data storage equipment; Data structures; Robustness (control systems); Trees (mathematics); Lock free systems; Memory locations; Nonblocking systems; Object-based software transactional memory (OSTM); Transactional memory; Computer programming
The WaveScalar architecture,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249721013&doi=10.1145%2f1233307.1233308&partnerID=40&md5=dbc13ee95288abb74c9d8ceee517f92b,"Silicon technology will continue to provide an exponential increase in the availability of raw transistors. Effectively translating this resource into application performance, however, is an open challenge that conventional superscalar designs will not be able to meet. We present WaveScalar as a scalable alternative to conventional designs. WaveScalar is a dataflow instruction set and execution model designed for scalable, low-complexity/high- performance processors. Unlike previous dataflow machines, WaveScalar can efficiently provide the sequential memory semantics that imperative languages require. To allow programmers to easily express parallelism, WaveScalar supports pthread-style, coarse-grain multithreading and dataflow-style, fine-grain threading. In addition, it permits blending the two styles within an application, or even a single function. To execute WaveScalar programs, we have designed a scalable, tile-based processor architecture called the WaveCache. As a program executes, the WaveCache maps the program's instructions onto its array of processing elements (PEs). The instructions remain at their processing elements for many invocations, and as the working set of instructions changes, the WaveCache removes unused instructions and maps new ones in their place. The instructions communicate directly with one another over a scalable, hierarchical on-chip interconnect, obviating the need for long wires and broadcast communication. This article presents the WaveScalar instruction set and evaluates a simulated implementation based on current technology. For single-threaded applications, the WaveCache achieves performance on par with conventional processors, but in less area. For coarse-grain threaded applications the WaveCache achieves nearly linear speedup with up to 64 threads and can sustain 7 - 14 multiply-accumulates per cycle on fine-grain threaded versions of well-known kernels. Finally, we apply both styles of threading to equake from Spec2000 and speed it up by 9x compared to the serial version. © 2007 ACM.",Dataflow computing; Multithreading; WaveScalar,Broadcasting; Data flow analysis; Program processors; Semantics; Silicon; Transistors; Dataflow computing; Multithreading; Processing elements; WaveScalar; Computer architecture
Trace Cache Sampling Filter,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350639508&doi=10.1145%2f1189736.1189739&partnerID=40&md5=a95b515df32418bec5ea116498d0aaf4,"A simple mechanism to increase the utilization of a small trace cache, and simultaneously reduce its power consumption, is presented in this article. The mechanism uses selective storage of traces (filtering) that is based on a new concept in computer architecture: random sampling. The sampling filter exploits the “hot/cold trace” principle, which divides the population of traces into two groups. The first group contains “hot traces” that are executed many times from the trace cache and contribute the majority of committed instructions. The second group contains “cold traces” that are rarely executed, but are responsible for the majority of writes to an unfiltered cache. The sampling filter selects traces without any prior knowledge of their quality. However, as most writes to the cache are of “cold traces” it statistically filters out those traces, reducing cache turnover and eventually leading to higher quality traces residing in the cache. In contrast with previously proposed filters, which perform bookkeeping for all traces in the program, the sampling filter can be implemented with minimal hardware. Results show that the sampling filter can increase the number of hits per build (utilization) by a factor of 38, reduce the miss rate by 20% and improve the performance-power efficiency by 15%. Further improvements can be obtained by extensions to the basic sampling filter: allowing “hot traces” to bypass the sampling filter, combining of sampling together with previously proposed filters, and changing the replacement policy in the trace cache. Those techniques combined with the sampling filter can reduce the miss rate of the trace cache by up to 40%. Although the effectiveness of the sampling filter is demonstrated for a trace cache, the sampling principle is applicable to other micro-architectural structures with similar access patterns. © 2007, ACM. All rights reserved.",cache utilization; Measurement; Performance; power dissipation; sampling filter; Trace cache,
Comprehensive Multivariate Extrapolation Modeling of Multiprocessor Cache Miss Rates,2007,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991842036&doi=10.1145%2f1189736.1189738&partnerID=40&md5=f0b8476a47cadac260d27391089d037e,"Cache miss rates are an important subset of system model inputs. Cache miss rate models are used for broad design space exploration in which many cache configurations cannot be simulated directly due to limitations of trace collection setups or available resources. Often it is not practical to simulate large caches. Large processor counts and consequent potentially high degree of cache sharing are frequently not reproducible on small existing systems. In this article, we present an approach to building multivariate regression models for predicting cache miss rates beyond the range of collectible data. The extrapolation model attempts to accurately estimate the high-level trend of the existing data, which can be extended in a natural way. We extend previous work by its applicability to multiple miss rate components and its ability to model a wide range of cache parameters, including size, line size, associativity and sharing. The stability of extrapolation is recognized to be a crucial requirement. The proposed extrapolation model is shown to be stable to small data perturbations that may be introduced during data collection. We show the effectiveness of the technique by applying it to two commercial workloads. The wide design space contains configurations that are much larger than those for which miss rate data were available. The fitted data match the simulation data very well. The various curves show how a miss rate model is useful for not only estimating the performance of specific configurations, but also for providing insight into miss rate trends. © 2007, ACM. All rights reserved.",Additive models; Algorithms; cache miss rates; extrapolation; isotonic regression; Performance; queuing models; Theory,
Using model checking to find serious file system errors,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847328383&doi=10.1145%2f1189256.1189259&partnerID=40&md5=f65b0879a217213d0abca72a63cfe3ea,"This article shows how to use model checking to find serious errors in file systems. Model checking is a formal verification technique tuned for finding corner-case errors by comprehensively exploring the state spaces defined by a system. File systems have two dynamics that make them attractive for such an approach. First, their errors are some of the most serious, since they can destroy persistent data and lead to unrecoverable corruption. Second, traditional testing needs an impractical, exponential number of test cases to check that the system will recover if it crashes at any point during execution. Model checking employs a variety of state-reducing techniques that allow it to explore such vast state spaces efficiently.We built a system, FiSC, for model checking file systems. We applied it to four widely-used, heavily-tested file systems: ext3, JFS, ReiserFS and XFS. We found serious bugs in all of them, 33 in total. Most have led to patches within a day of diagnosis. For each file system, FiSC found demonstrable events leading to the unrecoverable destruction of metadata and entire directories, including the file system root directory /"". © 2006 ACM.",Crash; File system; Journaling; Model checking; Recovery,Computer system recovery; Data structures; Errors; Metadata; Security of data; File system; Journaling; Model checking; File organization
Recovering device drivers,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847256887&doi=10.1145%2f1189256.1189257&partnerID=40&md5=e089584480b29d6f312d0058ccd8d076,"This article presents a new mechanism that enables applications to run correctly when device drivers fail. Because device drivers are the principal failing component in most systems, reducing driver-induced failures greatly improves overall reliability. Earlier work has shown that an operating system can survive driver failures [Swift et al. 2005], but the applications that depend on them cannot. Thus, while operating system reliability was greatly improved, application reliability generally was not.To remedy this situation, we introduce a new operating system mechanism called a shadow driver. A shadow driver monitors device drivers and transparently recovers from driver failures. Moreover, it assumes the role of the failed driver during recovery. In this way, applications using the failed driver, as well as the kernel itself, continue to function as expected.We implemented shadow drivers for the Linux operating system and tested them on over a dozen device drivers. Our results show that applications and the OS can indeed survive the failure of a variety of device drivers. Moreover, shadow drivers impose minimal performance overhead. Lastly, they can be introduced with only modest changes to the OS kernel and with no changes at all to existing device drivers. © 2006 ACM.",Device drivers; I/O; Recovery,Computer hardware; Computer operating systems; Input output programs; Reliability; Device drivers; Kernel; Linux; Principal failing component; Computer system recovery
Speculative execution in a distributed file system,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847293804&doi=10.1145%2f1189256.1189258&partnerID=40&md5=5861e2e72e9c90260c86146d53586e24,"Speculator provides Linux kernel support for speculative execution. It allows multiple processes to share speculative state by tracking causal dependencies propagated through interprocess communication. It guarantees correct execution by preventing speculative processes from externalizing output, for example, sending a network message or writing to the screen, until the speculations on which that output depends have proven to be correct. Speculator improves the performance of distributed file systems by masking I/O latency and increasing I/O throughput. Rather than block during a remote operation, a file system predicts the operation's result, then uses Speculator to checkpoint the state of the calling process and speculatively continue its execution based on the predicted result. If the prediction is correct, the checkpoint is discarded; if it is incorrect, the calling process is restored to the checkpoint, and the operation is retried. We have modified the client, server, and network protocol of two distributed file systems to use Speculator. For PostMark and Andrew-style benchmarks, speculative execution results in a factor of 2 performance improvement for NFS over local area networks and an order of magnitude improvement over wide area networks. For the same benchmarks, Speculator enables the Blue File System to provide the consistency of single-copy file semantics and the safety of synchronous I/O, yet still outperform current distributed file systems with weaker consistency and safety. © 2006 ACM.",Causality; Distributed file systems; Speculative execution,Benchmarking; Computer operating systems; File organization; Semantics; Speech intelligibility; Technical writing; Causality; Distributed file systems; Performance improvement; Speculative execution; Distributed parameter control systems
Energy-efficient CPU scheduling for multimedia applications,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748329477&doi=10.1145%2f1151690.1151693&partnerID=40&md5=547044c2ed09b96a9f713ee776726fea,"This article presents the design, implementation, and evaluation of EScheduler, an energy-efficient soft real-time CPU scheduler for multimedia applications running on a mobile device. EScheduler seeks to minimize the total energy consumed by the device while meeting multimedia timing requirements. To achieve this goal, EScheduler integrates dynamic voltage scaling into the traditional soft real-time CPU scheduling: It decides at what CPU speed to execute applications in addition to when to execute what applications. EScheduler makes these scheduling decisions based on the probability distribution of cycle demand of multimedia applications and obtains their demand distribution via online profiling. We have implemented EScheduler in the Linux kernel and evaluated it on a laptop with a variable-speed CPU and typical multimedia codecs. Our experimental results show four findings: first, the cycle demand distribution of our studied codecs is stable or changes slowly. This stability implies the feasibility to perform our proposed energy-efficient scheduling with low overhead. Second, EScheduler delivers soft performance guarantees to these codecs by bounding their deadline miss ratio under the application-specific performance requirements. Third, EScheduler reduces the total energy of the laptop by 14.4% to 37.2% relative to the scheduling algorithm without voltage scaling and by 2% to 10.5% relative to voltage scaling algorithms without considering the demand distribution. Finally, EScheduler saves energy by 2% to 5% by explicitly considering the discrete CPU speeds and the corresponding total power of the whole laptop, rather than assuming continuous speeds and cubic speed-power relationship. © 2006 ACM.",Mobile computing; Multimedia; Power management; Soft real-time,Computer hardware; Energy utilization; Laptop computers; Mobile computing; Real time systems; Scheduling; Voltage control; Power management; Soft real-time systems; Voltage scaling; Multimedia systems
Energy-aware lossless data compression,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748324558&doi=10.1145%2f1151690.1151692&partnerID=40&md5=2b116002e9ed84943ffe35223ac71ae6,"Wireless transmission of a single bit can require over 1000 times more energy than a single 32-bit computation. It can therefore be beneficial to perform additional computation to reduce the number of bits transmitted. If the energy required to compress data is less than the energy required to send it, there is a net energy savings and an increase in battery life for portable computers. This article presents a study of the energy savings possible by losslessly compressing data prior to transmission. A variety of algorithms were measured on a StrongARM SA-110 processor. This work demonstrates that, with several typical compression algorithms, there is a actually a net energy increase when compression is applied before transmission. Reasons for this increase are explained and suggestions are made to avoid it. One such energy-aware suggestion is asymmetric compression, the use of one compression algorithm on the transmit side and a different algorithm for the receive path. By choosing the lowest-energy compressor and decompressor on the test platform, overall energy to send and receive data can be reduced by 11% compared with a well-chosen symmetric pair, or up to 57% over the default symmetric zlib scheme. © 2006 ACM.",Compression; Energy-aware; Lossless; Low-power; Power-aware,Algorithms; Computation theory; Portable equipment; Wireless telecommunication systems; Energy-aware; Lossless; Low-power; Power-aware; Data compression
The liberty simulation environment: A deliberate approach to high-level system modeling,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748306072&doi=10.1145%2f1151690.1151691&partnerID=40&md5=3e059e07b681a63643e10753ec3bbbaa,"In digital hardware system design, the quality of the product is directly related to the number of meaningful design alternatives properly considered. Unfortunately, existing modeling methodologies and tools have properties which make them less than ideal for rapid and accurate design-space exploration. This article identifies and evaluates the shortcomings of existing methods to motivate the Liberty Simulation Environment (LSE). LSE is a high-level modeling tool engineered to address these limitations, allowing for the rapid construction of accurate high-level simulation models. LSE simplifies model specification with low-overhead component-based reuse techniques and an abstraction for timing control. As part of a detailed description of LSE, this article presents these features, their impact on model specification effort, their implementation, and optimizations created to mitigate their otherwise deleterious impact on simulator execution performance. © 2006 ACM.",Component reuse; Liberty Simulation Environment (LSE); Simulator construction; Structural modeling,Computer aided design; Computer hardware; Computer simulation; Digital instruments; Mathematical models; Component reuse; Liberty Simulation Environment (LSE); Simulator construction; Structural modeling; Systems engineering
Locking under pfair scheduling,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745187321&doi=10.1145%2f1132026.1132028&partnerID=40&md5=22e2b89123d0e77f777e519c8db3e838,"We present several locking synchronization protocols for Pfair-scheduled multiprocessor systems. We focus on two classes of protocols. The first class is only applicable in systems in which all critical sections are short relative to the length of the scheduling quantum. In this case, efficient synchronization can be achieved by ensuring that all locks have been released before tasks are preempted. This is accomplished by exploiting the quantum-based nature of Pfair scheduling, which provides a priori knowledge of all possible preemption points. The second and more general protocol class is applicable to any system. For this class, we consider the use of a client-server model. We also discuss the viability of inheritance-based protocols in Pfair-scheduled systems. © 2006 ACM.",Locking; Multiprocessor; Pfairness; Real-time; Scheduling; Semaphore; Supertask; Synchronization,Client server computer systems; Mathematical models; Network protocols; Quantum theory; Synchronization; Locking; Pfairness; Semaphore; Supertask; Scheduling
Inferring internet denial-of-service activity,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745205813&doi=10.1145%2f1132026.1132027&partnerID=40&md5=aafdb68efd5e5a8e01312a73e51d7110,"In this article, we seek to address a simple question: ""How prevalent are denial-of-service attacks in the Internet?"" Our motivation is to quantitatively understand the nature of the current threat as well as to enable longer-term analyses of trends and recurring patterns of attacks. We present a new technique, called ""backscatter analysis,"" that provides a conservative estimate of worldwide denial-of-service activity. We use this approach on 22 traces (each covering a week or more) gathered over three years from 2001 through 2004. Across this corpus we quantitatively assess the number, duration, and focus of attacks, and qualitatively characterize their behavior. In total, we observed over 68,000 attacks directed at over 34,000 distinct victim IP addresses-ranging from well-known e-commerce companies such as Amazon and Hotmail to small foreign ISPs and dial-up connections. We believe our technique is the first to provide quantitative estimates of Internet-wide denial-of-service activity and that this article describes the most comprehensive public measurements of such activity to date. © 2006 ACM.",Backscatter; Denial-of-service; Network measurement; Network security,Backscattering; Internet; Parameter estimation; Security of data; Backscatter; Denial-of-service; Network measurement; Network security; Computer crime
On the performance of wide-area thin-client computing,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745203235&doi=10.1145%2f1132026.1132029&partnerID=40&md5=24a4c627dc505822af50eb69bad69956,"While many application service providers have proposed using thin-client computing to deliver computational services over the Internet, little work has been done to evaluate the effectiveness of thin-client computing in a wide-area network. To assess the potential of thin-client computing in the context of future commodity high-bandwidth Internet access, we have used a novel, noninvasive slow-motion benchmarking technique to evaluate the performance of several popular thin-client computing platforms in delivering computational services cross-country over Internet2. Our results show that using thin-client computing in a wide-area network environment can deliver acceptable performance over Internet2, even when client and server are located thousands of miles apart on opposite ends of the country. However, performance varies widely among thin-client platforms and not all platforms are suitable for this environment. While many thin-client systems are touted as being bandwidth efficient, we show that network latency is often the key factor in limiting wide-area thin-client performance. Furthermore, we show that the same techniques used to improve bandwidth efficiency often result in worse overall performance in wide-area networks. We characterize and analyze the different design choices in the various thin-client platforms and explain which of these choices should be selected for supporting wide-area computing services. © 2006 ACM.",Internet2; Slow-motion benchmarking; Thin-client; Wide-area networks,Bandwidth; Benchmarking; Client server computer systems; Computation theory; Wide area networks; Cross-country; Internet2; Slow-motion benchmarking; Thin-client; Internet
The costs and limits of availability for replicated services,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745220038&doi=10.1145%2f1124153.1124156&partnerID=40&md5=e60831c01f4a19c57b92cd17eaba188c,"As raw system performance continues to improve at exponential rates, the utility of many services is increasingly limited by availability rather than performance. A key approach to improving availability involves replicating the service across multiple, wide-area sites. However, replication introduces well-known trade-offs between service consistency and availability. Thus, this article explores the benefits of dynamically trading consistency for availability using a continuous consistency model. In this model, applications specify a maximum deviation from strong consistency on a per-replica basis. In this article, we: i) evaluate the availability of a prototype replication system running across the Internet as a function of consistency level, consistency protocol, and failure characteristics, ii) demonstrate that simple optimizations to existing consistency protocols result in significant availability improvements (more than an order of magnitude in some scenarios), iii) use our experience with these optimizations to prove tight upper bound on the availability of services, and iv) show that maximizing availability typically entails remaining as close to strong consistency as possible during times of good connectivity, resulting in a communication versus availability trade-off. © 2006 ACM.",Availability; Continuous consistency; Network services; Replication; Trade-off; Upper bound,Availability; Communication systems; Computer systems; Mathematical models; Network protocols; Continuous consistency; Network services; Replication; Trade-off; Upper bound; Electronic commerce
Performance analysis of TLS web servers,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745212646&doi=10.1145%2f1124153.1124155&partnerID=40&md5=65ad3f22934603e116c9bd42ef0debcb,"TLS is the protocol of choice for securing today's e-commerce and online transactions but adding TLS to a Web server imposes a significant overhead relative to an insecure Web server on the same platform. We perform a comprehensive study of the performance costs of TLS. Our methodology is to profile TLS Web servers with trace-driven workloads, replace individual components inside TLS with no-ops, and measure the observed increase in server throughput. We estimate the relative costs of each TLS processing stage, identifying the areas for which future optimizations would be worthwhile. Our results show that while the RSA operations represent the largest performance cost in TLS Web servers, they do not solely account for TLS overhead. RSA accelerators are effective for e-commerce site workloads since they experience low TLS session reuse. Accelerators appear to be less effective for sites where all the requests are handled by a TLS server because they have a higher session reuse rate. In this case, investing in a faster CPU might provide a greater boost in performance. Our experiments show that having a second CPU is at least as useful as an RSA accelerator. Our results seem to suggest that, as CPUs become faster, the cryptographic costs of TLS will become dwarfed by the CPU costs of the nonsecurity aspects of a Web server. Optimizations aimed at general purpose Web servers should continue to be a focus of research and would benefit secure Web servers as well. © 2006 ACM.",E-commerce; Internet; RSA accelerator; SecureWeb servers; TLS,Cryptography; Electronic commerce; Network protocols; Optimization; Security of data; World Wide Web; RSA accelerator; SecureWeb servers; Session reuse; TLS; Servers
Cryptography as an operating system service: A case study,2006,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745191399&doi=10.1145%2f1124153.1124154&partnerID=40&md5=55867ba57ec948f227863bbfb90bce7a,"Cryptographic transformations are a fundamental building block in many security applications and protocols. To improve performance, several vendors market hardware accelerator cards. However, until now no operating system provided a mechanism that allowed both uniform and efficient use of this new type of resource. We present the OpenBSD Cryptographic Framework (OCF), a service virtualization layer implemented inside the operating system kernel, that provides uniform access to accelerator functionality by hiding card-specific details behind a carefully designed API. We evaluate the impact of the OCF in a variety of benchmarks, measuring overall system performance, application throughput and latency, and aggregate throughput when multiple applications make use of it. We conclude that the OCF is extremely efficient in utilizing cryptographic accelerator functionality, attaining 95% of the theoretical peak device performance and over 800 Mbps aggregate throughput using 3DES. We believe that this validates our decision to opt for ease of use by applications and kernel components through a uniform API and for seamless support for new accelerators. Furthermore, our evaluation points to several bottlenecks in system and operating system design: data copying between user and kernel modes, PCI bus signaling inefficiency, protocols that use small data units, and single-threaded applications. We identify some of these limitations through a set of measurements focusing on application-layer cryptographic protocols such as SSL. We offer several suggestions for improvements and directions for future work. We provide experimental evidence of the effectiveness of a new approach which we call operating system shortcutting. Short-cutting can improve the performance of application-layer cryptographic protocols by 27% with very small changes to the kernel. © 2006 ACM.",Authentication; Cryptographic protocols; Digital signatures; Encryption; Hash functions,Computer hardware; Computer operating systems; Network protocols; Particle accelerators; Security of data; Application-layer; Authentication; Cryptographic protocols; Hash functions; Cryptography
The automatic improvement of locality in storage systems,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745218265&doi=10.1145%2f1113574.1113577&partnerID=40&md5=4420bc3d46dfcdf2af4ac7e4086dba4f,"Disk I/O is increasingly the performance bottleneck in computer systems despite rapidly increasing disk data transfer rates. In this article, we propose Automatic Locality-Improving Storage (ALIS), an introspective storage system that automatically reorganizes selected disk blocks based on the dynamic reference stream to increase effective storage performance. ALIS is based on the observations that sequential data fetch is far more efficient than random access, that improving seek distances produces only marginal performance improvements, and that the increasingly powerful processors and large memories in storage systems have ample capacity to reorganize the data layout and redirect the accesses so as to take advantage of rapid sequential data transfer. Using trace-driven simulation with a large set of real workloads, we demonstrate that ALIS considerably outperforms prior techniques, improving the average read performance by up to 50% for server workloads and by about 15% for personal computer workloads. We also show that the performance improvement persists as disk technology evolves. Since disk performance in practice is increasing by only about 8% per year, the benefit of ALIS may correspond to as much as several years of technological progress. © 2005 ACM.",Block layout; Data layout optimization; Data reorganization; Data restructuring; Defragmentation; Disk technology trends; Locality improvement; Prefetching,Computer science; Computer simulation; Data transfer; Personal computers; Random access storage; Servers; Block layout; Data layout optimization; Data reorganization; Data restructuring; Defragmentation; Disk technology trends; Locality improvement; Prefetching; Data storage equipment
Shared memory computing on clusters with symmetric multiprocessors and system area networks,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745212645&doi=10.1145%2f1082469.1082472&partnerID=40&md5=3dce0619c9ca9c95784f232675a1e270,"ACM Cashmere is a software distributed shared memory (S-DSM) system designed for clusters of server-class machines. It is distinguished from most other S-DSM projects by (1) the effective use of fast user-level messaging, as provided by modern system-area networks, and (2) a ""two-level"" protocol structure that exploits hardware coherence within multiprocessor nodes. Fast user-level messages change the tradeoffs in coherence protocol design; they allow Cashmere to employ a relatively simple directory-based coherence protocol. Exploiting hardware coherence within SMP nodes improves overall performance when care is taken to avoid interference with inter-node software coherence. We have implemented Cashmere on a Compaq AlphaServer/Memory Channel cluster, an architecture that provides fast user-level messages. Experiments indicate that a one-level, version of the Cashmere protocol provides performance comparable to, or slightly better than, that of Tread-Marks' lazy release consistency. Comparisons to Compaq's Shasta protocol also suggest that while fast user-level messages make finer-grain software DSMs competitive, VM-based systems continue to outperform software-based access control for applications without extensive fine-grain sharing. Within the family of Cashmere protocols, we find that leveraging intranode hardware coherence provides a 37% performance advantage over a more straightforward one-level implementation. Moreover, contrary to our original expectations, noncoherent hardware support for remote memory writes, total message ordering, and broadcast, provide comparatively little in the way of additional benefits over just fast messaging for our application suite. © 2005.",Distributed shared memory; Relaxed consistency; Software coherence,Computer networks; Computer software; Data storage equipment; Database systems; Microprocessor chips; Network protocols; Distributed shared memory; Message ordering; Relaxed consistency; Software coherence; Distributed computer systems
Quickly finding near-optimal storage designs,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745205292&doi=10.1145%2f1113574.1113575&partnerID=40&md5=f518fd20dc6482dff4296a932199c2d1,"Despite the importance of storage in enterprise computer systems, there are few adequate tools to design and configure a storage system to meet application data requirements efficiently. Storage system design involves choosing the disk arrays to use, setting the configuration options on those arrays, and determining an efficient mapping of application data onto the configured system. This is a complex process because of the multitude of disk array configuration options, and the need to take into account both capacity and potentially contending I/O performance demands when placing the data. Thus, both existing tools and administrators using rules of thumb often generate designs that are of poor quality. This article presents the Disk Array Designer (DAD), which is a tool that can be used both to guide administrators in their design decisions and to automate the design process. DAD uses a generalized best-fit bin packing heuristic with randomization and backtracking to search efficiently through the huge number of possible design choices. It makes decisions using device models that estimate storage system performance. We evaluate DAD's designs based on traces from a variety of database, filesystem, and e-mail workloads. We show that DAD can handle the difficult task of configuring midrange and high-end disk arrays, even with complex real-world workloads. We also show that DAD quickly generates near-optimal storage system designs, improving in both speed and quality over previous tools. © 2005 ACM.",Algorithms; Design; Management; Performance,Algorithms; Arrays; Data storage equipment; Decision theory; Electronic mail; Mapping; Mathematical models; Application data; Data requirements; Disk Array Designer (DAD); Near-optimal storage designs; Computer systems
The STAMPede approach to thread-level speculation,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745198176&doi=10.1145%2f1082469.1082471&partnerID=40&md5=1078d60ab7aa499409a6c663d0137109,"Multithreaded processor architectures are becoming increasingly commonplace: many current and upcoming designs support chip multiprocessing, simultaneous multithreading, or both. While it is relatively straightforward to use these architectures to improve the throughput of a multithreaded or multiprogrammed workload, the real challenge is how to easily create parallel software to allow single programs to effectively exploit all of this raw performance potential. One promising technique for overcoming this problem is Thread-Level Speculation (TLS), which enables the compiler to optimistically create parallel threads despite uncertainty as to whether those threads are actually independent. In this article, we propose and evaluate a design for supporting TLS that seamlessly scales both within a chip and beyond because it is a straightforward extension of write-back invalidation-based cache coherence (which itself scales both up and down). Our experimental results demonstrate that our scheme performs well on single-chip multiprocessors where the first level caches are either private or shared. For our private-cache design, the program performance of two of 13 general purpose applications studied improves by 86% and 56%, four others by more than 8%, and an average across all applications of 16%-confirming that TLS is a promising way to exploit the naturally-multithreaded processing resources of future computer systems. © 2005 ACM.",Automatic parallelization; Cache coherence; Chip-multiprocessing; Thread-level speculation,Computer architecture; Computer software; Computer systems; Multitasking; Problem solving; Automatic parallelization; Cache coherence; Chip-multiprocessing; Thread-level speculation; Microprocessor chips
MIDDLE-R: Consistent database replication at the middleware level,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745211410&doi=10.1145%2f1113574.1113576&partnerID=40&md5=a455232743330f36d7dc211742b9c2d2,"The widespread use of clusters and Web farms has increased the importance of data replication. In this article, we show how to implement consistent and scalable data replication at the middleware level. We do this by combining transactional concurrency control with group communication primitives. The article presents different replication protocols, argues their correctness, describes their implementation as part of a generic middleware, Middle-R, and proves their feasibility with an extensive performance evaluation. The solution proposed is well suited for a variety of applications including Web farms and distributed object platforms. © 2005 ACM.",Database replication; Eager data replication; Middleware; Scalability,Communication channels (information theory); Concurrency control; Data processing; Middleware; Problem solving; World Wide Web; Database replication; Eager data replication; Scalability; Web farms; Database systems
Gossip-based aggregation in large dynamic networks,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645666358&doi=10.1145%2f1082469.1082470&partnerID=40&md5=aa2698ca71d643e375dd13a9a387d948,"As computer networks increase in size, become more heterogeneous and span greater geographic distances, applications must be designed to cope with the very large scale, poor reliability, and often, with the extreme dynamism of the underlying network. Aggregation is a key functional building block for such applications: it refers to a set of functions that provide components of a distributed system access to global information including network size, average load, average uptime, location and description of hotspots, and so on. Local access to global information is often very useful, if not indispensable for building applications that are robust and adaptive. For example, in an industrial control application, some aggregate value reaching threshold may trigger the execution of certain actions; a distributed storage system will want to know the total available free space; load-balancing protocols may benefit from knowing the target average load so as to minimize the load they transfer. We propose a gossip-based protocol for computing aggregate values over network components in a fully decentralized fashion. The class of aggregate functions we can compute is very broad and includes many useful special cases such as counting, averages, sums, products, and extremal values. The protocol is suitable for extremely large and highly dynamic systems due to its proactive structure - all nodes receive the aggregate value continuously, thus being able to track any changes in the system. The protocol is also extremely lightweight, making it suitable for many distributed applications including peer-to-peer and grid computing systems. We demonstrate the efficiency and robustness of our gossip-based protocol both theoretically and experimentally under a variety of scenarios including node and communication failures. © 2005 ACM.",Gossip-based protocols; Proactive aggregation,Computation theory; Computer system recovery; Distributed computer systems; Information analysis; Network protocols; Robustness (control systems); Available free space; Decentralized fashion; Gossip-based protocols; Proactive aggregation; Computer networks
Improved latency and accuracy for neural branch prediction,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544503640&doi=10.1145%2f1062247.1062250&partnerID=40&md5=c3b7c44018b658aa438be395670740ad,"Microarchitectural prediction based on neural learning has received increasing attention in recent years. However, neural prediction remains impractical because its superior accuracy over conventional predictors is not enough to offset the cost imposed by its high latency. We present a new neural branch predictor that solves the problem from both directions: it is both more accurate and much faster than previous neural predictors. Our predictor improves accuracy by combining path and pattern history to overcome limitations inherent to previous predictors. It also has much lower latency than previous neural predictors. The result is a predictor with accuracy far superior to conventional predictors but with latency comparable to predictors from industrial designs. Our simulations show that a path-based neural predictor improves the instructions-per-cycle (IPC) rate of an aggressively clocked microarchitecture by 16% over the original perceptron predictor. One reason for the improved accuracy is the ability of our new predictor to learn linearly inseparable branches; we show that these branches account for 50% of all branches and almost all branch mispredictions. © 2005 ACM.",Branch prediction; Machine learning,Computer simulation; Costs; Learning systems; Problem solving; Microarchitectural prediction; Neural branch prediction; Neural learning; Computer systems
Nonblocking memory management support for dynamic-sized data structures,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544489038&doi=10.1145%2f1062247.1062249&partnerID=40&md5=c054f827a082690f655967547e2390c8,"Conventional dynamic memory management methods interact poorly with lock-free synchronization. In this article, we introduce novel techniques that allow lock-free data structures to allocate and free memory dynamically using any thread-safe memory management library. Our mechanisms are lock-free in the sense that they do not allow a thread to be prevented from allocating or freeing memory by the failure or delay of other threads. We demonstrate the utility of these techniques by showing how to modify the lock-free FIFO queue implementation of Michael and Scott to free unneeded memory. We give experimental results that show that the overhead introduced by such modifications is moderate, and is negligible under low contention.",Concurrent data structures; Dynamic data structures; Memory management; Multiprocessors; Nonblocking synchronization,Digital libraries; Queueing theory; Resource allocation; Synchronization; Dynamic memory management; FIFO queue; Thread-safe memory; Data structures
Comprehensive multiprocessor cache miss rate generation using multivariate models,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544508069&doi=10.1145%2f1062247.1062248&partnerID=40&md5=d3ec15813b2ac6df5d57f2fe8d940644,"This article presents a technique for taking a sparse set of cache simulation data and fitting a multivariate model to fill in the missing points over a broad region of cache configurations. We extend previous work by its applicability to multiple miss rate components and its ability to model a wide range of cache parameters, including size, associativity and sharing. Miss rate models are useful for broad design exploration in which many cache configurations cannot be simulated directly due to limitations of trace collection setups or available resources. We show the effectiveness of the technique by applying it to two commercial workloads and presenting miss rate data for a broad design space with cache size, associativity, sharing and number of processors as variables. The fitted data match the simulation data very well. The various curves show how a miss rate model is useful for not only estimating the performance of specific configurations, but also for providing insight into miss rate trends. Furthermore, this modeling methodology is robust in the presence of corrupted simulation data and variations in simulation data from multiple sources.",Additive models; Cache miss rates; Extrapolation; Isotonic regression; Queuing models,Computer simulation; Database systems; Decision making; Mathematical models; Cache configurations; Miss rate components; Multiprocessor cache; Cache memory
The LOCKSS peer-to-peer digital preservation system,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644392046&doi=10.1145%2f1047915.1047917&partnerID=40&md5=6cee8cc46b493638c5990df037938d2d,"The LOCKSS project has developed and deployed in a world-wide test a peer-to-peer system for preserving access to journals and other archival information published on the Web. It consists of a large number of independent, low-cost, persistent Web caches that cooperate to detect and repair damage to their content by voting in ""opinion polls."" Based on this experience, we present a design for and simulations of a novel protocol for voting in systems of this kind. It incorporates rate limitation and intrusion detection to ensure that even some very powerful adversaries attacking over many years have only a small probability of causing irrecoverable damage before being detected. © 2005.",Digital preservation; Rate limiting; Replicated storage,Computer operating systems; Computer simulation; Digital storage; Estimation; Information retrieval; Large scale systems; Mathematical models; Network protocols; Probability; Problem solving; World Wide Web; Digital preservation; Peer-to-peer opinion poll protocols; Rate limiting; Replicated storage; Digital libraries
Improving the reliability of commodity operating systems,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644400693&doi=10.1145%2f1047915.1047919&partnerID=40&md5=abf20c72afc348f28e2286d6b0ca0906,"Despite decades of research in extensible operating system technology, extensions such as device drivers remain a significant cause of system failures. In Windows XP, for example, drivers account for 85% of recently reported failures. This article describes Nooks, a reliability subsystem that seeks to greatly enhance operating system (OS) reliability by isolating the OS from driver failures. The Nooks approach is practical: rather than guaranteeing complete fault tolerance through a new (and incompatible) OS or driver architecture, our goal is to prevent the vast majority of driver-caused crashes with little or no change to the existing driver and system code. Nooks isolates drivers within lightweight protection domains inside the kernel address space, where hardware and software prevent them from corrupting the kernel. Nooks also tracks a driver's use of kernel resources to facilitate automatic cleanup during recovery. To prove the viability of our approach, we implemented Nooks in the Linux operating system and used it to fault-isolate several device drivers. Our results show that Nooks offers a substantial increase in the reliability of operating systems, catching and quickly recovering from many faults that would otherwise crash the system. Under a wide range and number of fault conditions, we show that Nooks recovers automatically from 99% of the faults that otherwise cause Linux to crash. While Nooks was designed for drivers, our techniques generalize to other kernel extensions. We demonstrate this by isolating a kernel-mode file system and an in-kernel Internet service. Overall, because Nooks supports existing C-language extensions, runs on a commodity operating system and hardware, and enables automated recovery, it represents a substantial step beyond the specialized architectures and type-safe languages required by previous efforts directed at safe extensibility. © 2005 ACM.",Device drivers; I/O; Protection; Recovery; Virtual memory,Codes (symbols); Computer architecture; Computer hardware; Computer programming languages; Data structures; Error analysis; Fault tolerant computer systems; Interfaces (computer); Internet; Reliability; Commodity operating systems; Device drivers; Input/output (I/O); Virtual memory; Computer operating systems
Backtracking intrusions,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644382986&doi=10.1145%2f1047915.1047918&partnerID=40&md5=f48b7974c6fea4a15cb30341789dbd06,"Analyzing intrusions today is an arduous, largely manual task because system administrators lack the information and tools needed to understand easily the sequence of steps that occurred in an attack. The goal of BackTracker is to identify automatically potential sequences of steps that occurred in an intrusion. Starting with a single detection point (e.g., a suspicious file), BackTracker identifies files and processes that could have affected that detection point and displays chains of events in a dependency graph. We use BackTracker to analyze several real attacks against computers that we set up as honeypots. In each case, BackTracker is able to highlight effectively the entry point used to gain access to the system and the sequence of steps from that entry point to the point at which we noticed the intrusion. The logging required to support BackTracker added 9% overhead in running time and generated 1.2 GB per day of log data for an operating-system intensive workload. © 2005.",Computer forensics; Information flow; Intrusion analysis,Computer crime; Computer networks; Computer operating systems; Computer software; Computer viruses; Data acquisition; Information analysis; Management information systems; Computer forensics; Disk state; Information flow; Intrusion analysis; Security of data
ACM Transactions on Computer Systems: Editorial,2005,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644365589&doi=10.1145%2f1047915.1047916&partnerID=40&md5=af3c2d7b254f57548ec60ae7c10be126,[No abstract available],,
System support for pervasive applications,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-19944379443&doi=10.1145%2f1035582.1035584&partnerID=40&md5=973df551e4b461caf9ee5b86a3ddb5b8,"Pervasive computing provides an attractive vision for the future of computing. Computational power will be available everywhere. Mobile and stationary devices will dynamically connect and coordinate to seamlessly help people in accomplishing their tasks. For this vision to become a reality, developers must build applications that constantly adapt to a highly dynamic computing environment. To make the developers' task feasible, we present a system architecture for pervasive computing, called one.world. Our architecture provides an integrated and comprehensive framework for building pervasive applications. It includes services, such as discovery and migration, that help to build applications and directly simplify the task of coping with constant change. We describe our architecture and its programming model and reflect on our own and others' experiences with using it.",Asynchronous events; Checkpointing; Discovery; Logic/operation pattern; Migration; One.world; Pervasive computing; Structured I/O; Tuples; Ubiquitous computing,Computer architecture; Computer programming; Computer science; Mathematical models; Network protocols; Problem solving; Search engines; Websites; Asynchronous events; Checkpointing; Logic/operation pattern; Migration; One.world; Pervasive computing; Tuples; Ubiquitous computing; Distributed computer systems
Firmato: A novel firewall management toolkit,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10944269775&doi=10.1145%2f1035582.1035583&partnerID=40&md5=b87ad7441724135f29f3b4e6a39986d6,"In recent years packet-filtering firewalls have seen some impressive technological advances (e.g., stateful inspection, transparency, performance, etc.) and wide-spread deployment. In contrast, fire-wall and security management technology is lacking. In this paper we present Firmato, a firewall management toolkit, with the following distinguishing properties and components: (1) an entity-relationship model containing, in a unified form, global knowledge of the security policy and of the network topology; (2) a model definition language, which we use as an interface to define an instance of the entity-relationship model; (3) a model compiler, translating the global knowledge of the model into firewall-specific configuration files; and (4) a graphical firewall rule illustrator. We implemented a prototype of our toolkit to work with several commercially available fire-wall products. This prototype was used to control an operational firewall for several months. We believe that our approach is an important step toward streamlining the process of configuring and managing firewalls, especially in complex, multi-firewall installations.",,Computer programming languages; Gateways (computer networks); Intranets; Mathematical models; Program compilers; Security of data; Topology; Visualization; Firewall management; Model definition language; Security policy; Computer system firewalls
Cluster communication protocols for parallel-programming systems,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444332600&doi=10.1145%2f1012268.1012269&partnerID=40&md5=8dba567803f4214a78c6a5381d9a65ff,"Clusters of workstations are a popular platform for high-performance computing. For many parallel applications, efficient use of a fast interconnection network is essential for good performance. Several modern System Area Networks include programmable network interfaces that can be tailored to perform protocol tasks that otherwise would need to be done by the host processors. Finding the right trade-off between protocol processing at the host and the network interface is difficult in general. In this work, we systematically evaluate the performance of different implementations of a single, user-level communication interface. The implementations make different architectural assumptions about the reliability of the network and the capabilities of the network interface. The implementations differ accordingly in their division of protocol tasks between host software, network-interface firmware, and network hardware. Also, we investigate the effects of alternative data-transfer methods and multicast implementations, and we evaluate the influence of packet size. Using microbenchmarks, parallel-programming systems, and parallel applications, we assess the performance of the different implementations at multiple levels. We use two hardware platforms with different performance characteristics to validate our conclusions. We show how moving protocol tasks to a relatively slow network interface can yield both performance advantages and disadvantages, depending on specific characteristics of the application and the underlying parallel-programming system.",Clusters; Parallel-programming systems; System area networks,Benchmarking; Communication systems; Computer programming; Data storage equipment; Data transfer; Distributed computer systems; Interconnection networks; Interfaces (computer); Parallel processing systems; Clusters; Host processors; Parallel programming systems; Systems area network; Network protocols
A study of source-level compiler algorithms for automatic construction of pre-execution code,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444263176&doi=10.1145%2f1012268.1012270&partnerID=40&md5=3fc1e8b0716dd10fa20d55532aef79c1,The different source-to-source C compilers and algorithms for extracting pre-execution thread code automatically relieving the programmer and the hardware to perform onerous tasks was discussed. An aggressive profile-driven compiler was presented that employed three powerful algorithms for code extraction. These three algorithms were program slicing prefetch conversion and speculative loop parallelization. The results shows that the compiler based pre-execution achieved performance gains and reduced execution time by 20.9% for 10 out of 13 applications. The aggressive compiler could also be simplified with minimal impact on the performance.,Data prefetching; Memory-level parallelism; Multithreading; Pre-execution; Prefetch conversion; Program slicing; Speculative loop parallelization,Algorithms; Binary codes; Buffer storage; Computer hardware; Computer programming; Computer programming languages; Information dissemination; Multiprogramming; Programmed control systems; Software prototyping; Data prefetching; Memory-level parallelism; Multithreading; Pre-execution; Program slicing; Speculative loop parallelization; Program compilers
Managing battery lifetime with energy-aware adaptation,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2542487475&doi=10.1145%2f986533.986534&partnerID=40&md5=61aac453142ccc4941b44db7971d4dd9,"We demonstrate that a collaborative relationship between the operating system and applications can be used to meet user-specified goals for battery duration. We first describe a novel profiling-based approach for accurately measuring application and system energy consumption. We then show how applications can dynamically modify their behavior to conserve energy. We extend the Linux operating system to yield battery lifetimes of user-specified duration. By monitoring energy supply and demand and by maintaining a history of application energy use, the approach can dynamically balance energy conservation and application quality. Our evaluation shows that this approach can meet goals that extend battery life by as much as 30%.",Adaptation; Power management,Computer hardware; Computer operating systems; Computer simulation; Decision making; Electric batteries; Energy management; Energy utilization; Systems analysis; Adaptation; Battery lifetime; LINUX; Power management; Mobile computing
Coupling compiler-enabled and conventional memory accessing for energy efficiency,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2542424763&doi=10.1145%2f986533.986535&partnerID=40&md5=594741e25b918fb6b295eb9f454e348b,"This article presents Cool-Mem, a family of memory system architectures that integrate conventional memory system mechanisms, energy-aware address translation, and compiler-enabled cache disambiguation techniques, to reduce energy consumption in general-purpose architectures. The solutions provided in this article leverage on interlayer tradeoffs between architecture, compiler, and operating system layers. Cool-Mem achieves power reduction by statically matching memory operations with energy-efficient cache and virtual memory access mechanisms. It combines statically speculative cache access modes, a dynamic content addressable memory-based (CAM-based) Tag-Cache used as backup for statically mispredicted accesses, different conventional multilevel associative cache organizations, embedded protection checking along all cache access mechanisms, as well as architectural organizations to reduce the power consumed by address translation in virtual memory. Because it is based on speculative static information, a superset of the predictable program information available at compile-time, our approach removes the burden of provable correctness in compiler analysis passes that extract static information. This makes Cool-Mem highly practical, applicable for large and complex applications, without having any limitations due to complexity issues in our compiler passes or the presence of precompiled static libraries. Based on extensive evaluation, for both SPEC2000 and Mediabench applications, we obtain from 6% to 19% total energy savings in the processor, with performance ranging from 1.5% degradation to 6% improvement, for the applications studied. We have also compared Cool-Mem to several prior arts and have found Cool-Mem to perform better in almost all cases.",Energy efficiency; Translation buffers; Virtually addressed caches,Algorithms; Computer operating systems; Computer programming; Energy efficiency; Program compilers; Program translators; Content addressable memory-based (CAM-based); Memory systems; Translation buffers; Virtually addressed caches; Cache memory
A general framework for prefetch scheduling in linked data structures and its application to multi-chain prefetching,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2542441690&doi=10.1145%2f986533.986536&partnerID=40&md5=d747895285f216ae59e87ee6bd522def,"The interchain memory parallelism for the purposes of memory latency tolerance was investigated, using multi-chain prefetching technique. A framework was introduced for compactly describing linked data structures (LDS) traversals, providing the data layout and traversal code work information necessary for prefetching. An off-line scheduling algorithm was presented for computing a prefetch schedule from the LDS decriptors that overlaps serialized cache. The results show that compiler-instrumented multi-chain prefetching improves execution time by 40% across six pointer-chasing kernels.",Data prefetching; Memory parallelism; Pointer-chasing code,Algorithms; Benchmarking; Cache memory; Codes (symbols); Data compression; Markov processes; Object oriented programming; Problem solving; Program compilers; Scheduling; Speech recognition; Trees (mathematics); Data prefetching; Linked data structures (LDS); Memory parallelism; Multiple independent pointer chains; Pointer-chaising code; Data structures
Parallel program performance prediction using deterministic task graph analysis,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442517698&doi=10.1145%2f966785.966788&partnerID=40&md5=6c2a358f92baaa2e6314a5fd0fa870e5,"The techniques for predicting detailed performance characteristics of a single shared memory parallel program were discussed. A deterministic task graph analysis was developed that provided detailed performance prediction for shared-memory programs with arbitary task graps. The model assumed the deterministic task execution times and was evaluated in three ways. The results show that the technique is accurate and efficient for a variety of shared-memory programs, and the deterministic assumption is crucial to permit accurate and efficient analysis of these programs.",Analytical model; Deterministic model; Parallel program performance prediction; Queueing network; Shared memory; Task graph; Task scheduling,Algorithms; Computational methods; Computer program listings; Computer simulation; Parameter estimation; Queueing networks; Random processes; Scheduling; Synchronization; Analytical models; Deterministic models; Parallel program performance prediction; Shared memory; Task graph; Task scheduling; Parallel processing systems
Using certes to infer client response time at the web server,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442507119&doi=10.1145%2f966785.966787&partnerID=40&md5=98c20d19d7fb07953b5ee3b2b38ce35e,"As businesses continue to grow their World Wide Web presence, it is becoming increasingly vital for them to have quantitative measures of the mean client perceived response times of their web services. We present Certes (CliEnt Response Time Estimated by the Server), an online server-based mechanism that allows web servers to estimate mean client perceived response time, as if measured at the client. Certes is based on a model of TCP that quantifies the effect that connection drops have on mean client perceived response time by using three simple server-side measurements: connection drop rate, connection accept rate and connection completion rate. The mechanism does not require modifications to HTTP servers or web pages, does not rely on probing or third party sampling, and does not require client-side modifications or scripting. Certes can be used to estimate response times for any web content, not just HTML. We have implemented Certes and compared its response time estimates with those obtained with detailed client instrumentation. Our results demonstrate that Certes provides accurate server-based estimates of mean client response times in HTTP 1.0/1.1 environments, even with rapidly changing workloads. Certes runs online in constant time with very low overhead. It can be used at websites and server farms to verify compliance with service level objectives.",Client perceived response time; Web server,Benchmarking; Computational methods; Computer operating systems; HTML; Network protocols; Problem solving; Response time (computer systems); Servers; World Wide Web; Client perceived response times; Operational analysis; Web servers; Client server computer systems
Stateful distributed interposition,2004,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442509236&doi=10.1145%2f966785.966786&partnerID=40&md5=d30d0a5eac245024a7e2022dfcf19709,"Interposition-based system enhancements for multitiered servers are difficult to build because important system context is typically lost at application and machine boundaries. For example, resource quotas and user identities do not propagate easily between cooperating services that execute on different hosts or that communicate with each other via intermediary services. Application-transparent system enhancement is difficult to achieve when such context information is obscured by complex service interaction patterns. We propose a basic mechanism for sharing contextual information across the tiers of multitier computations to support system enhancement for multitier servers and applications. This article introduces generic, cluster-wide context as a new, configurable abstraction for the OS. System administrator- or application-specified context tracking rules determine how context is associated with system processes, sockets, messages, how it is relayed along the interapplication communication channels, and how it is to be interpreted by system interpositions, thus realizing Stateful Distributed Interposition.",Component services; Distributed computing; Distributed context; Multitiered services; Operating systems; Server consolidation,Computational methods; Computer operating systems; Database systems; Error analysis; Information analysis; Interfaces (computer); Servers; World Wide Web; Component services; Distributed computing; Distributed context; Multitiered services; Server consolidation; Distributed computer systems
"Astrolabe: A robust and scalable technology for distributed system monitoring, management, and data mining",2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746780102&doi=10.1145%2f762483.762485&partnerID=40&md5=39e35e6dcafb50fca7f2d7f2b17d0831,"Scalable management and self-organizational capabilities are emerging as central requirements for a generation of large-scale, highly dynamic, distributed applications. We have developed an entirely new distributed information management system called Astrolabe. Astrolabe collects large-scale system state, permitting rapid updates and providing on-the-fly attribute aggregation. This latter capability permits an application to locate a resource, and also offers a scalable way to track system state as it evolves over time. The combination of features makes it possible to solve a wide variety of management and self-configuration problems. This paper describes the design of the system with a focus upon its scalability. After describing the Astrolabe service, we present examples of the use of Astrolabe for locating resources, publish-subscribe, and distributed synchronization in large systems. Astrolabe is implemented using a peer-to-peer protocol, and uses a restricted form of mobile code based on the SQL query language for aggregation. This protocol gives rise to a novel consistency model. Astrolabe addresses several security considerations using a built-in PKI. The scalability of the system is evaluated using both simulation and experiments; these confirm that Astrolabe could scale to thousands and perhaps millions of nodes, with information propagation delays in the tens of seconds. © 2003 ACM.",Algorithms; Design; Management; Performance; Reliability; Security,Algorithms; Computer programming languages; Condition monitoring; Data mining; Information management; Large scale systems; Management; Mathematical models; Network protocols; Query languages; Synchronization; Distributed applications; Distributed synchronization; Information propagation; Nodes; Scalable technology; Security; Distributed computer systems
Size-based scheduling to improve web performance,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2342603698&doi=10.1145%2f762483.762486&partnerID=40&md5=82f4b5682159085371d2cee6dbc85ce8,"Is it possible to reduce the expected response time of every request at a web server, simply by changing the order in which we schedule the requests? That is the question we ask in this paper. This paper proposes a method for improving the performance of web servers servicing static HTTP requests. The idea is to give preference to requests for small files or requests with short remaining file size, in accordance with the SRPT (Shortest Remaining Processing Time) scheduling policy. The implementation is at the kernel level and involves controlling the order in which socket buffers are drained into the network. Experiments are executed both in a LAN and a WAN environment. We use the Linux operating system and the Apache and Flash web servers. Results indicate that SRPT-based scheduling of connections yields significant reductions in delay at the web server. These result in a substantial reduction in mean response time and mean slowdown for both the LAN and WAN environments. Significantly, and counter to intuition, the requests for large files are only negligibly penalized or not at all penalized as a result of SRPT-based scheduling. © 2003 ACM.",Conservation law; Networking; Scheduling; SJF; SRPT; System performance and design; Web servers,Computer operating systems; Controllability; HTTP; Local area networks; Network protocols; Servers; Wide area networks; World Wide Web; Conservation law; Networking; SJF; SRPT; System performance and design; Web servers; Scheduling
A SMART scheduler for multimedia applications,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-26444588421&doi=10.1145%2f762483.762484&partnerID=40&md5=2ce0f2733d50132da9bc3699ed75f5ad,"Real-time applications such as multimedia audio and video are increasingly populating the work-station desktop. To support the execution of these applications in conjunction with traditional non-real-time applications, we have created SMART, a Scheduler for Multimedia And Real-Time applications. SMART supports applications with time constraints, and provides dynamic feedback to applications to allow them to adapt to the current load. In addition, the support for real-time applications is integrated with the support for conventional computations. This allows the user to prioritize across real-time and conventional computations, and dictate how the processor is to be shared among applications of the same priority. As the system load changes, SMART adjusts the allocation of resources dynamically and seamlessly. It can dynamically shed real-time computations and regulate the execution rates of real-time tasks when the system is overloaded, while providing better value in underloaded conditions than previously proposed schemes. We have implemented SMART in the Solaris UNIX operating system and measured its performance against other schedulers commonly used in research and practice in executing real-time, interactive, and batch applications. Our experimental results demonstrate SMARTS superior performance over fair queueing and UNIX SVR4 schedulers in supporting multimedia applications. © 2003 ACM.",Multimedia; Proportional sharing; Real-time; Scheduling,Audio systems; Computation theory; Computer operating systems; Constraint theory; Digital communication systems; Feedback; Multimedia systems; Program processors; Real time systems; Resource allocation; Multimedia; Proportional sharing; Queueing; Real-time; UNIX SVR4 schedulers; Scheduling
Lightweight probabilistic broadcast,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442558299&doi=10.1145%2f945506.945507&partnerID=40&md5=ae3523288000b0434f40e4071822bb1d,"Gossip-based broadcast algorithms, a family of probabilistic broadcast algorithms, trade reliability guarantees against ""scalability"" properties. Scalability in this context has usually been expressed in terms of message throughput and delivery latency, but there has been little work on how to reduce the memory consumption for membership management and message buffering at large scale. This paper presents lightweight probabilistic broadcast (lpbcast), a novel gossip-based broad-cast algorithm, which complements the inherent throughput scalability of traditional probabilistic broadcast algorithms with a scalable memory management technique. Our algorithm is completely decentralized and based only on local information: in particular, every process only knows a fixed subset of processes in the system and only buffers fixed ""most suitable"" subsets of messages. We analyze our broadcast algorithm stochastically and compare the analytical results both with simulations and concrete implementation measurements.",Broadcast; Buffering; Garbage collection; Gossip; Noise; Randomization; Reliability; Scalability,Algorithms; Broadcasting; Failure analysis; Multicasting; Optimization; Probability distributions; Random processes; Reliability; Spurious signal noise; Broadcast; Buffering; Garbage collection; Gossip; Noise; Randomization; Scalability; Telecommunication networks
BASE: Using abstraction to improve fault tolerance,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442619381&doi=10.1145%2f859716.859718&partnerID=40&md5=9ed6e55870dfcd436587cd438c8e2d1a,"Software errors are a major cause of outages and they are increasingly exploited in malicious attacks. Byzantine fault tolerance allows replicated systems to mask some software errors but it is expensive to deploy. This paper describes a replication technique, BASE, which uses abstraction to reduce the cost of Byzantine fault tolerance and to improve its ability to mask software errors. BASE reduces cost because it enables reuse of off-the-shelf service implementations. It improves availability because each replica can be repaired periodically using an abstract view of the state stored by correct replicas, and because each replica can run distinct or nondeterministic service implementations, which reduces the probability of common mode failures. We built an NFS service where each replica can run a different off-the-shelf file system implementation, and an object-oriented database where the replicas ran the same, nondeterministic implementation. These examples suggest that our technique can be used in practice - in both cases, the implementation required only a modest amount of new code, and our performance results indicate that the replicated services perform comparably to the implementations that they reuse.",Asynchronous systems; Byzantine fault tolerance; N-version programming; Proactive recovery; State machine replication,Computer networks; Computer programming; Cryptography; Database systems; Error analysis; Performance; Probability; Computer-communication networks; Proactive recovery; State machine replication; Computer software
ACM transaction on computer systems: Editorial,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442547760&doi=10.1145%2f859716.859717&partnerID=40&md5=54779495ebee8a9e7f0a7d45fe229c33,[No abstract available],,
An evaluation of speculative instruction execution on simultaneous multithreaded processors,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442554106&doi=10.1145%2f859716.859720&partnerID=40&md5=a3c188d0172d75983cab2828e9531665,"Modern superscalar processors rely heavily on speculative execution for performance. For example, our measurements show that on a 6-issue superscalar, 93% of committed instructions for SPECINT95 are speculative. Without speculation, processor resources on such machines would be largely idle. In contrast to superscalars, simultaneous multithreaded (SMT) processors achieve high resource utilization by issuing instructions from multiple threads every cycle. An SMT processor thus has two means of hiding latency: speculation and multithreaded execution, However, these two techniques may conflict; on an SMT processor, wrong-path speculative instructions from one thread may compete with and displace useful instructions from another thread. For this reason, it is important to understand the trade-offs between these two latency-hiding techniques, and to ask whether multithreaded processors should speculate differently than conventional superscalars. This paper evaluates the behavior of instruction speculation on SMT processors using both multiprogrammed (SPECINT and SPECFP) and multithreaded (the Apache Web server) workloads. We measure and analyze the impact of speculation and demonstrate how speculation on an 8-context SMT differs from superscalar speculation. We also examine the effect of speculation-aware fetch and branch prediction policies in the processor. Our results quantify the extent to which (1) speculation is critical to performance on a multithreaded processor because it ensures an ample supply of parallelism to feed the functional units, and (2) SMT actually enhances the effectiveness of speculative execution, compared to a superscalar processor by reducing the impact of branch misprediction. Finally, we quantify the impact of both hardware configuration and workload characteristics on speculation's usefulness and demonstrate that, in nearly all cases, speculation is beneficial to SMT performance. Instruction-level parallelism, multiprocessors, multithreading, simultaneous multithreading, speculation, thread-level parallelism.",,Computer architecture; Computer programming; Computer simulation; Decision making; Mathematical models; Parallel processing systems; Performance; Servers; Functional units; Multithread execution; Multithread processors; Processor architectures; Multiprocessing systems
"New directions in traffic measurement and accounting: Focusing on the elephants, ignoring the mice",2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442583610&doi=10.1145%2f859716.859719&partnerID=40&md5=c5101cb09e5247b6318d977c07436323,"Accurate network traffic measurement is required for accounting, bandwidth provisioning and detecting DoS attacks. These applications see the traffic as a collection of flows they need to measure. As link speeds and the number of flows increase, keeping a counter for each flow is too expensive (using SRAM) or slow (using DRAM). The current state-of-the-art methods (Cisco's sampled NetFlow), which count periodically sampled packets are slow, inaccurate and resource-intensive. Previous work showed that at different granularities a small number of ""heavy hitters"" accounts for a large share of traffic. Our paper introduces a paradigm shift by concentrating the measurement process on large flows only - those above some threshold such as 0.1% of the link capacity. We propose two novel and scalable algorithms for identifying the large flows: sample and hold and multistage filters, which take a constant number of memory references per packet and use a small amount of memory. If M is the available memory, we show analytically that the errors of our new algorithms are proportional to 1/M; by contrast, the error of an algorithm based on classical sampling is proportional to 1/√M, thus providing much less accuracy for the same amount of memory. We also describe optimizations such as early removal and conservative update that further improve the accuracy of our algorithms, as measured on real traffic traces, by an order of magnitude. Our schemes allow a new form of accounting called threshold accounting in which only flows above a threshold are charged by usage while the rest are charged a fixed fee. Threshold accounting generalizes usage-based and duration based pricing. Additional Key Words and Phrases: Network traffic measurement, usage based accounting, scalability, on-line algorithms, identifying large flows.",,Algorithms; Bandwidth; Data storage equipment; Dynamic random access storage; Error analysis; Optimization; Static random access storage; Computer-communication networks; Network monitoring; Network traffic measurement; On-line algorithms; Telecommunication traffic
Balancing performance and flexibility with hardware support for network architectures,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442430636&doi=10.1145%2f945506.945508&partnerID=40&md5=4a6644a756a1ec80529ae1b81e9746d1,"The goals of performance and flexibility are often at odds in the design of network systems. The tension is common enough to justify an architectural solution, rather than a set of context-specific solutions. The Programmable Protocol Processing Pipeline (P4) design uses programmable hardware to selectively accelerate protocol processing functions. A set of field-programmable gate arrays (FPGAs) and an associated library of network processing modules implemented in hardware are augmented with software support for function selection and composition, and applied to processing-intensive portions of a user-programmable protocol stack. The system is sufficiently flexible to support protocol stacks that are dynamically altered in reaction to changing network conditions or user needs. The P4 can be transparently inserted into a conventional protocol architecture, such as that of TCP/IP. This experimental demonstration shows that the P4's programmability can be used to significantly improve the performance of TCP/IP under operating conditions where the protocol would perform poorly without augmentation. Generalizing from these experiments, the P4 is shown to have many applications as an open platform for implementing adaptive and programmable networks, and has illustrated new security issues that arise in FPGA-based architectures. The P4 and closely-related systems, such as network processors, are attractive architectural solutions to balancing performance and flexibility.",Computer networking; Flexibility; FPGA; Hardware; P4; Performance; Programmable logic devices; Programmable networks; Protocol processing,Algorithms; Architectural design; Computer programming; Field programmable gate arrays; Hardware; Network protocols; Optimization; Programmable logic controllers; Signal detection; Standardization; Computer networking; Flexibility; P4; Programmable logic devices; Programmable networks; Protocol processing; Internet
Measuring thin-client performance using slow-motion benchmarking,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442545605&doi=10.1145%2f592637.592640&partnerID=40&md5=b2435caf34f0cf8c65d766ce21708c78,"Modern thin-client systems are designed to provide the same graphical interfaces and applications available on traditional desktop computers while centralizing administration and allowing more efficient use of computing resources. Despite the rapidly increasing popularity of these client-server systems, there are few reliable analyses of their performance. Industry standard benchmark techniques commonly used for measuring desktop system performance are ill-suited for measuring the performance of thin-client systems because these benchmarks only measure application performance on the server, not the actual user-perceived performance on the client. To address this problem, we have developed slow-motion benchmarking, a new measurement technique for evaluating thin-client systems. In slow-motion benchmarking, performance is measured by capturing network packet traces between a thin client and its respective server during the execution of a slow-motion version of a conventional benchmark application. These results can then be used either independently or in conjunction with conventional benchmark results to yield an accurate and objective measure of the performance of thin-client systems. We have demonstrated the effectiveness of slow-motion benchmarking by using this technique to measure the performance of several popular thin-client systems in various network environments on Web and multimedia workloads. Our results show that slow-motion benchmarking solves the problems with using conventional benchmarks on thin-client systems and is an accurate tool for analyzing the performance of these systems.",Client-server; Measurement methodology; Multimedia; Thin-client computing,Benchmarking; Computer networks; Graphical user interfaces; Multimedia systems; Personal computers; Problem solving; Websites; Client-server; Measurement methodology; Thin-client computing; Client server computer systems
Run-time support for distributed sharing in safe languages,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442552023&doi=10.1145%2f592637.592638&partnerID=40&md5=097d385252dc9c07df0269a088a8e3a7,"We present a new run-time system that supports object sharing in a distributed system. The key insight in this system is that a handle-based implementation of such a system enables efficient and transparent sharing of data with both fine- and coarse-grained access patterns. In addition, it supports efficient execution of garbage-collected programs. In contrast, conventional distributed shared memory (DSM) systems are limited to providing only one granularity with good performance, and have experienced difficulty in efficiently supporting garbage collection. A safe language, in which no pointer arithmetic is allowed, can transparently be compiled into a handle-based system and constitutes its preferred mode of use. A programmer can also directly use a handle-based programming model that avoids pointer arithmetic on the handles, and achieve the same performance but without the programming benefits of a safe programming language. This new run-time system, DOSA (Distributed Object Sharing Architecture), provides a shared object space abstraction rather than a shared address space abstraction. The key to its efficiency is the observation that a handle-based distributed implementation permits VM-based access and modification detection without suffering false sharing for fine-grained access patterns. We compare DOSA to TreadMarks, a conventional DSM system that is efficient at handling coarse-grained sharing. The performance of fine-grained applications and garbage-collected applications is considerably better than in TreadMarks, and the performance of coarse-grained applications is nearly as good as in TreadMarks. Inasmuch as the performance of such applications is already good in TreadMarks, we consider this an acceptable performance penalty.",Communications; Distributed sharing; Memory consistency; Safe programming languages,Computer architecture; Computer networks; Computer operating systems; Computer software; Data storage equipment; Java programming language; Network protocols; Problem solving; Distributed sharing; Memory consistency; Safe programming language; Distributed computer systems
Run-time adaptation in River,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442499596&doi=10.1145%2f592637.592639&partnerID=40&md5=3fad7a059d1044c600135234a7722714,"We present the design, implementation, and evaluation of run-time adaptation within the River dataflow programming environment. The goal of the River system is to provide adaptive mechanisms that allow database query-processing applications to cope with performance variations that are common in cluster platforms. We describe the system and its basic mechanisms, and carefully evaluate those mechanisms and their effectiveness. In our analysis, we answer four previously unanswered and important questions. Are the core run-time adaptive mechanisms effective, especially as compared to the ideal? What are the keys to making them work well? Can applications easily use these primitives? And finally, are there situations in which run-time adaptation is not sufficient? In performing our study, we utilize a three-pronged approach, comparing results from idealized models of system behavior, targeted simulations, and a prototype implementation. As well as providing insight on the positives and negatives of run-time adaptation both specifically in River and in a broader context, we also comment on the interplay of modeling, simulation, and implementation in system design.",Clusters; Parallel I/O; Performance availability; Performance faults; Robust performance; Run-time adaptation,Computer simulation; Data processing; Data reduction; Database systems; Disks (machine components); Mathematical models; Robustness (control systems); Parallel I/O; Performance availability; Performance faults; Robust performance; Run-time adaptation; Query languages
Call graph prefetching for database applications,2003,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442585659&doi=10.1145%2f945506.945509&partnerID=40&md5=7abf4597d8ed46624e53bfaf38bf14e8,"With the continuing technological trend of ever cheaper and larger memory, most data sets in database servers will soon be able to reside in main memory. In this configuration, the performance bottleneck is likely to be the gap between the processing speed of the CPU and the memory access latency. Previous work has shown that database applications have large instruction and data footprints and hence do not use processor caches effectively. In this paper, we propose Call Graph Prefetching (CGP), an N instruction prefetching technique that analyzes the call graph of a database system and prefetches instructions from the function that is deemed likely to be called next. CGP capitalizes on the highly predictable function call sequences that are typical of database systems. CGP can be implemented either in software or in hardware. The software-based CGP (CGP_S) uses profile information to build a call graph, and uses the predictable call sequences in the call graph to determine which function to prefetch next. The hardware-based CGP(CGP_H) uses a hardware table, called the Call Graph History Cache (CGHC), to dynamically store sequences of functions invoked during program execution, and uses that stored history when choosing which functions to prefetch. We evaluate the performance of CGP on sets of Wisconsin and TPC-H queries, as well as on CPU-2000 benchmarks. For most CPU-2000 applications the number of instruction cache (I-cache) misses were very few even without any prefetching, obviating the need for CGP. On the other hand, the database workloads do suffer a significant number of I-cache misses; CGP_S improves their performance by 23% and CGP_H by 26% over a baseline system that has already been highly tuned for efficient I-cache usage by using the OM tool. CGP, with or without OM, reduces the I-cache miss stall time by about 50% relative to O5+OM, taking us about halfway from an already highly tuned baseline system toward perfect I-cache performance.",Call graph; Database; Instruction cache prefetching,Algorithms; Architectural design; Cache memory; Codes (symbols); Graph theory; Hierarchical systems; Optimization; Call graph; Database; Instruction cache prefetching; Database systems
Neural Methods for Dynamic Branch Prediction,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1942512699&doi=10.1145%2f571637.571639&partnerID=40&md5=a86f58a1c161803daccc7717577bc146,"This article presents a new and highly accurate method for branch prediction. The key idea is to use one of the simplest possible neural methods, the perceptron, as an alternative to the commonly used two-bit counters. The source of our predictor's accuracy is its ability to use long history lengths, because the hardware resources for our method scale linearly, rather than exponentially, with the history length. We describe two versions of perceptron predictors, and we evaluate these predictors with respect to five well-known predictors. We show that for a 4 KB hardware budget, a simple version of our method that uses a global history achieves a misprediction rate of 4.6% on the SPEC 2000 integer benchmarks, an improvement of 26% over gshare. We also introduce a global/local version of our predictor that is 14% more accurate than the McFarling-style hybrid predictor of the Alpha 21264. We show that for hardware budgets of up to 256 KB, this global/local perceptron predictor is more accurate than Evers' multicomponent predictor, so we conclude that ours is the most accurate dynamic predictor currently available. To explore the feasibility of our ideas, we provide a circuit-level design of the perceptron predictor and describe techniques that allow our complex predictor to operate quickly. Finally, we show how the relatively complex perceptron predictor can be used in modern CPUs by having it override a simpler, quicker Smith predictor, providing IPC improvements of 15.8% over gshare and 5.7% over the McFarling hybrid predictor.",Branch prediction; C.1.1 [Computer Systems Organization]: Processor Architectures - Single data stream architectures; Neural networks; Performance,
Secure Program Partitioning,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037974191&doi=10.1145%2f566340.566343&partnerID=40&md5=3af2276d63f5bdcc4b0d3aa89c67cbde,"This paper presents secure program partitioning, a language-based technique for protecting confidential data during computation in distributed systems containing mutually untrusted hosts. Confidentiality and integrity policies can be expressed by annotating programs with security types that constrain information flow; these programs can then be partitioned automatically to run securely on heterogeneously trusted hosts. The resulting communicating subprograms collectively implement the original program, yet the system as a whole satisfies the security requirements of participating principals without requiring a universally trusted host machine. The experience in applying this methodology and the performance of the resulting distributed code suggest that this is a promising way to obtain secure distributed computation.",Categories and Subject Descriptors: D.4.6 [Operating Systems]: Security and Protection - Information flow controls; D.4.7 [Operating Systems]: Organization and Design - Distributed systems,
Practical Byzantine Fault Tolerance and Proactive Recovery,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345757358&doi=10.1145%2f571637.571640&partnerID=40&md5=aa98997ce3ee218bcf6e4fb192a16610,"Our growing reliance on online services accessible on the Internet demands highly available systems that provide correct service without interruptions. Software bugs, operator mistakes, and malicious attacks are a major cause of service interruptions and they can cause arbitrary behavior, that is, Byzantine faults. This article describes a new replication algorithm, BFT, that can be used to build highly available systems that tolerate Byzantine faults. BFT can be used in practice to implement real services: it performs well, it is safe in asynchronous environments such as the Internet, it incorporates mechanisms to defend against Byzantine-faulty clients, and it recovers replicas proactively. The recovery mechanism allows the algorithm to tolerate any number of faults over the lifetime of the system provided fewer than 1/3 of the replicas become faulty within a small window of vulnerability. BFT has been implemented as a generic program library with a simple interface. We used the library to implement the first Byzantine-fault-tolerant NFS file system, BFS. The BFT library and BFS perform well because the library incorporates several important optimizations, the most important of which is the use of symmetric cryptography to authenticate messages. The performance results show that BFS performs 2% faster to 24% slower than production implementations of the NFS protocol that are not replicated. This supports our claim that the BFT library can be used to build practical systems that tolerate Byzantine faults.",C.2.0 [Computer-Communication Networks]: General - Security and protection; C.2.4 [Computer-Communication Networks]: Distributed Systems - Client/server; D.4.3 [Operating Systems]: File Systems Management,
COCA: A Secure Distributed Online Certification Authority,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345757359&doi=10.1145%2f571637.571638&partnerID=40&md5=17b5c2c526eb804ce041ada3e8a42386,"COCA is a fault-tolerant and secure online certification authority that has been built and deployed both in a local area network and in the Internet. Extremely weak assumptions characterize environments in which COCA's protocols execute correctly: no assumption is made about execution speed and message delivery delays; channels are expected to exhibit only intermittent reliability; and with 3t + 1 COCA servers up to t may be faulty or compromised. COCA is the first system to integrate a Byzantine quorum system (used to achieve availability) with proactive recovery (used to defend against mobile adversaries which attack, compromise, and control one replica for a limited period of time before moving on to another). In addition to tackling problems associated with combining fault-tolerance and security, new proactive recovery protocols had to be developed. Experimental results give a quantitative evaluation for the cost and effectiveness of the protocols.",C.2.0 [Computer-Communication Networks]: General - Security and protection; C.2.4 [Computer-Communication Networks]: Distributed Systems - Client/server; D.4.5 [Operating Systems]: Reliability - Fault-tolerance,
Design and Evaluation of a Conit-Based Continuous Consistency Model for Replicated Services,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042420303&doi=10.1145%2f566340.566342&partnerID=40&md5=ee3b27a6b17306e4ccb6a13fd6da3c97,"The tradeoffs between consistency, performance, and availability are well understood. Traditionally, however, designers of replicated systems have been forced to choose from either strong consistency guarantees or none at all. This paper explores the semantic space between traditional strong and optimistic consistency models for replicated services. We argue that an important class of applications can tolerate relaxed consistency, but benefit from bounding the maximum rate of inconsistent access in an application-specific manner. Thus, we develop a conit-based continuous consistency model to capture the consistency spectrum using three application-independent metrics, numerical error, order error, and staleness. We then present the design and implementation of TACT, a middleware layer that enforces arbitrary consistency bounds among replicas using these metrics. We argue that the TACT consistency model can simultaneously achieve the often conflicting goals of generality and practicality by describing how a broad range of applications can express their consistency semantics using TACT and by demonstrating that application-independent algorithms can efficiently enforce target consistency levels. Finally, we show that three replicated applications running across the Internet demonstrate significant semantic and performance benefits from using our framework.",Categories and Subject Descriptors: D.4.7 [Operating Systems]: Organization and Design - Distributed systems; Conit; Consistency model; Design; Experimentation; H.2.4 [Database Management]: Systems - Distributed databases,
Measuring System Normality,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242572726&doi=10.1145%2f507052.507054&partnerID=40&md5=7dcba7f64fe3382aadf30a400e88aa55,"A comparative analysis of transaction time-series is made, for light to moderately loaded hosts, motivated by the problem of anomaly detection in computers. Criteria for measuring the statistical state of hosts are examined. Applying a scaling transformation to the measured data, it is found that the distribution of fluctuations about the mean is closely approximated by a steady-state, maximum-entropy distribution, modulated by a periodic variation. The shape of the distribution, under these conditions, depends on the dimensionless ratio of the daily/weekly periodicity and the correlation length of the data. These values are persistent or even invariant. We investigate the limits of these conclusions, and how they might be applied in anomaly detection. Categories and Subject Descriptors: C.4 [Computer Systems Organization]: Performance of Systems; H.1.M [Information Systems]: Models and Principles; I.5.1 [Computing Methodologies]: Pattern Recognition.",Anomaly detection; Experimentation; Measurement; Statistical mechanics; Theory,
Moshe: A Group Membership Service for WANs,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012585725&doi=10.1145%2f566340.566341&partnerID=40&md5=af3d5fe70f4a14976caa89123fb139d1,"We present Moshe, a novel scalable group membership algorithm built specifically for use in wide area networks (WANs), which can suffer partitions. Moshe is designed with three new significant features that are important in this setting: it avoids delivering views that reflect out-of-date memberships; it requires a single round of messages in the common case; and it employs a client-server design for scalability. Furthermore, Moshe's interface supplies the hooks needed to provide clients with full virtual synchrony semantics. We have implemented Moshe on top of a network event mechanism also designed specifically for use in a WAN. In addition to specifying the properties of the algorithm and proving that this specification is met, we provide empirical results of an implementation of Moshe running over the Internet. The empirical results justify the assumptions made by our design and exhibit good performance. In particular, Moshe terminates within a single communication round over 98% of the time. The experimental results also lead to interesting observations regarding the performance of membership algorithms over the Internet.",Categories and Subject Descriptors: C.2.4 [Computer-Communication Networks]: Distributed Systems; D.4.7 [Operating Systems]: Organization and Design - Distributed Systems,
Let Caches Decay: Reducing Leakage Energy via Exploitation of Cache Generational Behavior,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345757132&doi=10.1145%2f507052.507055&partnerID=40&md5=45f27c3308e2d96930b17eb4f12ed459,"Power dissipation is increasingly important in CPUs ranging from those intended for mobile use, all the way up to high-performance processors for highend servers. Although the bulk of the power dissipated is dynamic switching power, leakage power is also beginning to be a concern. Chipmakers expect that in future chip generations, leakage's proportion of total chip power will increase significantly. This article examines methods for reducing leakage power within the cache memories of the CPU. Because caches comprise much of a CPU chip's area and transistor counts, they are reasonable targets for attacking leakage. We discuss policies and implementations for reducing cache leakage by invalidating and ""turning off"" cache lines when they hold data not likely to be reused. In particular, our approach is targeted at the generational nature of cache line usage. That is, cache lines typically have a flurry of frequent use when first brought into the cache, and then have a period of ""dead time"" before they are evicted. By devising effective, low-power ways of deducing dead time, our results show that in many cases we can reduce L1 cache leakage energy by 4x in SPEC2000 applications without having an impact on performance. Because our decay-based techniques have notions of competitive online algorithms at their roots, their energy usage can be theoretically bounded at within a factor of two of the optimal oracle-based policy. We also examine adaptive decay-based policies that make energy-minimizing policy choices on a per-application basis by choosing appropriate decay intervals individually for each cache line. Our proposed adaptive policies effectively reduce L1 cache leakage energy by 5x for the SPEC2000 with only negligible degradations in performance. Categories and Subject Descriptors: B.3.2 [Bold]: Memory Structures Design Styles - Cache memories.",Algorithms; Cache decay; Cache memories; Design; Generational behavior; Leakage power; Measurement,
The Evolution of Coda,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002141696&doi=10.1145%2f507052.507053&partnerID=40&md5=e4c796ef810bd3a9e9b424e5b413ee5b,"Failure-resilient, scalable, and secure read-write access to shared information by mobile and static users over wireless and wired networks is a fundamental computing challenge. In this article, we describe how the Coda file system has evolved to meet this challenge through the development of mechanisms for server replication, disconnected operation, adaptive use of weak connectivity, isolation-only transactions, translucent caching, and opportunistic exploitation of hardware surrogates. For each mechanism, the article explains how usage experience with it led to the insights for another mechanism. It also shows how Coda has been influenced by the work of other researchers and by industry. The article closes with a discussion of the technical and nontechnical lessons that can be learned from the evolution of the system. Categories and Subject Descriptors: D.4.3 [Software]: File Systems Management - Distributed file systems; D.4.5 [Operating Systems]: Reliability - Fault-tolerance; E.5 [Data]: Files - Backup/recovery; C.2.4 [Computer Systems Organization]: Distributed Systems -Client/server; C.2.1 [Computer Systems Organization]: Network Architecture and Design -Wireless communication; D.2.7 [Software]: Distribution, Maintenance, and Enhancement; D.2.11 [Software]: Software architecture; D.2.13 [Software]: Reusable Software.",Adaptation; Caching; Conflict resolution; Continuous data access; Data staging; Design; Disaster recovery; Disconnected operation; Experimentation; Failure; High availability; Hoarding; Intermittent networks; Isolation-only transactions; Performance; Reliability,
Fast and Flexible Application-Level Networking on Exokernel Systems,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012527927&doi=10.1145%2f505452.505455&partnerID=40&md5=836cd60b0607c98178db44912ce834eb,"Application-level networking is a promising software organization for improving performance and functionality for important network services. The Xok/ExOS exokernel system includes application-level support for standard network services, while at the same time allowing application writers to specialize networking services. This paper describes how Xok/ExOS's kernel mechanisms and library operating system organization achieve this flexibility, and retrospectively shares our experiences and lessons learned (both positive and negative). It also describes how we used this flexibility to build and specialize three network data services: the Cheetah HTTP server, the webswamp Web benchmarking tool, and an application-level TCP forwarder. Overall measurements show large performance improvements relative to similar services built on conventional interfaces, in each case reaching the maximum possible end-to-end performance for the experimental platform. For example. Cheetah provides factor of 2-4 increases in throughput compared to highly tuned socket-based implementations and factor of 3-8 increases compared to conventional systems. Webswamp can offer loads that are two to eight times heavier. The TCP forwarder provides 50-300% higher throughput while also providing end-to-end TCP semantics that cannot be achieved with POSIX sockets. With more detailed measurements and profiling, these overall performance improvements are also broken down and attributed to the specific specializations described, providing server writers with insights into where to focus their optimization efforts.",C.2.2 [Computer-Communication Networks]: Network Protocols; C.5 [Computer Systems Organization]: Computer System Implementation; D.4.4 [Operating Systems]: Communications Management; D.4.7 [Operating Systems]: Organization and Design; Management,
Interposed Request Routing for Scalable Network Storage,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012525225&doi=10.1145%2f505452.505454&partnerID=40&md5=ab718eb85f767b966f4d298aee90ecfd,"This paper explores interposed request routing in Slice, a new storage system architecture for high-speed networks incorporating network-attached block storage. Slice interposes a request switching filter - called a μproxy - along each client's network path to the storage service (e.g., in a network adapter or switch). The μproxy intercepts request traffic and distributes it across a server ensemble. We propose request routing schemes for I/O and file service traffic, and explore their effect on service structure. The Slice prototype uses a packet filter μproxy to virtualize the standard Network File System (NFS) protocol, presenting to NFS clients a unified shared file volume with scalable bandwidth and capacity. Experimental results from the industry-standard SPECsfs97 workload demonstrate that the architecture enables construction of powerful network-attached storage services by aggregating cost-effective components on a switched Gigabit Ethernet LAN.",Content switch; D.4.3 [Operating Systems]: File Systems Management - Distributed file systems; Design; File server; Network file system; Network storage; Performance; Request redirection; Service virtualization,
Fast and Secure Distributed Read-Only File System,2002,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346739133&doi=10.1145%2f505452.505453&partnerID=40&md5=957f41df3ddc3154bfc45000c99478de,"Internet users increasingly rely on publicly available data for everything from software installation to investment decisions. Unfortunately, the vast majority of public content on the Internet comes with no integrity or authenticity guarantees. This paper presents the self-certifying read-only file system, a content distribution system providing secure, scalable access to public, read-only data. The read-only file system makes the security of published content independent from that of the distribution infrastructure. In a secure area (perhaps off-line), a publisher creates a digitally signed database out of a file system's contents. The publisher then replicates the database on untrusted content-distribution servers, allowing for high availability. The read-only file system avoids performing any cryptographic operations on servers and keeps the overhead of cryptography low on clients, allowing servers to scale to a large number of clients. Measurements of an implementation show that an individual server running on a 550-Mhz Pentium III with FreeBSD can support 1,012 connections per second and 300 concurrent clients compiling a large software package.",D.4.3 [Operating Systems]: File System Management - Distributed file systems; D.4.6 [Operating Systems]: Security and Protection - Authentication; D.4.7 [Operating Systems]: Organization and Design - Distributed systems; Design; Management; Performance,
Runtime identification of cache conflict misses: The adaptive miss buffer,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041906916&doi=10.1145%2f502912.502913&partnerID=40&md5=dd779f94296c6fece55904f4334ce325,"This paper describes the miss classification table, a simple mechanism that enables the processor or memory controller to identify each cache miss as either a conflict miss or a capacity (non conflict) miss. The miss classification table works by storing part of the tag of the most recently evicted line of a cache set. If the next miss to that cache set has a matching tag, it is identified as a conflict miss. This technique correctly identifies 88% of misses. Several applications of this information are demonstrated, including improvements to victim caching, next-line prefetching, cache exclusion, and a pseudo-associative cache. This paper also presents the adaptive miss buffer (AMB), which combines several of these techniques, targeting each miss with the most appropriate optimization, all within a single small miss buffer. The AMB's combination of techniques achieves 16% better performance than any single technique alone. Categories and Subject Descriptors: B.3.m [Memory Structures]: Miscellaneous; B.8.2 [Performance and Reliability]: Performance Analysis and Design Aids; C.1.0 [Processor Architectures]: General; C.4 [Performance of Systems]: - Performance Attributes, Measurement Techniques.",Adaptive miss buffer; Cache architecture; Cache exclusion; Conflict misses; Design; Performance; Prefetching; Victim cache,
Implicit coscheduling: Coordinated scheduling with implicit information in distributed systems,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001357914&doi=10.1145%2f380749.380764&partnerID=40&md5=a7f1861531d2e9cb5f7f6d20f7346513,"In modern distributed systems, coordinated time-sharing is required for communicating processes to leverage the performance of switch-based networks and low-overhead protocols. Coordinated time-sharing has traditionally been achieved with gang scheduling or explicit coscheduling, implementations of which often suffer from many deficiencies: multiple points of failure, high context-switch overheads, and poor interaction with client-server, interactive, and I/O-intensive workloads. Implicit coscheduling dynamically coordinates communicating processes across distributed machines without these structural deficiencies. In implicit coscheduling, no communication is required across operating system schedulers; instead, cooperating processes achieve coordination by reacting to implicit information carried by communication existing within the parallel application. The implementation of this approach is simple and allows participating nodes to act autonomously. We introduce two key mechanisms in implicit coscheduling. The first is conditional two-phase waiting, a generalization of traditional two-phase waiting in which spin-time may be increased depending upon events occuring while the process waits. The second is an extension to stride scheduling that provides preemption and is fair to processes that block. To demonstrate that implicit coscheduling performs well, we show results from an extensive set of simulation and implementation experiments. To exercise the conditional two-phase waiting algorithm, we examine three workloads: bulk-synchronous and continuous-communication synthetic applications and application kernels written in the Split-C language. To exercise the local scheduler, we examine competing jobs with different communication characteristics. We demonstrate that our implementation scales well with the number of jobs and workstations and is robust to process placement. Our experiments show that implicit coscheduling is effective and fair for a wide range of workloads; most perform within 30% of an idealized model of gang scheduling.",Algorithms; C.2.4 [computer-communication networks]: Distributed systems - Network operating systems; Clusters; Coscheduling; D.4.1 [operating systems]: Process managament - Scheduling; Design; Gang scheduling; Networks of workstations; Performance,
Specifying and using a partitionable group communication service,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003153962&doi=10.1145%2f377769.377776&partnerID=40&md5=fc770e3bfdc46eae47d2b35b721e7a7b,[No abstract available],,
Scalable high-speed prefix matching,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038787613&doi=10.1145%2f502912.502914&partnerID=40&md5=470590e7994ab143603301f7d2596025,"Finding the longest matching prefix from a database of keywords is an old problem with a number of applications, ranging from dictionary searches to advanced memory management to computational geometry. But perhaps today's most frequent best matching prefix lookups occur in the Internet, when forwarding packets from router to router. Internet traffic volume and link speeds are rapidly increasing; at the same time, a growing user population is increasing the size of routing tables against which packets must be matched. Both factors make router prefix matching extremely performance critical. In this paper, we introduce a taxonomy for prefix matching technologies, which we use as a basis for describing, categorizing, and comparing existing approaches. We then present in detail a fast scheme using binary search over hash tables, which is especially suited for matching long addresses, such as the 128 bit addresses proposed for use in the next generation Internet Protocol, IPv6. We also present optimizations that exploit the structure of existing databases to further improve access time and reduce storage space. Categories and Subject Descriptors: C.2.6 [Computer-Communication Networks]: Internet-working - Routers; E.2 [Data Storage Representations]: Hash-table representations; F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems -Pattern matching.",Algorithms; Collision resolution; Forwarding lookups; High-speed networking; Performance,
Design and evaluation of a wide-area event notification service,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001655450&doi=10.1145%2f380749.380767&partnerID=40&md5=16d3acece2484145136b5bc93c477237,"The components of a loosely coupled system are typically designed to operate by generating and responding to asynchronous events. An event notification service is an application-independent infrastructure that supports the construction of event-based systems, whereby generators of events publish event notifications to the infrastructure and consumers of events subscribe with the infrastructure to receive relevant notifications. The two primary services that should be provided to components by the infrastructure are notification selection (i.e., determining which notifications match which subscriptions) and notification delivery (i.e., routing matching notifications from publishers to subscribers). Numerous event notification services have been developed for local-area networks, generally based on a centralized server to select and deliver event notifications. Therefore, they suffer from an inherent inability to scale to wide-area networks, such as the Internet, where the number and physical distribution of the service's clients can quickly overwhelm a centralized solution. The critical challenge in the setting of a wide-area network is to maximize the expressiveness in the selection mechanism without sacrificing scalability in the delivery mechanism. This paper presents SIENA, an event notification service that we have designed and implemented to exhibit both expressiveness and scalability. We describe the service's interface to applications, the algorithms used by networks of servers to select and deliver event notifications, and the strategies used to optimize performance. We also present results of simulation studies that examine the scalability and performance of the service.",C.2.1 [network architecture and design]: Distributed networks; C.2.2 [network protocols]: Applications; C.2.4 [distributed systems]: Client/server -distributed; Network communication; Network topology; Routing protocols; Store and forward networks,
Compiler-based I/O prefetching for out-of-core applications,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012609370&doi=10.1145%2f377769.377774&partnerID=40&md5=5f170b22d725125c91c7ee81b2b43231,"Current operating systems offer poor performance when a numeric application's working set does not fit in main memory. As a result, programmers who wish to solve ""out-of-core"" problems efficiently are typically faced with the onerous task of rewriting an application to use explicit I/O operations (e.g., read/write). In this paper, we propose and evaluate a fully automatic technique which liberates the programmer from this task, provides high performance, and requires only minimal changes to current operating systems. In our schemethe compiler provides the crucial information on future access patterns without burdening the programmer; the operating system supports nonbinding prefetch and release hints for managing I/O; and the operating system cooperates with a run-time layer to accelerate performance by adapting to dynamic behavior and minimizing prefetch overhead. This approach maintains the abstraction of unlimited virtual memory for the programmer, gives the compiler the flexibility to aggressively insert prefetches ahead of references, and gives the operating system the flexibility to arbitrate between the competing resource demands of multiple applications. We implemented our compiler analysis within the SUIF compiler, and used it to target implementations of our run-time and OS support on both research and commercial systems (Hurricane and IRIX 6.5, respectively). Our experimental results show large performance gains for out-of-core scientific applications on both systems: more than 50% of the I/O stall time has been eliminated in most cases, thus translating into overall speedups of roughly twofold in many cases.",Compiler optimization; D.3.4 [Programming Languages]: Processors - Compilers; D.4.2 [Operating Systems]: Storage Management - Virtual memory; D.4.8 [Operating Systems]: Performance; Design; Experimentation; Optimization; Performance; Virtual memory,
The effect of seance communication on multiprocessing systems,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040750313&doi=10.1145%2f377769.377780&partnerID=40&md5=7259c5ea08beb6a51c3a742b4ea50608,"This paper introduces the seance communication phenomenon and analyzes its effect on a multiprocessing environment. Seance communication is an unnecessary coherency-related activity that is associated with dead cache information. Dead information may reside in the cache for various reasons: task migration, context switches, or working-set changes. Dead information does not have a significant performance impact on a single-processor system; however, it can dominate the performance of multicache environment. In order to evaluate the overhead of seance communication, we develop an analytical model that is based on the fractal behavior of the memory references. So far, all previous works that used the same modeling approach extracted the fractal parameters of a program manually. This paper provides an additional important contribution by demonstrating how these parameters can be automatically extracted from the program trace. Our analysis indicates that Seance communication may severely reduce the overall system performance when using write-update or write-invalidate cache coherency protocols. In addition, we find that the performance of write-update protocols is affected more severely than write-invalidate protocols. The results that are provided by our model are important for better understanding of the coherency-related overhead in multicache systems and for better development of parallel applications and operating systems.",B.3 [Hardware]: Memory Structures; B.3.2 [Memory Structures]: Design Styles - Cache memories; C.0 [Computer Systems Organization]: General - System architectures; Shared memory,
Specialization tools and techniques for systematic optimization of system software,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-18044400243&doi=10.1145%2f377769.377778&partnerID=40&md5=0619d23b22cae031c6e36143e725cef1,"Specialization has been recognized as a powerful technique for optimizing operating systems. However, specialization has not been broadly applied beyond the research community because current techniques, based on manual specialization, are time-consuming and error-prone. The goal of the work described in this paper is to help operating system tuners perform specialization more easily. We have built a specialization toolkit that assists the major tasks of specializing operating systems. We demonstrate sthe effectiveness of the toolkit by applying it to three diverse operating system components. We show that using tools to assist specialization enables significant performance optimizations without error-prone manual modifications. Our experience with the toolkit suggests new ways of designing systems that combine high performance and clean structure.",D.4.7 [Operating Systems]: Organization and Design; Design; Operating system specialization; Optimization; Performance; Software architecture,
An internet multicast system for the stock market,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041905101&doi=10.1145%2f380749.380771&partnerID=40&md5=44c5d493bf2de620194aed180a501f42,"We are moving toward an international, 24-hour, distributed, electronic stock exchange. The exchange will use the global Internet, or internet technology. This system is a natural application of multicast because there are a large number of receivers that should receive the same information simultaneously. The data requirements for the stock exchange are discussed. The current multicast protocols lack the reliability, fairness, and scalability needed in this application. We describe a distributed architecture and a timed reliable multicast protocol, TRMP, that has the appropriate characteristics. We consider three applications: (1) A unified stock ticker of the transactions that are being conducted on the various physical and electronic exchanges. Our objective is to deliver the same combined ticker reliably and simultaneously to all receivers, anywhere in the world. (2) A unified sequence of buy and sell offers that are delivered to a single exchange or a collection of exchanges. Our objective is to give all traders the same fair access to an exchange independent of their relative distances to the exchange or the delay and loss characteristics of the international network. (3) A distributed, electronic trading floor that can replace the current exchanges. This application has the fairness attributes of the first two applications and uses TRMP to conduct irrefutable, distributed trades.",C.2.1 [Computer-Communication Networks]: Network Architecture and Design; C.2.2 [Computer-Communication Networks]: Network Protocols; C.2.4 [Computer-Communication Networks]: Distributed Systems; Design; Multicast; Performance; Theory,
"Separating access control policy, enforcement, and functionality in extensible systems",2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041865338&doi=10.1145%2f367742.367773&partnerID=40&md5=cec299bc53751d966d06ff292fa5740a,"Extensible systems, such as Java or the SPIN extensible operating system, allow for units of code, or extensions, to be added to a running system in almost arbitrary fashion. Extensions closely interact through low-latency but type-safe interfaces to form a tightly integrated system. As extensions can come from arbitrary sources, not all of whom can be trusted to conform to an organization's security policy, such structuring raises the question of how security constraints are enforced in an extensible system. In this paper, we present an access control mechanism for extensible systems to address this problem. Our access control mechanism decomposes access control into a policy-neutral enforcement manager and a security policy manager, and it is transparent to extensions in the absence of security violations. It structures the system into protection domains, enforces protection domains through access control checks, and performs auditing of system operations. The access control mechanism works by inspecting extensions for their types and operations to determine which abstractions require protection and by redirecting procedure or method invocations to inject access control operations into the system. We describe the design of this access control mechanism, present an implementation within the SPIN extensible operating system, and provide a qualitative as well as quantitative evaluation of the mechanism.",Access check; Auditing; D.4 [Software]: Operating Systems; D.4.6 [Operating Systems]: Security and Protection - Access controls; Extensible systems; Java; Protection domain; Protection domain transfer; Security; Security policy; SPIN,
Accelerating shared virtual memory via general-purpose network interface support,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042366311&doi=10.1145%2f367742.367747&partnerID=40&md5=eb25c1e4f6c367927c13ed9d3f3814b4,"Clusters of symmetric multiprocessors (SMPs) are important platforms for high-performance computing. With the success of hardware cache-coherent distributed shared memory (DSM), a lot of effort has also been made to support the coherent shared-address-space programming model in software on clusters. Much research has been done in fast communication on clusters and in protocols for supporting software shared memory across them. However, the performance of software virtual memory (SVM) is still far from that achieved on hardware DSM systems. The goal of this paper is to improve the performance of SVM on system area network clusters by considering communication and protocol layer interactions. We first examine what are the important communication system bottlenecks that stand in the way of improving parallel performance of SVM clusters; in particular, which parameters of the communication architecture are most important to improve further relative to processor speed, which ones are already adequate on modern systems for most applications, and how will this change with technology in the future. We find that the most important communication subsystem cost to improve is the overhead of generating and delivering interrupts for asynchronous protocol processing. Then we proceed to show, that by providing simple and general support for asynchronous message handling in a commodity network interface (NI) and by altering SVM protocols appropriately, protocol activity can be decoupled from asynchronous message handling, and the need for interrupts or polling can be eliminated. The NI mechanisms needed are generic, not SVM-dependent. We prototype the mechanisms and such a synchronous home-based LRC protocol, called GeNIMA (GEneral-purpose Network Interface support for shared Memory Abstractions), on a cluster of SMPs with a programmable NI. We find that the performance improvements are substantial, bringing performance on a small-scale SMP cluster much closer to that of hardware-coherent shared memory for many applications, and we show the value of each of the mechanisms in different applications.",,
MINERVA: An automated resource provisioning tool for large-scale storage systems,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-18044404941&doi=10.1145%2f502912.502915&partnerID=40&md5=13ac3947e7c4a88e80e58dd2e24bc9f6,"Enterprise-scale storage systems, which can contain hundreds of host computers and storage devices and up to tens of thousands of disks and logical volumes, are difficult to design. The volume of choices that need to be made is massive, and many choices have unforeseen interactions. Storage system design is tedious and complicated to do by hand, usually leading to solutions that are grossly over-provisioned, substantially under-performing or, in the worst case, both. To solve the configuration nightmare, we present MINERVA: a suite of tools for designing storage systems automatically. MINERVA uses declarative specifications of application requirements and device capabilities; constraint-based formulations of the various sub-problems; and optimization techniques to explore the search space of possible solutions. This paper also explores and evaluates the design decisions that went into MINERVA, using specialized micro-and macro-benchmarks. We show that MINERVA can successfully handle a workload with substantial complexity (a decision-support database benchmark). MINERVA created a 16-disk design in only a few minutes that achieved the same performance as a 30-disk system manually designed by human experts. Of equal importance, MINERVA was able to predict the resulting system's performance before it was built. Categories and Subject Descriptors: D.4.2 [Operating systems]: Storage management-Secondary storage; G.1.6 [Numerical analysis]: Optimization-Constrained optimization; D.4.8 [Operating systems]: Performance-Modeling and Prediction.",Algorithms; Automatic design; Disk array; Management; Performance; RAID,
Architectural and compiler support for effective instruction prefetching: A cooperative approach,2001,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042366306&doi=10.1145%2f367742.367786&partnerID=40&md5=94bd17bf57a94cf72df52b836aa82e39,"Instruction cache miss latency is becoming an increasingly important performance bottleneck, especially for commercial applications. Although instruction prefetching is an attractive technique for tolerating this latency, we find that existing prefetching schemes are insufficient for modern superscalar processors, since they fail to issue prefetches early enough (particularly for nonsequential accesses). To overcome these limitations, we propose a new instruction prefetching technique whereby the hardware and software cooperate to hide the latency as follows. The hardware performs aggressive sequential prefetching combined with a novel prefetch filtering mechanism to allow it to get far ahead without polluting the cache. To hide the latency of nonsequential accesses, we propose and implement a novel compiler algorithm which automatically inserts instruction-prefetch instructions into the executable to prefetch the targets of control transfers far enough in advance. Our experimental results demonstrate that this new approach hides 50% or more of the latency remaining with the best previous techniques, while at the same time reduces the number of useless prefetches by a factor of six. We find that both the prefetch filtering and compiler-inserted prefetching components of our design are essential and complementary, and that the compiler can limit the code expansion to only 9% on average. In addition, we show that the performance of our technique can be further increased by using profiling information to help reduce cache conflicts and unnecessary prefetches. From an architectural perspective, these performance advantages are sustained over a range of common miss latencies and bandwidth. Finally, our technique is cost effective as well, since it delivers performance comparable to (or even better than) that of larger caches, but requires a much smaller hardware budget.",B.3.2 [Memory Structures]: Design Styles - Cache memories; Compiler optimization; D.3.4 [Programming Languages]: Processors - Compilers; Design; Experimentation; Instruction prefetching; Optimization; Performance,
Multigrain shared memory,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041914530&doi=10.1145%2f350853.350871&partnerID=40&md5=5b9871b83968c1c40604b5e443598507,"Parallel workstations, each comprising tens of processors based on shared memory, promise cost-effective scalable multiprocessing. This article explores the coupling of such small-to medium-scale shared-memory multiprocessors through software over a local area network to synthesize larger shared-memory systems. We call these systems Distributed Shared-memory MultiProcessors (DSMPs). This article introduces the design of a shared-memory system that uses multiple granularities of sharing, called MGS, and presents a prototype implementation of MGS on the MIT Alewife multiprocessor. Multigrain shared memory enables the collaboration of hardware and software shared memory, thus synthesizing a single transparent shared-memory address space across a cluster of multiprocessors. The system leverages the efficient support for fine-grain cache-line sharing within multiprocessor nodes as often as possible, and resorts to coarse-grain page-level sharing across nodes only when absolutely necessary. Using our prototype implementation of MGS, an in-depth study of several shared-memory applications is conducted to understand the behavior of DSMPs. Our study is the first to comprehensively explore the DSMP design space, and to compare the performance of DSMPs against all-software and all-hardware DSMs on a single experimental platform. Keeping the total number of processors fixed, we show that applications execute up to 85% faster on a DSMP as compared to an all-software DSM. We also show that all-hardware DSMs hold a significant performance advantage over DSMPs on challenging applications, between 159% and 1014%. However, program transformations to improve data locality for these applications allow DSMPs to almost match the performance of an all-hardware multiprocessor of the same size.",B.3.2 [Memory Structures]; C.1.2 [Processor Architectures]; Design Styles - Shared memory; Multiple Data Stream Architectures,
Smart packets: Applying active networks to network management,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041080781&doi=10.1145%2f332799.332893&partnerID=40&md5=eaa0bd977651f28f4d6fc3feccbadb96,"This article introduces Smart Packets and describes the Smart Packets architecture, the packet formats, the language and its design goals, and security considerations. Smart Packets is an Active Networks project focusing on applying active networks technology to network management and monitoring. Messages in active networks are programs that are executed at nodes on the path to one or more target hosts. Smart Packets programs are written in a tightly encoded, safe language specifically designed to support network management and avoid dangerous constructs and accesses. Smart Packets improves the management of large complex networks by (1) moving management decision points closer to the node being managed, (2) targeting specific aspects of the node for information rather than exhaustive collection via polling, and (3) abstracting the management concepts to language constructs, allowing nimble network control.",Active Networks; C.2.1 [Computer-Communication Networks]: Network Architecture and Design; C.2.3 [Computer-Communication Networks]: Network Operations; D.3.3 [Programming Languages]: Language Constructs and Features; Management,
Hint-based cooperative caching,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038023772&doi=10.1145%2f362670.362675&partnerID=40&md5=479d86e99fee5c5a7a57a7bceed453d1,"This article presents the design, implementation, and measurement of a hint-based cooperative caching file system. Hints allow clients to make decisions based on local state, enabling a loosely coordinated system that is simple to implement. The resulting performance is comparable to that of existing tightly coordinated algorithms that use global state, but with less overhead. Simulations show that the block access times of our system are as good as those of the existing algorithms, while reducing manager load by more than a factor of seven, block lookup traffic by nearly a factor of two-thirds, and replacement traffic a factor of five. To verify our simulation results in a real system with real users, we implemented a prototype and measured its performance for one week. Although the simulation and prototype environments were very different, the prototype system mirrored the simulation results by exhibiting reduced overhead and high hint accuracy. Furthermore, hint-based cooperative caching reduced the average block access time to almost half that of NFS.",Algorithms; Cooperative caching; D.4.3 [Operating Systems]; Design; File Systems Management; Hints; Measurement; Performance,
IO-Lite: A unified I/O buffering and caching system,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002943256&doi=10.1145%2f332799.332895&partnerID=40&md5=a038afb92284e61345a9ea21382269a8,"This article presents the design, implementation, and evaluation of IO-Lite, a unified I/O buffering and caching system for general-purpose operating systems. IO-Lite unifies all buffering and caching in the system, to the extent permitted by the hardware. In particular, it allows applications, the interprocess communication system, the file system, the file cache, and the network subsystem to safely and concurrently share a single physical copy of the data. Protection and security are maintained through a combination of access control and read-only sharing. IO-Lite eliminates all copying and multiple buffering of I/O data, and enables various cross-subsystem optimizations. Experiments with a Web server show performance improvements between 40 and 80% on real workloads as a result of IO-Lite.",Caching; D.4.4 [Operating Systems]: Communications Management; D.4.8 [Operating Systems]: Performance; I/O buffering; Management; Networking; Performance; Zero-copy,
Cellular disco: Resource management using virtual clusters on shared-memory multiprocessors,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040518033&doi=10.1145%2f354871.354873&partnerID=40&md5=67f71a58bd2d0b3fd509ea8ea0ea4872,"Despite the fact that large-scale shared-memory multiprocessors have been commercially available for several years, system software that fully utilizes all their features is still not available, mostly due to the complexity and cost of making the required changes to the operating system. A recently proposed approach, called Disco, substantially reduces this development cost by using a virtual machine monitor that leverages the existing operating system technology. In this paper we present a system called Cellular Disco that extends the Disco work to provide all the advantages of the hardware partitioning and scalable operating system approaches. We argue that Cellular Disco can achieve these benefits at only a small fraction of the development cost of modifying the operating system. Cellular Disco effectively turns a large-scale shared-memory multiprocessor into a virtual cluster that supports fault containment and heterogeneity, while avoiding operating system scalability bottlenecks. Yet at the same time, Cellular Disco preserves the benefits of a shared-memory multiprocessor by implementing dynamic, fine-grained resource sharing, and by allowing users to overcommit resources such as processors and memory. This hybrid approach requires a scalable resource manager that makes local decisions with limited information while still providing good global performance and fault containment. In this paper we describe our experience with a Cellular Disco prototype on a 32-processor SGI Origin 2000 system. We show that the execution time penalty for this approach is low, typically within 10% of the best available commercial operating system for most workloads, and that it can manage the CPU and memory resources of the machine significantly better than the hardware partitioning approach.",C.1.2 [Computer Systems Organization]: Processor Architectures - Parallel Architecture; D.4.1 [Software]: Operating Systems - Process Management; D.4.2 [Software]: Operating Systems - Storage Management; D.4.5 [Software]: Operating Systems - Reliability,
Value-based clock gating and operation packing: Dynamic strategies to improving processor power and performance,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002525825&doi=10.1145%2f350853.350856&partnerID=40&md5=d6e723b468e97c2a040664dd1afabac1,"The large address space needs of many current applications have pushed processor designs toward 64-bit word widths. Although full 64-bit addresses and operations are indeed sometimes needed, arithmetic operations on much smaller quantities are still more common. In fact, another instruction set trend has been the introduction of instructions geared toward subword operations on 16-bit quantities. For example, most major processors now include instruction set support for multimedia operations allowing parallel execution of several subword operations in the same ALU. This article presents our observations demonstrating that operations on ""narrow-width"" quantities are common not only in multimedia codes, but also in more general workloads. In fact, across the SPECint95 benchmarks, over half the integer operation executions require 16 bits or less. Based on this data, we propose two hardware mechanisms that dynamically recognize and capitalize on these narrow-width operations. The first, power-oriented optimization reduces processor power consumption by using operand-value-based clock gating to turn off portions of arithmetic units that will be unused by narrow-width operations. This optimization results in a 45%-60% reduction in the integer unit's power consumption for the SPECint95 and MediaBench benchmark suites. Applying this optimization to SPECfp95 benchmarks results in slightly smaller power reductions, but still seems warranted. These reductions in integer unit power consumption equate to a 5%-10% full-chip power savings. Our second, performance-oriented optimization improves processor performance by packing together narrow-width operations so that they share a single arithmetic unit. Conceptually similar to a dynamic form of MMX, this optimization offers speedups of 4.3%-6.2% for SPECint95 and 8.0%-10.4% for MediaBench. Overall, these optimizations highlight an increasing opportunity for value-based optimizations to improve both power and performance in current microprocessors.","Arithmetic and Logic Structures; B.2 [Hardware]; C.1.1 [Processor Architectures]; Design; Experimentation; Performance; Single Data Stream Architectures - RISC / CISC, VLIW architectures",
Java consistency: Nonoperational characterizations for java memory behavior,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0005300107&doi=10.1145%2f362670.362673&partnerID=40&md5=b8d25824c3a66e39a830dc9eb46d8c36,"The Java Language Specification (JLS) [Gosling et al. 1996] provides an operational definition for the consistency of shared variables. This definition remains unchanged in the JLS 2nd edition, currently under peer review. The definition, which relies on a specific abstract machine as its underlying model, is very complicated. Several subsequent works have tried to simplify and formalize it. However, these revised definitions are also operational, and thus have failed to highlight the intuition behind the original specification. In this work we provide a complete nonoperational specification for Java and for the JVM, excluding synchronized operations. We provide a simpler definition, in which we clearly distinguish the consistency model that is promised to the programmer from that which should be implemented in the JVM. This distinction, which was implicit in the original definition, is crucial for building the JVM. We find that the programmer model is strictly weaker than that of the JVM, and precisely define their discrepancy. Moreover, our definition is independent of any specific (or even abstract) machine, and can thus be used to verify JVM implementations and compiler optimizations on any platform. Finally, we show the precise range of consistency relaxations obtainable for the Java memory model when a certain compiler optimization - called prescient stores in JLS - is applicable.",B.3.3 [Memory structures]; Java memory models; Multithreading; Nonoperational specification; Performance Analysis and Design Aids - Formal models; Verification,
"Manageability, availability, and performance in Porcupine: A highly scalable, cluster-based mail service",2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0004975335&doi=10.1145%2f354871.354875&partnerID=40&md5=bee6462c694f7fbeefaf47b1515cc4b6,"This paper describes the motivation, design, and performance of Porcupine, a scalable mail server. The goal of Porcupine is to provide a highly available and scalable electronic mail service using a large cluster of commodity PCs. We designed Porcupine to be easy to manage by emphasizing dynamic load balancing, automatic configuration, and graceful degradation in the presence of failures. Key to the system's manageability, availability, and performance is that sessions, data, and underlying services are distributed homogeneously and dynamically across nodes in a cluster.","C.2.4 [Computer-Communication Networks]: Distributed Systems - Distributed applications; C.4 [Performance of Systems]: Reliability, Availability, and Serviceability; C.5.5 [Computer System Implementation]: Servers; D.4.5 [Operating Systems",
Soft timers: Efficient microsecond software timer support for network processing,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039193020&doi=10.1145%2f354871.354872&partnerID=40&md5=8d538f9ce692794c073d1db241bc4aaa,"This paper proposes and evaluates soft timers, a new operating stem facility that allows the efficient scheduling of software events at a granularity down to tens of microseconds. Soft timers can be used to avoid interrupts and reduce context switches associated with network processing, without sacrificing low communication delays. More specifically, soft timers enable transport protocols like TCP to efficiently perform rate-based clocking of packet transmissions. Experiments indicate that soft timers allow a server to employ rate-based clocking with little CPU overhead (2-6%) at high aggregate bandwidths. Soft timers can also be used to perform network polling, which eliminates network interrupts and increases the memory access locality of the network subsystem without sacrificing delay. Experiments show that this technique can improve the throughput of a Web server by up to 25%.",C.5.5 [Computer System Implementation]: Servers; D.4.1 [Operating Systems]: Process Management - scheduling; D.4.4 [Operating Systems]: Communications Management - network communication; Design; Performance; Polling; Timers; Transmission scheduling,
The click modular router,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040291388&doi=10.1145%2f354871.354874&partnerID=40&md5=8e791680486812fd3494e07ba08f965c,"Click is a new software architecture for building flexible and configurable routers. A Click router is assembled from packet processing modules called elements. Individual elements implement simple router functions like packet classification, queuing, scheduling, and interfacing with network devices. A router configuration is a directed graph with elements at the vertices; packets flow along the edges of the graph. Several features make individual elements more powerful and complex configurations easier to write, including pull connections, which model packet flow driven by transmitting hardware devices, and flow-based router context, which helps an element locate other interesting elements. Click configurations are modular and easy to extend. A standards-compliant Click IP router has 16 elements on its forwarding path; some of its elements are also useful in Ethernet switches and IP tunneling configurations. Extending the IP router to support dropping policies, fairness among flows, or Differentiated Services simply requires adding a couple of elements at the right place. On conventional PC hardware, the Click IP router achieves a maximum loss-free forwarding rate of 333,000 64-byte packets per second, demonstrating that Click's modular and flexible architecture is compatible with good performance.",C.2.1 [Computer-Communication Networks]: Network Architecture and Design - Packet-switching networks; C.2.6 [Computer-Communication Networks]: Internetworking - Routers; D.2.11 [Software Engineering]: Software Architectures,
Soft updates: A solution to the metadata update problem in file systems,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0005094356&doi=10.1145%2f350853.350863&partnerID=40&md5=f5e3a9fe30c4f072b80f4df89e5be9b4,"Metadata updates, such as file creation and block allocation, have consistently been identified as a source of performance, integrity, security, and availability problems for file systems. Soft updates is an implementation technique for low-cost sequencing of fine-grained updates to write-back cache blocks. Using soft updates to track and enforce metadata update dependencies, a file system can safely use delayed writes for almost all file operations. This article describes soft updates, their incorporation into the 4.4BSD fast file system, and the resulting effects on the system. We show that a disk-based file system using soft updates achieves memory-based file system performance while providing stronger integrity and security guarantees than most disk-based file systems. For workloads that frequently perform updates on metadata (such as creating and deleting files), this improves performance by more than a factor of two and up to a factor of 20 when compared to the conventional synchronous write approach and by 4-19% when compared to an aggressive write-ahead logging approach. In addition, soft updates can improve file system availability by relegating crash-recovery assistance (e.g., the fsck utility) to an optional and background role, reducing file system recovery time to less than one second.","C.4 [Computer Systems Organization]; C.5.5 [Computer System Implementation]; D.4.2 [Operating Systems]; D.4.3 [Operating Systems]; Performance of Systems - Design studies; Reliability, availability, and serviceability; Servers; Storage Management",
A high-level abstraction of shared accesses,2000,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040486803&doi=10.1145%2f332799.332800&partnerID=40&md5=57f9dce67c14425744159d00f4c56c04,"We describe the design and use of the tape mechanism, a new high-level abstraction of accesses to shared data for software DSMs. Tapes consolidate and generalize a number of recent protocol optimizations, including update-based locks and record-replay barriers. Tapes are usually created by ""recording"" shared accesses. The resulting recordings can be used to anticipate future accesses by tailoring data movement to application semantics. Tapes-based mechanisms are layered on top of existing shared-memory protocols, and are largely independent of the underlying memory model. Tapes can also be used to emulate the data-movement semantics of several update-based protocol implementations, without altering the underlying protocol implementation. We have used tapes to create the Tapeworm synchronization library. Tapeworm implements sophisticated record-replay mechanisms across barriers, augments locks with data-movement semantics, and allows the use of producer-consumer segments, which move entire modified segments when any portion of the segment is accessed. We show that Tapeworm eliminates 85% of remote misses, reduces message traffic by 63%, and improves performance by an average of 29% for our application suite.",D.4.2 [Operating Systems]: Storage Management - Distributed memories; D.4.3 [Operating Systems]: File Systems Management - Access methods; Distributed file systems; DSM; Performance; Programming libraries; Reliability; Shared memory; Update protocols,
Garbage collection for a client-server persistent object store,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042043532&doi=10.1145%2f320656.322741&partnerID=40&md5=7d8790035ec54a4eba7925d5864863aa,"We describe an efficient server-based algorithm for garbage collecting persistent object stores in a client-server environment. The algorithm is incremental and runs concurrently with client transactions. Unlike previous algorithms, it does not hold any transactional locks on data and does not require callbacks to clients. It is fault-tolerant, but performs very little logging. The algorithm has been designed to be integrated into existing systems, and therefore it works with standard implementation techniques such as Two-Phase Locking and Write-Ahead-Logging. In addition, it supports client-server performance optimizations such as client caching and flexible management of client buffers. We describe an implementation of the algorithm in the EXODUS storage manager and present the results of a performance study of the implementation.",Algorithms; Client-server system; D.4.2 [Operating Systems]: Storage Management - Garbage collection; H.2.4 [Database Management]: Systems - Distributed databases; Logging; Measurement; Object-oriented databases; Performance; Transaction processing,
An Architecture for Packet-Striping Protocols,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0442310866&doi=10.1145%2f329466.329471&partnerID=40&md5=9824493cf24ec0c6205987c8c4a237ba,"Link-striping algorithms are often used to overcome transmission bottlenecks in computer networks. Traditional striping algorithms suffer from two major disadvantages. They provide inadequate load sharing in the presence of variable-length packets, and may result in non-FIFO delivery of data. We describe a new family of link-striping algorithms that solves both problems. Our scheme applies to any layer that can provide multiple FIFO channels. We deal with variable-sized packets by showing how fair-queuing algorithms can be transformed into load-sharing algorithms. Our transformation results in practical load-sharing protocols, and shows a theoretical connection between two seemingly different problems. The same transformation can be applied to obtain load-sharing protocols for links with different capacities. We deal with the FIFO requirement for two separate cases. If a sequence number can be added to each packet, we show how to speed up packet processing by letting the receiver simulate the sender algorithm. If no header can be added, we show how to provide quasi FIFO delivery. Quasi FIFO is FIFO except during occasional periods of loss of synchronization. We argue that quasi FIFO is adequate for most applications. We also describe a simple technique for speedy restoration of synchronization in the event of loss. We develop an architectural framework for transparently embedding our protocol at the network level by striping IP packets across multiple physical interfaces. The resulting stripe protocol has been implemented within the NetBSD kernel. Our measurements and simulations show that the protocol offers scalable throughput even when striping is done over dissimilar links, and that the protocol synchronizes quickly after packet loss. Measurements show performance improvements over conventional round-robin striping schemes and striping schemes that do not resequence packets. Some aspects of our solution have been implemented in Cisco's router operating system (IOS 11.3) in the context of Multilink PPP stiping.",Algorithms; C.2.2 [Computer-Communication Networks]: Network Protocols-Protocol architecture (OSI model); Causal fair queuing; Design; Fair queuing; Load sharing; Measurement; Multilink PPP; Packet striping; Performance; Stripe protocol; Striping; Theory,
Ace: A language for parallel programming with customizable protocols,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041542803&doi=10.1145%2f320656.320657&partnerID=40&md5=019ce6bd770940aba99f9503cee84162,"Customizing the protocols that manage accesses to different data structures within an application can improve the performance of software shared-memory programs substantially. Existing systems for using customizable protocols are hard to use directly because the mechanisms they provide for manipulating protocols are low-level ones. This article is an in-depth study of the issues involved in providing language support for application-specific protocols. We describe the design and implementation of a new language for parallel programming, Ace, that integrates support for customizable protocols with minimal extensions to C. Ace applications are developed using a shared-memory model with a default sequentially consistent protocol. Performance can then be optimized, with minor modifications to the application, by experimenting with different protocol libraries. The design of Ace was driven by a detailed study of the use of customizable protocols. We delineate the issues that arise when programming with customizable protocols and present novel abstractions that allow for their easy use. We describe the design and implementation of a runtime system and compiler for Ace and discuss compiler optimizations that improve the performance of such software shared-memory systems. We study the communication patterns of a set of benchmark applications and consider the use of customizable protocols to optimize their performance. We evaluate the performance of our system through experiments on a Thinking Machine CM-5 and a Cray T3E. We also present measurements that demonstrate that Ace has good performance compared to that of a modern distributed shared-memory system.",D.3.3 [Programming Languages]: Language Constructs and Features; D.3.4 [Programming Languages]: Processors - Compilers; Design; Parallel processing; Performance; Run-time environments,
Eliminating synchronization overhead in automatically parallelized programs using dynamic feedback,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0012711061&doi=10.1145%2f312203.312210&partnerID=40&md5=311c64ad56f1c2cc00c15dbe5596f376,"This article presents dynamic feedback, a technique that enables computations to adapt dynamically to different execution environments. A compiler that uses dynamic feedback produces several different versions of the same source code; each version uses a different optimization policy. The generated code alternately performs sampling phases and production phases. Each sampling phase measures the overhead of each version in the current environment. Each production phase uses the version with the least overhead in the previous sampling phase. The computation periodically resamples to adjust dynamically to changes in the environment. We have implemented dynamic feedback in the context of a parallelizing compiler for object-based programs. The generated code uses dynamic feedback to automatically choose the best synchronization optimization policy. Our experimental results show that the synchronization optimization policy has a significant impact on the overall performance of the computation, that the best policy varies from program to program, that the compiler is unable to statically choose the best policy, and that dynamic feedback enables the generated code to exhibit performance that is comparable to that of code that has been manually tuned to use the best policy. We have also performed a theoretical analysis which provides, under certain assumptions, a guaranteed optimality bound for dynamic feedback relative to a hypothetical (and unrealizable) optimal algorithm that uses the best policy at every point during the execution.",C.4 [Computer Systems Organization]: Performance of Systems-Measurement techniques; D.1.3 [Programming Techniques]: Concurrent Programming; D.1.5 [Programming Techniques]: Object-oriented Programming,
Effective Fine-Grain Synchronization for Automatically Parallelized Programs Using Optimistic Synchronization Primitives,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000151487&doi=10.1145%2f329466.329486&partnerID=40&md5=760e0e33adaafabb56a606ce3462e832,"This article presents our experience using optimistic synchronization to implement fine-grain atomic operations in the context of a parallelizing compiler for irregular, object-based computations. Our experience shows that the synchronization requirements of these programs differ significantly from those of traditional parallel computations, which use loop nests to access dense matrices using affine access functions. In addition to coarse-grain barrier synchronization, our irregular computations require synchronization primitives that support efficient fine-grain atomic operations. The standard implementation mechanism for atomic operations uses mutual exclusion locks. But the overhead of acquiring and releasing locks can reduce the performance. Locks can also consume significant amounts of memory. Optimisitic synchronization primitives such as load-linked|store conditional are an attractive alternative. They require no additional memory and eliminate the use of heavyweight blocking synchronization constructs. We evaluate the effectiveness of optimistic synchronization by comparing experimental results from two versions of a parallelizing compiler for irregular, object-based computations. One version generates code that uses mutual exclusion locks to make operations execute atomically. The other version uses optimistic synchronization. We used this compiler to automatically parallelize three irregular, object-based benchmark applications of interest to the scientific and engineering computation community. The presented experimental results indicate that the use of optimistic synchronization in this context can significantly reduce the memory consumption and improve the overall performance.",Algorithms; Atomic operations; Commutativity analysis; D.3.4 [Programming Languages]: Processors - Compilers; Experimentation; Optimistic synchronization; Parallel computing; Parallelizing compilers; Performance; Synchronization,
Bimodal multicast,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001818392&doi=10.1145%2f312203.312207&partnerID=40&md5=f5d0accd998515a765edb7155e0fc3ba,"There are many methods for making a multicast protocol ""reliable."" At one end of the spectrum, a reliable multicast protocol might offer atomicity guarantees, such as all-or-nothing delivery, delivery ordering, and perhaps additional properties such as virtually synchronous addressing. At the other are protocols that use local repair to overcome transient packet loss in the network, offering ""best effort"" reliability. Yet none of this prior work has treated stability of multicast delivery as a basic reliability property, such as might be needed in an internet radio, television, or conferencing application. This article looks at reliability with a new goal: development of a multicast protocol which is reliable in a sense that can be rigorously quantified and includes throughput stability guarantees. We characterize this new protocol as a ""bimodal multicast"" in reference to its reliability model, which corresponds to a family of bimodal probability distributions. Here, we introduce the protocol, provide a theoretical analysis of its behavior, review experimental results, and discuss some candidate applications. These confirm that bimodal multicast is reliable, scalable, and that the protocol provides remarkably stable delivery throughput.",C.2.1 [Computer-Communication Networks]: Network,
RecPlay: A fully integrated practical record/replay system,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001641893&doi=10.1145%2f312203.312214&partnerID=40&md5=99906f353db76901a5434846de10e29c,"This article presents a practical solution for the cyclic debugging of nondeterministic parallel programs. The solution consists of a combination of record/replay with automatic on-the-fly data race detection. This combination enables us to limit the record phase to the more efficient recording of the synchronization operations, while deferring the time-consuming data race detection to the replay phase. As the record phase is highly efficient, there is no need to switch it off, hereby eliminating the possibility of Heisenbugs because tracing can be left on all the time. This article describes an implementation of the tools needed to support RecPlay.",D.1.3 [Programming Techniques]: Concurrent Programming - Parallel programming; D.2.5 [Software Engineering]: Testing and Debugging -Debugging aids; D.4.1 [Operating Systems]: Process Management - Concurrency; Deadlocks; Monitors; Tracing,
Quantifying Loop Nest Locality Using SPEC'95 and the Perfect Benchmarks,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003665539&doi=10.1145%2f329466.329484&partnerID=40&md5=09628338b7808e705020ba2e237ce5da,"This article analyzes and quantifies the locality characteristics of numerical loop nests in order to suggest future directions for architecture and software cache optimizations. Since most programs spend the majority of their time in nests, the vast majority of cache optimization techniques target loop nests. In contrast, the locality characteristics that drive these optimizations are usually collected across the entire application rather than at the nest level. Researchers have studied numerical codes for so long that a number of commonly held assertions have emerged on their locality characteristics. In light of these assertions, we use the SPEC'95 and Perfect Benchmarks to take a new look at measuring locality on numerical codes based on references, loop nests, and program locality properties. Our results show that several popular assertions are at best overstatements. For example, although most reuse is within a loop nest, in line with popular assertions, most misses are internest capacity misses, and they correspond to potential reuse between nearby loop nests. In addition, we find that temporal and spatial reuse have balanced roles within a loop nest and that most reuse across nests and the entire program is temporal. These results are consistent with high hit rates (80% or more hits), but go against the commonly held assumption that spatial reuse dominates. Our locality measurements reveal important differences between loop nests and programs, refute some popular assertions, and provide new insights for the compiler writer and the architect.",C.4 [Computer Systems Organization]: Performance of Systems-Performance attributes; Measurement techniques; Measurement; Performance,
Fast address lookups using controlled prefix expansion,1999,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002260103&doi=10.1145%2f296502.296503&partnerID=40&md5=576a2b45650949873761934977ffaf1f,"Internet (IP) address lookup is a major bottleneck in high-performance routers. IP address lookup is challenging because it requires a longest matching prefix lookup. It is compounded by increasing routing table sizes, increased traffic, higher-speed links, and the migration to 128-bit IPv6 addresses. We describe how IP lookups and updates can be made faster using a set of transformation techniques. Our main technique, controlled prefix expansion, transforms a set of prefixes into an equivalent set with fewer prefix lengths. In addition, we use optimization techniques based on dynamic programming, and local transformations of data structures to improve cache behavior. When applied to trie search, our techniques provide a range of algorithms (Expanded Tries) whose performance can be tuned. For example, using a processor with 1MB of L2 cache, search of the MaeEast database containing 38000 prefixes can be done in 3 L2 cache accesses. On a 300MHz Pentium II which takes 4 cycles for accessing the first word of the L2 cacheline, this algorithm has a worst-case search time of 180 nsec., a worst-case insert/delete time of 2.5 msec., and an average insert/delete time of 4 usec. Expanded tries provide faster search and faster insert/delete times than earlier lookup algorithms. When applied to Binary Search on Levels, our techniques improve worst-case search times by nearly a factor of 2 (using twice as much storage) for the MaeEast database. Our approach to algorithm design is based on measurements using the VTune tool on a Pentium to obtain dynamic clock cycle counts. Our techniques also apply to similar address lookup problems in other network protocols.",Binary Search on Levels; C.2.3 [Computer-Communication Networks]: Network Operations - network monitoring; Controlled prefix expansion; Expanded tries; Internet address lookup; Longest-prefix match; Multibit tries; Performance; Router performance,
Coyote: A System for Constructing Fine-Grain Configurable Communication Services,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032203011&doi=10.1145%2f292523.292524&partnerID=40&md5=f651428cff1142b49878c429436580e2,"Communication-oriented abstractions such as atomic multicast, group RPC, and protocols for location-independent mobile computing can simplify the development of complex applications built on distributed systems. This article describes Coyote, a system that supports the construction of highly modular and configurable versions of such abstractions. Coyote extends the notion of protocol objects and hierarchical composition found in existing systems with support for finer-grain microprotocol objects and a nonhierarchical composition scheme for use within a single layer of a protocol stack. A customized service is constructed by selecting microprotocols based on their semantic guarantees and configuring them together with a standard runtime system to form a composite protocol implementing the service. This composite protocol is then composed hierarchically with other protocols to form a complete network subsystem. The overall approach is described and illustrated with examples of services that have been constructed using Coyote, including atomic multicast, group RPC, membership, and mobile computing protocols. A prototype implementation based on extending x-kernel version 3.2 running on Mach 3.0 with support for microprotocols is also presented, together with performance results from a suite of microprotocols from which over 60 variants of group RPC can be constructed.",C.2.2 [Computer-Communication Networks]: Network Protocols - protocol architecture; C.2.4 [Computer-Communication Networks]: Distributed Systems - distributed applications,Computer operating systems; Computer systems programming; Network protocols; Software engineering; Microprotocols; Data communication systems
Using Value Prediction to Increase the Power of Speculative Execution Hardware,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032132091&doi=10.1145%2f290409.290411&partnerID=40&md5=7841374fa197fe5ce607d21774070c51,"This article presents an experimental and analytical study of value prediction and its impact on speculative execution in superscalar microprocessors. Value prediction is a new paradigm that suggests predicting outcome values of operations (at run-time) and using these predicted values to trigger the execution of true-data-dependent operations speculatively. As a result, stalls to memory locations can be reduced and the amount of instruction-level parallelism can be extended beyond the limits of the program's dataflow graph. This article examines the characteristics of the value prediction concept from two perspectives: (1) the related phenomena that are reflected in the nature of computer programs and (2) the significance of these phenomena to boosting instruction-level parallelism of superscalar microprocessors that support speculative execution. In order to better understand these characteristics, our work combines both analytical and experimental studies.",C.0 [Computer Systems Organization]: General -system architectures; C.1.1 [Processor Architectures]: Single Data Stream Architectures -RISC; C.5.3 [Computer System Implementation]: Microcomputers-microprocessors; Design; Experimentation; Measurement,Computer operating systems; Reduced instruction set computing; Speculative execution hardware; Microprocessor chips
Ufo: A Personal Global File System Based on User-Level Extensions to the Operating System,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032131867&doi=10.1145%2f290409.290410&partnerID=40&md5=b337e46dfbbdf177d2fe893e7789c1d6,"In this article we show how to extend a wide range of functionality of standard operating systems completely at the user level. Our approach works by intercepting selected system calls at the user level using tracing facilities such as the /proc file system provided by many Unix operating systems. The behavior of some intercepted system calls is then modified to implement new functionality. This approach does not require any relinking or recompilation of existing applications. In fact, the extensions can even be dynamically ""installed"" into already running processes. The extensions work completely at the user level and install without system administrator assistance. Individual users can choose what extensions to run, in effect creating a personalized operating system view for themselves. We used this approach to implement a global file system, called Ufo, which allows users to treat remote files exactly as if they were local. Currently, Ufo supports file access through the FTP and HTTP protocols and allows new protocols to be plugged in. While several other projects have implemented global file system abstractions, they all require either changes to the operating system or modifications to standard libraries. The article gives a detailed performance analysis of our approach to extending the OS and establishes that Ufo introduces acceptable overhead for common applications even though intercepting individual system calls incurs a high cost.",D.4.3 [Operating Systems]: File Systems Management - access methods; Distributed file systems; File caching; Global name space; Performance; Proc file system; User-level operating system extensions,File organization; HTTP; Network protocols; User-level operating systems; Computer operating systems
Decay-Usage Scheduling in Multiprocessors,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032204647&doi=10.1145%2f292523.292535&partnerID=40&md5=5b861ebf6256614426d5219865df8765,"Decay-usage scheduling is a priority-aging time-sharing scheduling policy capable of dealing with a workload of both interactive and batch jobs by decreasing the priority of a job when it acquires CPU time, and by increasing its priority when it does not use the (a) CPU. In this article we deal with a decay-usage scheduling policy in multiprocessors modeled after widely used systems. The priority of a job consists of a base priority and a time-dependent component based on processor usage. Because the priorities in our model are time dependent, a queuing-theoretic analysis - for instance, for the mean job response time - seems impossible. Still, it turns out that as a consequence of the scheduling policy, the shares of the available CPU time obtained by jobs converge, and a deterministic analysis for these shares is feasible: We show how for a fixed set of jobs with large processing demands, the steady-state shares can be obtained given the base priorities, and conversely, how to set the base priorities given the required shares. In addition, we analyze the relation between the values of the scheduler parameters and the level of control it can exercise over the steady-state share ratios, and we deal with the rate of convergence. We validate the model by simulations and by measurements of actual systems.",Control; Convergence; D.4.1 [Operating Systems]: Process Management - multiprocessing/multiprogramming; scheduling; D.4.8 [Operating Systems]: Performance - measurements; modeling and prediction; simulation; Decay usage; Measurement; Performance; Priorities,Computer operating systems; Computer simulation; Scheduling; Time sharing programs; Decay-usage scheduling; Multiprocessing systems
The Totem Multiple-Ring Ordering and Topology Maintenance Protocol,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032058159&doi=10.1145%2f279227.279228&partnerID=40&md5=62d25ea1d851f0b6d4e44c58902e312a,"The Totem multiple-ring protocol provides reliable totally ordered delivery of messages across multiple local-area networks interconnected by gateways. This consistent message order is maintained in the presence of network partitioning and remerging, and of processor failure and recovery. The protocol provides accurate topology change information as part of the global total order of messages. It addresses the issue of scalability and achieves a latency that increases logarithmically with system size by exploiting process group locality and selective forwarding of messages through the gateways. Pseudocode for the protocol and an evaluation of its performance are given. Categories and Subject Descriptors: C.2.1 [Computer-Communication Networks]: Network Architecture and Design - network communications; C.2.2 [Computer-Communication Networks]: Network Protocols - protocol architecture; C.2.4 [Computer-Communication Networks]: Distributed Systems - network operating systems; C.2.5 [Computer-Communication Networks]: Local Networks - rings; D.4.4 [Operating Systems]: Communications Management - network communication; D.4.5 [Operating Systems]: Reliability - fault-tolerance; D.4.7 [Operating Systems]: Organization and Design - distributed systems.",Algorithms; Lamport timestamp; Network partitioning; Performance; Reliability; Reliable delivery; Topology maintenance; Total ordering; Virtual synchrony,Algorithms; Computer networks; Gateways (computer networks); Information technology; Local area networks; Multiple-ring protocol; Network protocols
A Quantitative Comparison of Parallel Computation Models,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032131992&doi=10.1145%2f290409.290412&partnerID=40&md5=6cb8a77dba8e36c729cfec7e2e0da657,"In recent years, a large number of parallel computation models have been proposed to replace the PRAM as the parallel computation model presented to the algorithm designer. Although mostly the theoretical justifications for these models are sound, and many algorithmic results were obtained through these models, little experimentation has been conducted to validate the effectiveness of these models for developing cost-effective algorithms and applications on existing hardware platforms. In this article a first attempt is made to perform a detailed experimental account on the preciseness of these models. To achieve this, three models (BSP, E-BSP, and BPRAM) were selected and validated on five parallel platforms (Cray T3E, Thinking Machines CM-5, Intel Paragon, MasPar MP-1, and Parsytec GCel). The work described in this article consists of three parts. First, the predictive capabilities of the models are investigated. Unlike previous experimental work, which mostly demonstrated a close match between the measured and predicted execution times, this article shows that there are several situations in which the models do not precisely predict the actual runtime behavior of an algorithm implementation. Second, a comparison between the models is provided in order to determine the model that induces the most efficient algorithms. Lastly, the performance achieved by the model-derived algorithms is compared with the performance attained by machine-specific algorithms in order to examine the effectiveness of deriving fast algorithms through the formalisms of the models.",C.1.2 [Processor Architectures]: Multiple Data Stream Architectures (Multiprocessor); C.4 [Computer Systems Organization]: Performance of Systems - modeling techniques; D.1.3 [Programming Techniques]: Concurrent Programming-parallel programming,Computer architecture; Computer systems programming; Mathematical models; Parallel computation models; Parallel processing systems
Informing Memory Operations: Memory Performance Feedback Mechanisms and Their Applications,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032058458&doi=10.1145%2f279227.279230&partnerID=40&md5=7869f0e2930ad74a28ffeb79451bdb6a,"Memory latency is an important bottleneck in system performance that cannot be adequately solved by hardware alone. Several promising software techniques have been shown to address this problem successfully in specific situations. However, the generality of these software approaches has been limited because current architectures do not provide a fine-grained, low-overhead mechanism for observing and reacting to memory behavior directly. To fill this need, this article proposes a new class of memory operations called informing memory operations, which essentially consist of a memory operation combined (either implicitly or explicitly) with a conditional branch-and-link operation that is taken only if the reference suffers a cache miss. This article describes two different implementations of informing memory operations. One is based on a cache-outcome condition code, and the other is based on low-overhead traps. We find that modern in-order-issue and out-of-order-issue superscalar processors already contain the bulk of the necessary hardware support. We describe how a number of software-based memory optimizations can exploit informing memory operations to enhance performance, and we look at cache coherence with fine-grained access control as a case study. Our performance results demonstrate that the runtime overhead of invoking the informing mechanism on the Alpha 21164 and MIPS R10000 processors is generally small enough to provide considerable flexibility to hardware and software designers, and that the cache coherence application has improved performance compared to other current solutions. We believe that the inclusion of informing memory operations in future processors may spur even more innovative performance optimizations. Categories and Subject Descriptors: B.3.2 [Memory Structures]: Design Styles - cache memories; B.3.3 [Memory Structures]: Performance Analysis and Design Aids - simulation; C.4 [Computer Systems Organization]: Performance of Systems - measurement techniques; D.3.4 [Programming Languages]: Processors - compilers; optimization.",Cache miss notification; Design; Experimentation; Memory latency; Performance; Processor architecture,Computer architecture; Computer hardware; Computer operating systems; Computer software; Feedback control; Optimization; Cache memories; Informing memory operations; Storage allocation (computer)
The Part-Time Parliament,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032058184&doi=10.1145%2f279227.279229&partnerID=40&md5=88c567ccf750cc2c472b7775b76fdc02,"Recent archaeological discoveries on the island of Paxos reveal that the parliament functioned despite the peripatetic propensity of its part-time legislators. The legislators maintained consistent copies of the parliamentary record, despite their frequent forays from the chamber and the forgetfulness of their messengers. The Paxon parliament's protocol provides a new way of implementing the state machine approach to the design of distributed systems. Categories and Subject Descriptors: C.2.4 [Computer-Communication Networks]: Distributed Systems - net work operating systems; D.4.5 [Operating Systems]: Reliability - fault-tolerance; J.1 [Computer Applications]: Administrative Data Processing - government.",Design; Reliability; State machines; Three-phase commit; Voting,Design; Distributed computer systems; Reliability; State machines; Network protocols
Tolerating Latency in Multiprocessors through Compiler-Inserted Prefetching,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031988272&doi=10.1145%2f273011.273021&partnerID=40&md5=82d174305edf512fb2fe80caf97b6c59,"The large latency of memory accesses in large-scale shared-memory multiprocessors is a key obstacle to achieving high processor utilization. Software-controlled prefetching is a technique for tolerating memory latency by explicitly executing instructions to move data close to the processor before the data are actually needed. To minimize the burden on the programmer, compiler support is needed to automatically insert prefetch instructions into the code. A key challenge when inserting prefetches is ensuring that the overheads of prefetching do not outweigh the benefits. While previous studies have demonstrated the effectiveness of hand-inserted prefetching in multiprocessor applications, the benefit of compiler-inserted prefetching in practice has remained an open question. This article proposes and evaluates a new compiler algorithm for inserting prefetches into multiprocessor code. The proposed algorithm attempts to minimize overheads by only issuing prefetches for references that are predicted to suffer cache misses. The algorithm can prefetch both dense-matrix and sparse-matrix codes, thus covering a large fraction of scientific applications. We have implemented our algorithm in the SUIF (Stanford University Intermediate Format) optimizing compiler. The results of our detailed architectural simulations demonstrate that compiler-inserted prefetching can improve the speed of some parallel applications by as much as a factor of two.",B.3.2 [Memory Structures]: Design Styles - cache memories; Compiler optimization; D.3.4 [Programming Languages]: Processors - compilers; Design; Experimentation; Optimization; Performance; Prefetching,Algorithms; Buffer storage; Computer architecture; Computer software; Fault tolerant computer systems; Multiprocessing systems; Optimization; Program processors; Compiler inserted prefetching; Tolerating latency; Program compilers
Reconfiguration for Fault Tolerance Using Graph Grammars,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031988309&doi=10.1145%2f273011.273019&partnerID=40&md5=cad5c8b196bbdd9f19f0a0f978fefc9e,"Reconfiguration for fault tolerance is a widely studied field, but this work applies graph grammars to this discipline for the first time. Reconfiguration Graph Grammars (RGG) are defined and applied to the definition of processor array reconfiguration algorithms. The nodes of a graph are associated with the processors of a processor array, and the edges are associated with those interprocessor communication lines that are active. The resulting algorithms for dynamic (run-time) reconfiguration are efficient and can be implemented distributively.",Algorithms; C.1.2 [Processor Architectures]: Multiple Data Stream architectures; C.4 [Computer Systems Organization]: Performance of Systems - reliability; Design; F.4.2 [Mathematical Logic and Formal Languages]: Grammars and Other Rewriting Systems,Algorithms; Computational grammars; Computer architecture; Computer systems; Formal languages; Formal logic; Parallel processing systems; Program processors; Reliability; Graph grammars; Multiple data stream architectures; Processor arrays; Reconfiguration; Fault tolerant computer systems
Performance Evaluation of the Orca Shared-Object System,1998,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031988269&doi=10.1145%2f273011.273014&partnerID=40&md5=72c06a470b30203c99a810668a5bd8a6,"Orca is a portable, object-based distributed shared memory (DSM) system. This article studies and evaluates the design choices made in the Orca system and compares Orca with other DSMs. The article gives a quantitative analysis of Orca's coherence protocol (based on write-updates with function shipping), the totally ordered group communication protocol, the strategy for object placement, and the all-software, user-space architecture. Performance measurements for 10 parallel applications illustrate the trade-offs made in the design of Orca and show that essentially the right design decisions have been made. A write-update protocol with function shipping is effective for Orca, especially since it is used in combination with techniques that avoid replicating objects that have a low read/write ratio. The overhead of totally ordered group communication on application performance is low. The Orca system is able to make near-optimal decisions for object placement and replication. In addition, the article compares the performance of Orca with that of a page-based DSM (TreadMarks) and another object-based DSM (CRL). It also analyzes the communication overhead of the DSMs for several applications. All performance measurements are done on a 32-node Pentium Pro cluster with Myrinet and Fast Ethernet networks. The results show that the Orca programs send fewer messages and less data than the TreadMarks and CRL programs and obtain better speedups.","D.1.3 [Programming Techniques]: Concurrent Programming - distributed programming; D.3.2 [Programming Languages]: Language Classifications - concurrent, distributed, and parallel languages; Parallel programming",Computer architecture; Computer networks; Computer software; Computer software portability; Data storage equipment; Distributed computer systems; Network protocols; Program compilers; Program processors; Concurrent programming; Distributed shared memory system; Orca shared object system; Run time environments; Parallel processing systems
Disco: Running Commodity Operating Systems on Scalable Multiprocessors,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031269854&doi=10.1145%2f265924.265930&partnerID=40&md5=e85491df4e9579c1beefc8c78af90ee4,"In this article we examine the problem of extending modern operating systems to run efficiently on large-scale shared-memory multiprocessors without a large implementation effort. Our approach brings back an idea popular in the 1970s: virtual machine monitors. We use virtual machines to run multiple commodity operating systems on a scalable multiprocessor. This solution addresses many of the challenges facing the system software for these machines. We demonstrate our approach with a prototype called Disco that runs multiple copies of Silicon Graphics' IRIX operating system on a multiprocessor. Our experience shows that the overheads of the monitor are small and that the approach provides scalability as well as the ability to deal with the nonuniform memory access time of these systems. To reduce the memory overheads associated with running multiple operating systems, virtual machines transparently share major data structures such as the program code and the file system buffer cache. We use the distributed-system support of modern operating systems to export a partial single system image to the users. The overall solution achieves most of the benefits of operating systems customized for scalable multiprocessors, yet it can be achieved with a significantly smaller implementation effort.",C.1.2 [Computer Systems Organization]: Multiple Data Stream Architectures -parallel processors; D.4.7 [Software]: Operating Systems - organization and design; Design; Experimentation; Performance; Scalable multiprocessors; Virtual machines,Buffer storage; Computer architecture; Computer monitors; Computer software; Data structures; Parallel processing systems; Running commodity operating systems; Scalable multiprocessors; Virtual machines; Computer operating systems
Eraser: A Dynamic Data Race Detector for Multithreaded Programs,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031272525&doi=10.1145%2f265924.265927&partnerID=40&md5=e449b945d8b95c8d42f57cfe10008555,"Multithreaded programming is difficult and error prone. It is easy to make a mistake in synchronization that produces a data race, yet it can be extremely hard to locate this mistake during debugging. This article describes a new tool, called Eraser, for dynamically detecting data races in lock-based multithreaded programs. Eraser uses binary rewriting techniques to monitor every shared-memory reference and verify that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a multithreaded Web search engine, that demonstrate the effectiveness of this approach.",D.1.3 [Programming Techniques]: Concurrent Programming - parallel programming; D.2.5 [Software Engineering]: Testing and Debugging - debugging aids; D.4.1 [Operating Systems]: Process Management -concurrency; Deadlock; Monitors; Tracing,Computer operating systems; Computer programming; Software engineering; Synchronization; Data race detector; Multithreaded programs; Program debugging
Continuous Profiling: Where Have All the Cycles Gone?,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031270220&doi=10.1145%2f265924.265925&partnerID=40&md5=cfc8fadc37ac4f1f980aba67303a697e,"This article describes the Digital Continuous Profiling Infrastructure, a sampling-based profiling system designed to run continuously on production systems. The system supports multiprocessors, works on unmodified executables, and collects profiles for entire systems, including user programs, shared libraries, and the operating system kernel. Samples are collected at a high rate (over 5200 samples/sec. per 333MHz processor), yet with low overhead (1-3% slowdown for most workloads). Analysis tools supplied with the profiling system use the sample data to produce a precise and accurate accounting, down to the level of pipeline stalls incurred by individual instructions, of where time is being spent. When instructions incur stalls, the tools identify possible reasons, such as cache misses, branch mispredictions, and functional unit contention. The fine-grained instruction-level analysis guides users and automated optimizers to the causes of performance problems and provides important insights for fixing them.",C.4 [Computer Systems Organization]: Performance of Systems; D.2.2 [Software Engineering]: Tools and Techniques - profiling tools; D.2.6 [Programming Languages]: Programming Environments - performance monitoring; D.4 [Operating Systems]: General,Computer hardware; Computer programming languages; Computer systems; Software engineering; Continuous profiling; Performance monitoring hardware; Program analysis; Computer operating systems
Editorial: Electronic Publication of Tocs,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024265079&doi=10.1145%2f244764.258064&partnerID=40&md5=51a1bcdd1fb5fb243610aad4955e9812,"With this issue of ACM Transactions on Computer Systems, I am pleased to introduce some major new steps toward fully electronic publishing both for TOCS and for other ACM journals. As many subscribers will be aware, ACM has developed a sophisticated electronic archival storage system over the past year. Starting with the present issue of TOCS, full-text copies of all articles will be available, online, to subscribers. TOCS subscribers will also have unrestricted free access to abstracts from other ACM journals. ACM is also planning to develop services for nonsubscribers and will announce them in the future. ACM will soon introduce other electronic products, such as a means of accessing the total “database,” including all journals. We'll also be placing copies of accepted articles online, so that readers can access these before the scheduled publication date. I think that for TOCS, which has a short backlog, the impact should be minor, but for some of ACM's other journals, it could be quite significant. Potential authors should consult the instructions for authors on the ACM web page. To make this electronic option work, we need to obtain your manuscripts in a machine-readable format. The current plan has some obvious limitations: for the time being, only a limited number of back issues will be available in the database, although more (eventually 5 years of issues) should be online soon. For online articles, full text is available through ACM's web site (choose WWW Account and follow the instructions for creating an account, which is required but will be done at no charge; a PDF viewer is also required, and a free downloadable version is available there from Adobe Systems, Inc. For this, go to the ACM Digital Library on the ACM web site). Additionally, we are discussing some TOCS-specific ideas. I would be open to suggestions or comments. Feel free to send me email. © 1997, ACM. All rights reserved.",,
Converting Thread-Level Parallelism to Instruction-Level Parallelism via Simultaneous Multithreading,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031199614&doi=10.1145%2f263326.263382&partnerID=40&md5=c16deddfb4e4dcb94209d3e9821ca7c5,"To achieve high performance, contemporary computer systems rely on two forms of parallelism: instruction-level parallelism (ILP) and thread-level parallelism (TLP). Wide-issue super-scalar processors exploit ILP by executing multiple instructions from a single program in a single cycle. Multiprocessors (MP) exploit TLP by executing different threads in parallel on different processors. Unfortunately, both parallel processing styles statically partition processor resources, thus preventing them from adapting to dynamically changing levels of ILP and TLP in a program. With insufficient TLP, processors in an MP will be idle; with insufficient ILP, multiple-issue hardware on a superscalar is wasted. This article explores parallel processing on an alternative architecture, simultaneous multithreading (SMT), which allows multiple threads to compete for and share all of the processor's resources every cycle. The most compelling reason for running parallel applications on an SMT processor is its ability to use thread-level parallelism and instruction-level parallelism interchangeably. By permitting multiple threads to share the processor's functional units simultaneously, the processor can use both ILP and TLP to accommodate variations in parallelism. When a program has only a single thread, all of the SMT processor's resources can be dedicated to that thread; when more TLP exists, this parallelism can compensate for a lack of per-thread ILP. We examine two alternative on-chip parallel architectures for the next generation of processors. We compare SMT and small-scale, on-chip multiprocessors in their ability to exploit both ILP and TLP. First, we identify the hardware bottlenecks that prevent multiprocessors from effectively exploiting ILP. Then, we show that because of its dynamic resource sharing, SMT avoids these inefficiencies and benefits from being able to run more threads on a single processor. The use of TLP is especially advantageous when per-thread ILP is limited. The ease of adding additional thread contexts on an SMT (relative to adding additional processors on an MP) allows simultaneous multithreading to expose more parallelism, further increasing functional unit utilization and attaining a 52% average speedup (versus a four-processor, single-chip multiprocessor with comparable execution resources). This study also addresses an often-cited concern regarding the use of thread-level parallelism or multithreading: interference in the memory system and branch prediction hardware. We find that multiple threads cause interthread interference in the caches and place greater demands on the memory system, thus increasing average memory latencies. By exploiting thread-level parallelism, however, SMT hides these additional latencies, so that they only have a small impact on total program performance. We also find that for parallel applications, the additional threads have minimal effects on branch prediction. Categories and Subject Descriptors: C.1.2 [Processor Architectures]: Multiple Data Stream Architectures.",Cache interference; Instruction-level parallelism; Measurement; Multiprocessors; Multithreading; Performance; Simultaneous multithreading; Thread-level parallelism,Design; Parallel algorithms; Parallel processing systems; Performance; Multithreading; Computer systems
HFS: A Performance-Oriented Flexible File System Based on Building-Block Compositions,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031199976&doi=10.1145%2f263326.263356&partnerID=40&md5=a6c98d486eb3a53408583bde5f0f7601,"The Hurricane File System (HFS) is designed for (potentially large-scale) shared-memory multiprocessors. Its architecture is based on the principle that, in order to maximize performance for applications with diverse requirements, a file system must support a wide variety of file structures, file system policies, and I/O interfaces. Files in HFS are implemented using simple building blocks composed in potentially complex ways. This approach yields great flexibility, allowing an application to customize the structure and policies of a file to exactly meet its requirements. As an extreme example, HFS allows a file's structure to be optimized for concurrent random-access write-only operations by 10 threads, something no other file system can do. Similarly, the prefetching, locking, and file cache management policies can all be chosen to match an application's access pattern. In contrast, most parallel file systems support a single file structure and a small set of policies. We have implemented HFS as part of the Hurricane operating system running on the Hector shared-memory multiprocessor. We demonstrate that the flexibility of HFS comes with little processing or I/O overhead. We also show that for a number of file access patterns, HFS is able to deliver to the applications the full I/O bandwidth of the disks on our system. Categories and Subject Descriptors: D.4.3 [Operating Systems]: File Systems Management-access methods; file organization; D.4.8 [Operating Systems]: Performance-measurements; E.5 [Data]: Files-optimization; organization/structure.",Customization; Data partitioning; Data replication; Design; Flexibility; Parallel computing; Parallel file system; Performance,Data processing; Design; File organization; Measurements; Parallel processing systems; Performance; Access methods; Customization; Computer systems
Exploiting Process Lifetime Distributions for Dynamic Load Balancing,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031199613&doi=10.1145%2f263326.263344&partnerID=40&md5=e45e98ce4ea9867932547a1c1bcdd2dd,"We consider policies for CPU load balancing in networks of workstations. We address the question of whether preemptive migration (migrating active processes) is necessary, or whether remote execution (migrating processes only at the time of birth) is sufficient for load balancing. We show that resolving this issue is strongly tied to understanding the process lifetime distribution. Our measurements indicate that the distribution of lifetimes for a UNIX process is Pareto (heavy-tailed), with a consistent functional form over a variety of workloads. We show how to apply this distribution to derive a preemptive migration policy that requires no hand-tuned parameters. We used a trace-driven simulation to show that our preemptive migration strategy is far more effective than remote execution, even when the memory transfer cost is high. Categories and Subject Descriptors: C.2.4 [Computer-Communication Networks]: Distributed Systems; C.4 [Computer Systems Organization]: Performance of Systems; C.5.3 [Computer System Implementation]: Microcomputers; G.3 [Mathematics of Computing]: Probability and Statistics; G.m [Mathematics of Computing]: Miscellaneous; I.6 [Computing Methodologies]: Simulation and Modeling.",Algorithms; Design; Heavy-tailed; Load balancing; Load sharing; Measurement; Migration; Network of workstations; Pareto distribution; Performance; Remote execution; Trace-driven simulation; Workload modeling,Algorithms; Communication; Computer networks; Computer simulation; Computer workstations; Design; Mathematical models; Perforators; Probability; Statistics; Dynamic load balancing; Computer systems
Eliminating Receive Livelock in an Interrupt-Driven Kernel,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031199999&doi=10.1145%2f263326.263335&partnerID=40&md5=5d80c024bbbc7e3cda04751a5f82478e,"Most operating systems use interface interrupts to schedule network tasks. Interrupt-driven systems can provide low overhead and good latency at low offered load, but degrade significantly at higher arrival rates unless care is taken to prevent several pathologies. These are various forms of receive livelock, in which the system spends all of its time processing interrupts, to the exclusion of other necessary tasks. Under extreme conditions, no packets are delivered to the user application or the output of the system. To avoid livelock and related problems, an operating system must schedule network interrupt handling as carefully as it schedules process execution. We modified an interrupt-driven networking implementation to do so; this modification eliminates receive livelock without degrading other aspects of system performance. Our modifications include the use of polling when the system is heavily loaded, while retaining the use of interrupts under lighter load. We present measurements demonstrating the success of our approach. Categories and Subject Descriptors: C.2 [Computer Systems Organization]: Computer-Communication Networks; D.4 [Software]: Operating Systems; D.4.1 [Operating Systems]: Process Management - scheduling; D.4.4 [Operating Systems]: Communications Management -input/output; network communication.",Interrupt-driven kernel; Livelock; Performance; Polling; Scheduling,Communication; Computer networks; Computer software; Scheduling; Interrupt-driven kernel; Livelock; Computer systems
Disk-Directed I/O for MIMD Multiprocessors,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031074074&doi=10.1145%2f244764.244766&partnerID=40&md5=62208451c60821b512e36137a96a5a1d,"Many scientific applications that run on today's multiprocessors, such as weather forecasting and seismic analysis, are bottlenecked by their file-I/O needs. Even if the multiprocessor is configured with sufficient I/O hardware, the file system software often fails to provide the available bandwidth to the application. Although libraries and enhanced file system interfaces can make a significant improvement, we believe that fundamental changes are needed in the file server software. We propose a new technique, disk-directed I/O, to allow the disk servers to determine the flow of data for maximum performance. Our simulations show that tremendous performance gains are possible both for simple reads and writes and for an out-of-core application. Indeed, our disk-directed I/O technique provided consistent high performance that was largely independent of data distribution and obtained up to 93% of peak disk bandwidth. It was as much as 18 times faster than either a typical parallel file system or a two-phase-I/O library.","Collective I/O; D.4.3 [Operating Systems]: File Systems Management-access methods; D.4.8 [Operating Systems]: Performance - Simulation; Disk-directed I/O; E.5 [Data]: Files General Terms: Design, Experimentation, Performance; File organization",Buffer storage; Computer simulation; File organization; Input output programs; Interfaces (computer); Disk directed input/output; Parallel file system; Parallel processing systems
Scheduler-Conscious Synchronization,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031073624&doi=10.1145%2f244764.244765&partnerID=40&md5=66ae291b3a77ce3ff895f07aa94ffa48,"Efficient synchronization is important for achieving good performance in parallel programs, especially on large-scale multiprocessors. Most synchronization algorithms have been designed to run on a dedicated machine, with one application process per processor, and can suffer serious performance degradation in the presence of multiprogramming. Problems arise when running processes block or, worse, busy-wait for action on the part of a process that the scheduler has chosen not to run. We show that these problems are particularly severe for scalable synchronization algorithms based on distributed data structures. We then describe and evaluate a set of algorithms that perform well in the presence of multiprogramming while maintaining good performance on dedicated machines. We consider both large and small machines, with a particular focus on scalability, and examine mutual-exclusion locks, reader-writer locks, and barriers. Our algorithms vary in the degree of support required from the kernel scheduler. We find that while it is possible to avoid pathological performance problems using previously proposed kernel mechanisms, a modest additional widening of the kernel/user interface can make scheduler-conscious synchronization algorithms significantly simpler and faster, with performance on dedicated machines comparable to that of scheduler-oblivious algorithms.",,Data structures; Multiprogramming; Parallel algorithms; Synchronization; User interfaces; Kernel scheduler; Large scale multiprocessors; Parallel processing systems
Real-Time Computing with Lock-Free Shared Objects,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031141994&doi=10.1145%2f253145.253159&partnerID=40&md5=8f2eac6d53d58d4fd68adf6c4efa1dd1,"This article considers the use of lock-free shared objects within hard real-time systems. As the name suggests, lock-free shared objects are distinguished by the fact that they are accessed without locking. As such, they do not give rise to priority inversions, a key advantage over conventional, lock-based object-sharing approaches. Despite this advantage, it is not immediately apparent that lock-free shared objects can be employed if tasks must adhere to strict timing constraints. In particular, lock-free object implementations permit concurrent operations to interfere with each other, and repeated interferences can cause a given operation to take an arbitrarily long time to complete. The main contribution of this article is to show that such interferences can be bounded by judicious scheduling. This work pertains to periodic, hard real-time tasks that share lock-free objects on a uniprocessor. In the first part of the article, scheduling conditions are derived for such tasks, for both static and dynamic priority schemes. Based on these conditions, it is formally shown that lock-free shared objects often incur less overhead than object implementations based on wait-free algorithms or lock-based schemes. In the last part of the article, this conclusion is validated experimentally through work involving a real-time desktop videoconferencing system.",Critical sections; Deadline monotonic; Earliest deadline first; Hard real time; Lock free; Rate monotonic; Scheduling; Synchronization; Wait free,Algorithms; Constraint theory; Data acquisition; Personal computers; Scheduling; Teleconferencing; Lock free shared objects; Real time systems
A High-Speed Network Interface for Distributed-Memory Systems: Architecture and Applications,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031074285&doi=10.1145%2f244764.244767&partnerID=40&md5=b94f6a46eb3d8b38fcb84ab46b1ab90f,"Distributed-memory systems have traditionally had great difficulty performing network I/O at rates proportional to their computational power. The problem is that the network interface has to support network I/O for a supercomputer, using computational and memory bandwidth resources similar to those of a workstation. As a result, the network interface becomes a bottleneck. In this article we present an I/O architecture that addresses these problems and supports high-speed network I/O on distributed-memory systems. The key to good performance is to partition the work appropriately between the system and the network interface. Some communication tasks are performed on the distributed-memory parallel system, since it is more powerful and less likely to become a bottleneck than the network interface. Tasks that do not parallelize well are performed on the network interface, and hardware support is provided for the most time-critical operations. This architecture has been implemented for the iWarp distributed-memory system and has been used by a number of applications. We describe this implementation, present performance results, and use application examples to validate the main features of the I/O architecture.",B.4.3 [Input/Output and Data Communications]: Interconnections-interfaces; C.0 [Computer Systems Organization]: General - Systems architectures; C.2.2 [Computer-Communication Networks]: Network Protocols - Protocol architecture,Bandwidth; Computational complexity; Computer architecture; Data communication systems; Data storage equipment; Input output programs; Interfaces (computer); Network protocols; Supercomputers; Distributed memory systems; Network input/output architecture; Distributed computer systems
"Optimally Adaptive, Minimum-Distance, Circuit-Switched Routing in Hypercubes",1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031141976&doi=10.1145%2f253145.253261&partnerID=40&md5=bbbaee35da1aaacc92a24f4badd43b13,"In circuit-switched routing, the path between a source and its destination is established by incrementally reserving all required links before the data transmission can begin. If the routing algorithm is not carefully designed, deadlocks can occur in reserving these links. Deadlock-free algorithms based on dimension-ordered routing, such as the E-cube, exist. However, E-cube does not provide any flexibility in choosing a path from a source to its destination and can thus result in long latencies under heavy or uneven traffic. Adaptive, minimum-distance routing algorithms, such as the Turn Model and the UP Preference algorithms, have previously been reported. In this article, we present a new class of adaptive, provably deadlock-free, minimum-distance routing algorithms. We prove that the algorithms developed here are optimally adaptive in the sense that any further flexibility in communication will result in deadlock. We show that the Turn Model is actually a member of our new class of algorithms that does not perform as well as other algorithms within the new class. It creates artificial hotspots in routing the traffic and allows fewer total paths. We present an analytical comparison of the flexibility and balance in routing provided by various algorithms and a comparison based on uniform and nonuniform traffic simulations. The Extended-UP Preference algorithm developed in this article is shown to have improved performance with respect to existing algorithms. The methodology and the algorithms developed here can be used to develop routing for other schemes such as wormhole routing, and for other recursively defined networks such as k-ary n-cubes.",Adaptive routing; Circuit switched; Hypercube; Interconnection networks; K-ary n-cube; Parallel processing; Routing algorithms,Computer simulation; Computer system recovery; Data communication systems; Electric network topology; Interconnection networks; Parallel processing systems; Telecommunication traffic; Hypercubes; Routing algorithm; Adaptive algorithms
Strong Loss Tolerance of Electronic Coin Systems,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031145012&doi=10.1145%2f253145.253282&partnerID=40&md5=c785250abe07eec096a2df76d215c2c7,"Untraceable electronic cash means prepaid digital payment systems, usually with offline payments, that protect user privacy. Such systems have recently been given considerable attention by both theory and development projects. However, in most current schemes, loss of a user device containing electronic cash implies a loss of money, just as with real cash. In comparison with credit schemes, this is considered a serious shortcoming. This article shows how untraceable electronic cash can be made loss tolerant, i.e., how the monetary value of the lost data can be recovered. Security against fraud and preservation of privacy are ensured; strong loss tolerance means that not even denial of recovery is possible. In particular, systems based on electronic coins are treated. We present general design principles and options and their instantiation in one concrete payment system. The measures are practical.",Byzantine faults; Electronic cash; Payment systems; Privacy,Administrative data processing; Algorithms; Computer networks; Cryptography; Distributed computer systems; Management information systems; Security of data; Byzantine faults; Electronic cash; Electronic coin systems; Fault tolerant computer systems
Device Reservation in Audio/Video Editing Systems,1997,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031147396&doi=10.1145%2f253145.253149&partnerID=40&md5=4e7175a60b5a01addf43518b2829189d,"What fraction of disks and other shared devices must be reserved to play an audio/video document without dropouts? In general, this question cannot be answered precisely. For documents with complex and irregular structure, such as those arising in audio/video editing, it is difficult even to give a good estimate. We describe three approaches to this problem. The first, based on long-term average properties of segments, is fast but imprecise: it underreserves in some cases and overreserves in others. The second approach models individual disk and network operations. It is precise but slow. The third approach, a hybrid, is both precise and fast.",Admission control; Edit decision list; Quality of service; Reservation,Algorithms; Computer operating systems; Data structures; Image segmentation; Interfaces (computer); Real time systems; Admission control; Audio video editing systems; Edit decision list; Multimedia information systems; File editors
Customized Information Extraction as a Basis for Resource Discovery,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030141988&doi=10.1145%2f227695.227697&partnerID=40&md5=725b58ce293c3eecd462f729f9b7c657,"Indexing file contents is a powerful means of helping users locate documents, software, and other types of data among large repositories. In environments that contain many different types of data, content indexing requires type-specific processing to extract information effectively. We present a model for type-specific, user-customizable information extraction, and a system implementation called Essence. This software structure allows users to associate specialized extraction methods with ordinary files, providing the illusion of an object-oriented file system that encapsulates indexing methods within files. By exploiting the semantics of common file types, Essence generates compact yet representative file summaries that can be used to improve both browsing and indexing in resource discovery systems. Essence can extract information from most of the types of files found in common file systems, including files with nested structure (such as compressed ""tar"" files). Essence interoperates with a number of different search/index systems (such as WAIS and Glimpse), as part of the Harvest system.",D.2 [Software]: Software Engineering; E.5 [Data]: Files - organization/structure; H.3 [Information Systems]: Information Storage and Retrieval; H.4 [Information Systems]: Information Systems Applications,Computer software; Database systems; File organization; Indexing (of information); Interactive computer systems; Object oriented programming; User interfaces; Distributed indexing; Information extraction; Internet; Resource discovery system; Information retrieval systems
Fault-Tolerance in Air Traffic Control Systems,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030214489&doi=10.1145%2f233557.233559&partnerID=40&md5=d55c3c1ea43deec548578cf96dd7fe3b,"The distributed real-time system services developed by Lockheed Martin's Air Traffic Management group serve as the infrastructure for a number of air traffic control systems. Either completed development or under development are the US Federal Aviation Administration's Display System Replacement (DSR) system, the UK Civil Aviation Authority's New Enroute Center (NERC) system, and the Republic of China's Air Traffic Control Automated System (ATCAS). These systems are intended to replace present en route systems over the next decade. High availability of air traffic control services is an essential requirement of these systems. This article discusses the general approach to fault-tolerance adopted in this infrastructure, by reviewing some of the questions which were asked during the system design, various alternative solutions considered, and the reasons for the design choices made. The aspects of this infrastructure chosen for the individual ATC systems mentioned above, along with the status of those systems, are presented in the Section 11 of the article.","C.4 [Computer Systems Organization]: Performance of Systems - reliability, availability, and serviceability; D.2.5 [Software Engineering]: Testing and Debugging - error handling and recovery; D.4.5 [Operating Systems]: Reliability - fault-tolerance",Computer software; Design; Fault tolerant computer systems; Reliability; Error handling and recovery; Real-time and embedded systems; Air traffic control
Diffracting Trees,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030289514&doi=10.1145%2f235543.235546&partnerID=40&md5=4ac0d9256aba5c0a365f88b6e01c3e8a,"Shared counters are among the most basic coordination structures in multiprocessor computation, with applications ranging from barrier synchronization to concurrent-data-structure design. This article introduces diffracting trees, novel data structures for shared counting and load balancing in a distributed/parallel environment. Empirical evidence, collected on a simulated distributed shared-memory machine and several simulated message-passing architectures, shows that diffracting trees scale better and are more robust than both combining trees and counting networks, currently the most effective known methods for implementing concurrent counters in software. The use of a randomized coordination method together with a combinatorial data structure overcomes the resiliency drawbacks of combining trees. Our simulations show that to handle the same load, diffracting trees and counting networks should have a similar width w, yet the depth of a diffracting tree is O(log w), whereas counting networks have depth O(log2 w). Diffracting trees have already been used to implement highly efficient producer/consumer queues, and we believe diffraction will prove to be an effective alternative paradigm to combining and queue-locking in the design of many concurrent data structures.",C.1.2 [Processor Architectures]: Multiple Data Stream Architectures; C.2.4 [Computer-Communication Networks]: Distributed Systems; D.4.1 [Operating Systems]: Process Management - Synchronization,Computer operating systems; Design; Distributed computer systems; Interconnection networks; Parallel processing systems; Synchronization; Diffracting trees; Multiprocessing systems
Recovery in the Calypso File System,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030215945&doi=10.1145%2f233557.233560&partnerID=40&md5=d4113f1c8256a4d445352a0a1234ac46,"This article presents the design and implementation of the recovery scheme in Calypso. Calypso is a cluster-optimized, distributed file system for UNIX clusters. As in Sprite and AFS, Calypso servers are stateful and scale well to a large number of clients. The recovery scheme in Calypso is nondisruptive, meaning that open files remain open, client modified data are saved, and in-flight operations are properly handled across server recovery. The scheme uses distributed state among the clients to reconstruct the server state on a backup node if disks are multiported or on the rebooted server node. It guarantees data consistency during recovery and provides congestion control. Measurements show that the state reconstruction can be quite fast: for example, in a 32-node cluster, when an average node contains state for about 420 files, the reconstruction time is about 3.3 seconds. However, the time to update a file system after a failure can be a major factor in the overall recovery time, even when using journaling techniques.",C.4 [Computer Systems Organization]: Performance of Systems; D.4.3 [Operating Systems]: File Systems Management - distributed file systems; D.4.5 [Operating Systems]: Reliability - fault-tolerance,Design; Fault tolerant computer systems; File organization; Management; Reliability; Cluster systems; Recovery scheme; State reconstruction; Distributed computer systems
An Empirical Study of a Wide-Area Distributed File System,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030149435&doi=10.1145%2f227695.227698&partnerID=40&md5=05cb41eff945282f8bb56150422d75ea,"The evolution of the Andrew File System (AFS) into a wide-area distributed file system has encouraged collaboration and information dissemination on a much broader scale than ever before. We examine AFS as a provider of wide-area file services to over 100 organizations around the world. We discuss usage characteristics of AFS derived from empirical measurements of the system. Our observations indicate that AFS provides robust and efficient data access in its current configuration, thus confirming its viability as a design point for wide-area distributed file systems.",Andrew; D.4.3 [Operating Systems]: File Systems Management - distributed file systems; D.4.8 [Operating Systems]: Performance - measurements; Design; Experimentation; Internet; Measurement; Performance; Scalability; Usage; Wide area; World Wide Web,Distributed computer systems; File organization; Information dissemination; Information management; Information services; Performance; Wide area networks; Andrew file system; File system management; Internet; Wide area distributed system; World wide web; Distributed database systems
The Vesta Parallel File System,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030214953&doi=10.1145%2f233557.233558&partnerID=40&md5=8bd480e72feab6c61dc39fd83178823a,"The Vesta parallel file system is designed to provide parallel file access to application programs running on multicomputers with parallel I/O subsystems. Vesta uses a new abstraction of files: a file is not a sequence of bytes, but rather it can be partitioned into multiple disjoint sequences that are accessed in parallel. The partitioning - which can also be changed dynamically - reduces the need for synchronization and coordination during the access. Some control over the layout of data is also provided, so the layout can be matched with the anticipated access patterns. The system is fully implemented and forms the basis for the AIX Parallel I/O File System on the IBM SP2. The implementation does not compromise scalability or parallelism. In fact, all data accesses are done directly to the I/O node that contains the requested data, without any indirection or access to shared metadata. Disk mapping and caching functions are confined to each I/O node, so there is no need to keep data coherent across nodes. Performance measurements show good scalability with increased resources. Moreover, different access patterns are shown to achieve similar performance.",C.1.2 [Processor Architectures]: Multiple Data Stream Architectures - parallel processors; D.1.3 [Programming Techniques]: Concurrent Programming - parallel programming; D.4.1 [Operating Systems]: Process Management - concurrency,Computer programming; Design; File organization; Program processors; Sorting; Data partitioning; Process management; Parallel processing systems
Portable Run-Time Support for Dynamic Object-Oriented Parallel Processing,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030149889&doi=10.1145%2f227695.227696&partnerID=40&md5=78fcb10739d0e1675557941c34d5bbdb,"Mentat is an object-oriented parallel processing system designed to simplify the task of writing portable parallel programs for parallel machines and workstation networks. The Mentat compiler and run-time system work together to automatically manage the communication and synchronization between objects. The run-time system marshalls member function arguments, schedules objects on processors, and dynamically constructs and executes large-grain data dependence graphs. In this article we present the Mentat run-time system. We focus on three aspects - the software architecture, including the interface to the compiler and the structure and interaction of the principle components of the run-time system; the run-time overhead on a component-by-component basis for two platforms, a Sun SparcStation 2 and an Intel Paragon; and an analysis of the minimum granularity required for application programs to overcome the run-time overhead.","D.1.3 [Programming Techniques]: Concurrent Programming - parallel programming; D.1.5 [Programming Techniques]: Object-Oriented Programming; D.3.2 [Programming Languages]: Language Classifications - concurrent, distributed, and parallel languages",Computer programming languages; Computer software; Computer systems programming; Computer workstations; Data structures; Flowcharting; Interfaces (computer); Object oriented programming; Program compilers; Response time (computer systems); Software engineering; Data dependence graphs; Data flow; Distributed memory; Parallel programming; Run time system; Software architecture; Parallel processing systems
Analysis of Benchmark Characteristics and Benchmark Performance Prediction,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030285193&doi=10.1145%2f235543.235545&partnerID=40&md5=e99972e3807750f560dbac71f24a952e,"Standard benchmarking provides the run-times for given programs on given machines, but fails to provide insight as to why those results were obtained (either in terms of machine or program characteristics) and fails to provide run-times for that program on some other machine, or some other programs on that machine. We have developed a machine-independent model of program execution to characterize both machine performance and program execution. By merging these machine and program characterizations, we can estimate execution time for arbitrary machine/program combinations. Our technique allows us to identify those operations, either on the machine or in the programs, which dominate the benchmark results. This information helps designers in improving the performance of future machines and users in tuning their applications to better utilize the performance of existing machines. Here we apply our methodology to characterize benchmarks and predict their execution times. We present extensive run-time statistics for a large set of benchmarks including the SPEC and Perfect Club suites. We show how these statistics can be used to identify important shortcomings in the programs. In addition, we give execution time estimates for a large sample of programs and machines and compare these against benchmark results. Finally, we develop a metric for program similarity that makes it possible to classify benchmarks with respect to a large set of characteristics.",C.4 [Computer Systems Organization]: Performance of Systems - Measurement techniques; D.2.8 [Software Engineering]: Metrics - Performance measures; Modeling techniques; Performance attributes,Algorithms; Computer operating systems; Computer software; Models; Software engineering; Benchmark analysis; Microbenchmarking; Computer systems
"Implementation and Performance of Integrated Application-Controlled File Caching, Prefetching, and Disk Scheduling",1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030288189&doi=10.1145%2f235543.235544&partnerID=40&md5=f9b176a0bf6110bc40b3c5d4752737e2,"As the performance gap between disks and microprocessors continues to increase, effective utilization of the file cache becomes increasingly important. Application-controlled file caching and prefetching can apply application-specific knowledge to improve file cache management. However, supporting application-controlled file caching and prefetching is nontrivial because caching and prefetching need to be integrated carefully, and the kernel needs to allocate cache blocks among processes appropriately. This article presents the design, implementation, and performance of a file system that integrates application-controlled caching, prefetching, and disk scheduling. We use a two-level cache management strategy. The kernel uses the LRU-SP (Least-Recently-Used with Swapping and Placeholders) policy to allocate blocks to processes, and each process integrates application-specific caching and prefetching based on the controlled-aggressive policy, an algorithm previously shown in a theoretical sense to be nearly optimal. Each process also improves its disk access latency by submitting its prefetches in batches so that the requests can be scheduled to optimize disk access performance. Our measurements show that this combination of techniques greatly improves the performance of the file system. We measured that the running time is reduced by 3% to 49% (average 26%) for single-process workloads and by 5% to 76% (average 32%) for multiprocess workloads.",C.4 [Computer Systems Organization]: Performance of Systems - Design studies; D.4.2 [Operating Systems]: Storage Management - Secondary storage; D.4.3 [Operating Systems]: File System Management - Access methods; Storage hierarchies,Algorithms; Computer operating systems; File organization; Storage allocation (computer); Disk scheduling; Performance; Computer systems
The Measured Performance of Personal Computer Operating Systems,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030080862&doi=10.1145%2f225535.225536&partnerID=40&md5=a45f4ff4043d136b5e9a494b25bf64d7,"This article presents a comparative study of the performance of three operating systems that run on the personal computer architecture derived from the IBM-PC. The operating systems, Windows for Workgroups, Windows NT, and NetBSD (a freely available variant of the UNIX operating system), cover a broad range of system functionality and user requirements, from a single-address-space model to full protection with preemptive multitasking. Our measurements are enabled by hardware counters in Intel's Pentium processor that permit measurement of a broad range of processor events including instruction counts and on-chip cache miss counts. We use both microbenchmarks, which expose specific differences between the systems, and application workloads, which provide an indication of expected end-to-end performance. Our microbenchmark results show that accessing system functionality is often more expensive in Windows for Workgroups than in the other two systems due to frequent changes in machine mode and the use of system call hooks. When running native applications, Windows NT is more efficient than Windows, but it incurs overhead similar to that of a microkernel, since its application interface (the Win32 API) is implemented as a user-level server. Overall, system functionality can be accessed most efficiently in NetBSD; we attribute this to its monolithic structure and to the absence of the complications created by hardware backward-compatibility requirements in the other systems. Measurements of application performance show that although the impact of these differences is significant in terms of instruction counts and other hardware events (often a factor of 2 to 7 difference between the systems), overall performance is sometimes determined by the functionality provided by specific subsystems, such as the graphics subsystem or the file system buffer cache.",C.4 [Computer Systems Organization]: Performance of Systems; D.4.0 [Operating Systems]: General; D.4.7 [Operating Systems]: Organization and Design; D.4.8 [Operating Systems]: Performance; Measurement; Microsoft windows; Performance,Buffer storage; Computer architecture; Computer hardware; Graphical user interfaces; Performance; Personal computers; Program processors; Microsoft windows; Operating systems performance measurement; Operating systems structure; Personal computer operating systems; Computer operating systems
Serverless Network File Systems,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030083168&doi=10.1145%2f225535.225537&partnerID=40&md5=b8075980c01ef328af524ac2d3e96bd0,"We propose a new paradigm for network file system design: serverless network file systems. While traditional network file systems rely on a central server machine, a serverless system utilizes workstations cooperating as peers to provide all file system services. Any machine in the system can store, cache, or control any block of data. Our approach uses this location independence, in combination with fast local area networks, to provide better performance and scalability than traditional file systems. Furthermore, because any machine in the system can assume the responsibilities of a failed component, our serverless design also provides high availability via redundant data storage. To demonstrate our approach, we have implemented a prototype serverless network file system called xFS. Preliminary performance measurements suggest that our architecture achieves its goal of scalability. For instance, in a 32-node xFS system with 32 active clients, each client receives nearly as much read or write throughput as it would see if it were the only active client.",D.4.2 [Operating Systems]: Storage Management - Allocation/deallocation strategies; secondary storage; D.4.3 [Operating Systems]: File Systems Management - Access methods; directory structures; distributed file systems; file organization,Algorithms; Buffer storage; Computer architecture; Computer workstations; File organization; Information retrieval systems; Local area networks; Performance; Reliability; Storage allocation (computer); Systems analysis; Log based striping; Log cleaning; Log structured; Logging; Redundant data storage; Scalable performance; Serverless network file systems; Computer operating systems
The HP AutoRAID Hierarchical Storage System,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030085468&doi=10.1145%2f225535.225539&partnerID=40&md5=ab36ea96ac5c79c541414bff4cb9ed28,"Configuring redundant disk arrays is a black art. To configure an array properly, a system administrator must understand the details of both the array and the workload it will support. Incorrect understanding of either, or changes in the workload over time, can lead to poor performance. We present a solution to this problem: a two-level storage hierarchy implemented inside a single disk-array controller. In the upper level of this hierarchy, two copies of active data are stored to provide full redundancy and excellent performance. In the lower level, RAID 5 parity protection is used to provide excellent storage cost for inactive data, at somewhat lower performance. The technology we describe in this article, known as HP AutoRAID, automatically and transparently manages migration of data blocks between these two levels as access patterns change. The result is a fully redundant storage system that is extremely easy to use, is suitable for a wide variety of workloads, is largely insensitive to dynamic workload changes, and performs much better than disk arrays with comparable numbers of spindles and much larger amounts of front-end RAM cache. Because the implementation of the HP AutoRAID technology is almost entirely in software, the additional hardware cost for these benefits is very small. We describe the HP AutoRAID technology in detail, provide performance data for an embodiment of it in a storage array, and summarize the results of simulation studies used to choose algorithms implemented in the array.","B.4.2 [Input/Output and Data Communications]: Input/Output Devices - Channels and controllers; B.4.5 [Input/Output and Data Communications]: Reliability, Testing, and Fault-Tolerance - redundant design",Algorithms; Computer hardware; Computer operating systems; Computer simulation; Data communication systems; Hierarchical systems; Magnetic disk storage; Performance; Reliability; Security of data; Systems analysis; Data blocks; Disk array; Hierarchical storage system; Information retrieval systems
Hypervisor-Based Fault-Tolerance,1996,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030086704&doi=10.1145%2f225535.225538&partnerID=40&md5=c14525b698140187daa9e1c682c4addd,"Protocols to implement a fault-tolerant computing system are described. These protocols augment the hypervisor of a virtual-machine manager and coordinate a primary virtual machine with its backup. No modifications to the hardware, operating system, or application programs are required. A prototype system was constructed for HP's PA-RISC instruction-set architecture. Even though the prototype was not carefully tuned, it ran programs about a factor of 2 slower than a bare machine would.",Algorithms; C.2.4 [Computer-Communication Networks]: Distributed Systems - Network operating systems; D.4.5 [Operating Systems]: Reliability - Checkpoint/restart; fault tolerance; Fault-tolerant computing system; Primary/backup approach; Reliability,Algorithms; Computer operating systems; Distributed computer systems; Network protocols; Reduced instruction set computing; Reliability; Hypervisor based fault tolerance; Primary backup approach; Virtual machine manager; Fault tolerant computer systems
1987 ACM/SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES.,1988,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023961216&partnerID=40&md5=46a22e9ab97ea68a85c99b68989864be,This issue contains 6 conference papers. The topics covered are: stored-voice management in the Etherphone system; 801 storage; scale and performance of a distributed file system; recovery performance in quicksilver; fine-grained mobility in the Emerald system; caching in the Sprite network file system.,,"COMPUTER ARCHITECTURE; COMPUTER NETWORKS; COMPUTER SYSTEMS, DIGITAL - Distributed; 801 STORAGE; EIREV; EMERALD SYSTEM; ETHERPHONE SYSTEM; QUICKSILVER; SPRITE NETWORK FILE SYSTEM; COMPUTER OPERATING SYSTEMS"
SCALE AND PERFORMANCE IN A DISTRIBUTED FILE SYSTEM.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023290996&partnerID=40&md5=fbb96b573c1d36a2bcef873041e54c43,"The Andrew File System is a location-transparent distributed file system that will eventually span more than 5000 workstations at Carnegie Mellon University. Large scale affects performance and complicates system operation. In this paper we present observations of a prototype implementation, motivate changes in the areas of cache validation, server process structure, name translation, and low-level storage representation, and quantitatively demonstrate Andrew's ability to scale gracefully. We establish the importance of whole-file transfer and caching in Andrew by comparing its performance with that of Sun Microsystem's NFS file system. We also show how the aggregation of files into volumes improves the operability of the system.",,"COMPUTER SYSTEMS, DIGITAL - Distributed; ANDREW FILE SYSTEM; DISTRIBUTED FILE SYSTEM; FILE TRANSFER; COMPUTER OPERATING SYSTEMS"
RECOVERY MANAGEMENT IN QUICKSILVER.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023291159&partnerID=40&md5=71049d02372e20cee544b2308032eaf3,"This paper describes QuickSilver, which uses atomic transactions as a unified failure recovery mechanism for a client-server structured distributed system. Transactions allow failure atomicity for related activities at a single server or at a number of independent servers. Rather than bundling transaction management into a dedicated language or recoverable object manager, QuickSilver exposes the basic commit protocol and log recovery primitives, allowing clients and servers to tailor their recovery techniques to their specific needs. Servers can implement their own log recovery protocols rather than being required to use a system-defined protocol. These decisions allow servers to make their own choices to balance simplicity, efficiency, and recoverability.",,"COMPUTER SYSTEMS, DIGITAL - Distributed; ATOMIC TRANSACTIONS; FAILURE ATOMICITY; QUICKSILVER; RECOVERY MANAGEMENT; COMPUTER OPERATING SYSTEMS"
MANAGING STORED VOICE IN THE ETHERPHONE SYSTEM.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023291167&partnerID=40&md5=315671ba59167e59f2f374ab22bd2ee1,"The voice manager in the Etherphone system provides facilities for recording, editing, and playing stored voice in a distributed personal-computing environment. To facilitate sharing, the voice manager stores voice on a special voice file server that is accessible via the local internet. Operations for editing a passage of recorded voice simply build persistent data structures to represent the edited voice. These data structures, implementing an abstraction called voice ropes, are stored in a server database and consist of lists of intervals within voice files. Clients refer to voice ropes solely by reference. Interests, additional persistent data structures maintained by the server, provide a sort of directory service for managing the voice ropes that have been created as well as a reliable reference-counting mechanism, permitting the garbage collection of voice ropes that are no longer needed.",,"COMPUTER NETWORKS; COMPUTER OPERATING SYSTEMS; COMPUTER SYSTEMS, DIGITAL - Distributed; DATA PROCESSING - Data Structures; ELECTRONIC MAIL; ETHERPHONE SYSTEM; VOICE EDITING; VOICE FILE SERVER; VOICE MANAGER; DIGITAL COMMUNICATION SYSTEMS"
FINE-GRAINED MOBILITY IN THE EMERALD SYSTEM.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023291168&partnerID=40&md5=58167599f480f44b96bf4797cca9b619,"Emerald is an object-based language and system designed for the construction of distributed programs. An explicit goal of Emerald is support for object mobility; objects in Emerald can freely move within the system to take advantage of distribution and dynamically changing environments. We say that Emerald has fine-grained mobility because Emerald objects can be small data objects as well as process objects. Fine-grained mobility allows us to apply mobility in new ways but presents implementation problems as well. This paper discusses the benefits of fine-grained mobility, the Emerald language and run-time mechanisms that support mobility, and techniques for implementing mobility that do not degrade the performance of local operations. Performance measurements of the current implementation are included.",,"COMPUTER PROGRAMMING LANGUAGES; COMPUTER SYSTEMS, DIGITAL - Distributed; DISTRIBUTED LANGUAGES; EMERALD; OBJECT-ORIENTED LANGUAGES; PROCESS MOBILITY; COMPUTER OPERATING SYSTEMS"
CACHING IN THE SPRITE NETWORK FILE SYSTEM.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023290610&partnerID=40&md5=f700c6ca1b388ddec6c6f68447238560,"The Sprite network operating system uses large main-memory disk block caches to achieve high performance in its file system. It provides non-write-through file caching on both client and server machines. A simple cache consistency mechanism permits files to be shared by multiple clients without danger of stale data. In order to allow the file cache to occupy as much memory as possible, the file system of each machine negotiates with the virtual memory system over physical memory usage and changes the size of the file cache dynamically. Benchmark programs indicate that client caches allow diskless Sprite workstations to perform within 0-12 percent of workstations with disks. In addition, client caching reduces server loading by 50 percent and network traffic by 90 percent.",,"COMPUTER SYSTEMS, DIGITAL - Distributed; CACHE CONSISTENCY; DISTRIBUTED FILE CACHING; DISTRIBUTED FILE SYSTEMS; SPRITE NETWORK; COMPUTER OPERATING SYSTEMS"
801 STORAGE: ARCHITECTURE AND PROGRAMMING.,1987,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023290846&partnerID=40&md5=da4a3eb90395431bf3943faa997178e8,"Based on novel architecture, the 801 minicomputer project has developed a low-level storage manager that can significantly simplify storage programming in subsystems and applications. The storage manager embodies three ideas: (1) large virtual storage, to contain all temporary data and permanent files for the active programs; (2) the innovation of database storage, which has implicit properties of access serializability and atomic update, similar to those of database transaction systems; and (3) access to all storage, including files, by the usual operations and types of a high-level programming language. The IBM RT PC implements the hardware architecture necessary for these storage facilities in its storage controller (MMU). The storage manager and language elements required, as well as subsystems and applications that use them, have been implemented and studied in a prototype operating system called CPR, that runs on the RT PC. Low cost and good performance are achieved in both hardware and software. The design is intended to be extensible across a wide performance/cost spectrum.",,"COMPUTER ARCHITECTURE; COMPUTERS, MINICOMPUTER; 801 MINICOMPUTER PROJECT; CPR OPERATING SYSTEM; IBM RT PC; LOW-LEVEL STORAGE MANAGER; COMPUTER OPERATING SYSTEMS"
Efficient Instruction Scheduling Using Real-time Load Delay Tracking,2022,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146365610&doi=10.1145%2f3548681&partnerID=40&md5=2a8dfe5c1a287faca81dce8a2b3e99eb,"Issue time prediction processors use dataflow dependencies and predefined instruction latencies to predict issue times of repeated instructions. In this work, we make two key observations: (1) memory accesses often take additional time to arrive than the static, predefined access latency that is used to describe these systems. This is due to contention in the memory hierarchy and variability in DRAM access times, and (2) we find that these memory access delays often repeat across iterations of the same code. We propose a new processor microarchitecture that replaces a complex reservation-station-based scheduler with an efficient, scalable alternative. Our scheduling technique tracks real-time delays of loads to accurately predict instruction issue times and uses a reordering mechanism to prioritize instructions based on that prediction. To accomplish this in an energy-efficient manner we introduce (1) an instruction delay learning mechanism that monitors repeated load instructions and learns their latest delay, (2) an issue time predictor that uses learned delays and dataflow dependencies to predict instruction issue times, and (3) priority queues that reorder instructions based on their issue time prediction. Our processor achieves 86.2% of the performance of a traditional out-of-order processor, higher than previous efficient scheduler proposals, while consuming 30% less power.  © 2022 Copyright held by the owner/author(s).",instruction reordering; Instruction scheduling; issue time prediction; load instruction delay scheduling; microarchitecture; processor architecture,Energy efficiency; Forecasting; Memory architecture; Dataflow; Delay scheduling; Instruction reordering; Instruction scheduling; Issue time prediction; Load instruction delay scheduling; Micro architectures; Processor architectures; Real- time; Time predictions; Dynamic random access storage
Using Pattern of On-Off Routers and Links and Router Delays to Protect Network-on-Chip Intellectual Property,2022,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146365575&doi=10.1145%2f3548680&partnerID=40&md5=541a08337fee2419c99802f8110dfd45,"Intellectual Property (IP) reuse is a well known practice in chip design processes. Nowadays, network-on-chips (NoCs) are increasingly used as IP and sold by various vendors to be integrated in a multiprocessor system-on-chip (MPSoC). However, IP reuse exposes the design to IP theft, and an attacker can launch IP stealing attacks against NoC IPs. With the growing adoption of MPSoC, such attacks can result in huge financial losses. In this article, we propose four NoC IP protection techniques using fingerprint embedding: ON-OFF router-based fingerprinting (ORF), ON-OFF link-based fingerprinting (OLF), Router delay-based fingerprinting (RTDF), and Row delay-based fingerprinting (RWDF). ORF and OLF techniques use patterns of ON-OFF routers and links, respectively, while RTDF and RWDF techniques use router delays to embed fingerprints. We show that all of our proposed techniques require much less hardware overhead compared to an existing NoC IP security solution (square spiral routing) and also provide better security from removal and masking attacks. In particular, our proposed techniques require between 40.75% and 48.43% less router area compared to the existing solution. We also show that our solutions do not affect the normal packet latency and hence do not degrade the NoC performance.  © 2022 Association for Computing Machinery.",fingerprinting technique; Intellectual Property protection; NoC IP protection,Integrated circuit design; Intellectual property; Internet protocols; Losses; Multiprocessing systems; Network architecture; Routers; Servers; Fingerprinting techniques; In-chip; Intellectual property protection; Intellectual property reuse; Link-based; Multiprocessor system on chips; Multiprocessor systems-on-chips; Networks on chips; NoC intellectual property protection; Network-on-chip
An OpenMP Runtime for Transparent Work Sharing across Cache-Incoherent Heterogeneous Nodes,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133859963&doi=10.1145%2f3505224&partnerID=40&md5=bb4960dea897974b235eb90ff3720f8b,"In this work, we present libHetMP, an OpenMP runtime for automatically and transparently distributing parallel computation across heterogeneous nodes. libHetMP targets platforms comprising CPUs with different instruction set architectures (ISA) coupled by a high-speed memory interconnect, where cross-ISA binary incompatibility and non-coherent caches require application data be marshaled to be shared across CPUs. Because of this, work distribution decisions must take into account both relative compute performance of asymmetric CPUs and communication overheads. libHetMP drives workload distribution decisions without programmer intervention by measuring performance characteristics during cross-node execution. A novel HetProbe loop iteration scheduler decides if cross-node execution is beneficial and either distributes work according to the relative performance of CPUs when it is or places all work on the set of homogeneous CPUs providing the best performance when it is not. We evaluate libHetMP using compute kernels from several OpenMP benchmark suites and show a geometric mean 41% speedup in execution time across asymmetric CPUs. Because some workloads may showcase irregular behavior among iterations, we extend libHetMP with a second scheduler called HetProbe-I. The evaluation of HetProbe-I shows it can further improve speedup for irregular computation, in some cases up to a 24%, by triggering periodic distribution decisions. © 2022 Association for Computing Machinery.",Heterogeneous-ISA CPUs; OpenMP; work sharing,Application programming interfaces (API); Computer architecture; Digital storage; Scheduling; Application data; Heterogeneous nodes; Heterogeneous-instruction set architecture CPU; High-speed memory; Instruction set architecture; Openmp; Parallel Computation; Performance; Runtimes; Work-sharing; Program processors
Unified Holistic Memory Management Supporting Multiple Big Data Processing Frameworks over Hybrid Memories,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132442277&doi=10.1145%2f3511211&partnerID=40&md5=cce6b67d7287eb867a4f985335b28637,"To process real-world datasets, modern data-parallel systems often require extremely large amounts of memory, which are both costly and energy inefficient. Emerging non-volatile memory (NVM) technologies offer high capacity compared to DRAM and low energy compared to SSDs. Hence, NVMs have the potential to fundamentally change the dichotomy between DRAM and durable storage in Big Data processing. However, most Big Data applications are written in managed languages and executed on top of a managed runtime that already performs various dimensions of memory management. Supporting hybrid physical memories adds a new dimension, creating unique challenges in data replacement. This article proposes Panthera, a semantics-aware, fully automated memory management technique for Big Data processing over hybrid memories. Panthera analyzes user programs on a Big Data system to infer their coarse-grained access patterns, which are then passed to the Panthera runtime for efficient data placement and migration. For Big Data applications, the coarse-grained data division information is accurate enough to guide the GC for data layout, which hardly incurs overhead in data monitoring and moving. We implemented Panthera in OpenJDK and Apache Spark. Based on Big Data applications' memory access pattern, we also implemented a new profiling-guided optimization strategy, which is transparent to applications. With this optimization, our extensive evaluation demonstrates that Panthera reduces energy by 32-53% at less than 1% time overhead on average. To show Panthera's applicability, we extend it to QuickCached, a pure Java implementation of Memcached. Our evaluation results show that Panthera reduces energy by 28.7% at 5.2% time overhead on average. © 2022 Association for Computing Machinery.",Big Data systems; garbage collection; Hybrid memories; memory management,Cost reduction; Data reduction; Information management; Large dataset; Semantics; Big data applications; Big data system; Coarse-grained; Data systems; Energy; Garbage collection; Hybrid memory; Memory-management; Panthera; Runtimes; Dynamic random access storage
Shooting Down the Server Front-End Bottleneck,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122638224&doi=10.1145%2f3484492&partnerID=40&md5=59dd2a68f931f7944d4de4c4f6d087ff,"The front-end bottleneck is a well-established problem in server workloads owing to their deep software stacks and large instruction footprints. Despite years of research into effective L1-I and BTB prefetching, state-of-the-art techniques force a trade-off between metadata storage cost and performance. Temporal Stream prefetchers deliver high performance but require a prohibitive amount of metadata to accommodate the temporal history. Meanwhile, BTB-directed prefetchers incur low cost by using the existing in-core branch prediction structures but fall short on performance due to BTB's inability to capture the massive control flow working set of server applications. This work overcomes the fundamental limitation of BTB-directed prefetchers, which is capturing a large control flow working set within an affordable BTB storage budget. We re-envision the BTB organization to maximize its control flow coverage by observing that an application's instruction footprint can be mapped as a combination of its unconditional branch working set and, for each unconditional branch, a spatial encoding of the cache blocks around the branch target. Effectively capturing a map of the application's instruction footprint in the BTB enables highly effective BTB-directed prefetching that outperforms the state-of-the-art prefetchers by up to 10% for equivalent storage budget.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",branch target buffer (BTB); instruction cache; microarchitecture; prefeteching; Server,Cache memory; Economic and social effects; Metadata; Branch target buffer; Branch target buffers; Control-flow; Front end; Instruction caches; Micro architectures; Performance; Prefetching; Prefeteching; Working set; Budget control
The Role of Compute in Autonomous Micro Aerial Vehicles: Optimizing for Mission Time and Energy Efficiency,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133867475&doi=10.1145%2f3511210&partnerID=40&md5=154e6cd16734434c5ab7c9788ce5fa16,"Autonomous and mobile cyber-physical machines are becoming an inevitable part of our future. In particular, Micro Aerial Vehicles (MAVs) have seen a resurgence in activity. With multiple use cases, such as surveillance, search and rescue, package delivery, and more, these unmanned aerial systems are on the cusp of demonstrating their full potential. Despite such promises, these systems face many challenges, one of the most prominent of which is their low endurance caused by their limited onboard energy. Since the success of a mission depends on whether the drone can finish it within such duration and before it runs out of battery, improving both the time and energy associated with the mission are of high importance. Such improvements have traditionally been arrived at through the use of better algorithms. But our premise is that more powerful and efficient onboard compute can also address the problem. In this article, we investigate how the compute subsystem, in a cyber-physical mobile machine such as a Micro Aerial Vehicle, can impact mission time (time to complete a mission) and energy. Specifically, we pose the question as what is the role of computing for cyber-physical mobile robots? We show that compute and motion are tightly intertwined, and as such a close examination of cyber and physical processes and their impact on one another is necessary. We show different ""impact paths""through which compute impacts mission metrics and examine them using a combination of analytical models, simulation, and micro and end-to-end benchmarking. To enable similar studies, we open sourced MAVBench, our tool-set, which consists of (1) a closed-loop real-time feedback simulator and (2) an end-to-end benchmark suite composed of state-of-the-art kernels. By combining MAVBench, analytical modeling, and an understanding of various compute impacts, we show up to 2X and 1.8X improvements for mission time and mission energy for two optimization case studies, respectively. Our investigations, as well as our optimizations, show that cyber-physical co-design, a methodology with which both the cyber and physical processes/quantities of the robot are developed with consideration of one another, similar to hardware-software co-design, is necessary for arriving at the design of the optimal robot. © 2022 Association for Computing Machinery.",autonomous machines; drones; Simulators; system design,Analytical models; Antennas; Cyber Physical System; Energy efficiency; Machine design; Micro air vehicle (MAV); Autonomous machines; Cyber physicals; End to end; Energy; Micro aerial vehicle; Multiple use-cases; Optimisations; Package delivery; Physical process; Search and rescue; Drones
Apache Nemo: A Framework for Optimizing Distributed Data Processing,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122627766&doi=10.1145%2f3468144&partnerID=40&md5=bfbc18a002d2be01313be7171ddfabca,"Optimizing scheduling and communication of distributed data processing for resource and data characteristics is crucial for achieving high performance. Existing approaches to such optimizations largely fall into two categories. First, distributed runtimes provide low-level policy interfaces to apply the optimizations, but do not ensure the maintenance of correct application semantics and thus often require significant effort to use. Second, policy interfaces that extend a high-level application programming model ensure correctness, but do not provide sufficient fine control.We describe Apache Nemo, an optimization framework for distributed dataflow processing that provides fine control for high performance and also ensures correctness for ease of use. We combine several techniques to achieve this, including an intermediate representation of dataflow, compiler optimization passes, and runtime extensions. Our evaluation results show that Nemo enables composable and reusable optimizations that bring performance improvements on par with existing specialized runtimes tailored for a specific deployment scenario. Apache Nemo is open-sourced at https://nemo.apache.org as an Apache incubator project.  © 2021 Association for Computing Machinery.",Data processing; distributed systems,Application programming interfaces (API); Computer software reusability; Data handling; Application Semantics; Data characteristics; Distributed data processing; Distributed runtime; High level applications; Optimisations; Performance; Policy interfaces; Resource characteristic; Runtimes; Semantics
"ROME: All Overlays Lead to Aggregation, but Some Are Faster than Others",2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133874443&doi=10.1145%2f3516430&partnerID=40&md5=77329463fdbd210dff2ec517aba3d839,"Aggregation is common in data analytics and crucial to distilling information from large datasets, but current data analytics frameworks do not fully exploit the potential for optimization in such phases. The lack of optimization is particularly notable in current ""online""approaches that store data in main memory across nodes, shifting the bottleneck away from disk I/O toward network and compute resources, thus increasing the relative performance impact of distributed aggregation phases. We present ROME, an aggregation system for use within data analytics frameworks or in isolation. ROME uses a set of novel heuristics based primarily on basic knowledge of aggregation functions combined with deployment constraints to efficiently aggregate results from computations performed on individual data subsets across nodes (e.g., merging sorted lists resulting from top-k). The user can either provide minimal information that allows our heuristics to be applied directly, or ROME can autodetect the relevant information at little cost. We integrated ROME as a subsystem into the Spark and Flink data analytics frameworks. We use real-world data to experimentally demonstrate speedups up to 3× over single-level aggregation overlays, up to 21% over other multi-level overlays, and 50% for iterative algorithms like gradient descent at 100 iterations. © 2022 Association for Computing Machinery.",Big data aggregation overlay; distributed algorithms,Gradient methods; Large dataset; Optimization; 'current; Big data aggregation overlay; Current data; Data aggregation; Data analytics; Disk I/O; Large datasets; Main-memory; Network resource; Optimisations; Data Analytics
Boosting Inter-process Communication with Architectural Support,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133886306&doi=10.1145%2f3532861&partnerID=40&md5=b9cdf07507032b56fef44ef49ff13c58,"IPC (inter-process communication) is a critical mechanism for modern OSes, including not only microkernels such as seL4, QNX, and Fuchsia where system functionalities are deployed in user-level processes, but also monolithic kernels like Android where apps frequently communicate with plenty of user-level services. However, existing IPC mechanisms still suffer from long latency. Previous software optimizations of IPC usually cannot bypass the kernel that is responsible for domain switching and message copying/remapping across different address spaces; hardware solutions such as tagged memory or capability replace page tables for isolation, but usually require non-trivial modification to existing software stack to adapt to the new hardware primitives. In this article, we propose a hardware-assisted OS primitive, XPC (Cross Process Call), for efficient and secure synchronous IPC. XPC enables direct switch between IPC caller and callee without trapping into the kernel and supports secure message passing across multiple processes without copying. We have implemented a prototype of XPC based on the ARM AArch64 with Gem5 simulator and RISC-V architecture with FPGA boards. The evaluation shows that XPC can reduce IPC call latency from 664 to 21 cycles, 14×-123× improvement on Android Binder (ARM), and improve the performance of real-world applications on microkernels by 1.6× on Sqlite3. © 2022 Association for Computing Machinery.",hardware-software co-design; inter-process communication; microkernel; Operating system,Android (operating system); ARM processors; Hardware-software codesign; Architectural support; Communication mechanisms; Hardware/software codesign; Interprocess communication; Level process; Micro kernel; Monolithics; Operating system; System functionality; User levels; Message passing
Scaling Membership of Byzantine Consensus,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122622924&doi=10.1145%2f3473138&partnerID=40&md5=be3f97897d6f06e2cba9e47c127ea495,"Scaling Byzantine Fault Tolerant (BFT) systems in terms of membership is important for secure applications with large participation such as blockchains. While traditional protocols have low latency, they cannot handle many processors. Conversely, blockchains often have hundreds to thousands of processors to increase robustness, but they typically have high latency or energy costs.We describe various sources of unscalability in BFT consensus protocols. To improve performance, many BFT protocols optimize the ""normal case,""where there are no failures. This can be done in a modular fashion by wrapping existing BFT protocols with a building block that we call alliance. In normal case executions, alliance can scalably determine if the initial conditions of a BFT consensus protocol predetermine the outcome, obviating running the consensus protocol.We give examples of existing protocols that solve alliance. We show that a solution based on hypercubes and MACs has desirable scalability and performance in normal case executions, with only a modest overhead otherwise. We provide important optimizations. Finally, we evaluate our solution using the ns3 simulator and show that it scales up to thousands of processors and compare with prior work in various network topologies.  © 2021 Association for Computing Machinery.",asynchronous; blockchain; byzantine; consensus; reliability; Scalability,Blockchain; Asynchronoi; Block-chain; Byzantine; Byzantine consensus; Byzantine fault; Consensus; Consensus protocols; Fault tolerant protocols; Fault-tolerant; Scalings; Scalability
H-Container: Enabling Heterogeneous-ISA Container Migration in Edge Computing,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133870426&doi=10.1145%2f3524452&partnerID=40&md5=58753478f40b665411addbdedb192752,"Edge computing is a recent computing paradigm that brings cloud services closer to the client. Among other features, edge computing offers extremely low client/server latencies. To consistently provide such low latencies, services should run on edge nodes that are physically as close as possible to their clients. Thus, when the physical location of a client changes, a service should migrate between edge nodes to maintain proximity. Differently from cloud nodes, edge nodes integrate CPUs of different Instruction Set Architectures (ISAs), hence a program natively compiled for a given ISA cannot migrate to a server equipped with a CPU of a different ISA. This hinders migration to the closest node. We introduce H-Container, a system that migrates natively compiled containerized applications across compute nodes featuring CPUs of different ISAs. H-Container advances over existing heterogeneous-ISA migration systems by being (a) highly compatible - no user's source-code nor compiler toolchain modifications are needed; (b) easily deployable - fully implemented in user space, thus without any OS or hypervisor dependency, and (c) largely Linux-compliant - it can migrate most Linux software, including server applications and dynamically linked binaries. H-Container targets Linux and its already-compiled executables, adopts LLVM, extends CRIU, and integrates with Docker. Experiments demonstrate that H-Container adds no overheads during program execution, while 10-100 ms are added during migration. Furthermore, we show the benefits of H-Container in real-world scenarios, demonstrating, for example, up to 94% increase in Redis throughput when client/server proximity is maintained through heterogeneous container migration. © 2022 Association for Computing Machinery.",containers; Edge; heterogeneous ISA; migration,Application programs; C (programming language); Computer architecture; Edge computing; Linux; Program compilers; Client /server; Cloud services; Computing paradigm; Edge; Edge computing; Edge nodes; Heterogeneous instruction set architecture; Instruction set architecture; Low latency; Migration; Containers
Systemizing Interprocedural Static Analysis of Large-scale Systems Code with Graspan,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111707085&doi=10.1145%2f3466820&partnerID=40&md5=017a09d054d3b4069a7814cae120e388,"There is more than a decade-long history of using static analysis to find bugs in systems such as Linux. Most of the existing static analyses developed for these systems are simple checkers that find bugs based on pattern matching. Despite the presence of many sophisticated interprocedural analyses, few of them have been employed to improve checkers for systems code due to their complex implementations and poor scalability. In this article, we revisit the scalability problem of interprocedural static analysis from a ""Big Data""perspective. That is, we turn sophisticated code analysis into Big Data analytics and leverage novel data processing techniques to solve this traditional programming language problem. We propose Graspan, a disk-based parallel graph system that uses an edge-pair centric computation model to compute dynamic transitive closures on very large program graphs. We develop two backends for Graspan, namely, Graspan-C running on CPUs and Graspan-G on GPUs, and present their designs in the article. Graspan-C can analyze large-scale systems code on any commodity PC, while, if GPUs are available, Graspan-G can be readily used to achieve orders of magnitude speedup by harnessing a GPU's massive parallelism. We have implemented fully context-sensitive pointer/alias and dataflow analyses on Graspan. An evaluation of these analyses on large codebases written in multiple languages such as Linux and Apache Hadoop demonstrates that their Graspan implementations are language-independent, scale to millions of lines of code, and are much simpler than their original implementations. Moreover, we show that these analyses can be used to uncover many real-world bugs in large-scale systems code.  © 2021 ACM.",Disk-based systems; Graph processing; Static analysis,Advanced Analytics; Big data; Data Analytics; Data flow analysis; Data handling; Large scale systems; Linux; Pattern matching; Personal computers; Problem oriented languages; Program debugging; Program processors; Scalability; Data processing techniques; Inter-procedural analysis; Language independents; Massive parallelism; Multiple languages; Orders of magnitude; Scalability problems; Transitive closure; Static analysis
Modular and Distributed Management of Many-Core SoCs,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111630684&doi=10.1145%2f3458511&partnerID=40&md5=fb3cc301c5fca7eb13615c313b6643f8,"Many-Core Systems-on-Chip increasingly require Dynamic Multi-objective Management (DMOM) of resources. DMOM uses different management components for objectives and resources to implement comprehensive and self-adaptive system resource management. DMOMs are challenging because they require a scalable and well-organized framework to make each component modular, allowing it to be instantiated or redesigned with a limited impact on other components. This work evaluates two state-of-the-art distributed management paradigms and, motivated by their drawbacks, proposes a new one called Management Application (MA), along with a DMOM framework based on MA. MA is a distributed application, specific for management, where each task implements a management role. This paradigm favors scalability and modularity because the management design assumes different and parallel modules, decoupled from the OS. An experiment with a task mapping case study shows that MA reduces the overhead of management resources (-61.5%), latency (-66%), and communication volume (-96%) compared to state-of-the-art per-application management. Compared to cluster-based management (CBM) implemented directly as part of the OS, MA is similar in resources and communication volume, increasing only the mapping latency (+16%). Results targeting a complete DMOM control loop addressing up to three different objectives show the scalability regarding system size and adaptation frequency compared to CBM, presenting an overall management latency reduction of 17.2% and an overall monitoring messages' latency reduction of 90.2%.  © 2021 ACM.",Distributed resource management; Many-core; System-on-Chip (SoC),Control systems; Mapping; Scalability; System-on-chip; Application management; Distributed applications; Distributed management; Latency reduction; Management applications; Management components; Parallel modules; Self-adaptive system; Adaptive systems
Metron: High-performance NFV Service Chaining even in the Presence of Blackboxes,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111657554&doi=10.1145%2f3465628&partnerID=40&md5=7a8191c62df83bab41b469b6c01a5d46,"Deployment of 100Gigabit Ethernet (GbE) links challenges the packet processing limits of commodity hardware used for Network Functions Virtualization (NFV). Moreover, realizing chained network functions (i.e., service chains) necessitates the use of multiple CPU cores, or even multiple servers, to process packets from such high speed links. Our system Metron jointly exploits the underlying network and commodity servers' resources: (i) to offload part of the packet processing logic to the network, (ii) by using smart tagging to setup and exploit the affinity of traffic classes, and (iii) by using tag-based hardware dispatching to carry out the remaining packet processing at the speed of the servers' cores, with zero inter-core communication. Moreover, Metron transparently integrates, manages, and load balances proprietary ""blackboxes""together with Metron service chains. Metron realizes stateful network functions at the speed of 100GbE network cards on a single server, while elastically and rapidly adapting to changing workload volumes. Our experiments demonstrate that Metron service chains can coexist with heterogeneous blackboxes, while still leveraging Metron's accurate dispatching and load balancing. In summary, Metron has (i) 2.75-8× better efficiency, up to (ii) 4.7× lower latency, and (iii) 7.8× higher throughput than OpenBox, a state-of-the-art NFV system.  © 2021 Owner/Author.",100 GbE; Accurate dispatching; Blackboxes; Elasticity; Hardware offloading; Load balancing; NFV; Service chains; Tagging,Carry logic; Computer hardware; Electric load dispatching; Transfer functions; Changing workload; Commodity hardware; High-speed links; Inter-core communications; Multiple servers; Network functions; Packet processing; Underlying networks; Network function virtualization
SmartIO: Zero-overhead Device Sharing through PCIe Networking,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111673870&doi=10.1145%2f3462545&partnerID=40&md5=376c5b51ea772bc199014fff1692a7dd,"The large variety of compute-heavy and data-driven applications accelerate the need for a distributed I/O solution that enables cost-effective scaling of resources between networked hosts. For example, in a cluster system, different machines may have various devices available at different times, but moving workloads to remote units over the network is often costly and introduces large overheads compared to accessing local resources. To facilitate I/O disaggregation and device sharing among hosts connected using Peripheral Component Interconnect Express (PCIe) non-transparent bridges, we present SmartIO. NVMes, GPUs, network adapters, or any other standard PCIe device may be borrowed and accessed directly, as if they were local to the remote machines. We provide capabilities beyond existing disaggregation solutions by combining traditional I/O with distributed shared-memory functionality, allowing devices to become part of the same global address space as cluster applications. Software is entirely removed from the data path, and simultaneous sharing of a device among application processes running on remote hosts is enabled. Our experimental results show that I/O devices can be shared with remote hosts, achieving native PCIe performance. Thus, compared to existing device distribution mechanisms, SmartIO provides more efficient, low-cost resource sharing, increasing the overall system performance.  © 2021 Owner/Author.",Cluster architecture; Composable infrastructure; Device Lending; Distributed I/O; GPU; I/O disaggregation; NTB; NVMe; PCIe; Resource sharing,Cost effectiveness; Memory architecture; Program processors; Application process; Data-driven applications; Distributed shared memory; Distribution mechanism; Global address spaces; Network adapters; Peripheral component interconnect express; Resource sharing; Application programs
A Simulation Software for the Evaluation of Vulnerabilities in Reputation Management Systems,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109081422&doi=10.1145%2f3458510&partnerID=40&md5=c227cdf1ed861ff0803b5df79f4dd03a,"Multi-agent distributed systems are characterized by autonomous entities that interact with each other to provide, and/or request, different kinds of services. In several contexts, especially when a reward is offered according to the quality of service, individual agents (or coordinated groups) may act in a selfish way. To prevent such behaviours, distributed Reputation Management Systems (RMSs) provide every agent with the capability of computing the reputation of the others according to direct past interactions, as well as indirect opinions reported by their neighbourhood. This last point introduces a weakness on gossiped information that makes RMSs vulnerable to malicious agents' intent on disseminating false reputation values. Given the variety of application scenarios in which RMSs can be adopted, as well as the multitude of behaviours that agents can implement, designers need RMS evaluation tools that allow them to predict the robustness of the system to security attacks, before its actual deployment. To this aim, we present a simulation software for the vulnerability evaluation of RMSs and illustrate three case studies in which this tool was effectively used to model and assess state-of-the-art RMSs.  © 2021 ACM.",Agent-based simulation; distributed reputation management systems; multi-agent systems,Distributed computer systems; Distributed database systems; Multi agent systems; Network security; Petroleum reservoir evaluation; Quality of service; Application scenario; Autonomous entities; Distributed systems; Individual agent; Reputation management; Simulation software; State of the art; Vulnerability evaluations; Autonomous agents
AI Tax: The Hidden Cost of AI Data Center Applications,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109101254&doi=10.1145%2f3440689&partnerID=40&md5=65658087bc2e52498d19c8d6a3fccd44,"Artificial intelligence and machine learning are experiencing widespread adoption in industry and academia. This has been driven by rapid advances in the applications and accuracy of AI through increasingly complex algorithms and models; this, in turn, has spurred research into specialized hardware AI accelerators. Given the rapid pace of advances, it is easy to forget that they are often developed and evaluated in a vacuum without considering the full application environment. This article emphasizes the need for a holistic, end-to-end analysis of artificial intelligence (AI) workloads and reveals the ""AI tax.""We deploy and characterize Face Recognition in an edge data center. The application is an AI-centric edge video analytics application built using popular open source infrastructure and machine learning (ML) tools. Despite using state-of-the-art AI and ML algorithms, the application relies heavily on pre-and post-processing code. As AI-centric applications benefit from the acceleration promised by accelerators, we find they impose stresses on the hardware and software infrastructure: storage and network bandwidth become major bottlenecks with increasing AI acceleration. By specializing for AI applications, we show that a purpose-built edge data center can be designed for the stresses of accelerated AI at 15% lower TCO than one derived from homogeneous servers and infrastructure.  © 2021 ACM.",AI tax; end-to-end AI application,Digital storage; Face recognition; Machine learning; Open source software; Application environment; Complex algorithms; End-to-end analysis; Hardware and software; Network bandwidth; Specialized hardware; State of the art; Video analytics; Application programs
Distributed Graph Processing System and Processing-in-memory Architecture with Precise Loop-carried Dependency Guarantee,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109105071&doi=10.1145%2f3453681&partnerID=40&md5=14462eefda365cde50c2939ebdc7d467,"To hide the complexity of the underlying system, graph processing frameworks ask programmers to specify graph computations in user-defined functions (UDFs) of graph-oriented programming model. Due to the nature of distributed execution, current frameworks cannot precisely enforce the semantics of UDFs, leading to unnecessary computation and communication. It exemplifies a gap between programming model and runtime execution. This article proposes novel graph processing frameworks for distributed system and Processing-in-memory (PIM) architecture that precisely enforces loop-carried dependency; i.e., when a condition is satisfied by a neighbor, all following neighbors can be skipped. Our approach instruments the UDFs to express the loop-carried dependency, then the distributed execution framework enforces the precise semantics by performing dependency propagation dynamically. Enforcing loop-carried dependency requires the sequential processing of the neighbors of each vertex distributed in different nodes. We propose to circulant scheduling in the framework to allow different nodes to process disjoint sets of edges/vertices in parallel while satisfying the sequential requirement. The technique achieves an excellent trade-off between precise semantics and parallelism-the benefits of eliminating unnecessary computation and communication offset the reduced parallelism. We implement a new distributed graph processing framework SympleGraph, and two variants of runtime systems-GraphS and GraphSR-for PIM-based graph processing architecture, which significantly outperform the state-of-the-art.  © 2021 ACM.",big data; compilers; graph algorithms; Graph analytics,Distributed database systems; Economic and social effects; Semantics; Distributed systems; Execution framework; Graph oriented programming; Loop-carried dependencies; Processing in memory; Run-time execution; Sequential processing; User Defined Functions; Memory architecture
Highly Concurrent Latency-tolerant Register Files for GPUs,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109091133&doi=10.1145%2f3419973&partnerID=40&md5=eb5de8d840174d8030b2a64d691cad95,"Graphics Processing Units (GPUs) employ large register files to accommodate all active threads and accelerate context switching. Unfortunately, register files are a scalability bottleneck for future GPUs due to long access latency, high power consumption, and large silicon area provisioning. Prior work proposes hierarchical register file to reduce the register file power consumption by caching registers in a smaller register file cache. Unfortunately, this approach does not improve register access latency due to the low hit rate in the register file cache. In this article, we propose the Latency-Tolerant Register File (LTRF) architecture to achieve low latency in a two-level hierarchical structure while keeping power consumption low. We observe that compile-time interval analysis enables us to divide GPU program execution into intervals with an accurate estimate of a warp's aggregate register working-set within each interval. The key idea of LTRF is to prefetch the estimated register working-set from the main register file to the register file cache under software control, at the beginning of each interval, and overlap the prefetch latency with the execution of other warps. We observe that register bank conflicts while prefetching the registers could greatly reduce the effectiveness of LTRF. Therefore, we devise a compile-time register renumbering technique to reduce the likelihood of register bank conflicts. Our experimental results show that LTRF enables high-capacity yet long-latency main GPU register files, paving the way for various optimizations. As an example optimization, we implement the main register file with emerging high-density high-latency memory technologies, enabling 8× larger capacity and improving overall GPU performance by 34%.  © 2021 ACM.",bank conflicts; GPUs; high performance; latency tolerance; parallelism; register files; register renumbering,Computer graphics; Electric power utilization; Program processors; Access latency; Context switching; Hierarchical structures; High power consumption; Memory technology; Register access; Register files; Software control; Graphics processing unit
UNIQ: Uniform Noise Injection for Non-Uniform Qantization of Neural Networks,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109098163&doi=10.1145%2f3444943&partnerID=40&md5=601fe8e18cb41ec1d8ed418346e79a57,"We present a novel method for neural network quantization. Our method, named UNIQ, emulates a non-uniform k-quantile quantizer and adapts the model to perform well with quantized weights by injecting noise to the weights at training time. As a by-product of injecting noise to weights, we find that activations can also be quantized to as low as 8-bit with only a minor accuracy degradation. Our non-uniform quantization approach provides a novel alternative to the existing uniform quantization techniques for neural networks. We further propose a novel complexity metric of number of bit operations performed (BOPs), and we show that this metric has a linear relation with logic utilization and power. We suggest evaluating the trade-off of accuracy vs. complexity (BOPs). The proposed method, when evaluated on ResNet18/34/50 and MobileNet on ImageNet, outperforms the prior state of the art both in the low-complexity regime and the high accuracy regime. We demonstrate the practical applicability of this approach, by implementing our non-uniformly quantized CNN on FPGA.  © 2021 ACM.",Deep learning; efficient deep learning; neural networks; quantization,Complex networks; Economic and social effects; Bit-operations; High-accuracy; Linear relation; Noise injection; Non-uniform quantization; State of the art; Training time; Uniform quantization; Neural networks
KylinX: Simplified Virtualization Architecture for Specialized Virtual Appliances with Strong Isolation,2021,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105314948&doi=10.1145%2f3436512&partnerID=40&md5=77b11b984ef074646ef2217f16b799f8,"Unikernel specializes a minimalistic LibOS and a target application into a standalone single-purpose virtual machine (VM) running on a hypervisor, which is referred to as (virtual) appliance. Compared to traditional VMs, Unikernel appliances have smaller memory footprint and lower overhead while guaranteeing the same level of isolation. On the downside, Unikernel strips off the process abstraction from its monolithic appliance and thus sacrifices flexibility, efficiency, and applicability. In this article, we examine whether there is a balance embracing the best of both Unikernel appliances (strong isolation) and processes (high flexibility/efficiency). We present KylinX, a dynamic library operating system for simplified and efficient cloud virtualization by providing the pVM (process-like VM) abstraction. A pVM takes the hypervisor as an OS and the Unikernel appliance as a process allowing both page-level and library-level dynamic mapping. At the page level, KylinX supports pVM fork plus a set of API for inter-pVM communication (IpC, which is compatible with conventional UNIX IPC). At the library level, KylinX supports shared libraries to be linked to a Unikernel appliance at runtime. KylinX enforces mapping restrictions against potential threats. We implement a prototype of KylinX by modifying MiniOS and Xen tools. Extensive experimental results show that KylinX achieves similar performance both in micro benchmarks (fork, IpC, library update, etc.) and in applications (Redis, web server, and DNS server) compared to conventional processes, while retaining the strong isolation benefit of VMs/Unikernels.  © 2021 ACM.",process-like VM (pVM); Unikernel; virtual appliances; Virtualization architecture,Benchmarking; Mapping; Virtual machine; Virtualization; Dynamic mapping; High flexibility; Memory footprint; Micro-benchmark; Potential threats; Shared libraries; Target application; Virtual appliance; Digital libraries
SILK+ Preventing Latency Spikes in Log-Structured Merge Key-Value Stores Running Heterogeneous Workloads,2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086759897&doi=10.1145%2f3380905&partnerID=40&md5=55c0bd70a88cf412d44801f7dfb0446a,"Log-Structured Merge Key-Value stores (LSM KVs) are designed to offer good write performance, by capturing client writes in memory, and only later flushing them to storage. Writes are later compacted into a tree-like data structure on disk to improve read performance and to reduce storage space use. It has been widely documented that compactions severely hamper throughput. Various optimizations have successfully dealt with this problem. These techniques include, among others, rate-limiting flushes and compactions, selecting among compactions for maximum effect, and limiting compactions to the highest level by so-called fragmented LSMs. In this article, we focus on latencies rather than throughput. We first document the fact that LSM KVs exhibit high tail latencies. The techniques that have been proposed for optimizing throughput do not address this issue, and, in fact, in some cases, exacerbate it. The root cause of these high tail latencies is interference between client writes, flushes, and compactions. Another major cause for tail latency is the heterogeneous nature of the workloads in terms of operation mix and item sizes whereby a few more computationally heavy requests slow down the vast majority of smaller requests. We introduce the notion of an Input/Output (I/O) bandwidth scheduler for an LSM-based KV store to reduce tail latency caused by interference of flushing and compactions and by workload heterogeneity. We explore three techniques as part of this I/O scheduler: (1) opportunistically allocating more bandwidth to internal operations during periods of low load, (2) prioritizing flushes and compactions at the lower levels of the tree, and (3) separating client requests by size and by data access path. SILK+ is a new open-source LSM KV that incorporates this notion of an I/O scheduler. © 2020 ACM.",I/O scheduling; log-structured merge key-value stores; tail latency,Bandwidth; Digital storage; Forestry; Scheduling; Silk; Trees (mathematics); Client request; Heterogeneous workloads; Input/output bandwidths; Internal operations; Key-value stores; Log structured; Read performance; Storage spaces; Compaction
Erratum: Derecho: Fast State Machine Replication for Cloud Services (ACM Transactions on Computer Systems 36:2 (4) DOI: 10.1145/3302258),2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086774198&doi=10.1145%2f3395604&partnerID=40&md5=ae0fa51e235352516eed8d05504a932b,"In ACM Transactions on Computer Systems (TOCS) volume 36, issue 2, article no. 4 (Jha et al., ""Derecho: Fast State Machine Replication for Cloud Services""), there are three minor typos, which should be corrected as follows: 1 PAGE 4:32, BOTTOM On page 4:32, near the bottom, the formula ∂i (M(i, k)) = i ∗ |G| + k has two typos. The correct formula is ∂i (M(i, k)) = i + |G| ∗ k. 2 PAGE 4:33, BOX A.2.3 On page 4:33, the box labeled A.2.3 includes the following if statement: if (sent-num-completed-num < window-size) { return nullptr; } The test condition has a typo. The correct test condition is as follows: if (sent-num-completed-num > window-size) { return nullptr; } 3 APPENDIX A In appendix A, the pseudo-code will assign the initial message global number 1. In the earlier discussion the paper states that the initial message will have number 0. Either value results in correct behavior provided that the logic is self-consistent. © 2020 Association for Computing Machinery. All rights reserved.",,
Effective Detection of Sleep-in-atomic-context Bugs in the Linux Kernel,2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086766541&doi=10.1145%2f3381990&partnerID=40&md5=f4caa525cb9be5cbbef34a24f688b505,"Atomic context is an execution state of the Linux kernel in which kernel code monopolizes a CPU core. In this state, the Linux kernel may only perform operations that cannot sleep, as otherwise a system hang or crash may occur. We refer to this kind of concurrency bug as a sleep-in-atomic-context (SAC) bug. In practice, SAC bugs are hard to find, as they do not cause problems in all executions. In this article, we propose a practical static approach named DSAC to effectively detect SAC bugs in the Linux kernel. DSAC uses three key techniques: (1) a summary-based analysis to identify the code that may be executed in atomic context, (2) a connection-based alias analysis to identify the set of functions referenced by a function pointer, and (3) a path-check method to filter out repeated reports and false bugs. We evaluate DSAC on Linux 4.17 and find 1,159 SAC bugs. We manually check all the bugs and find that 1,068 bugs are real. We have randomly selected 300 of the real bugs and sent them to kernel developers. 220 of these bugs have been confirmed, and 51 of our patches fixing 115 bugs have been applied. © 2020 ACM.",atomic context; bug detection; operating system; Static analysis,Atoms; Sleep research; Alias analysis; Check method; Concurrency bugs; CPU cores; Function pointers; Linux kernel; Static approach; Linux
A Retargetable System-level DBT Hypervisor,2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086754701&doi=10.1145%2f3386161&partnerID=40&md5=e50a9ba4aa372ec02180b3121d117c56,"System-level Dynamic Binary Translation (DBT) provides the capability to boot an Operating System (OS) and execute programs compiled for an Instruction Set Architecture (ISA) different from that of the host machine. Due to their performance-critical nature, system-level DBT frameworks are typically hand-coded and heavily optimized, both for their guest and host architectures. While this results in good performance of the DBT system, engineering costs for supporting a new architecture or extending an existing architecture are high. In this article, we develop a novel, retargetable DBT hypervisor, which includes guest-specific modules generated from high-level guest machine specifications. Our system simplifies retargeting of the DBT, but it also delivers performance levels in excess of existing manually created DBT solutions. We achieve this by combining offline and online optimizations and exploiting the freedom of a Just-in-time (JIT) compiler operating in a bare-metal environment provided by a Virtual Machine (VM) hypervisor. We evaluate our DBT using both targeted micro-benchmarks as well as standard application benchmarks, and we demonstrate its ability to outperform the de facto standard QEMU DBT system. Our system delivers an average speedup of 2.21× over QEMU across SPEC CPU2006 integer benchmarks running in a full-system Linux OS environment, compiled for the 64-bit ARMv8-A ISA and hosted on an x86-64 platform. For floating-point applications the speedup is even higher, reaching 6.49× on average. We demonstrate that our system-level DBT system significantly reduces the effort required to support a new ISA while delivering outstanding performance. © 2020 ACM.",dynamic binary translation; hypervisor; Virtualization,Architecture; Benchmarking; Computer operating systems; Cost engineering; Digital arithmetic; Just in time production; Program translators; De facto standard; Dynamic binary translation; Engineering costs; Existing architectures; Instruction set architecture; Just-in-time compiler; Online optimization; Performance level; Computer architecture
Transactuations: Where Transactions Meet the Physical World,2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086768975&doi=10.1145%2f3380907&partnerID=40&md5=a5b4e329a16abec02f3da7ac34d07080,"A large class of IoT applications read sensors, execute application logic, and actuate actuators. However, the lack of high-level programming abstractions compromises correctness, especially in the presence of failures and unwanted interleaving between applications. A key problem arises when operations on IoT devices or the application itself fails, which leads to inconsistencies between the physical state and application state, breaking application semantics and causing undesired consequences. Transactions are a well-established abstraction for correctness, but assume properties that are absent in an IoT context. In this article, we study one such environment, smart home, and establish inconsistencies manifesting out of failures. We propose an abstraction called transactuation that empowers developers to build reliable applications. Our runtime, Relacs, implements the abstraction atop a real smart-home platform. We evaluate programmability, performance, and effectiveness of transactuations to demonstrate its potential as a powerful abstraction and execution model. © 2020 ACM.",actuators; reliability; sensors; transactions; Transactuations,Abstracting; Automation; Computer programming; Semantics; Application logic; Application Semantics; Execution model; High-level programming; IOT applications; Physical state; Physical world; Programmability; Internet of things
Introduction to the Special Issue on the Award Papers of USENIX ATC 2019,2020,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086786388&doi=10.1145%2f3395034&partnerID=40&md5=ed5794362c88b0bc72c22e58dd375f28,[No abstract available],,
An instruction set architecture for machine learning,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075547370&doi=10.1145%2f3331469&partnerID=40&md5=d3edd3f4d52c41526fc03eda8784260b,"Machine Learning (ML) are a family of models for learning from the data to improve performance on a certain task. ML techniques, especially recent renewed neural networks (deep neural networks), have proven to be efficient for a broad range of applications. ML techniques are conventionally executed on general-purpose processors (such as CPU and GPGPU), which usually are not energy efficient, since they invest excessive hardware resources to flexibly support various workloads. Consequently, application-specific hardware accelerators have been proposed recently to improve energy efficiency. However, such accelerators were designed for a small set of ML techniques sharing similar computational patterns, and they adopt complex and informative instructions (control signals) directly corresponding to high-level functional blocks of an ML technique (such as layers in neural networks) or even an ML as a whole. Although straightforward and easy to implement for a limited set of similar ML techniques, the lack of agility in the instruction set prevents such accelerator designs from supporting a variety of different ML techniques with sufficient flexibility and efficiency. In this article, we first propose a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques.We then extend the application scope of Cambricon from NN to ML techniques.We also propose an assembly language, an assembler, and runtime to support programming with Cambricon, especially targeting large-scale ML problems. Our evaluation over a total of 16 representative yet distinct ML techniques have demonstrated that Cambricon exhibits strong descriptive capacity over a broad range of ML techniques and provides higher code density than general-purpose ISAs such as x86, MIPS, and GPGPU. Compared to the latest state-ofthe-art NN accelerator design DaDianNao [7] (which can only accommodate three types of NN techniques), our Cambricon-based accelerator prototype implemented in TSMC 65nm technology incurs only negligible latency/power/area overheads, with a versatile coverage of 10 different NN benchmarks and 7 other ML benchmarks. Compared to the recent prevalentML accelerator PuDianNao, our Cambricon-based accelerator is able to support all the ML techniques as well as the 10 NNs but with only approximate 5.1% performance loss. © 2019 Association for Computing Machinery. All rights reserved.",Instruction set architecture; Machine learning; Machine-learning accelerator,Acceleration; Data transfer; Deep neural networks; Energy efficiency; General purpose computers; Learning systems; Machine learning; Multilayer neural networks; Network architecture; Network layers; Program processors; 65-nm technologies; Application specific hardwares; Comprehensive analysis; Computational patterns; Control instruction; General purpose processors; Improve performance; Instruction set architecture; Computer architecture
Software prefetching for indirect memory accesses: A microarchitectural perspective,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067567188&doi=10.1145%2f3319393&partnerID=40&md5=08d4d0eb99319e057cb65a3560aeead2,"Many modern data processing and HPC workloads are heavily memory-latency bound. A tempting proposition to solve this is software prefetching, where special non-blocking loads are used to bring data into the cache hierarchy just before being required. However, these are difficult to insert to effectively improve performance, and techniques for automatic insertion are currently limited. This article develops a novel compiler pass to automatically generate software prefetches for indirect memory accesses, a special class of irregular memory accesses often seen in high-performance workloads. We evaluate this across a wide set of systems, all of which gain benefit from the technique. We then evaluate the extent to which good prefetch instructions are architecture dependent and the class of programs that are particularly amenable. Across a set of memory-bound benchmarks, our automated pass achieves average speedups of 1.3× for an Intel Haswell processor, 1.1× for both an ARM Cortex-A57 and Qualcomm Kryo, 1.2× for a Cortex-72 and an Intel Kaby Lake, and 1.35× for an Intel Xeon Phi Knight's Landing, each of which is an out-of-order core, and performance improvements of 2.1× and 2.7× for the in-order ARM Cortex-A53 and first generation Intel Xeon Phi. © 2019 Association for Computing Machinery.",Compiler analysis; Microarchitecture; Software prefetching,Benchmarking; Data handling; Program compilers; Cache hierarchies; Compiler analysis; Improve performance; Memory bounds; Memory latencies; Micro architectures; Software prefetching; Special class; ARM processors
The Arm triple core lock-step (TCLS) processor,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067547296&doi=10.1145%2f3323917&partnerID=40&md5=c5039a7b823bc3585396d0bc036c90c8,"The Arm Triple Core Lock-Step (TCLS) architecture is the natural evolution of Arm Cortex-R Dual Core Lock-Step (DCLS) processors to increase dependability, predictability, and availability in safety-critical and ultra-reliable applications. TCLS is simple, scalable, and easy to deploy in applications where Arm DCLS processors are widely used (e.g., automotive), as well as in new sectors where the presence of Arm technology is incipient (e.g., enterprise) or almost non-existent (e.g., space). Specifically in space, COTS Arm processors provide optimal power-to-performance, extensibility, evolvability, software availability, and ease of use, especially in comparison with the decades old rad-hard computing solutions that are still in use. This article discusses the fundamentals of an Arm Cortex-R5 based TCLS processor, providing key functioning and implementation details. The article shows that the TCLS architecture keeps the use of rad-hard technology to a minimum, namely, using rad-hard by design standard cell libraries only to protect the critical parts that account for less than 4% of the entire TCLS solution. Moreover, when exposure to radiation is relatively low, such as in terrestrial applications or even satellites operating in Low Earth Orbits (LEO), the system could be implemented entirely using commercial cell libraries, relying on the radiation mitigation methods implemented on the TCLS to cope with sporadic soft errors in its critical parts. The TCLS solution allows thus to significantly reduce chip manufacturing costs and keep pace with advances in low power consumption and high density integration by leveraging commercial semiconductor processes, while matching the reliability levels and improving availability that can be achieved using extremely expensive rad-hard semiconductor processes. Finally, the article describes a TRL4 proof-of-concept TCLS-based System-on-Chip (SoC) that has been prototyped and tested to power the computer on-board an Airbus Defence and Space telecom satellite. When compared to the currently used processor solution by Airbus, the TCLS-based SoC results in a more than 5× performance increase and cuts power consumption by more than half. © 2019 Association for Computing Machinery.",Arm; Safety-critical; Soft error resilience; Space avionics,Availability; Closed loop control systems; Electric power utilization; Error correction; Libraries; Locks (fasteners); Manufacture; Orbits; Programmable logic controllers; Radiation hardening; High-density integration; Low earth orbit(LEO); Low-power consumption; Semiconductor process; Soft error; Software availability; System on chips (SoC); Terrestrial application; System-on-chip
Venice: An effective resource sharing architecture for data center servers,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063198415&doi=10.1145%2f3310360&partnerID=40&md5=f0e0c344e5dcbd1fb1b0f92fc306c7be,"Consolidated server racks are quickly becoming the standard infrastructure for engineering, business, medicine, and science. Such servers are still designed much in the way when they were organized as individual, distributed systems. Given that many fields rely on big-data analytics substantially, its cost-effectiveness and performance should be improved, which can be achieved by flexibly allowing resources to be shared across nodes. Here we describe Venice, a family of data-center server architectures that includes a strong communication substrate as a first-class resource. Venice supports a diverse set of resource-joining mechanisms that enables applications to leverage non-local resources efficiently. We have constructed a hardware prototype to better understand the implications of design decisions about system support for resource sharing. We use it to measure the performance of at-scale applications and to explore performance, power, and resource-sharing transparency tradeoffs (i.e., how many programming changes are needed). We analyze these tradeoffs for sharing memory, accelerators, and NICs. We find that reducing/hiding latency is particularly important, the chosen communication channels should match the sharing access patterns of the applications, and of which we can improve performance by exploiting interchannel collaboration. © 2019 Association for Computing Machinery.",Data center architecture; Interconnect fabric; Resource sharing; Scheduling,Cost effectiveness; Data Analytics; Scheduling; Data center architecture; Distributed systems; Improve performance; Interconnect fabrics; Joining mechanisms; Non-local resources; Resource sharing; Resource-sharing architectures; Commerce
Deca: A garbage collection optimizer for in-memory data processing,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063187599&doi=10.1145%2f3310361&partnerID=40&md5=275dd3858bb64201ec1556ea6efd199c,"In-memory caching of intermediate data and active combining of data in shuffle buffers have been shown to be very effective in minimizing the recomputation and I/O cost in big data processing systems such as Spark and Flink. However, it has also been widely reported that these techniques would create a large amount of long-living data objects in the heap. These generated objects may quickly saturate the garbage collector, especially when handling a large dataset, and hence, limit the scalability of the system. To eliminate this problem, we propose a lifetime-based memory management framework, which, by automatically analyzing the user-defined functions and data types, obtains the expected lifetime of the data objects and then allocates and releases memory space accordingly to minimize the garbage collection overhead. In particular,we present Deca,1 a concrete implementation of our proposal on top of Spark, which transparently decomposes and groups objects with similar lifetimes into byte arrays and releases their space altogether when their lifetimes come to an end. When systems are processing very large data, Deca also provides field-oriented memory pages to ensure high compression efficiency. Extensive experimental studies using both synthetic and real datasets show that, in comparing to Spark, Deca is able to (1) reduce the garbage collection time by up to 99.9%, (2) reduce the memory consumption by up to 46.6% and the storage space by 23.4%, (3) achieve 1.2× to 22.7× speedup in terms of execution time in cases without data spilling and 16× to 41.6× speedup in cases with data spilling, and (4) provide similar performance compared to domain-specific systems. © 2019 Association for Computing Machinery.",Data processing system; Distributed system; Garbage collection; Inmemory; Memory management,Data handling; Digital storage; Large dataset; Real time systems; Refuse collection; Data processing systems; Distributed systems; Garbage collection; Inmemory; Memory management; Information management
Lock-unlock: Is that all? A pragmatic analysis of locking in software systems,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063190550&doi=10.1145%2f3301501&partnerID=40&md5=24b1e9cda3a452568c167e11bc3a9c19,"A plethora of optimized mutex lock algorithms have been designed over the past 25 years to mitigate performance bottlenecks related to critical sections and locks. Unfortunately, there is currently no broad study of the behavior of these optimized lock algorithms on realistic applications that consider different performance metrics, such as energy efficiency and tail latency. In this article, we perform a thorough and practical analysis of synchronization, with the goal of providing software developers with enough information to design fast, scalable, and energy-efficient synchronization in their systems. First, we perform a performance study of 28 state-of-the-art mutex lock algorithms, on 40 applications, on four different multicore machines. We consider not only throughput (traditionally the main performance metric) but also energy efficiency and tail latency, which are becoming increasingly important. Second, we present an in-depth analysis in which we summarize our findings for all the studied applications. In particular, we describe nine different lock-related performance bottlenecks, and we propose six guidelines helping software developers with their choice of a lock algorithm according to the different lock properties and the application characteristics. From our detailed analysis, we make several observations regarding locking algorithms and application behaviors, several of which have not been previously discovered: (i) applications stress not only the lock- unlock interface but also the full locking API (e.g., trylocks, condition variables); (ii) thememory footprint of a lock can directly affect the application performance; (iii) for many applications, the interaction between locks and scheduling is an important application performance factor; (vi) lock tail latencies may or may not affect application tail latency; (v) no single lock is systematically the best; (vi) choosing the best lock is difficult; and (vii) energy efficiency and throughput go hand in hand in the context of lock algorithms. These findings highlight that locking involves more considerations than the simple lock/unlock interface and call for further research on designing low-memory footprint adaptive locks that fully and efficiently support the full lock interface, and consider all performance metrics. © 2019 Association for Computing Machinery.",Lock interface; Locks; Multicore; Performance bottleneck; Synchronization,Application programming interfaces (API); Application programs; Locks (fasteners); Synchronization; Application behaviors; Application performance; Multi core; Multi-core machines; Performance bottlenecks; Performance metrices; Performance metrics; Realistic applications; Energy efficiency
SPIN: Seamless operating system integration of peer-to-peer DMA between SSDs and GPUs,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065790486&doi=10.1145%2f3309987&partnerID=40&md5=46ba5f62a8cd73480f65434b73fe9b87,"Recent GPUs enable Peer-to-Peer Direct Memory Access (p2p) from fast peripheral devices like NVMe SSDs to exclude the CPU from the data path between them for efficiency. Unfortunately, using p2p to access files is challenging because of the subtleties of low-level non-standard interfaces, which bypass the OS file I/O layers and may hurt system performance. Developers must possess intimate knowledge of low-level interfaces to manually handle the subtleties of data consistency and misaligned accesses. We present SPIN, which integrates p2p into the standard OS file I/O stack, dynamically activating p2p where appropriate, transparently to the user. It combines p2p with page cache accesses, re-enables read-ahead for sequential reads, all while maintaining standard POSIX FS consistency, portability across GPUs and SSDs, and compatibility with virtual block devices such as software RAID. We evaluate SPIN on NVIDIA and AMD GPUs using standard file I/O benchmarks, application traces, and end-to-end experiments. SPIN achieves significant performance speedups across a wide range of workloads, exceeding p2p throughput by up to an order of magnitude. It also boosts the performance of an aerial imagery rendering application by 2.6× by dynamically adapting to its input-dependent file access pattern, enables 3.3× higher throughput for a GPU-accelerated log server, and enables 29% faster execution for the highly optimized GPU-accelerated image collage with only 30 changed lines of code. © 2019 Association for Computing Machinery.",Accelerators; File systems; GPU; I/O subsystem; Operating systems,Aerial photography; Antennas; Benchmarking; Computer operating systems; Computer software portability; Distributed computer systems; Graphics processing unit; Particle accelerators; Program processors; Data consistency; Direct memory access; File access patterns; File systems; GPU-accelerated; Peripheral devices; Standard interface; System integration; Peer to peer networks
Derecho: Fast state machine replication for cloud services,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065756265&doi=10.1145%2f3302258&partnerID=40&md5=e6147b17cd4eb2aecb125430b95b6b09,"Cloud computing services often replicate data and may require ways to coordinate distributed actions. Here we present Derecho, a library for such tasks. The API provides interfaces for structuring applications into patterns of subgroups and shards, supports state machine replication within them, and includes mechanisms that assist in restart after failures. Running over 100Gbps RDMA, Derecho can send millions of events per second in each subgroup or shard and throughput peaks at 16GB/s, substantially outperforming prior solutions. Configured to run purely on TCP, Derecho is still substantially faster than comparable widely used, highly-tuned, standard tools. The key insight is that on modern hardware (including non-RDMA networks), data-intensive protocols should be built from non-blocking data-flow components. © 2019 Association for Computing Machinery.",Cloud computing; Consistency; Non-volatile memory; RDMA; Replication,Application programming interfaces (API); Cloud computing; Digital storage; Web services; Cloud computing services; Cloud services; Consistency; Non-volatile memory; RDMA; Replication; Standard tools; State machine replication; Interface states
Mitigating load imbalance in distributed data serving with rack-scale memory pooling,2019,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065764850&doi=10.1145%2f3309986&partnerID=40&md5=3ab9936c3dba3b9d17e2f66e37d3926c,"To provide low-latency and high-throughput guarantees, most large key-value stores keep the data in the memory of many servers. Despite the natural parallelism across lookups, the load imbalance, introduced by heavy skew in the popularity distribution of keys, limits performance. To avoid violating tail latency service-level objectives, systems tend to keep server utilization low and organize the data in micro-shards, which provides units of migration and replication for the purpose of load balancing. These techniques reduce the skew but incur additional monitoring, data replication, and consistency maintenance overheads. In this work, we introduce RackOut, a memory pooling technique that leverages the one-sided remote read primitive of emerging rack-scale systems to mitigate load imbalance while respecting service-level objectives. In RackOut, the data are aggregated at rack-scale granularity, with all of the participating servers in the rack jointly servicing all of the rack's micro-shards. We develop a queuing model to evaluate the impact of RackOut at the datacenter scale. In addition, we implement a RackOut proof-of-concept key-value store, evaluate it on two experimental platforms based on RDMA and Scale-Out NUMA, and use these results to validate the model. We devise two distinct approaches to load balancing within a RackOut unit, one based on random selection of nodes-RackOut_static-and another one based on an adaptive load balancing mechanism-RackOut_adaptive. Our results show that RackOut_static increases throughput by up to 6× for RDMA and 8.6× for Scale-Out NUMA compared to a scale-out deployment, while respecting tight tail latency service-level objectives. RackOut_adaptive improves the throughput by 30% for workloads with 20% of writes over RackOut_static. © 2019 Association for Computing Machinery.",CREW; Key-value stores; Latency-critical applications; Load imbalance; One-sided operations; Rack-scale systems; RDMA; SLO; Tail latency,Computer science; Computer systems; CREW; Critical applications; Key-value stores; Load imbalance; One-sided operations; RDMA; Scale system; Tail latency; Queueing theory
Pivot tracing: Dynamic causal monitoring for distributed systems,2018,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061210619&doi=10.1145%2f3208104&partnerID=40&md5=b8c7f6d6a18757671e9651bdefbeb5eb,"Monitoring and troubleshooting distributed systems is notoriously difficult; potential problems are complex, varied, and unpredictable. The monitoring and diagnosis tools commonly used today-logs, counters, and metrics-have two important limitations: what gets recorded is defined a priori, and the information is recorded in a component-or machine-centric way, making it extremely hard to correlate events that cross these boundaries. This article presents Pivot Tracing, a monitoring framework for distributed systems that addresses both limitations by combining dynamic instrumentation with a novel relational operator: the happened-before join. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, filter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. We have implemented a prototype of Pivot Tracing for Java-based systems and evaluate it on a heterogeneous Hadoop cluster comprising HDFS, HBase, MapReduce, and YARN. We show that Pivot Tracing can effectively identify a diverse range of root causes such as software bugs, misconfiguration, and limping hardware. We show that Pivot Tracing is dynamic, extensible, and enables cross-tier analysis between inter-operating applications, with low execution overhead. © 2018 Copyright held by the owner/author(s).",Distributed systems monitoring; End-to-end tracing,Program debugging; Crossing-component; Distributed systems; Dynamic instrumentation; End to end; Monitoring and diagnosis; Monitoring frameworks; Potential problems; Relational operator; Monitoring
Ryoan: A distributed sandbox for untrusted computation on secret data,2018,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061180770&doi=10.1145%2f3231594&partnerID=40&md5=fa5fe65fb5bd67fac1d6e6c3279311e6,"                             Users of modern data-processing services such as tax preparation or genomic screening are forced to trust them with data that the users wish to keep secret. Ryoan                             1                              protects secret data while it is processed by services that the data owner does not trust. Accomplishing this goal in a distributed setting is difficult, because the user has no control over the service providers or the computational platform. Confining code to prevent it from leaking secrets is notoriously difficult, but Ryoan benefits from new hardware and a request-oriented data model. Ryoan provides a distributed sandbox, leveraging hardware enclaves (e.g., Intel's software guard extensions (SGX) [40]) to protect sandbox instances from potentially malicious computing platforms. The protected sandbox instances confine untrusted data-processing modules to prevent leakage of the user's input data. Ryoan is designed for a request-oriented data model, where confined modules only process input once and do not persist state about the input. We present the design and prototype implementation of Ryoan and evaluate it on a series of challenging problems including email filtering, health analysis, image processing and machine translation.                          © 2018 Copyright held by the owner/author(s).",Enclaves; Intel SGX; Private computation; Sandboxing; Untrusted OS,Image processing; Computational platforms; Computing platform; Enclaves; Intel SGX; Machine translations; Private computation; Prototype implementations; Sandboxing; Data handling
Building consistent transactions with inconsistent replication,2018,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061202644&doi=10.1145%2f3269981&partnerID=40&md5=24ba02d490ae3f830839474fd5e9c07a,"Application programmers increasingly prefer distributed storage systems with strong consistency and distributed transactions (e.g., Google's Spanner) for their strong guarantees and ease of use. Unfortunately, existing transactional storage systems are expensive to use-in part, because they require costly replication protocols, like Paxos, for fault tolerance. In this article, we present a new approach that makes transactional storage systems more afordable: We eliminate consistency from the replication protocol, while still providing distributed transactions with strong consistency to applications. We present the Transactional Application Protocol for Inconsistent Replication (TAPIR), the first transaction protocol to use a novel replication protocol, called inconsistent replication, that provides fault tolerance without consistency. By enforcing strong consistency only in the transaction protocol, TAPIR can commit transactions in a single round-trip and order distributed transactions without centralized coordination. We demonstrate the use of TAPIR in a transactional key-value store, tapir-kv. Compared to conventional systems, tapir-kv provides better latency and better throughput. © 2018 Copyright held by the owner/author(s).",Distributed transactional storage; Inconsistent replication; Strict serializability,Multiprocessing systems; Application programmers; Application protocols; Conventional systems; Distributed storage system; Distributed transaction; Inconsistent replication; Replication protocol; Serializability; Fault tolerance
Determining application-specific peak power and energy requirements for ultra-low-power processors,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041433903&doi=10.1145%2f3148052&partnerID=40&md5=145558b5ad1032a13fe502039b4a9b09,"Many emerging applications such as the Internet of Things, wearables, implantables, and sensor networks are constrained by power and energy. These applications rely on ultra-low-power processors that have rapidly become the most abundant type of processor manufactured today. In the ultra-low-power embedded systems used by these applications, peak power and energy requirements are the primary factors that determine critical system characteristics, such as size, weight, cost, and lifetime. While the power and energy requirements of these systems tend to be application specific, conventional techniques for rating peak power and energy cannot accurately bound the power and energy requirements of an application running on a processor, leading to overprovisioning that increases system size and weight. In this article, we present an automated technique that performs hardware-software coanalysis of the application and ultra-low-power processor in an embedded system to determine application-specific peak power and energy requirements. Our technique provides more accurate, tighter bounds than conventional techniques for determining peak power and energy requirements. Also, unlike conventional approaches, our technique reports guaranteed bounds on peak power and energy independent of an application's input set. Tighter bounds on peak power and energy can be exploited to reduce system size, weight, and cost. © 2017 ACM.",Application-specific hardware; Hardware-software coanalysis; Internet of Things; Peak power analysis; Ultra-low-power processors,Embedded systems; Hardware; Internet of things; Sensor networks; Application specific; Application specific hardwares; Co-analysis; Conventional approach; Conventional techniques; Emerging applications; Peak power; Ultra low power; Application programs
"Corrigendum: The IX operating system: Combining low latency, high throughput and efficiency in a protected dataplane (ACM Transactions on Computer Systems (21) DOI: 10.1145/2997641)",2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041407537&doi=10.1145%2f3154292&partnerID=40&md5=3256d3bb20479672ec2ca201b9c2e498,"On page 21 of ""The IX Operating System: Combining Low Latency, High Throughput and Efficiency in a Protected Dataplane"" we describe our use of the tool mutilate to evaluate the latency and throughput of memcached. We discovered an error in our setup: we did not load the initial key-value state into memcached before the start of the experiment. Instead, memcached started in an empty state, causing some GET requests to require less computation than intended. Table 1 shows the performance differences between our original and corrected memcached results. Table presented. The full revised article can be accessed at the ACM DL, DOI http://dx.doi.org/10.1145/3154292. In addition to corrected results for memcached, all experiments have been updated to Linux kernel version 4.8 (previously 4.2 was evaluated) to accommodate the latest configuration of our test cluster. © 2017 ACM.",,
The hipster approach for improving cloud system efficiency,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038630824&doi=10.1145%2f3144168&partnerID=40&md5=74111ac9d6c9007bcbf3bd2ee01cfc02,"In 2013, U.S. data centers accounted for 2.2% of the country’s total electricity consumption, a figure that is projected to increase rapidly over the next decade. Many important data center workloads in cloud computing are interactive, and they demand strict levels of quality-of-service (QoS) to meet user expectations, making it challenging to optimize power consumption along with increasing performance demands. This article introduces Hipster, a technique that combines heuristics and reinforcement learning to improve resource efficiency in cloud systems. Hipster explores heterogeneous multi-cores and dynamic voltage and frequency scaling for reducing energy consumption while managing the QoS of the latency-critical workloads. To improve data center utilization and make best usage of the available resources, Hipster can dynamically assign remaining cores to batch workloads without violating the QoS constraints for the latency-critical workloads. We perform experiments using a 64-bit ARM big.LITTLE platform and show that, compared to prior work, Hipster improves the QoS guarantee for Web-Search from 80% to 96%, and for Memcached from 92% to 99%, while reducing the energy consumption by up to 18%. Hipster is also effective in learning and adapting automatically to specific requirements of new incoming workloads just enough to meet the QoS and optimize resource consumption. © 2017 ACM.",Cloud computing; Data center; Energy efficient computing; Interference; Latency-critical applications; Performance isolation; QoS; Resource efficiency; Scheduling; Warehouse-scale computer,Cloud computing; Dynamic frequency scaling; Electric power utilization; Embedded systems; Energy efficiency; Energy utilization; Green computing; Optimization; Reinforcement learning; Scheduling; Voltage scaling; Wave interference; Critical applications; Data centers; Energy efficient computing; Performance isolation; Resource efficiencies; Quality of service
Seer: Probabilistic Scheduling for Hardware Transactional Memory,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034662976&doi=10.1145%2f3132036&partnerID=40&md5=be12c998bfdb759386c094d1551de201,"The ubiquity of multicore processors has led programmers to write parallel and concurrent applications to take advantage of the underlying hardware and speed up their executions. In this context, Transactional Memory (TM) has emerged as a simple and effective synchronization paradigm, via the familiar abstraction of atomic transactions. After many years of intense research, major processor manufacturers (including Intel) have recently released mainstream processors with hardware support for TM (HTM). In this work, we study a relevant issue with great impact on the performance of HTM. Due to the optimistic and inherently limited nature of HTM, transactions may have to be aborted and restarted numerous times, without any progress guarantee. As a result, it is up to the software library that regulates the HTM usage to ensure progress and optimize performance. Transaction scheduling is probably one of the most well-studied and effective techniques to achieve these goals. However, these recent mainstream HTMs have some technical limitations that prevent the adoption of known scheduling techniques: unlike software implementations of TM used in the past, existing HTMs provide limited or no information on which memory regions or contending transactions caused the abort. To address this crucial issue for HTMs, we propose Seer, a software scheduler that addresses precisely this restriction of HTM by leveraging on an online probabilistic inference technique that identifies the most likely conflict relations and establishes a dynamic locking scheme to serialize transactions in a fine-grained manner. The key idea of our solution is to constrain the portions of parallelism that are affecting negatively the whole system. As a result, this not only prevents performance reduction but also in fact unveils further scalability and performance for HTM. Via an extensive evaluation study, we show that Seer improves the performance of the Intel’s HTM by up to 3.6×, and by 65% on average across all concurrency degrees and benchmarks on a large processor with 28 cores. © 2017 ACM.",Best-effort; Hardware transactional memory; Scheduling,Benchmarking; Hardware; Locks (fasteners); Parallel processing systems; Scheduling; Storage allocation (computer); Best effort; Hardware transactional memory; Probabilistic inference; Probabilistic scheduling; Scalability and performance; Scheduling techniques; Software implementation; Transaction scheduling; Multitasking
Apache REEF: Retainable evaluator execution framework,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032886342&doi=10.1145%2f3132037&partnerID=40&md5=a94c03e787a825d5ff7ddd8b1fcb89e1,"Resource Managers like YARN and Mesos have emerged as a critical layer in the cloud computing system stack, but the developer abstractions for leasing cluster resources and instantiating application logic are very low level. This flexibility comes at a high cost in terms of developer effort, as each application must repeatedly tackle the same challenges (e.g., fault tolerance, task scheduling and coordination) and reimplement common mechanisms (e.g., caching, bulk-data transfers). This article presents REEF, a development framework that provides a control plane for scheduling and coordinating task-level (data-plane) work on cluster resources obtained from a Resource Manager. REEF provides mechanisms that facilitate resource reuse for data caching and state management abstractions that greatly ease the development of elastic data processing pipelines on cloud platforms that support a Resource Manager service. We illustrate the power of REEF by showing applications built atop: a distributed shell application, a machine-learning framework, a distributed in-memory caching system, and a port of the CORFU system. REEF is currently an Apache top-level project that has attracted contributors from several institutions and it is being used to develop several commercial offerings such as the Azure Stream Analytics service.",Data processing; Resource management,Abstracting; Cluster computing; Computation theory; Data handling; Data processing; Data transfer; Distributed computer systems; Fault tolerance; Fault tolerant computer systems; Learning systems; Managers; Network function virtualization; Pipeline processing systems; Reefs; Application logic; Bulk data transfer; Data processing pipelines; Developer efforts; Development frameworks; Execution framework; Resource management; Resource managers; Information management
Supercloud: A library cloud for exploiting cloud diversity,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033231767&doi=10.1145%2f3132038&partnerID=40&md5=e0bc80b100bfa113c48299214be2e365,"Infrastructure-as-a-Service (IaaS) cloud providers hide available interfaces for virtual machine (VM) placement and migration, CPU capping, memory ballooning, page sharing, and I/O throttling, limiting the ways in which applications can optimally configure resources or respond to dynamically shifting workloads. Given these interfaces, applications could migrate VMs in response to diurnal workloads or changing prices, adjust resources in response to load changes, and so on. This article proposes a new abstraction that we call a Library Cloud and that allows users to customize the diverse available cloud resources to best serve their applications. We built a prototype of a Library Cloud that we call the Supercloud. The Supercloud encapsulates applications in a virtual cloud under users' full control and can incorporate one or more availability zones within a cloud provider or across different providers. The Supercloud provides virtual machine, storage, and networking complete with a full set of management operations, allowing applications to optimize performance. In this article, we demonstrate various innovations enabled by the Library Cloud. © 2017 ACM.",Cloud computing; Cloud Federation; Nested virtualization,Cloud computing; Network security; Virtual machine; Cloud federations; Cloud providers; Full control; Load change; Management operation; Nested Virtualization; Page sharing; Virtual cloud; Infrastructure as a service (IaaS)
Fast in-memory transaction processing using RDMA and HTM,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026529417&doi=10.1145%2f3092701&partnerID=40&md5=102e83ec43472c72e8921a36bd82183a,"DrTM is a fast in-memory transaction processing system that exploits advanced hardware features such as remote direct memory access (RDMA) and hardware transactional memory (HTM). To achieve high efficiency, it mostly offloads concurrency control such as tracking read/write accesses and conflict detection into HTM in a local machine and leverages the strong consistency between RDMA and HTM to ensure serializability among concurrent transactions across machines. To mitigate the high probability of HTM aborts for large transactions, we design and implement an optimized transaction chopping algorithm to decompose a set of large transactions into smaller pieces such that HTM is only required to protect each piece. We further build an efficient hash table for DrTM by leveraging HTM and RDMA to simplify the design and notably improve the performance. We describe how DrTM supports common database features like read-only transactions and logging for durability. Evaluation using typical OLTP workloads including TPC-C and SmallBank shows that DrTM has better single-node efficiency and scales well on a six-node cluster; it achieves greater than 1.51, 34 and 5.24, 138 million transactions per second for TPC-C and SmallBank on a single node and the cluster, respectively. Such numbers outperform a state-of-the-art single-node system (i.e., Silo) and a distributed transaction system (i.e., Calvin) by at least 1.9X and 29.6X for TPC-C. © 2017 ACM 0734-2071/2017/07-ART3 $15.00",,Computer hardware; Efficiency; Hardware; Chopping algorithms; Concurrent transactions; Design and implements; Distributed transaction; Hardware transactional memory; Memory transactions; Read-only transaction; Remote direct memory access; Concurrency control
Using multicore reuse distance to study coherence directories,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026921649&doi=10.1145%2f3092702&partnerID=40&md5=837360c7a8396d74da0169a80b191bb8,"Researchers have proposed numerous techniques to improve the scalability of coherence directories. The effectiveness of these techniques not only depends on application behavior, but also on the CPU's configuration, for example, its core count and cache size. As CPUs continue to scale, it is essential to explore the directory's application and architecture dependencies. However, this is challenging given the slow speed of simulators. While it is common practice to simulate different applications, previous research on directory designs have explored only a few-and in most cases, only one-CPU configuration, which can lead to an incomplete and inaccurate view of the directory's behavior. This article proposes to use multicore reuse distance analysis to study coherence directories. We develop a framework to extract the directory access stream from parallel least recently used (LRU) stacks, enabling rapid analysis of the directory's accesses and contents across both core count and cache size scaling. A key part of our framework is the notion of relative reuse distance between sharers, which defines sharing in a capacity-dependent fashion and facilitates our analyses along the data cache size dimension. We implement our framework in a profiler and then apply it to gain insights into the impact of multicore CPU scaling on directory behavior. Our profiling results show that directory accesses reduce by 3.3× when scaling the data cache size from 16KB to 1MB, despite an increase in sharing-based directory accesses. We also show that increased sharing caused by data cache scaling allows the portion of on-chip memory occupied by the directory to be reduced by 43.3%, compared to a reduction of only 2.6% when scaling the number of cores. And, we show certain directory entries exhibit high temporal reuse. In addition to gaining insights, we also validate our profile-based results, and find they are within 2-10% of cache simulations on average, across different validation experiments. Finally, we conduct four case studies that illustrate our insights on existing directory techniques. In particular, we demonstrate our directory occupancy insights on a Cuckoo directory;we apply our sharing insights to provide bounds on the size of Scalable CoherenceDirectories (SCD) and Dual-Grain Directories (DGD); and, we demonstrate our directory entry reuse insights on a multilevel directory design. © 2017 ACM.",Cache coherence directories; Data sharing; Reuse distance analysis,Program processors; Application behaviors; Cache Coherence; Cache simulation; CPU configuration; Data Sharing; Least recently used; Profile based results; Reuse distance; Cache memory
Optimizing General-Purpose CPUs for Energy-Efficient Mobile Web Computing,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016217775&doi=10.1145%2f3041024&partnerID=40&md5=35630b226070093c7d2f0324d6649954,"Mobile applications are increasingly being built using web technologies as a common substrate to achieve portability and to improve developer productivity. Unfortunately, web applications often incur large performance overhead, directly affecting the user quality-of-service (QoS) experience. Traditional techniques in improving mobile processor performance have mostly been adopting desktop-like design techniques such as increasing single-core microarchitecture complexity and aggressively integrating more cores. However, such a desktop-oriented strategy is likely coming to an end due to the stringent energy and thermal constraints that mobile devices impose. Therefore, we must pivot away from traditional mobile processor design techniques in order to provide sustainable performance improvement while maintaining energy efficiency. In this article, we propose to combine hardware customization and specialization techniques to improve the performance and energy efficiency of mobile web applications. We first perform design-space exploration (DSE) and identify opportunities in customizing existing general-purpose mobile processors, that is, tuning microarchitecture parameters. The thorough DSE also lets us discover sources of energy inefficiency in customized general-purpose architectures. To mitigate these inefficiencies, we propose, synthesize, and evaluate two new domain-specific specializations, called the Style Resolution Unit and the Browser Engine Cache. Our optimizations boost performance and energy efficiency at the same time while maintaining generalpurpose programmability. As emerging mobile workloads increasingly rely more on web technologies, the type of optimizations we propose will become important in the future and are likely to have a long-lasting and widespread impact. © 2017 ACM.",Accelerator; Customization; Softwaremanaged cache; Specialization; Web browsing,Computer architecture; Integrated circuit design; Particle accelerators; Program processors; Quality of service; Web browsers; Web crawler; Customization; General purpose architectures; Mobile web applications; Softwaremanaged cache; Specialization; Sustainable performance improvements; Traditional techniques; User Quality of Service; Energy efficiency
Reining in long tails in warehouse-scale computers with quick voltage boosting using Adrenaline,2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017109105&doi=10.1145%2f3054742&partnerID=40&md5=0630234b5e47286a9c04319514520070,"Reducing the long tail of the query latency distribution in modern warehouse scale computers is critical for improving performance and quality of service (QoS) of workloads such as Web Search and Memcached. Traditional turbo boost increases a processor's voltage and frequency during a coarse-grained sliding window, boosting all queries that are processed during that window. However, the inability of such a technique to pinpoint tail queries for boosting limits its tail reduction benefit. In this work, we propose Adrenaline, an approach to leverage finer-granularity (tens of nanoseconds) voltage boosting to effectively rein in the tail latency with query-level precision. Two key insights underlie this work. First, emerging finer granularity voltage/frequency boosting is an enabling mechanism for intelligent allocation of the power budget to precisely boost only the queries that contribute to the tail latency; second, per-query characteristics can be used to design indicators for proactively pinpointing these queries, triggering boosting accordingly. Based on these insights, Adrenaline effectively pinpoints and boosts queries that are likely to increase the tail distribution and can reap more benefit from the voltage/frequency boost. By evaluating under various workload configurations, we demonstrate the effectiveness of our methodology. We achieve up to a 2.50 × tail latency improvement for Memcached and up to a 3.03 × for Web Search over coarse-grained dynamic voltage and frequency scaling (DVFS) given a fixed boosting power budget. When optimizing for energy reduction, Adrenaline achieves up to a 1.81 × improvement for Memcached and up to a 1.99 × for Web Search over coarse-grained DVFS. By using the carefully chosen boost thresholds, Adrenaline further improves the tail latency reduction to 4.82 × over coarse-grained DVFS. © 2017 ACM.",Datacenters; Energy efficiency; Fine-grained dynamic voltage/frequency scaling; Latency-critical workloads; Tail queries,Budget control; Dynamic frequency scaling; Energy efficiency; Green computing; Information retrieval; Voltage scaling; Warehouses; Web crawler; Websites; Coarse grained dynamics; Data centers; Dynamic voltage/frequency scaling; Improving performance; Latency reduction; Latency-critical workloads; Tail distribution; Tail queries; Quality of service
"Computational sprinting: Architecture, dynamics, and strategies",2017,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011383092&doi=10.1145%2f3014428&partnerID=40&md5=54d3dd3f59010d6e91b8841741c7e71d,"Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chips' thermal limits and the rack's power limits. Moreover, we present the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4-6×over prior greedy heuristics and performs within 90% of an upper bound on throughput from a globally optimized policy. © 2017 ACM.",Energy; Modeling; Power; Resource management; Thermalmanagement and scheduling,Models; Scheduling; Chip Multiprocessor; Energy; Greedy heuristics; Optimized policies; Power; Resource management; System conditions; Thermal limits; Multi agent systems
"The IX operating system: Combining low latency, high throughput, and efficiency in a protected dataplane",2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008625508&doi=10.1145%2f2997641&partnerID=40&md5=19e8af48e59ccc2066af191e2673b85e,"The conventional wisdom is that aggressive networking requirements, such as high packet rates for small messages and μs-scale tail latency, are best addressed outside the kernel, in a user-level networking stack. We present IX, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation benefits of existing kernels. IX uses hardware virtualization to separate management and scheduling functions of the kernel (control plane) from network processing (dataplane). The dataplane architecture builds upon a native, zero-copy API and optimizes for both bandwidth and latency by dedicating hardware threads and networking queues to dataplane instances, processing bounded batches of packets to completion, and eliminating coherence traffic and multicore synchronization. The control plane dynamically adjusts core allocations and voltage/frequency settings to meet service-level objectives. We demonstrate that IX outperforms Linux and a user-space network stack significantly in both throughput and end-to-end latency. Moreover, IX improves the throughput of a widely deployed, key-value store by up to 6.4× and reduces tail latency by more than 2×. With three varying load patterns, the control plane saves 46%-54% of processor energy, and it allows background jobs to run at 35%-47% of their standalone throughput. © 2016 ACM.",Dataplane operating systems; Energy-proportionality; Latency-critical applications; Microsecond-scale computing; Virtualization; Workload consolidation,Hardware; Linux; Multiprocessing systems; Quality of service; Scheduling; Virtual reality; Virtualization; Critical applications; Data-plane; Energy proportionalities; Microsecond-scale computing; Workload consolidation; Throughput
Reliability analysis of SSDs under power fault,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994527606&doi=10.1145%2f2992782&partnerID=40&md5=9aba09718733eb6cf44a258e9cc910de,"Modern storage technology (solid-state disks (SSDs), NoSQL databases, commoditized RAID hardware, etc.) brings new reliability challenges to the already-complicated storage stack. Among other things, the behavior of these new components during power faults-which happen relatively frequently in data centers-is an important yet mostly ignored issue in this dependability-critical area. Understanding how new storage components behave under power fault is the first step towards designing new robust storage systems. In this article, we propose a new methodology to expose reliability issues in block devices under power faults. Our framework includes specially designed hardware to inject power faults directly to devices, workloads to stress storage components, and techniques to detect various types of failures. Applying our testing framework, we test 17 commodity SSDs from six different vendors using more than three thousand fault injection cycles in total. Our experimental results reveal that 14 of the 17 tested SSD devices exhibit surprising failure behaviors under power faults, including bit corruption, shorn writes, unserializable writes, metadata corruption, and total device failure. © 2016 ACM.",Fault injection; Flash memory; Power failure; SSD; Storage systems,Crime; Fault detection; Flash memory; Hardware; Outages; Software testing; Failure behaviors; Fault injection; Power failure; Solid state disks; Storage component; Storage systems; Storage technology; Testing framework; Reliability analysis
GPUnet: Networking abstractions for GPU programs,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989353495&doi=10.1145%2f2963098&partnerID=40&md5=1531d1c4376c6996f605858351a631d2,"Despite the popularity of GPUs in high-performance and scientific computing, and despite increasingly general-purpose hardware capabilities, the use of GPUs in network servers or distributed systems poses significant challenges. GPUnet is a native GPU networking layer that provides a socket abstraction and high-level networking APIs for GPU programs. We use GPUnet to streamline the development of high-performance, distributed applications like in-GPU-memory MapReduce and a new class of low-latency, high-throughput GPU-native network services such as a face verification server. © 2016 ACM.",Accelerators; GPGPUs; Network servers; Operating systems design,Abstracting; Computer hardware; Computer operating systems; Graphics processing unit; Network layers; Particle accelerators; Program processors; Distributed applications; Distributed systems; Face Verification; GPGPUs; GPU programs; High throughput; Network server; Network services; Distributed computer systems
BlueDBM: Distributed flash storage for big data analytics,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978049873&doi=10.1145%2f2898996&partnerID=40&md5=524e3b8f9cc3bd437064828cbaea0377,"Complex data queries, because of their need for random accesses, have proven to be slow unless all the data can be accommodated in DRAM. There are many domains, such as genomics, geological data, and daily Twitter feeds, where the datasets of interest are 5TB to 20TB. For such a dataset, one would need a cluster with 100 servers, each with 128GB to 256GB of DRAM, to accommodate all the data in DRAM. On the other hand, such datasets could be stored easily in the flash memory of a rack-sized cluster. Flash storage has much better random access performance than hard disks, which makes it desirable for analytics workloads. However, currently available off-the-shelf flash storage packaged as SSDs does notmake effective use of flash storage because it incurs a great amount of additional overhead during flash device management and network access. In this article, we present BlueDBM, a new system architecture that has flash-based storage with in-store processing capability and a low-latency high-throughput intercontroller network between storage devices. We show that BlueDBM outperforms a flash-based system without these features by a factor of 10 for some important applications. While the performance of a DRAM-centric system falls sharply even if only 5%to 10%of the references are to secondary storage, this sharp performance degradation is not an issue in BlueDBM. BlueDBM presents an attractive point in the cost/performance tradeoff for Big Data analytics. © 2016 ACM.",Media access control; Multichannel; Radio interference; Time synchronization; Wireless sensor networks,Access control; Complex networks; Digital storage; Dynamic random access storage; Flash memory; Medium access control; Radio interference; Random access storage; Virtual storage; Wireless sensor networks; Attractive points; Media access control; Multichannel; Performance degradation; Processing capability; Secondary storage; System architectures; Time synchronization; Big data
A virtualized separation kernel for mixed-criticality systems,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978121218&doi=10.1145%2f2935748&partnerID=40&md5=6b944882a3e49ba1e752a4b427b85b50,"Multi- and many-core processors are becoming increasingly popular in embedded systems. Many of these processors now feature hardware virtualization capabilities, as found on the ARM Cortex A15 and x86 architectures with Intel VT-x or AMD-V support.Hardware virtualization provides away to partition physical resources, including processor cores, memory, and I/O devices, among guest virtual machines (VMs). Each VM is then able to host tasks of a specific criticality level, as part of a mixed-criticality system with different timing and safety requirements. However, traditional virtual machine systems are inappropriate for mixedcriticality computing. They use hypervisors to schedule separate VMs on physical processor cores. The costs of trapping into hypervisors to multiplex and manage machine physical resources on behalf of separate guests are too expensive for many time-critical tasks. Additionally, traditional hypervisors have memory footprints that are often too large for many embedded computing systems. In this article, we discuss the design of the Quest-V separation kernel, which partitions services of different criticality levels across separate VMs, or sandboxes. Each sandbox encapsulates a subset of machine physical resources that it manages without requiring intervention from a hypervisor. In Quest-V, a hypervisor is only needed to bootstrap the system, recover from certain faults, and establish communication channels between sandboxes. This not only reduces the memory footprint of the most privileged protection domain but also removes it from the control path during normal system operation, thereby heightening security. © 2016 ACM.",Chip-level distributed system; Mixed criticality; Separation kernel,Criticality (nuclear fission); Java programming language; Separation; Virtual reality; Distributed systems; Embedded computing system; Hardware virtualization; Many-core processors; Mixed criticalities; Mixed-criticality systems; Physical processors; Virtual machine systems; Embedded systems
Improving resource efficiency at scale with Heracles,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970021948&doi=10.1145%2f2882783&partnerID=40&md5=f5fb3b5589983be3bfebf9c20d56c38f,"User-facing, latency-sensitive services, such as websearch, underutilize their computing resources during daily periods of low traffic. Reusing those resources for other tasks is rarely done in production services since the contention for shared resources can cause latency spikes that violate the service-level objectives of latency-sensitive tasks. The resulting under-utilization hurts both the affordability and energy efficiency of large-scale datacenters. With the slowdown in technology scaling caused by the sunsetting of Moore's law, it becomes important to address this opportunity. We present Heracles, a feedback-based controller that enables the safe colocation of best-effort tasks alongside a latency-critical service. Heracles dynamically manages multiple hardware and software isolation mechanisms, such as CPU, memory, and network isolation, to ensure that the latency-sensitive job meets latency targets while maximizing the resources given to best-effort tasks. We evaluate Heracles using production latency-critical and batch workloads from Google and demonstrate average server utilizations of 90% without latency violations across all the load and colocation scenarios that we evaluated. 2016 Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 0734-2071/2016/05-ART6 $15.00.",Datacenter; Interference; Latency-critical applications; Performance isolation; Qos; Resource efficiency; Scheduling; Warehouse-scale computer,Energy efficiency; Quality of service; Scheduling; Wave interference; Computing resource; Critical applications; Datacenter; Hardware and software; Performance isolations; Production services; Resource efficiencies; Service level objective; Green computing
Full-stack architecting to achieve a billion-requests-per-second throughput on a single key-value store server platform,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966331133&doi=10.1145%2f2897393&partnerID=40&md5=5d32cb7616dcd0f9e8ffc6b462a7edc7,"Distributed in-memory key-value stores (KVSs), such as memcached, have become a critical data serving layer inmodern Internet-oriented data center infrastructure. Their performance and efficiency directly affect the QoS of web services and the efficiency of data centers. Traditionally, these systems have had significant overheads from inefficient network processing, OS kernel involvement, and concurrency control. Two recent research thrusts have focused on improving key-value performance. Hardware-centric research has started to explore specialized platforms including FPGAS for KVSs; results demonstrated an order of magnitude increase in throughput and energy efficiency over stock memcached. Software-centric research revisited the KVS application to address fundamental software bottlenecks and to exploit the full potential of modern commodity hardware; these efforts also showed orders of magnitude improvement over stock memcached. We aim at architecting high-performance and efficient KVS platforms, and start with a rigorous architectural characterization across system stacks over a collection of representative KVS implementations. Our detailed full-system characterization not only identifies the critical hardware/software ingredients for high-performance KVS systems but also leads to guided optimizations atop a recent design to achieve a record-setting throughput of 120 million requests per second (MRPS) (167MRPS with client-side batching) on a single commodity server. Our system delivers the best performance and energy efficiency (RPS/watt) demonstrated to date over existing KVSs including the best-published FPGA-based and GPU-based claims. We craft a set of design principles for future platform architectures, and via detailed simulations demonstrate the capability of achieving a billion RPS with a single server constructed following our principles. © 2016 Copyright is held by the owner/author(s).",Cloud and network; Energy efficiency; Key-value stores; Many core; Storage performance,Application programs; Computer hardware; Concurrency control; Digital storage; Field programmable gate arrays (FPGA); Hardware; Reconfigurable hardware; Throughput; Web services; Key-value stores; Many core; Network processing; Orders of magnitude; Platform architecture; Software bottlenecks; Storage performance; System characterization; Energy efficiency
Identifying power-efficient multicore cache hierarchies via reuse distance analysis,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966330287&doi=10.1145%2f2851503&partnerID=40&md5=5ee81d8e6f47c872135dc1492f3009fc,"To enable performance improvements in a power-efficient manner, computer architects have been building CPUs that exploit greater amounts of thread-level parallelism. A key consideration in such CPUs is properly designing the on-chip cache hierarchy. Unfortunately, this can be hard to do, especially for CPUs with high core counts and large amounts of cache. The enormous design space formed by the combinatorial number of ways in which to organize the cache hierarchy makes it difficult to identify power-efficient configurations. Moreover, the problem is exacerbated by the slow speed of architectural simulation, which is the primary means for conducting such design space studies. A powerful tool that can help architects optimize CPU cache hierarchies is reuse distance (RD) analysis. Recent work has extended uniprocessor RD techniques-i.e., by introducing concurrent RD and private-stack RD profiling-to enable analysis of different types of caches in multicore CPUs. Once acquired, parallel locality profiles can predict the performance of numerous cache configurations, permitting highly efficient design space exploration. To date, existing work on multicore RD analysis has focused on developing the profiling techniques and assessing their accuracy. Unfortunately, there has been no work on using RD analysis to optimize CPU performance or power consumption. This article investigates applying multicore RD analysis to identify the most power efficient cache configurations for a multicore CPU. First, we develop analytical models that use the cache-miss counts from parallel locality profiles to estimate CPU performance and power consumption. Although future scalable CPUs will likely employ multithreaded (and even out-of-order) cores, our current study assumes single-threaded inorder cores to simplify the models, allowing us to focus on the cache hierarchy and our RD-based techniques. Second, to demonstrate the utility of our techniques, we apply our models to optimize a large-scale tiled CPU architecture with a two-level cache hierarchy. We show that the most power efficient configuration varies considerably across different benchmarks, and that our locality profiles provide deep insights into why certain configurations are power efficient. We also show that picking the best configuration can provide significant gains, as there is a 2.01x power efficiency spread across our tiled CPU design space. Finally, we validate the accuracy of our techniques using detailed simulation. Among several simulated configurations, our techniques can usually pick the most power efficient configuration, or one that is very close to the best. In addition, across all simulated configurations, we can predict power efficiency with 15.2% error. © 2016 ACM.",Cache performance; Chip multiprocessors; Design space exploration; Reuse distance,Design; Efficiency; Electric power utilization; Systems analysis; Architectural simulation; Cache configurations; Cache performance; Chip Multiprocessor; Design space exploration; Efficient design space explorations; Reuse distance; Thread level parallelism; Program processors
L4 microkernels: The lessons from 20 years of research and deployment,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966318606&doi=10.1145%2f2893177&partnerID=40&md5=1a47a9eab2663d457bd86aec5c1034b0,"The L4 microkernel has undergone 20 years of use and evolution. It has an active user and developer community, and there are commercial versions that are deployed on a large scale and in safety-critical systems. In this article we examine the lessons learnt in those 20 years about microkernel design and implementation. We revisit the L4 design articles and examine the evolution of design and implementation from the original L4 to the latest generation of L4 kernels.We specifically look at seL4, which has pushed the L4 model furthest and was the first OS kernel to undergo a complete formal verification of its implementation as well as a sound analysis of worst-case execution times.We demonstrate that while much has changed, the fundamental principles of minimality, generality, and high inter-process communication (IPC) performance remain the main drivers of design and implementation decisions. © 2016 ACM.",Formal verification; IPC; L4; Message passing; Microkernels; Minimality; Performance; Real time; SeL4; Virtualization; Worst-case execution time,Design; Message passing; Micro kernel; Minimality; Performance; Real time; SeL4; Virtualizations; Worst-case execution time; Formal verification
"Designing future warehouse-scale computers for sirius, an end-to-end voice and vision personal assistant",2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966348710&doi=10.1145%2f2870631&partnerID=40&md5=72696d65a124092e3b681c73ecab0c12,"As user demand scales for intelligent personal assistants (IPAs) such as Apple's Siri, Google's Google Now, and Microsoft's Cortana, we are approaching the computational limits of current datacenter (DC) architectures. It is an open question how future server architectures should evolve to enable this emerging class of applications, and the lack of an open-source IPA workload is an obstacle in addressing this question. In this article, we present the design of Sirius, an open end-to-end IPA Web-service application that accepts queries in the form of voice and images, and responds with natural language. We then use this workload to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FPGAS. To investigate future server designs for Sirius, we decompose Sirius into a suite of eight benchmarks (Sirius Suite) comprising the computationally intensive bottlenecks of Sirius. We port Sirius Suite to a spectrum of accelerator platforms and use the performance and power trade-offs across these platforms to perform a total cost of ownership (TCO) analysis of various server design points. In our study, we find that accelerators are critical for the future scalability of IPA services. Our results show that GPU- and FPGA-accelerated servers improve the query latency on average by 8.5× and 15×, respectively. For a given throughput, GPU- and FPGA-accelerated servers can reduce the TCO of DCs by 2.3× and 1.3×, respectively. © 2016 ACM.",Datacenters; Emerging workloads; Intelligent personal assistants; Warehouse-scale computers,Design; Economic and social effects; Field programmable gate arrays (FPGA); Personal computers; Program processors; Reconfigurable hardware; Search engines; Warehouses; Web services; Data centers; Emerging workloads; Natural languages; Personal assistants; Server architecture; Total-cost-of-ownership analysis; Voice and images; Web service applications; Integrated circuit design
Eole: Combining static and dynamic scheduling through value prediction to reduce complexity and increase performance,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969981793&doi=10.1145%2f2870632&partnerID=40&md5=2070310255af823d970e70d1066f31e9,"Recent work in the field of value prediction (VP) has shown that given an efficient confidence estimation mechanism, prediction validation could be removed from the out-of-order engine and delayed until commit time. As a result, a simple recovery mechanism-pipeline squashing-can be used, whereas the out-of-order engine remains mostly unmodified. Yet, VP and validation at commit time require additional ports on the physical register file, potentially rendering the overall number of ports unbearable. Fortunately, VP also implies that many single-cycle ALU instructions have their operands predicted in the front-end and can be executed in-place, in-order. Similarly, the execution of single-cycle instructions whose result has been predicted can be delayed until commit time since predictions are validated at commit time. Consequently, a significant number of instructions-10% to 70% in our experiments-can bypass the outof-order engine, allowing for a reduction of the issue width. This reduction paves the way for a truly practical implementation of VP. Furthermore, since VP in itself usually increases performance, our resulting {Early-Out-of-Order-Late} Execution architecture, EOLE, is often more efficient than a baseline VP-augmented 6-issue superscalar while having a significantly narrower 4-issue out-of-order engine. © 2016 Copyright held by the owner/author(s). 0734-2071/2016/04-ART4 $15.00.",EOLE; Out-of-order execution; Speculative execution; Value prediction; VTAGE,Engines; Value engineering; EOLE; Out-of-order execution; Speculative execution; Value prediction; VTAGE; Forecasting
Fast and portable locking for multicore architectures,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954089641&doi=10.1145%2f2845079&partnerID=40&md5=28e08b02b2fe188d561eeab77876108a,"The scalability of multithreaded applications on current multicore systems is hampered by the performance of lock algorithms, due to the costs of access contention and cache misses. The main contribution presented in this article is a new locking technique, Remote Core Locking (RCL), that aims to accelerate the execution of critical sections in legacy applications on multicore architectures. The idea of RCL is to replace lock acquisitions by optimized remote procedure calls to a dedicated server hardware thread. RCL limits the performance collapse observed with other lock algorithms when many threads try to acquire a lock concurrently and removes the need to transfer lock-protected shared data to the hardware thread acquiring the lock, because such data can typically remain in the server's cache. Other contributions presented in this article include a profiler that identifies the locks that are the bottlenecks in multithreaded applications and that can thus benefit from RCL, and a reengineering tool that transforms POSIX lock acquisitions into RCL locks. Eighteen applications were used to evaluate RCL: the nine applications of the SPLASH-2 benchmark suite, the seven applications of the Phoenix 2 benchmark suite, Memcached, and Berkeley DB with a TPC-C client. Eight of these applications are unable to scale because of locks and benefit from RCL on an ×86 machine with four AMD Opteron processors and 48 hardware threads. By using RCL instead of Linux POSIX locks, performance is improved by up to 2.5 times on Memcached, and up to 11.6 times on Berkeley DB with the TPC-C client. On a SPARC machine with two Sun Ultrasparc T2+ processors and 128 hardware threads, three applications benefit from RCL. In particular, performance is improved by up to 1.3 times with respect to Solaris POSIX locks on Memcached, and up to 7.9 times on Berkeley DB with the TPC-C client. © 2016 ACM.",Busy-waiting; Locality; Locks; Memory contention; Multicore; Profiling; Reengineering; RPC; Synchronization,Algorithms; Benchmarking; Buffer storage; Computer architecture; Computer hardware; Computer operating systems; Distributed computer systems; Hardware; Reconfigurable hardware; Reengineering; Software architecture; Synchronization; Busy-waiting; Locality; Memory contentions; Multi core; Profiling; RPC; Locks (fasteners)
Assisting static compiler vectorization with a speculative dynamic vectorizer in an HW/SW codesigned environment,2016,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954125093&doi=10.1145%2f2807694&partnerID=40&md5=981a77145d1911514445136a41273809,"Compiler-based static vectorization is used widely to extract data-level parallelism from computationintensive applications. Static vectorization is very effective in vectorizing traditional array-based applications. However, compilers' inability to do accurate interprocedural pointer disambiguation and interprocedural array dependence analysis severely limits vectorization opportunities. HW/SW codesigned processors provide an excellent opportunity to optimize the applications at runtime. The availability of dynamic application behavior at runtime helps in capturing vectorization opportunities generally missed by the compilers. This article proposes to complement the static vectorization with a speculative dynamic vectorizer in an HW/SW codesigned processor. We present a speculative dynamic vectorization algorithm that speculatively reorders ambiguous memory references to uncover vectorization opportunities. The speculative reordering of memory instructions avoids the need for accurate interprocedural pointer disambiguation and interprocedural array dependence analysis. The hardware checks for any memory dependence violation due to speculative vectorization and takes corrective action in case of violation. Our experiments show that the combined (static + dynamic) vectorization approach provides a 2× performance benefit compared to the static GCC vectorization alone, for SPECFP2006. Furthermore, the speculative dynamic vectorizer is able to vectorize 48% of the loops that ICC failed to vectorize due to conservative dependence analysis in the TSVC benchmark suite. Moreover, the dynamic vectorization scheme is as effective in vectorization of pointer-based applications as for the array-based ones, whereas compilers lose significant vectorization opportunities in pointer-based applications. Furthermore, we show that speculation is not only a luxury but also a necessity for runtime vectorization. Copyright © 2016 ACM.",Dynamic optimizations; Hardware/software codesigned processors; Speculation; Vectorization,Hardware; Hardware-software codesign; Reconfigurable hardware; Co-designed processors; Data-level parallelism; Dynamic applications; Dynamic optimization; Dynamic vectorization; Hw/sw co-designed processors; Speculation; Vectorization; Program compilers
Component-distinguishable Co-location and Resource Reclamation for High-throughput Computing,2024,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193549336&doi=10.1145%2f3630006&partnerID=40&md5=2422120fc247bd1807879e7085e21a77,"Cloud service providers improve resource utilization by co-locating latency-critical (LC) workloads with best-effort batch (BE) jobs in datacenters. However, they usually treat multi-component LCs as monolithic applications and treat BEs as ""second-class citizens""when allocating resources to them. Neglecting the inconsistent interference tolerance abilities of LC components and the inconsistent preemption loss of BE workloads can result in missed co-location opportunities for higher throughput.We present Rhythm, a co-location controller that deploys workloads and reclaims resources rhythmically for maximizing the system throughput while guaranteeing LC service's tail latency requirement. The key idea is to differentiate the BE throughput launched with each LC component, that is, components with higher interference tolerance can be deployed together with more BE jobs. It also assigns different reclamation priority values to BEs by evaluating their preemption losses into a multi-level reclamation queue. We implement and evaluate Rhythm using workloads in the form of containerized processes and microservices. Experimental results show that it can improve the system throughput by 47.3%, CPU utilization by 38.6%, and memory bandwidth utilization by 45.4% while guaranteeing the tail latency requirement.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesDatacenters; co-locating; resource utilization; tail latency,Reclamation; Additional key word and phrasesdatacenter; Batch jobs; Best-effort; Co-locating; Colocations; Critical component; Interference tolerance; Key words; Resources utilizations; Tail latency; Location
Optimizing Resource Management for Shared Microservices: A Scalable System Design,2024,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193495821&doi=10.1145%2f3631607&partnerID=40&md5=57fba3dd167489778a31c99ea1864f73,"A common approach to improving resource utilization in data centers is to adaptively provision resources based on the actual workload. One fundamental challenge of doing this in microservice management frameworks, however, is that different components of a service can exhibit significant differences in their impact on end-to-end performance. To make resource management more challenging, a single microservice can be shared by multiple online services that have diverse workload patterns and SLA requirements.We present an efficient resource management system, namely Erms, for guaranteeing SLAs with high probability in shared microservice environments. Erms profiles microservice latency as a piece-wise linear function of the workload, resource usage, and interference. Based on this profiling, Erms builds resource scaling models to optimally determine latency targets for microservices with complex dependencies. Erms also designs new scheduling policies at shared microservices to further enhance resource efficiency. Experiments across microservice benchmarks as well as trace-driven simulations demonstrate that Erms can reduce SLA violation probability by 5× and more importantly, lead to a reduction in resource usage by 1.6×, compared to state-of-the-art approaches.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesShared microservices; resource management; SLA guarantees,Natural resources management; Additional key word and phrasesshared microservice; Datacenter; Key words; Management frameworks; Resource management; Resource usage; Resources based; Resources utilizations; Scalable systems; SLA guarantee; Resource allocation
Diciclo: Flexible User-level Services for Efficient Multitenant Isolation,2024,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193473526&doi=10.1145%2f3639404&partnerID=40&md5=8e4fe6a68707cd0c7d3456ef600ef10c,"Containers are a mainstream virtualization technique for running stateful workloads over persistent storage. In highly utilized multitenant hosts, resource contention at the system kernel leads to inefficient container input/output (I/O) handling. Although there are interesting techniques to address this issue, they incur high implementation complexity and execution overhead. As a cost-effective alternative, we introduce the Diciclo architecture with our assumptions, goals, and principles. For each tenant, Diciclo isolates the control and data I/O path at user level and runs dedicated storage systems. Diciclo includes the libservice unified user-level abstraction of system services and the node structure design pattern for the application and server side. We prototyped a toolkit of user-level components that comprise the library to invoke the standard I/O calls, the I/O communication mechanism, and the I/O services. Based on Diciclo, we built Danaus, a filesystem client that integrates a union filesystem with a Ceph distributed filesystem client and configurable shared cache. Across different host configurations, workloads, and systems, Danaus achieves improved performance stability, because it handles I/O with reserved per-tenant resources and avoids intensive kernel locking. Based on having built and evaluated Danaus, we share valuable lessons about resource contention, file management, service separation, and performance stability in multitenant systems. © 2024 Copyright held by the owner/author(s).",Additional Key Words and PhrasesUser-level services; concurrent queues; container storage; memory copy; notification,Cost effectiveness; Digital storage; File organization; System stability; Additional key word and phrasesuser-level service; Concurrent queue; Container storage; Input-output; Key words; Memory copy; Multi tenants; Notification; Resource contention; User levels; Containers
Hardware-Software Collaborative Tiered-Memory Management Framework for Virtualization,2024,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193460507&doi=10.1145%2f3639564&partnerID=40&md5=ca2752b652805743ff157f516268a04a,"The tiered-memory system can effectively expand the memory capacity for virtual machines (VMs). However, virtualization introduces new challenges specifically in enforcing performance isolation, minimizing context switching, and providing resource overcommit. None of the state-of-the-art designs consider virtualization and address these challenges; we observe that a VM with tiered memory incurs up to a 2× slowdown compared to a DRAM-only VM.We propose vTMM, a hardware-software collaborative tiered-memory management framework for virtualization. A key insight in vTMM is to leverage the unique system features in virtualization to meet the above challenges. vTMM automatically determines page hotness and migrates pages between fast and slow memory to achieve better performance. Specially, vTMM optimizes page tracking and migration based on page-modification logging (PML), a hardware-assisted virtualization mechanism, and adaptively distinguishes hot/cold pages through the page ""temperature""sorting. vTMM also dynamically adjusts fast memory among multi-VMs on demand by using a memory pool. Further, vTMM tracks huge pages at regular-page granularity in hardware and splits/merges pages in software, realizing hybrid-grained page management and optimization. We implement and evaluate vTMM with single-grained page management on an Intel processor, and the hybrid-grained page management on a Sunway processor with hardware mode supporting hardware/software co-designs. Experiments show that vTMM outperforms existing tiered-memory management designs in virtualization. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Additional Key Words and PhrasesTiered memory; hardware and software co-design; PML; virtual machine,Dynamic random access storage; Hardware-software codesign; Integrated circuit design; Network security; Virtual machine; Virtual reality; Additional key word and phrasestiered memory; Co-designs; Hardware and software; Hardware and software co-design; Hardware/software; Key words; Management frameworks; Memory-management; Page-modification logging; Virtualizations; Virtualization
Modeling the Interplay between Loop Tiling and Fusion in Optimizing Compilers Using Affine Relations,2024,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183313243&doi=10.1145%2f3635305&partnerID=40&md5=128ee466b0983d23f3a28e4f2f384512,"Loop tiling and fusion are two essential transformations in optimizing compilers to enhance the data locality of programs. Existing heuristics either perform loop tiling and fusion in a particular order, missing some of their profitable compositions, or execute ad-hoc implementations for domain-specific applications, calling for a generalized and systematic solution in optimizing compilers. In this article, we present a so-called basteln (an abbreviation for backward slicing of tiled loop nests) strategy in polyhedral compilation to better model the interplay between loop tiling and fusion. The basteln strategy first groups loop nests by preserving their parallelism/tilability and next performs rectangular/parallelogram tiling to the output groups that produce data consumed outside the considered program fragment. The memory footprints required by each tile are then computed, from which the upward exposed data are extracted to determine the tile shapes of the remaining fusion groups. Such a tiling mechanism can construct complex tile shapes imposed by the dependences between these groups, which are further merged by a post-tiling fusion algorithm for enhancing data locality without losing the parallelism/tilability of the output groups. The basteln strategy also takes into account the amount of redundant computations and the fusion of independent groups, exhibiting a general applicability. We integrate the basteln strategy into two optimizing compilers, with one a general-purpose optimizer and the other a domain-specific compiler for deploying deep learning models. The experiments are conducted on CPU, GPU, and a deep learning accelerator to demonstrate the effectiveness of the approach for a wide class of application domains, including deep learning, image processing, sparse matrix computation, and linear algebra. In particular, the basteln strategy achieves a mean speedup of 1.8× over cuBLAS/cuDNN and 1.1× over TVM on GPU when used to optimize deep learning models; it also outperforms PPCG and TVM by 11% and 20%, respectively, when generating code for the deep learning accelerator.  © 2024 Copyright held by the owner/author(s).",data locality; fusion; memory hierarchy; optimizing compilers; parallelism; polyhedral model; redundant computation; Tiling,Deep learning; Image processing; Learning systems; Matrix algebra; Optimization; Parallel programming; Backward slicing; Data locality; Loop nests; Loop tiling; Memory hierarchy; Optimizing compilers; Parallelism; Polyhedral models; Redundant computation; Tiling; Program compilers
Partial Network Partitioning,2023,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183317969&doi=10.1145%2f3576192&partnerID=40&md5=76a674f15e1234990f8585bff1072c6e,"We present an extensive study focused on partial network partitioning. Partial network partitions disrupt the communication between some but not all nodes in a cluster. First, we conduct a comprehensive study of system failures caused by this fault in 13 popular systems. Our study reveals that the studied failures are catastrophic (e.g., lead to data loss), easily manifest, and are mainly due to design flaws. Our analysis identifies vulnerabilities in core systems mechanisms including scheduling, membership management, and ZooKeeper-based configuration management. Second, we dissect the design of nine popular systems and identify four principled approaches for tolerating partial partitions. Unfortunately, our analysis shows that implemented fault tolerance techniques are inadequate for modern systems they either patch a particular mechanism or lead to a complete cluster shutdown, even when alternative network paths exist. Finally, our findings motivate us to build Nifty, a transparent communication layer that masks partial network partitions. Nifty builds an overlay between nodes to detour packets around partial partitions. Nifty provides an approach for applications to optimize their operation during a partial partition. We demonstrate the benefit of this approach through integrating Nifty with VoltDB, HDFS, and Kafka.  © 2023 Association for Computing Machinery.",distributed systems; fault tolerance; Network failures; partial network partitions; reliability,Network security; Configuration management; Core systems; Data loss; Distributed systems; Membership management; Network failure; Network partitioning; Network partitions; Partial network partition; System failures; Fault tolerance
Symphony: Orchestrating Sparse and Dense Tensors with Hierarchical Heterogeneous Processing,2023,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183316769&doi=10.1145%2f3630007&partnerID=40&md5=2d6920d62fd39ea3d6703feb18b2849d,"Sparse tensor algorithms are becoming widespread, particularly in the domains of deep learning, graph and data analytics, and scientific computing. Current high-performance broad-domain architectures, such as GPUs, often suffer memory system inefficiencies by moving too much data or moving it too far through the memory hierarchy. To increase performance and efficiency, proposed domain-specific accelerators tailor their architectures to the data needs of a narrow application domain, but as a result cannot be applied to a wide range of algorithms or applications that contain a mix of sparse and dense algorithms. This article proposes Symphony, a hybrid programmable/specialized architecture that focuses on the orchestration of data throughout the memory hierarchy to simultaneously reduce the movement of unnecessary data and data movement distances. Key elements of the Symphony architecture include (1) specialized reconfigurable units aimed not only at roofline floating-point computations but also at supporting data orchestration features, such as address generation, data filtering, and sparse metadata processing and (2) distribution of computation resources (both programmable and specialized) throughout the on-chip memory hierarchy. We demonstrate that Symphony can match non-programmable ASIC perfor mance on sparse tensor algebra and provide 31× improved runtime and 44× improved energy over a comparably provisioned GPU for these applications.  © 2023 Copyright held by the owner/author(s).",accelerators; data orchestration; Sparse tensor algebra,Data Analytics; Graphics processing unit; Memory architecture; Program processors; Reconfigurable architectures; Tensors; Data orchestration; Graph-analytic; Heterogeneous processing; Learning data; Learning graphs; Memory hierarchy; Performance; Sparse tensor algebra; Sparse tensors; Tensor algebra; Deep learning
Filesystem Fragmentation on Modern Storage Systems,2023,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183316371&doi=10.1145%2f3611386&partnerID=40&md5=859ed1bbb47cc8b833e87a96275bcbee,"Filesystem fragmentation has been one of the primary reasons for computer systems to get slower over time. However, there have been rapid changes in modern storage systems over the past decades, and modern storage devices such as solid state drives have different mechanisms to access data, compared with traditional rotational ones. In this article, we revisit filesystem fragmentation on modern computer systems from both performance and fairness perspectives. According to our extensive experiments, filesystem fragmentation not only degrades I/O performance of modern storage devices, but also incurs various problems related to I/O fairness, such as performance interference. Unfortunately, conventional defragmentation tools are designed primarily for hard disk drives and thus generate an unnecessarily large amount of I/Os for data migration. To mitigate such problems, this article present FragPicker, a new defragmentation tool for modern storage devices. FragPicker analyzes the I/O behaviors of each target application and defragments only necessary pieces of data whose migration can contribute to performance improvement, thereby effectively minimizing the I/O amount for defragmentation. Our evaluation with YCSB workload-C shows FragPicker reduces the total amount of I/O for defragmentation by around 66% and the elapsed time by around 84%, while showing a similar level of defragmentation effect. © 2023 Association for Computing Machinery. All rights reserved.",Filesystem fragmentation; Linux I/O stack; storage systems,File organization; Hard disk storage; Linux; De-fragmentation; Different mechanisms; Filesystem; Filesystem fragmentation; Hard Disk Drive; Large amounts; Linux I/O stack; Modern computer systems; Performance; Storage systems; Virtual storage
Charlotte: Reformulating Blockchains into a Web of Composable Attested Data Structures for Cross-Domain Applications,2023,ACM Transactions on Computer Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183329532&doi=10.1145%2f3607534&partnerID=40&md5=15e30b3514e580e6ab2eeba61cc26465,"Cross-domain applications are rapidly adopting blockchain techniques for immutability, availability, integrity, and interoperability. However, for most applications, global consensus is unnecessary and may not even provide sufficient guarantees. We propose a new distributed data structure: Attested Data Structures (ADS), which generalize not only blockchains but also many other structures used by distributed applications. As in blockchains, data in ADSs is immutable and self-authenticating. ADSs go further by supporting application-defined proofs (attestations). Attestations enable applications to plug in their own mechanisms to ensure availability and integrity. We present Charlotte, a framework for composable ADSs. Charlotte deconstructs conventional blockchains into more primitive mechanisms. Charlotte can be used to construct blockchains but does not impose the usual global-ordering overhead. Charlotte offers a flexible foundation for interacting applications that define their own policies for availability and integrity. Unlike traditional distributed systems, Charlotte supports heterogeneous trust: different observers have their own beliefs about who might fail, and how. Nevertheless, each observer has a consistent, available view of data. Charlotte's data structures are interoperable and composable: applications and data structures can operate fully independently or can share data when desired. Charlotte defines a language-independent format for data blocks and a network API for servers. To demonstrate Charlotte's flexibility, we implement several integrity mechanisms, including consensus and proof of work. We explore the power of disentangling availability and integrity mechanisms in prototype applications. The results suggest that Charlotte can be used to build flexible, fast, composable applications with strong guarantees.  © 2023 Copyright held by the owner/author(s).",authenticated data structure; Blockchain; DAG; distributed systems,Data structures; Interoperability; Authenticated data structures; Availability and integrities; Block-chain; Composable; Cross-domain; DAG; Distributed applications; Distributed data structures; Distributed systems; Plug-ins; Blockchain
