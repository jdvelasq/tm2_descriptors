Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
Multi-donor Neural Transfer Learning for Genetic Programming,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177877531&doi=10.1145%2f3563043&partnerID=40&md5=31fd36691c9c57fb6ad64ef7624eb215,"Genetic programming (GP), for the synthesis of brand new programs, continues to demonstrate increasingly capable results towards increasingly complex problems. A key challenge in GP is how to learn from the past so that the successful synthesis of simple programs can feed into more challenging unsolved problems. Transfer Learning (TL) in the literature has yet to demonstrate an automated mechanism to identify existing donor programs with high-utility genetic material for new problems, instead relying on human guidance. In this article we present a transfer learning mechanism for GP which fills this gap: we use a Turing-complete language for synthesis, and demonstrate how a neural network (NN) can be used to guide automated code fragment extraction from previously solved problems for injection into future problems. Using a framework which synthesises code from just 10 input-output examples, we first study NN ability to recognise the presence of code fragments in a larger program, then present an end-to-end system which takes only input-output examples and generates code fragments as it solves easier problems, then deploys selected high-utility fragments to solve harder ones. The use of NN-guided genetic material selection shows significant performance increases, on average doubling the percentage of programs that can be successfully synthesised when tested on two different problem corpora, compared with a non-transfer-learning GP baseline. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",genetic algorithms; Genetic programming; neural networks; transfer learning,Genetic programming; Code fragments; Complex problems; Genetic materials; Input-output; Learn+; Neural-networks; New projects; Simple++; Transfer learning; Unsolved problems; artificial neural network; automation; genetic algorithm; input-output analysis; performance assessment; Genetic algorithms
AutoML Loss Landscapes,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149661110&doi=10.1145%2f3558774&partnerID=40&md5=07af026802ac5b7fd152f7e570f8c1ee,"As interest in machine learning and its applications becomes more widespread, how to choose the best models and hyper-parameter settings becomes more important. This problem is known to be challenging for human experts, and consequently, a growing number of methods have been proposed for solving it, giving rise to the area of automated machine learning (AutoML). Many of the most popular AutoML methods are based on Bayesian optimization, which makes only weak assumptions about how modifying hyper-parameters effects the loss of a model. This is a safe assumption that yields robust methods, as the AutoML loss landscapes that relate hyper-parameter settings to loss are poorly understood. We build on recent work on the study of one-dimensional slices of algorithm configuration landscapes by introducing new methods that test n-dimensional landscapes for statistical deviations from uni-modality and convexity, and we use them to show that a diverse set of AutoML loss landscapes are highly structured. We introduce a method for assessing the significance of hyper-parameter partial derivatives, which reveals that most (but not all) AutoML loss landscapes only have a small number of hyper-parameters that interact strongly. To further assess hyper-parameter interactions, we introduce a simplistic optimization procedure that assumes each hyper-parameter can be optimized independently, a single time in sequence, and we show that it obtains configurations that are statistically tied with optimal in all of the n-dimensional AutoML loss landscapes that we studied. Our results suggest many possible new directions for substantially improving the state of the art in AutoML. © 2022 Association for Computing Machinery.",AutoML; hyper-parameter optimization; Landscape analysis,Automated machine learning; Automated machines; Best model; Hyper-parameter; Hyper-parameter optimizations; ITS applications; Landscape analysis; Machine learning applications; Machine-learning; Parameter-setting; algorithm; Bayesian analysis; landscape; machine learning; one-dimensional modeling; optimization; Machine learning
Analysis of Evolutionary Diversity Optimization for Permutation Problems,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167678283&doi=10.1145%2f3561974&partnerID=40&md5=835143ad821e53cb72094c11a0e8e9c8,"Generating diverse populations of high-quality solutions has gained interest as a promising extension to the traditional optimization tasks. This work contributes to this line of research with an investigation on evolutionary diversity optimization for three of the most well-studied permutation problems: the Traveling Salesperson Problem (TSP), both symmetric and asymmetric variants, and the Quadratic Assignment Problem (QAP). It includes an analysis of the worst-case performance of a simple mutation-only evolutionary algorithm with different mutation operators, using an established diversity measure. Theoretical results show that many mutation operators for these problems guarantee convergence to maximally diverse populations of sufficiently small size within cubic to quartic expected runtime. On the other hand, the results regarding QAP suggest that strong mutations give poor worst-case performance, as mutation strength contributes exponentially to the expected runtime. Additionally, experiments are carried out on QAPLIB and synthetic instances in unconstrained and constrained settings, and reveal much more optimistic practical performances while corroborating the theoretical findings regarding mutation strength. These results should serve as a baseline for future studies. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",diversity maximization; Evolutionary algorithms; quadratic assignment problem; runtime analysis; traveling salesperson problem,Combinatorial optimization; Traveling salesman problem; Diversity maximization; Evolutionary diversity; Mutation operators; Optimisations; Permutation problems; Quadratic assignment problems; Run-time analysis; Runtimes; Traveling salesperson problem; Worst-case performance; algorithm; computer simulation; data quality; evolution; experimental study; future prospect; mathematical analysis; numerical model; optimization; performance assessment; research work; theoretical study; Evolutionary algorithms
On the Design of a Matrix Adaptation Evolution Strategy for Optimization on General Quadratic Manifolds,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169024438&doi=10.1145%2f3551394&partnerID=40&md5=07ad659358ca885eb52e53b21d2499e3,"An evolution strategy design is presented that allows for an evolution on general quadratic manifolds. That is, it covers elliptic, parabolic, and hyperbolic equality constraints. The peculiarity of the presented algorithm design is that it is an interior point method. It evaluates the objective function only for feasible search parameter vectors and it evolves itself on the nonlinear constraint manifold. Such a characteristic is particularly important in situations where it is not possible to evaluate infeasible parameter vectors, e.g., in simulation-based optimization. This is achieved by a closed form transformation of an individual's parameter vector, which is in contrast to iterative repair mechanisms. This constraint handling approach is incorporated into a matrix adaptation evolution strategy making such algorithms capable of handling problems containing the constraints considered. Results of different experiments are presented. A test problem consisting of a spherical objective function and a single hyperbolic/parabolic equality constraint is used. It is designed to be scalable in the dimension. As a further benchmark, the Thomson problem is used. Both problems are used to compare the performance of the developed algorithm with other optimization methods supporting constraints. The experiments show the effectiveness of the proposed algorithm on the considered problems. Additionally, an idea for handling multiple constraints is discussed. And for a better understanding of the dynamical behavior of the proposed algorithm, single run dynamics are presented. © 2022 Association for Computing Machinery.",constraint handling by repair; elliptic constraint; hyperbolic constraint; Matrix adaptation evolution strategy; nonlinear constraint; parabolic constraint,Constraint handling; Evolutionary algorithms; Hyperbolic functions; Optimization; Repair; Constraint handling; Constraint handling by repair; Elliptic constraint; Evolution strategies; Hyperbolic constraint; matrix; Matrix adaptation evolution strategy; Non-linear constraints; Parabolic constraint; Parabolics; algorithm; design method; optimization; vector; Iterative methods
Deep Genetic Programming Trees Are Robust,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177835616&doi=10.1145%2f3539738&partnerID=40&md5=315a08e25fc15cf798f9c5dcbb30c505,"We sample the genetic programming tree search space and show it is smooth, since many mutations on many test cases have little or no fitness impact. We generate uniformly at random high-order polynomials composed of 12,500 and 750,000 additions and multiplications and follow the impact of small changes to them. From information theory, 32 bit floating point arithmetic is dissipative, and even with 1,501 test cases, deep mutations seldom have any impact on fitness. Absolute difference between parent and child evaluation can grow as well as fall further from the code change location, but the number of disrupted fitness tests falls monotonically. In many cases, deeply nested expressions are robust to crossover syntax changes, bugs, errors, run time glitches, perturbations, and so on, because their disruption falls to zero, and so it fails to propagate beyond the program. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",correctness attraction; diversity; error hiding; evolvability; failed disruption propagation; FDP; FEP; GP fitness landscape; Heritability; information funnels; information theory; introns; invisible faults; mutational robustness; neutral networks; sandpile 1/f powerlaw; SBSE; self-organised criticality; self-similar fractal; SOC; software robustness; software testing; theory of bloat,Digital arithmetic; Genetic algorithms; Information theory; Petroleum reservoir evaluation; Program debugging; Software testing; Correctness attraction; Diversity; Error hiding; Evolvability; Failed disruption propagation; FDP; FEP; Fitness landscape; GP fitness landscape; Heritability; Information funnel; Intron; Invisible fault; Mutational robustness; Neutral network; Power-law; Sandpile 1/f powerlaw; SBSE; Self-organized criticality; Self-similar fractals; SOC; Software robustness; Software testings; Theory of bloat; correction; diversity index; foreign direct investment; genetic analysis; mutation; tree; Genetic programming
Analysis of Evolved Response Thresholds for Decentralized Dynamic Task Allocation,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177847959&doi=10.1145%2f3530821&partnerID=40&md5=c70486ad9f6f47ae42b686bdf119d760,"In this work, we investigate the application of a multi-objective genetic algorithm to the problem of task allocation in a self-organizing, decentralized, threshold-based swarm. We use a multi-objective genetic algorithm to evolve response thresholds for a simulated swarm engaged in dynamic task allocation problems: two-dimensional and three-dimensional collective tracking. We show that evolved thresholds not only outperform uniformly distributed thresholds and dynamic thresholds but achieve nearly optimal performance on a variety of tracking problem instances (target paths). More importantly, we demonstrate that thresholds evolved for some problem instances generalize to all other problem instances, eliminating the need to evolve new thresholds for each problem instance to be solved. We analyze the properties that allow these paths to serve as universal training instances and show that they are quite natural.After a priori evolution, the response thresholds in our system are static. The problem instances solved by the swarms are highly dynamic, with schedules of task demands that change over time with significant differences in rate and magnitude of change. That the swarm is able to achieve nearly optimal results refutes the common assumption that a swarm must be dynamic to perform well in a dynamic environment. © 2022 Association for Computing Machinery.",generalization; Inter-agent variation; response thresholds,Allocation problems; Decentralised; Dynamic task allocation; Generalisation; Inter-agent variation; Multi-objectives genetic algorithms; Problem instances; Response threshold; Self-organising; Task allocation; computer simulation; genetic algorithm; threshold; Genetic algorithms
A Survey on High-dimensional Gaussian Process Modeling with Application to Bayesian Optimization,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139906022&doi=10.1145%2f3545611&partnerID=40&md5=4300827877f3a690f2d6e84a45c43c79,"Bayesian Optimization (BO), the application of Bayesian function approximation to finding optima of expensive functions, has exploded in popularity in recent years. In particular, much attention has been paid to improving its efficiency on problems with many parameters to optimize. This attention has trickled down to the workhorse of high-dimensional BO, high-dimensional Gaussian process regression, which is also of independent interest. The great flexibility that the Gaussian process prior implies is a boon when modeling complicated, low-dimensional surfaces but simply says too little when dimension grows too large. A variety of structural model assumptions have been tested to tame high dimensions, from variable selection and additive decomposition to low-dimensional embeddings and beyond. Most of these approaches in turn require modifications of the acquisition function optimization strategy as well. Here, we review the defining structural model assumptions and discuss the benefits and drawbacks of these approaches in practice. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",active subspace; additivity; Black-box optimization; low-intrinsic dimensionality; variable selection,Gaussian noise (electronic); Optimization; Active subspace; Additivity; Bayesian optimization; Black-box optimization; High-dimensional; Higher-dimensional; Intrinsic dimensionalities; Low-intrinsic dimensionality; Structural modeling; Variables selections; Bayesian analysis; Gaussian method; modeling; optimization; Gaussian distribution
Code and Data Synthesis for Genetic Improvement in Emergent Software Systems,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177882325&doi=10.1145%2f3542823&partnerID=40&md5=657cf2dc2152f5cdf8b4898e7ad58168,"Emergent software systems are assembled from a collection of small code blocks, where some of those blocks have alternative implementation variants; they optimise at run-time by learning which compositions of alternative blocks best suit each deployment environment encountered.In this paper we study the automated synthesis of new implementation variants for a running system using genetic improvement (GI). Typical GI approaches, however, rely on large amounts of data for accurate training and large code bases from which to source genetic material. In emergent systems we have neither asset, with sparsely sampled runtime data and small code volumes in each building block.We therefore examine two approaches to more effective GI under these constraints: the synthesis of data from sparse samples to construct statistically representative larger training corpora; and the synthesis of code to counter the relative lack of genetic material in our starting population members.Our results demonstrate that a mixture of synthesised and existing code is a viable optimisation strategy, and that phases of increased synthesis can make GI more robust to deleterious mutations. On synthesised data, we find that we can produce equivalent optimisation compared to GI methods using larger data sets, and that this optimisation can produce both useful specialists and generalists. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",data sampling; data synthesis; emergent systems; fitness function; Genetic improvement; language; optimization,Computer software; Population statistics; Data sampling; Data synthesis; Emergent system; Fitness functions; Genetic improvements; Genetic materials; Language; Optimisations; Software-systems; Synthesised; data set; language; optimization; sampling; software; Personnel training
IOHanalyzer: Detailed Performance Analyses for Iterative Optimization Heuristics,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174274837&doi=10.1145%2f3510426&partnerID=40&md5=7e71fe82c278c1c91c9c6d0adf7aaaca,"Benchmarking and performance analysis play an important role in understanding the behaviour of iterative optimization heuristics (IOHs) such as local search algorithms, genetic and evolutionary algorithms, Bayesian optimization algorithms, etc. This task, however, involves manual setup, execution, and analysis of the experiment on an individual basis, which is laborious and can be mitigated by a generic and well-designed platform. For this purpose, we propose IOHanalyzer, a new user-friendly tool for the analysis, comparison, and visualization of performance data of IOHs.Implemented in R and C++, IOHanalyzer is fully open source. It is available on CRAN and GitHub. IOHanalyzer provides detailed statistics about fixed-target running times and about fixed-budget performance of the benchmarked algorithms with a real-valued codomain, single-objective optimization tasks. Performance aggregation over several benchmark problems is possible, for example in the form of empirical cumulative distribution functions. Key advantages of IOHanalyzer over other performance analysis packages are its highly interactive design, which allows users to specify the performance measures, ranges, and granularity that are most useful for their experiments, and the possibility to analyze not only performance traces, but also the evolution of dynamic state parameters.IOHanalyzer can directly process performance data from the main benchmarking platforms, including the COCO platform, Nevergrad, the SOS platform, and IOHexperimenter. An R programming interface is provided for users preferring to have a finer control over the implemented functionalities.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",black-box optimization; Evolutionary computation; performance analysis,Budget control; C++ (programming language); Data visualization; Distribution functions; Genetic algorithms; Iterative methods; Open source software; Bayesian optimization algorithms; Black-box optimization; Iterative Optimization; Local search algorithm; Manual analysis; Manual setups; Optimization heuristics; Performance; Performance data; Performances analysis; algorithm; Bayesian analysis; benchmarking; experimental study; optimization; Benchmarking
Reusability and Transferability of Macro Actions for Reinforcement Learning,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174231800&doi=10.1145%2f3514260&partnerID=40&md5=eee8e328a009d2dd2588b3ee19751828,"Conventional reinforcement learning (RL) typically determines an appropriate primitive action at each timestep. However, by using a proper macro action, defined as a sequence of primitive actions, an RL agent is able to bypass intermediate states to a farther state and facilitate its learning procedure. The problem we would like to investigate is what associated beneficial properties that macro actions may possess. In this article, we unveil the properties of reusability and transferability of macro actions. The first property, reusability, means that a macro action derived along with one RL method can be reused by another RL method for training, while the second one, transferability, indicates that a macro action can be utilized for training agents in similar environments with different reward settings. In our experiments, we first derive macro actions along with RL methods. We then provide a set of analyses to reveal the properties of reusability and transferability of the derived macro actions.  © 2022 Association for Computing Machinery.",genetic algorithm; macro actions; Reinforcement learning; reusability; transferability,Genetic algorithms; Learning algorithms; Reinforcement learning; Conventional reinforcement learning; Intermediate state; Macro action; Primitive actions; Property; Reinforcement learning agent; Reinforcement learning method; Reinforcement learnings; Time step; Transferability; genetic algorithm; machine learning; Reusability
Saddle Point Optimization with Approximate Minimization Oracle and Its Application to Robust Berthing Control,2022,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135249293&doi=10.1145%2f3510425&partnerID=40&md5=776323187e28f6b35d63e0122fe81231,"We propose an approach to saddle point optimization relying only on oracles that solve minimization problems approximately. We analyze its convergence property on a strongly convex-concave problem and show its linear convergence toward the global min-max saddle point. Based on the convergence analysis, we develop a heuristic approach to adapt the learning rate. An implementation of the developed approach using the (1+1)-CMA-ES as the minimization oracle, namely, Adversarial-CMA-ES, is shown to outperform several existing approaches on test problems. Numerical evaluation confirms the tightness of the theoretical convergence rate bound as well as the efficiency of the learning rate adaptation mechanism. As an example of real-world problems, the suggested optimization method is applied to automatic berthing control problems under model uncertainties, showing its usefulness in obtaining solutions robust to uncertainty.  © 2022 Association for Computing Machinery.",automatic berthing; convergence analysis; Minimax optimization; reliability; robust control; robust optimization; saddle point optimization; zero-order approach,Heuristic methods; Learning algorithms; Petroleum reservoir evaluation; Reliability analysis; Robust control; Uncertainty analysis; Automatic berthing; Convergence analysis; Minimax optimization; Minimisation; Optimisations; Robust optimization; Saddle point; Saddle point optimization; Zero order; Zero-order approach; computer simulation; convergence; machine learning; numerical model; optimization; reliability analysis; uncertainty analysis; Optimization
A Learning-based Innovized Progress Operator for Faster Convergence in Evolutionary Multi-objective Optimization,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132826791&doi=10.1145%2f3474059&partnerID=40&md5=7cc2aa081709d7217323adaac3b1d4c1,"Learning effective problem information from already explored search space in an optimization run, and utilizing it to improve the convergence of subsequent solutions, have represented important directions in Evolutionary Multi-objective Optimization (EMO) research. In this article, a machine learning (ML)-Assisted approach is proposed that: (a) maps the solutions from earlier generations of an EMO run to the current non-dominated solutions in the decision space; (b) learns the salient patterns in the mapping using an ML method, here an artificial neural network (ANN); and (c) uses the learned ML model to advance some of the subsequent offspring solutions in an adaptive manner. Such a multi-pronged approach, quite different from the popular surrogate-modeling methods, leads to what is here referred to as the Innovized Progress (IP) operator. On several test and engineering problems involving two and three objectives, with and without constraints, it is shown that an EMO algorithm assisted by the IP operator offers faster convergence behavior, compared to its base version independent of the IP operator. The results are encouraging, pave a new path for the performance improvement of EMO algorithms, and set the motivation for further exploration on more challenging problems.  © 2021 Association for Computing Machinery.",artificial neural networks; innovization; learning-based optimization; Multiobjective optimization; online innovization,E-learning; Evolutionary algorithms; Internet protocols; Neural networks; Evolutionary multiobjective optimization; Fast convergence; Innovization; Learning-based optimization; Multi-objectives optimization; Online innovization; Optimisations; Optimization algorithms; Search spaces; algorithm; artificial neural network; comparative study; machine learning; optimization; surrogate method; Multiobjective optimization
Efficient Computation of Probabilistic Dominance in Multi-objective Optimization,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174716289&doi=10.1145%2f3469801&partnerID=40&md5=962741b1d7f8f83641ae81167fe8ef37,"Real-world problems typically require the simultaneous optimization of multiple, often conflicting objectives. Many of these multi-objective optimization problems are characterized by wide ranges of uncertainties in their decision variables or objective functions. To cope with such uncertainties, stochastic and robust optimization techniques are widely studied aiming to distinguish candidate solutions with uncertain objectives specified by confidence intervals, probability distributions, sampled data, or uncertainty sets. In this scope, this article first introduces a novel empirical approach for the comparison of candidate solutions with uncertain objectives that can follow arbitrary distributions. The comparison is performed through accurate and efficient calculations of the probability that one solution dominates the other in terms of each uncertain objective. Second, such an operator can be flexibly used and combined with many existing multi-objective optimization frameworks and techniques by just substituting their standard comparison operator, thus easily enabling the Pareto front optimization of problems with multiple uncertain objectives. Third, a new benchmark for evaluating uncertainty-aware optimization techniques is introduced by incorporating different types of uncertainties into a well-known benchmark for multi-objective optimization problems. Fourth, the new comparison operator and benchmark suite are integrated into an existing multi-objective optimization framework that features a selection of multi-objective optimization problems and algorithms. Fifth, the efficiency in terms of performance and execution time of the proposed comparison operator is evaluated on the introduced uncertainty benchmark. Finally, statistical tests are applied giving evidence of the superiority of the new comparison operator in terms of -dominance and attainment surfaces in comparison to previously proposed approaches. © 2021 Association for Computing Machinery.",comparison operator; Multi-objective optimization; probabilistic dominance; uncertainty,Benchmarking; Probability distributions; Stochastic systems; Comparison operators; Efficient computation; Multi-objective optimization problem; Multi-objectives optimization; Optimization framework; Optimization techniques; Probabilistic dominance; Probabilistics; Real-world problem; Uncertainty; benchmarking; data set; optimization; probability; statistical analysis; uncertainty analysis; Multiobjective optimization
Reproducibility in Evolutionary Computation,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126856638&doi=10.1145%2f3466624&partnerID=40&md5=ac52c1597fa6be0652ec3e9a1e388faf,"Experimental studies are prevalent in Evolutionary Computation (EC), and concerns about the reproducibility and replicability of such studies have increased in recent times, reflecting similar concerns in other scientific fields. In this article, we discuss, within the context of EC, the different types of reproducibility and suggest a classification that refines the badge system of the Association of Computing Machinery (ACM) adopted by ACM Transactions on Evolutionary Learning and Optimization (TELO). We identify cultural and technical obstacles to reproducibility in the EC field. Finally, we provide guidelines and suggest tools that may help to overcome some of these reproducibility obstacles. © 2021 Association for Computing Machinery.",benchmarking; empirical study; Evolutionary computation; reproducibility,Association of computing machineries; Empirical studies; Evolutionary Learning; Evolutionary optimizations; Replicability; Reproducibilities; Scientific fields; benchmarking; empirical analysis; evolutionary theory; experimental study
Precise Runtime Analysis for Plateau Functions,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128127985&doi=10.1145%2f3469800&partnerID=40&md5=7938cfdd4a98f74598ec6a01d2b5ce34,"To gain a better theoretical understanding of how evolutionary algorithms (EAs) cope with plateaus of constant fitness, we propose the n-dimensional Plateauk function as natural benchmark and analyze how different variants of the (1 + 1) EA optimize it. The Plateauk function has a plateau of second-best fitness in a ball of radius k around the optimum. As evolutionary algorithm, we regard the (1 + 1) EA using an arbitrary unbiased mutation operator. Denoting by α the random number of bits flipped in an application of this operator and assuming that Pr [α = 1] has at least some small sub-constant value, we show the surprising result that for all constant k ≥ 2, the runtime T follows a distribution close to the geometric one with success probability equal to the probability to flip between 1 and k bits divided by the size of the plateau. Consequently, the expected runtime is the inverse of this number, and thus only depends on the probability to flip between 1 and k bits, but not on other characteristics of the mutation operator. Our result also implies that the optimal mutation rate for standard bit mutation here is approximately k/(en). Our main analysis tool is a combined analysis of the Markov chains on the search point space and on the Hamming level space, an approach that promises to be useful also for other plateau problems. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",plateaus; Runtime analysis; theory,Inverse problems; Markov processes; Probability distributions; Constant values; K-function; Mutation operators; Mutation rates; Optimal mutation; Plateau; Random Numbers; Run-time analysis; Runtimes; Theory; algorithm; Markov chain; plateau; theory; Evolutionary algorithms
A Survey on Recent Progress in the Theory of Evolutionary Algorithms for Discrete Optimization,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177835824&doi=10.1145%2f3472304&partnerID=40&md5=5b7d6e321a3aed4c7bae7bee13196f13,"The theory of evolutionary computation for discrete search spaces has made significant progress since the early 2010s. This survey summarizes some of the most important recent results in this research area. It discusses fine-grained models of runtime analysis of evolutionary algorithms, highlights recent theoretical insights on parameter tuning and parameter control, and summarizes the latest advances for stochastic and dynamic problems. We regard how evolutionary algorithms optimize submodular functions, and we give an overview over the large body of recent results on estimation of distribution algorithms. Finally, we present the state of the art of drift analysis, one of the most powerful analysis technique developed in this field. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",discrete optimization; estimation of distribution algorithms; evolutionary algorithms; parameterized complexity; Theory,Computational complexity; Optimization; Parameter estimation; Stochastic models; Stochastic systems; Discrete optimization; Distribution algorithms; Estimation of distribution algorithm; Estimation of distributions; Fine grained; Parameterized complexity; Recent progress; Research areas; Search spaces; Theory; algorithm; estimation method; optimization; parameterization; stochasticity; survey method; Evolutionary algorithms
A Comparison of Learning Classifier Systems' Rule Compaction Algorithms for Knowledge Visualization,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124781961&doi=10.1145%2f3468166&partnerID=40&md5=563999bcf89d2332f4082126a5e74d00,"Learning Classifier Systems (LCSs) are a paradigm of rule-based evolutionary computation (EC). LCSs excel in data-mining tasks regarding helping humans to understand the explored problem, often through visualizing the discovered patterns linking features to classes. Due to the stochastic nature of EC, LCSs unavoidably produce and keep redundant rules, which obscure the patterns. Thus, rule compaction methods are invoked to produce a better population by removing problematic rules. Previously, compaction methods have neither been tested on large-scale problems nor been assessed on the performance of capturing patterns. We review and test the most popular compaction algorithms, finding that across multiple LCSs' populations for the same task, although the redundant rules can be different, the accurate rules are common. Furthermore, the patterns contained consistently refer to the nature of the explored domain, e.g., the data distribution or the importance of features for determining actions. This extends the [O] set hypothesis proposed by Butz et al. [1], in which an LCS is expected to evolve a minimal number of non-overlapped rules to represent an addressed domain. Two new compaction algorithms are introduced to search at the rule level and the population level by compacting multiple LCSs' populations. Two visualization methods are employed for verifying the interpretability of these populations. Successful compaction is demonstrated on complex and real problems with clean datasets, e.g., the 11-bits Majority-On problem that requires 924 different interacting rules in the optimal solution to be uniquely identified to enable correct visualization. For the first time, the patterns contained in learned models for the large-scale 70-bits Multiplexer problem are visualized successfully. © 2021 Association for Computing Machinery.",Learning classifier systems; pattern visualization; rule compaction algorithms,Compaction; Data mining; Learning algorithms; Learning systems; Stochastic systems; Visualization; Compaction algorithms; Compaction methods; Data mining tasks; Excel; Knowledge Visualization; Learning classifier system; Pattern visualization; Redundant rules; Rule based; Rule compaction algorithm; algorithm; comparative study; data mining; machine learning; visualization; Evolutionary algorithms
"Is Our Archiving Reliable? Multiobjective Archiving Methods on ""Simple"" Artificial Input Sequences",2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124681454&doi=10.1145%2f3465335&partnerID=40&md5=93a99a0f10044d95b60b8cf2b057a9cf,"In evolutionary multiobjective optimisation (EMO), archiving is a common component that maintains an (external or internal) set during the search process, typically with a fixed size, in order to provide a good representation of high-quality solutions produced. Such an archive set can be used solely to store the final results shown to the decision maker, but in many cases may participate in the process of producing solutions (e.g., as a solution pool where the parental solutions are selected). Over the last three decades, archiving stands as an important issue in EMO, leading to the emergence of various methods such as those based on Pareto, indicator, or decomposition criteria. Such methods have demonstrated their effectiveness in literature and have been believed to be good options to many problems, particularly those having a regular Pareto front shape, e.g., a simplex shape. In this article, we challenge this belief. We do this through artificially constructing several sequences with extremely simple shapes, i.e., 1D/2D simplex Pareto front. We show the struggle of predominantly used archiving methods which have been deemed to well handle such shapes. This reveals that the order of solutions entering the archive matters, and that current EMO algorithms may not be fully capable of maintaining a representative population on problems with linear Pareto fronts even in the case that all of their optimal solutions can be found. © 2021 Association for Computing Machinery.",archiving; deterioration; elitism; Multiobjective optimisation; population maintenance,Decision making; Evolutionary algorithms; Multiobjective optimization; Archiving; Elitism; Evolutionary multiobjective optimization; Input sequence; Multi objective; Multi-objectives optimization; Pareto front; Population maintenances; Search process; Simple++; algorithm; decision making; optimization; Deterioration
Constraint-Objective Cooperative Coevolution for Large-scale Constrained Optimization,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120003920&doi=10.1145%2f3469036&partnerID=40&md5=fc44c9047da5b0c27aa2e7c67d21fee2,"Large-scale optimization problems and constrained optimization problems have attracted considerable attention in the swarm and evolutionary intelligence communities and exemplify two common features of real problems, i.e., a large scale and constraint limitations. However, only a little work on solving large-scale continuous constrained optimization problems exists. Moreover, the types of benchmarks proposed for large-scale continuous constrained optimization algorithms are not comprehensive at present. In this article, first, a constraint-objective cooperative coevolution (COCC) framework is proposed for large-scale continuous constrained optimization problems, which is based on the dual nature of the objective and constraint functions: modular and imbalanced components. The COCC framework allocates the computing resources to different components according to the impact of objective values and constraint violations. Second, a benchmark for large-scale continuous constrained optimization is presented, which takes into account the modular nature, as well as both imbalanced and overlapping characteristics of components. Finally, three different evolutionary algorithms are embedded into the COCC framework for experiments, and the experimental results show that COCC performs competitively. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",cooperative coevolution; evolutionary algorithms; Large-scale constrained optimization,Evolutionary algorithms; Common features; Constrained optimi-zation problems; Cooperative co-evolution; Intelligence communities; Large scale constrained optimization; Large-scale optimization; Large-scales; Modulars; Optimization problems; Real problems; algorithm; optimization; Constrained optimization
Emergent Tangled Program Graphs in Partially Observable Recursive Forecasting and ViZDoom Navigation Tasks,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143132611&doi=10.1145%2f3468857&partnerID=40&md5=dc315880a6c77e1b07d3f86510a6ce5e,"Modularity represents a recurring theme in the attempt to scale evolution to the design of complex systems. However, modularity rarely forms the central theme of an artificial approach to evolution. In this work, we report on progress with the recently proposed Tangled Program Graph (TPG) framework in which programs are modules. The combination of the TPG representation and its variation operators enable both teams of programs and graphs of teams of programs to appear in an emergent process. The original development of TPG was limited to tasks with, for the most part, complete information. This work details two recent approaches for scaling TPG to tasks that are dominated by partially observable sources of information using different formulations of indexed memory. One formulation emphasizes the incremental construction of memory, again as an emergent process, resulting in a distributed view of state. The second formulation assumes a single global instance of memory and develops it as a communication medium, thus a single global view of state. The resulting empirical evaluation demonstrates that TPG equipped with memory is able to solve multi-task recursive time-series forecasting problems and visual navigation tasks expressed in two levels of a commercial first-person shooter environment. © 2001 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Coevolution; modularity; partial observability; time series,Co-evolution; Complete information; Graph framework; Graph representation; Modularity; Navigation tasks; Partial observability; Scalings; Times series; Variation operator; forecasting method; navigation; time series analysis; Time series
Genetic Improvement of Data for Maths Functions,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136140448&doi=10.1145%2f3461016&partnerID=40&md5=e6aeb8a25453e3c0014e5d1dbf9907a0,"We use continuous optimisation and manual code changes to evolve up to 1024 Newton-Raphson numerical values embedded in an open source GNU C library glibc square root sqrt to implement a double precision cube root routine cbrt, binary logarithm log2 and reciprocal square root function for C in seconds. The GI inverted square root x-1/2 is far more accurate than Quake's InvSqrt, Quare root. GI shows potential for automatically creating mobile or low resource mote smart dust bespoke custom mathematical libraries with new functionality. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",data transplantation; Evolutionary computing; glibc; Newton's method; SBSE; search based software engineering; software engineering; software maintenance of empirical constants; vector normalisation,C (programming language); Open source software; Open systems; Optimization; Data transplantation; Empirical constants; Evolutionary computing; Glibc; Newton's methods; SBSE; Search based software engineering; Search-based; Software maintenance of empirical constant; Vector normalization; data management; numerical method; software; vector; Newton-Raphson method
A Novel Approach to Designing Surrogate-assisted Genetic Algorithms by Combining Efficient Learning of Walsh Coefficients and Dependencies,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115885507&doi=10.1145%2f3453141&partnerID=40&md5=4866a1b649230110846908ff64fcf5eb,"Surrogate-assisted evolutionary algorithms have the potential to be of high value for real-world optimization problems when fitness evaluations are expensive, limiting the number of evaluations that can be performed. In this article, we consider the domain of pseudo-Boolean functions in a black-box setting. Moreover, instead of using a surrogate model as an approximation of a fitness function, we propose to precisely learn the coefficients of the Walsh decomposition of a fitness function and use the Walsh decomposition as a surrogate. If the coefficients are learned correctly, then the Walsh decomposition values perfectly match with the fitness function, and, thus, the optimal solution to the problem can be found by optimizing the surrogate without any additional evaluations of the original fitness function. It is known that the Walsh coefficients can be efficiently learned for pseudo-Boolean functions with k-bounded epistasis and known problem structure. We propose to learn dependencies between variables first and, therefore, substantially reduce the number of Walsh coefficients to be calculated. After the accurate Walsh decomposition is obtained, the surrogate model is optimized using GOMEA, which is considered to be a state-of-the-art binary optimization algorithm. We compare the proposed approach with standard GOMEA and two other Walsh decomposition-based algorithms. The benchmark functions in the experiments are well-known trap functions, NK-landscapes, MaxCut, and MAX3SAT problems. The experimental results demonstrate that the proposed approach is scalable at the supposed complexity of O(ĝ.,""logĝ.,"") function evaluations when the number of subfunctions is O(ĝ.,"") and all subfunctions are k-bounded, outperforming all considered algorithms. © 2021 Association for Computing Machinery.",evolutionary algorithms; GOMEA; Linkage-learning; surrogate model; Walsh decomposition,Boolean functions; Genetic algorithms; Learning algorithms; Walsh transforms; Efficient learning; Fitness functions; GOMEA; Learn+; Linkage learning; Pseudo-Boolean function; Subfunctions; Surrogate modeling; Walsh Coefficients; Walsh decomposition; benchmarking; genetic algorithm; learning; optimization; Function evaluation
Evolution of Activation Functions: An Empirical Investigation,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133775808&doi=10.1145%2f3464384&partnerID=40&md5=c94febd9fbddfe79355f48e2bd7df841,"The hyper-parameters of a neural network are traditionally designed through a time-consuming process of trial and error that requires substantial expert knowledge. Neural Architecture Search algorithms aim to take the human out of the loop by automatically finding a good set of hyper-parameters for the problem at hand. These algorithms have mostly focused on hyper-parameters such as the architectural configurations of the hidden layers and the connectivity of the hidden neurons, but there has been relatively little work on automating the search for completely new activation functions, which are one of the most crucial hyperparameters to choose. There are some widely used activation functions nowadays that are simple and work well, but nonetheless, there has been some interest in finding better activation functions. The work in the literature has mostly focused on designing new activation functions by hand or choosing from a set of predefined functions while this work presents an evolutionary algorithm to automate the search for completely new activation functions. We compare these new evolved activation functions to other existing and commonly used activation functions. The results are favorable and are obtained from averaging the performance of the activation functions found over 30 runs, with experiments being conducted on 10 different datasets and architectures to ensure the statistical robustness of the study. © 2021 Association for Computing Machinery.",Activation functions; deep learning; evolutionary computation; genetic programming; neural architecture search; neural networks,Chemical activation; Deep learning; Genetic algorithms; Network architecture; Parameter estimation; Activation functions; Deep learning; Empirical investigation; Expert knowledge; Hyper-parameter; Neural architecture search; Neural architectures; Neural-networks; New activation functions; Trial and error; algorithm; artificial neural network; data set; empirical analysis; experimental study; machine learning; Genetic programming
Spatial Coevolution for Generative Adversarial Network Training,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119850381&doi=10.1145%2f3458845&partnerID=40&md5=60cff31877610226d8a6e3852e730639,"Generative Adversarial Networks (GANs) are difficult to train because of pathologies such as mode and discriminator collapse. Similar pathologies have been studied and addressed in competitive evolutionary computation by increased diversity. We study a system, Lipizzaner, that combines spatial coevolution with gradient-based learning to improve the robustness and scalability of GAN training. We study different features of Lipizzaner's evolutionary computation methodology. Our ablation experiments determine that communication, selection, parameter optimization, and ensemble optimization each, as well as in combination, play critical roles. Lipizzaner succumbs less frequently to critical collapses and, as a side benefit, demonstrates improved performance. In addition, we show a GAN-training feature of Lipizzaner: the ability to train simultaneously with different loss functions in the gradient descent parameter learning framework of each GAN at each cell. We use an image generation problem to show that different loss function combinations result in models with better accuracy and more diversity in comparison to other existing evolutionary GAN models. Finally, Lipizzaner with multiple loss function options promotes the best model diversity while requiring a large grid size for adequate accuracy. © 2021 Association for Computing Machinery.",coevolution; diversity; Generative adversarial networks,Gradient methods; Learning systems; Optimization; Pathology; Ablation experiments; Co-evolution; Computation methodologies; Diversity; Gradient-based learning; Loss functions; Network training; Optimisations; Parameter optimization; Selection parameters; accuracy assessment; artificial neural network; ensemble forecasting; parameter estimation; pathology; spatiotemporal analysis; Generative adversarial networks
Genetic Improvement of Routing Protocols for Delay Tolerant Networks,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136333465&doi=10.1145%2f3453683&partnerID=40&md5=b6259e49944a63d737d703c27a5c45f8,"Routing plays a fundamental role in network applications, but it is especially challenging in Delay Tolerant Networks (DTNs). These are a kind of mobile ad hoc networks made of, e.g., (possibly, unmanned) vehicles and humans where, despite a lack of continuous connectivity, data must be transmitted while the network conditions change due to the nodes' mobility. In these contexts, routing is NP-hard and is usually solved by heuristic ""store and forward""replication-based approaches, where multiple copies of the same message are moved and stored across nodes in the hope that at least one will reach its destination. Still, the existing routing protocols produce relatively low delivery probabilities. Here, we genetically improve two routing protocols widely adopted in DTNs, namely, Epidemic and PRoPHET, in the attempt to optimize their delivery probability. First, we dissect them into their fundamental components, i.e., functionalities such as checking if a node can transfer data, or sending messages to all connections. Then, we apply Genetic Improvement (GI) to manipulate these components as terminal nodes of evolving trees. We apply this methodology, in silico, to six test cases of urban networks made of hundreds of nodes and find that GI produces consistent gains in delivery probability in four cases. We then verify if this improvement entails a worsening of other relevant network metrics, such as latency and buffer time. Finally, we compare the logics of the best evolved protocols with those of the baseline protocols, and we discuss the generalizability of the results across test cases. © 2021 Association for Computing Machinery.",Ad hoc network; delay tolerant networks; epidemic routing; genetic improvement; genetic programming; PRoPHET,Delay tolerant networks; Genetic algorithms; Mobile ad hoc networks; Routing protocols; Ad-hoc networks; Delay-Tolerant Network; Delivery probabilities; Epidemic routing; Genetic improvements; In networks; PRoPHET; Routing-protocol; Routings; Test case; computer simulation; epidemic; genetic algorithm; probability density function; tolerance; Genetic programming
On Steady-State Evolutionary Algorithms and Selective Pressure: Why Inverse Rank-Based Allocation of Reproductive Trials Is Best,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114954001&doi=10.1145%2f3427474&partnerID=40&md5=067125c0feb9dc08fa32dbba696d483d,"We analyse the impact of the selective pressure for the global optimisation capabilities of steady-state evolutionary algorithms (EAs). For the standard bimodal benchmark function TwoMax, we rigorously prove that using uniform parent selection leads to exponential runtimes with high probability to locate both optima for the standard (+1) EA and (+1) RLS with any polynomial population sizes. However, we prove that selecting the worst individual as parent leads to efficient global optimisation with overwhelming probability for reasonable population sizes. Since always selecting the worst individual may have detrimental effects for escaping from local optima, we consider the performance of stochastic parent selection operators with low selective pressure for a function class called TruncatedTwoMax, where one slope is shorter than the other. An experimental analysis shows that the EAs equipped with inverse tournament selection, where the loser is selected for reproduction and small tournament sizes, globally optimise TwoMax efficiently and effectively escape from local optima of TruncatedTwoMax with high probability. Thus, they identify both optima efficiently while uniform (or stronger) selection fails in theory and in practice. We then show the power of inverse selection on function classes from the literature where populations are essential by providing rigorous proofs or experimental evidence that it outperforms uniform selection equipped with or without a restart strategy. We conclude the article by confirming our theoretical insights with an empirical analysis of the different selective pressures on standard benchmarks of the classical MaxSat and multidimensional knapsack problems. © 2021 Association for Computing Machinery.",(μ+1) EA; diversity; parent selection; Randomised search heuristics; TwoMax,Cell proliferation; Combinatorial optimization; Computation theory; Global optimization; Heuristic algorithms; Inverse problems; Population statistics; Stochastic systems; (μ+1) evolutionary algorithm; Diversity; High probability; Parent selection; Randomized search; Randomized search heuristic; Search heuristics; Selective pressure; Steady state; Twomax; algorithm; empirical analysis; experimental study; heuristics; population size; pressure; steady-state equilibrium; Evolutionary algorithms
ACM Transactions on Evolutionary Learning and Optimization Inaugural Issue Editorial,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177847611&doi=10.1145%2f3449277&partnerID=40&md5=8d09a285c63152ac436308454dbe793a,[No abstract available],,Evolutionary Learning; Evolutionary optimizations
Feature Construction for Meta-heuristic Algorithm Recommendation of Capacitated Vehicle Routing Problems,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131394281&doi=10.1145%2f3447540&partnerID=40&md5=caaead69a2952911cf7aedfc5e84603b,"The algorithm recommendation is attracting increasing attention in solving real-world capacitated vehicle routing problems (CVRPs), due to the fact that existing meta-heuristic algorithms often show different performances on different CVRPs. To effectively perform algorithm recommendation for CVRPs, it becomes vital to extract suitable features to characterize the CVRPs accurately. To this end, in this article three groups of penetrating features are proposed to capture the characteristics of CVRPs. The first group consists of some basic features of CVRPs, where several features are suggested to capture the distribution of customer demand, the relationship between customer demand and vehicle capacity, besides some common attributes widely used in CVRPs. The second group is composed of the features extracted from some CVRP solutions generated by local search, where in addition to the feasible and better solutions, the worse solutions and the distribution of travel cost are also used to measure the sensitivity of CVRPs to local search operations. The third group is made up of image features obtained by depicting CVRP instances through images, which is first introduced by us to enhance the generalization of algorithm recommendation. Furthermore, based on the three groups of features, an algorithm recommendation method called ARM-I is built on the basis of a KNN classifier to recommend suitable algorithm for CVRPs. Experimental results on several selected benchmarks demonstrate the effectiveness of the designed features. More interestingly, the proposed ARM-I shows high generalization on real-world instances. © 2021 Association for Computing Machinery.",algorithm recommendation; Capacitated vehicle routing problem; CVRP features; image features; meta-heuristic algorithms,Heuristic algorithms; Image enhancement; Local search (optimization); Routing algorithms; Vehicles; Algorithm recommendation; Capacitated vehicle routing problem; Capacitated vehicle routing problem feature; Customer demands; Feature construction; Generalisation; Image features; Meta-heuristics algorithms; Real-world; accuracy assessment; algorithm; experimental study; feasibility study; heuristics; meta-analysis; performance assessment; traffic management; Vehicle routing
Greed Is Good: Exploration and Exploitation Trade-offs in Bayesian Optimisation,2021,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177855490&doi=10.1145%2f3425501&partnerID=40&md5=583b576071e5aa22ac2a670c804bbc84,"The performance of acquisition functions for Bayesian optimisation to locate the global optimum of continuous functions is investigated in terms of the Pareto front between exploration and exploitation. We show that Expected Improvement (EI) and the Upper Confidence Bound (UCB) always select solutions to be expensively evaluated on the Pareto front, but Probability of Improvement is not guaranteed to do so and Weighted Expected Improvement does so only for a restricted range of weights. We introduce two novel -greedy acquisition functions. Extensive empirical evaluation of these together with random search, purely exploratory, and purely exploitative search on 10 benchmark problems in 1 to 10 dimensions shows that -greedy algorithms are generally at least as effective as conventional acquisition functions (e.g., EI and UCB), particularly with a limited budget. In higher dimensions, -greedy approaches are shown to have improved performance over conventional approaches. These results are borne out on a real-world computational fluid dynamics optimisation problem and a robotics active learning problem. Our analysis and experiments suggest that the most effective strategy, particularly in higher dimensions, is to be mostly greedy, occasionally selecting a random exploratory solution. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",acquisition function; Bayesian optimisation; exploration-exploitation trade-off; infill criteria; ϵ-greedy,Budget control; Economic and social effects; Mergers and acquisitions; Acquisition function; Bayesian optimization; Expected improvements; Exploration and exploitation; Exploration-exploitation trade-off; Exploration/exploitation; Infill criteria; Performance; Trade off; Ε-greedy; Bayesian analysis; mineral exploration; mineral resource; multicriteria analysis; optimization; Computational fluid dynamics
"Introduction to the ""Best of GECCO 2022"" Special Issue: Part II",2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196634184&doi=10.1145%2f3665797&partnerID=40&md5=d5572e4884c183cb5726c2a58ad88f71,[No abstract available],,
Marginal Probability-Based Integer Handling for CMA-ES Tackling Single- and Multi-Objective Mixed-Integer Black-Box Optimization,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185374309&doi=10.1145%2f3632962&partnerID=40&md5=3b432edf24887b05c5145ded69919b4a,"This study targets the mixed-integer black-box optimization (MI-BBO) problem where continuous and integer variables should be optimized simultaneously. The covariance matrix adaptation evolution strategy (CMA-ES), our focus in this study, is a population-based stochastic search method that samples solution candidates from a multivariate Gaussian distribution (MGD), which shows excellent performance in continuous black-box optimization. The parameters of MGD, mean and (co)variance, are updated based on the evaluation value of candidate solutions in the CMA-ES. If the CMA-ES is applied to the MI-BBO with straightforward discretization, however, the variance corresponding to the integer variables becomes much smaller than the granularity of the discretization before reaching the optimal solution, which leads to the stagnation of the optimization. In particular, when binary variables are included in the problem, this stagnation more likely occurs because the granularity of the discretization becomes wider, and the existing integer handling for the CMA-ES does not address this stagnation. To overcome these limitations, we propose a simple integer handling for the CMA-ES based on lower-bounding the marginal probabilities associated with the generation of integer variables in the MGD. The numerical experiments on the MI-BBO benchmark problems demonstrate the efficiency and robustness of the proposed method. Furthermore, to demonstrate the generality of the idea of the proposed method, in addition to the single-objective optimization case, we incorporate it into multi-objective CMA-ES and verify its performance on bi-objective mixed-integer benchmark problems. © 2024 Copyright held by the owner/author(s).",Covariance matrix adaptation evolution strategy; mixed-integer black-box optimization,Benchmarking; Evolutionary algorithms; Integer programming; Multiobjective optimization; Numerical methods; Stochastic systems; Black-box optimization; Covariance matrix adaptation evolution strategies; Discretizations; Integer variables; Marginal probability; Mixed integer; Mixed-integer black-box optimization; Multi objective; Multivariate Gaussian Distributions; Performance; Covariance matrix
Generating Cheap Representative Functions for Expensive Automotive Crashworthiness Optimization,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196745502&doi=10.1145%2f3646554&partnerID=40&md5=5e544e73958577526d0f9ed269d4f3ef,"Solving real-world engineering optimization problems, such as automotive crashworthiness optimization, is extremely challenging, because the problem characteristics are oftentimes not well understood. Furthermore, typical hyperparameter optimization (HPO) approaches that require a large function evaluation budget are computationally hindered, if the function evaluation is expensive, for example, requires finite element (FE) simulation runs. In this article, we propose an approach to characterize real-world expensive black-box optimization problems using the exploratory landscape analysis (ELA). Based on these landscape characteristics, we can identify test functions that are fast-to-evaluate and representative for HPO purposes. Focusing on 20 problem instances from automotive crashworthiness optimization, our results reveal that these 20 crashworthiness problems exhibit landscape features different from classical optimization benchmark test suites, such as the widely-used black-box optimization benchmarking (BBOB) problem set. In fact, these 20 problem instances belong to problem classes that are distinct from the BBOB test functions based on the clustering results. Further analysis indicates that, as far as the ELA features concern, they are most similar to problem classes of tree-based test functions. By analyzing the performance of two optimization algorithms with different hyperparameters, namely the covariance matrix adaptation evolutionary strategy (CMA-ES) and Bayesian optimization (BO), we show that the tree-based test functions are indeed representative in terms of predicting the algorithm performances. Following this, such scalable and fast-to-evaluate tree-based test functions have promising potential for automated design of an optimization algorithm for specific real-world problem classes. © 2024 Copyright held by the owner/author(s).",Automotive crashworthiness; black-box optimization; exploratory landscape analysis; representative functions; single-objective,Accidents; Benchmarking; Budget control; Clustering algorithms; Covariance matrix; Evolutionary algorithms; Function evaluation; Optimization; Statistical tests; Trees (mathematics); Automotive crashworthiness; Automotives; Black-box optimization; Crashworthiness optimization; Exploratory landscape analyse; Landscape analysis; Representative function; Single objective; Test-functions; Tree-based; Crashworthiness
Iterated Local Search with Linkage Learning,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196533871&doi=10.1145%2f3651165&partnerID=40&md5=a8ea3416b3f8d9d376cc01315065a4f7,"In pseudo-Boolean optimization, a variable interaction graph represents variables as vertices, and interactions between pairs of variables as edges. In black-box optimization, the variable interaction graph may be at least partially discovered by using empirical linkage learning techniques. These methods never report false variable interactions, but they are computationally expensive. The recently proposed local search with linkage learning discovers the partial variable interaction graph as a side-effect of iterated local search. However, information about the strength of the interactions is not learned by the algorithm. We propose local search with linkage learning 2, which builds a weighted variable interaction graph that stores information about the strength of the interaction between variables. The weighted variable interaction graph can provide new insights about the optimization problem and behavior of optimizers. Experiments with NK landscapes, knapsack problem, and feature selection show that local search with linkage learning 2 is able to efficiently build weighted variable interaction graphs. In particular, experiments with feature selection show that the weighted variable interaction graphs can be used for visualizing the feature interactions in machine learning. Additionally, new transformation operators that exploit the interactions between variables can be designed. We illustrate this ability by proposing a new perturbation operator for iterated local search. © 2024 Copyright held by the owner/author(s).",feature interaction; Iterated local search; linkage learning; variable interaction graph,Feature Selection; Graphic methods; Learning systems; Local search (optimization); Black-box optimization; Feature interactions; Features selection; Interaction graphs; Iterated local search; Linkage learning; Local search; Pseudo-Boolean optimization; Variable interaction; Variable interaction graph; Combinatorial optimization
Multiobjective Evolutionary Component Effect on Algorithm Behaviour,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196723600&doi=10.1145%2f3612933&partnerID=40&md5=79f647bc45cefc4bdc39d11409251d1b,"The performance of multiobjective evolutionary algorithms (MOEAs) varies across problems, making it hard to develop new algorithms or apply existing ones to new problems. To simplify the development and application of new multiobjective algorithms, there has been an increasing interest in their automatic design from their components. These automatically designed metaheuristics can outperform their human-developed counterparts. However, it is still unknown what are the most influential components that lead to performance improvements. This study specifies a new methodology to investigate the effects of the final configuration of an automatically designed algorithm. We apply this methodology to a tuned Multiobjective Evolutionary Algorithm based on Decomposition (MOEA/D) designed by the iterated racing (irace) configuration package on constrained problems of 3 groups: (1) analytical real-world problems, (2) analytical artificial problems and (3) simulated real-world. We then compare the impact of the algorithm components in terms of their Search Trajectory Networks (STNs), the diversity of the population, and the anytime hypervolume values. Looking at the objective space behavior, the MOEAs studied converged before half of the search to generally good HV values in the analytical artificial problems and the analytical real-world problems. For the simulated problems, the HV values are still improving at the end of the run. In terms of decision space behavior, we see a diverse set of the trajectories of the STNs in the analytical artificial problems. These trajectories are more similar and frequently reach optimal solutions in the other problems. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Algorithm analysis; automatic algorithm configuration; continuous optimization; multiobjective optimization,Evolutionary algorithms; Trajectories; Algorithm analysis; Algorithm configurations; Artificial problems; Automatic algorithm configuration; Automatic algorithms; Continuous optimization; Multi-Objective Evolutionary Algorithm; Multi-objectives optimization; Multiobjective evolutionary algorithms; Performance; Multiobjective optimization
The Influence of Noise on Multi-parent Crossover for an Island Model Genetic Algorithm,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196502849&doi=10.1145%2f3630638&partnerID=40&md5=39a1184450bf1c6dbec8261675e7d5de,"Many optimization problems tackled by evolutionary algorithms are not only computationally expensive but also complicated, with one or more sources of noise. One technique to deal with high computational overhead is parallelization. However, though the existing literature gives good insight about the expected behavior of parallelized evolutionary algorithms, we still lack an understanding of their performance in the presence of noise. This article considers how parallelization might be leveraged together with multi-parent crossover in order to handle noisy problems. We present a rigorous running time analysis of an island model with weakly connected topology tasked with hill climbing in the presence of general additive noise (i.e., noisy OneMax). Our proofs yield insights into the relationship between the noise intensity and number of required parents. We translate this into positive and negative results for two kinds of multi-parent crossover operators. We then empirically analyze and extend this framework to investigate the tradeoffs between noise impact, optimization time, and limits of computation power to deal with noise.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Island model; noisy optimization; runtime analysis,Additive noise; Genetic algorithms; Noise pollution; Computational overheads; Island model; Island model genetic algorithm; Multi-parent crossover; Noisy optimization; Optimization problems; Parallelizations; Performance; Run-time analysis; Running time analysis; Topology
On the Use of Quality Diversity Algorithms for the Travelling Thief Problem,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196757439&doi=10.1145%2f3641109&partnerID=40&md5=b1f730d6bd590231580a4f0c2d39e675,"In real-world optimisation, it is common to face several sub-problems interacting and forming the main problem. There is an inter-dependency between the sub-problems, making it impossible to solve such a problem by focusing on only one component. The travelling thief problem (TTP) belongs to this category and is formed by the integration of the travelling salesperson problem (TSP) and the knapsack problem (KP). In this paper, we investigate the inter-dependency of the TSP and the KP by means of quality diversity (QD) approaches. QD algorithms provide a powerful tool not only to obtain high-quality solutions but also to illustrate the distribution of high-performing solutions in the behavioural space.We introduce a multi-dimensional archive of phenotypic elites (MAP-Elites) based evolutionary algorithm using well-known TSP and KP search operators, taking the TSP and KP score as the behavioural descriptor. MAP-Elites algorithms are QD-based techniques to explore high-performing solutions in a behavioural space. Afterwards, we conduct comprehensive experimental studies that show the usefulness of using the QD approach applied to the TTP. First, we provide insights regarding high-quality TTP solutions in the TSP/KP behavioural space. Afterwards, we show that better solutions for the TTP can be obtained by using our QD approach, and it can improve the best-known solution for a number of TTP instances used for benchmarking in the literature. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",MAP-Elites; Quality diversity; travelling thief problem,Combinatorial optimization; High-quality solutions; Inter-dependencies; Knapsack problems; Multi dimensional; Multi-dimensional archive of phenotypic elite; Quality diversity; Real-world optimization; Sub-problems; Traveling salesperson problem; Traveling thief problem; Evolutionary algorithms
Introduction to the Special Issue on Explainable AI in Evolutionary Computation,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187920673&doi=10.1145%2f3649144&partnerID=40&md5=09b9f6273154c6e38bb0a6bc7c100ad4,[No abstract available],,
An Analysis of the Ingredients for Learning Interpretable Symbolic Regression Models with Human-in-The-loop and Genetic Programming,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187802221&doi=10.1145%2f3643688&partnerID=40&md5=0bae125cc568ddd03928ccdc26bd391f,"Interpretability is a critical aspect to ensure a fair and responsible use of machine learning (ML) in high-stakes applications. Genetic programming (GP) has been used to obtain interpretable ML models because it operates at the level of functional building blocks: if these building blocks are interpretable, there is a chance that their composition (i.e., the entire ML model) is also interpretable. However, the degree to which a model is interpretable depends on the observer. Motivated by this, we study a recently-introduced human-in-The-loop system that allows the user to steer GP's generation process to their preferences, which shall be online-learned by an artificial neural network (ANN). We focus on the generation of ML models as analytical functions (i.e., symbolic regression) as this is a key problem in interpretable ML, and propose a two-fold contribution. First, we devise more general representations for the ML models for the ANN to learn upon, to enable the application of the system to a wider range of problems. Second, we delve into a deeper analysis of the system's components. To this end, we propose an incremental experimental evaluation, aimed at (1) studying the effectiveness by which an ANN can capture the perceived interpretability for simulated users, (2) investigating how the GP's outcome is affected across different simulated user feedback profiles, and (3) determining whether humans participants would prefer models that were generated with or without their involvement. Our results pose clarity on pros and cons of using a human-in-The-loop approach to discover interpretable ML models with GP. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",active learning; deep learning; evolutionary algorithms; evolutionary computation; Explainable artificial intelligence; explainable evolutionary computation; genetic programming; interpretable machine learning; neural networks,Deep learning; Functional programming; Genetic algorithms; Learning systems; Neural networks; Regression analysis; Reinforcement learning; Active Learning; Deep learning; Explainable artificial intelligence; Explainable evolutionary computation; Human-in-the-loop; Interpretable machine learning; Machine learning models; Machine-learning; Neural-networks; Symbolic regression; Genetic programming
Exploring the Explainable Aspects and Performance of a Learnable Evolutionary Multiobjective Optimization Method,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187787516&doi=10.1145%2f3626104&partnerID=40&md5=548573e92cb5dbdc4a70b0c4293a9686,"Multiobjective optimization problems have multiple conflicting objective functions to be optimized simultaneously. The solutions to these problems are known as Pareto optimal solutions, which are mathematically incomparable. Thus, a decision maker must be employed to provide preferences to find the most preferred solution. However, decision makers often lack support in providing preferences and insights in exploring the solutions available.We explore the combination of learnable evolutionary models with interactive indicator-based evolutionary multiobjective optimization to create a learnable evolutionary multiobjective optimization method. Furthermore, we leverage interpretable machine learning to provide decision makers with potential insights about the problem being solved in the form of rule-based explanations. In fact, we show that a learnable evolutionary multiobjective optimization method can offer advantages in the search for solutions to a multiobjective optimization problem. We also provide an open source software framework for other researchers to implement and explore our ideas in their own works.Our work is a step toward establishing a new paradigm in the field on multiobjective optimization: explainable and learnable multiobjective optimization. We take the first steps toward this new research direction and provide other researchers and practitioners with necessary tools and ideas to further contribute to this field. © 2024 Copyright held by the owner/author(s).",Additional Key Words and PhrasesMultiobjective optimization; evolutionary multiobjective optimization; explainable artificial intelligence; learnable evolutionary models,Artificial intelligence; Computer programming; Decision making; Open source software; Open systems; Pareto principle; Additional key word and phrasesmultiobjective optimization; Decision makers; Evolutionary models; Evolutionary multiobjective optimization; Explainable artificial intelligence; Key words; Learnable evolutionary model; Multiobjective optimization problems; Optimisations; Optimization method; Multiobjective optimization
Multi-objective Feature Attribution Explanation for Explainable Machine Learning,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178998217&doi=10.1145%2f3617380&partnerID=40&md5=6c10d48012f5c2fd5d1aabf2df2f5afe,"The feature attribution-based explanation (FAE) methods, which indicate how much each input feature contributes to the model's output for a given data point, are one of the most popular categories of explainable machine learning techniques. Although various metrics have been proposed to evaluate the explanation quality, no single metric could capture different aspects of the explanations. Different conclusions might be drawn using different metrics. Moreover, during the processes of generating explanations, existing FAE methods either do not consider any evaluation metric or only consider the faithfulness of the explanation, failing to consider multiple metrics simultaneously. To address this issue, we formulate the problem of creating FAE explainable models as a multi-objective learning problem that considers multiple explanation quality metrics simultaneously. We first reveal conflicts between various explanation quality metrics, including faithfulness, sensitivity, and complexity. Then, we define the considered multi-objective explanation problem and propose a multi-objective feature attribution explanation (MOFAE) framework to address this newly defined problem. Subsequently, we instantiate the framework by simultaneously considering the explanation's faithfulness, sensitivity, and complexity. Experimental results comparing with six state-of-The-Art FAE methods on eight datasets demonstrate that our method can optimize multiple conflicting metrics simultaneously and can provide explanations with higher faithfulness, lower sensitivity, and lower complexity than the compared methods. Moreover, the results have shown that our method has better diversity, i.e., it provides various explanations that achieve different tradeoffs between multiple conflicting explanation quality metrics. Therefore, it can provide tailored explanations to different stakeholders based on their specific requirements. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Explainable machine learning; feature attribution explanations; multi-objective evolutionary algorithms; multi-objective learning,Evolutionary algorithms; Learning algorithms; Quality control; Datapoints; Explainable machine learning; Feature attribution explanation; Input features; Machine-learning; Model outputs; Multi objective; Multi-Objective Evolutionary Algorithm; Multi-objective learning; Quality metrices; Machine learning
A Multi-Objective Evolutionary Approach to Discover Explainability Tradeoffs when Using Linear Regression to Effectively Model the Dynamic Thermal Behaviour of Electrical Machines,2024,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187793818&doi=10.1145%2f3597618&partnerID=40&md5=e6baafe449b07e18ace438eca9ff4481,"Modelling and controlling heat transfer in rotating electrical machines is very important as it enables the design of assemblies (e.g., motors) that are efficient and durable under multiple operational scenarios. To address the challenge of deriving accurate data-driven estimators of key motor temperatures, we propose a multi-objective strategy for creating Linear Regression (LR) models that integrate optimised synthetic features. The main strength of our approach is that it provides decision makers with a clear overview of the optimal tradeoffs between data collection costs, the expected modelling errors and the overall explainability of the generated thermal models. Moreover, as parsimonious models are required for both microcontroller deployment and domain expert interpretation, our modelling strategy contains a simple but effective step-wise regularisation technique that can be applied to outline domain-relevant mappings between LR variables and thermal profiling capabilities. Results indicate that our approach can generate accurate LR-based dynamic thermal models when training on data associated with a limited set of load points within the safe operating area of the electrical machine under study.  © 2024 Copyright held by the owner/author(s).",cost vs accuracy; Data-driven thermal models; electrical machines; explainability; linear regression; NSGA-II; problem formalisation,Commerce; Decision making; Evolutionary algorithms; Heat transfer; Thermography (temperature measurement); Cost vs accuracy; Data driven; Data-driven thermal model; Electrical machine; Explainability; Formalisation; Multi-objective evolutionary; NSGA-II; Problem formalization; Thermal model; Linear regression
Model-based Gradient Search for Permutation Problems,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181020536&doi=10.1145%2f3628605&partnerID=40&md5=779d1e5d2140f097f714d5498899d4d0,"Global random search algorithms are characterized by using probability distributions to optimize problems. Among them, generative methods iteratively update the distributions by using the observations sampled. For instance, this is the case of the well-known Estimation of Distribution Algorithms. Although successful, this family of algorithms iteratively adopts numerical methods for estimating the parameters of a model or drawing observations from it. This is often a very time-consuming task, especially in permutation-based combinatorial optimization problems. In this work, we propose using a generative method, under the model-based gradient search framework, to optimize permutation-coded problems and address the mentioned computational overheads. To that end, the Plackett–Luce model is used to define the probability distribution on the search space of permutations. Not limited to that, a parameter-free variant of the algorithm is investigated. Conducted experiments, directed to validate the work, reveal that the gradient search scheme produces better results than other analogous competitors, reducing the computational cost and showing better scalability. © 2023 Copyright held by the owner/author(s).",combinatorial problem; Gradient search; permutation; probability distribution; self-adaptive,Combinatorial optimization; Evolutionary algorithms; Iterative methods; Numerical methods; Parameter estimation; Combinatorial problem; Generative methods; Gradient search; Model-based OPC; Permutation; Permutation problems; Probability: distributions; Random search algorithm; Self-adaptive; Using probabilities; Probability distributions
Evolving Software: Combining Online Learning with Mutation-Based Stochastic Search,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181047159&doi=10.1145%2f3597617&partnerID=40&md5=cefc2144f573144c1032ed085660adab,"Evolutionary algorithms and related mutation-based methods have been used in software engineering, with recent emphasis on the problem of repairing bugs. In this work, programs are typically not synthesized from a random start. Instead, existing solutions—which may be flawed or inefficient—are taken as starting points, with the evolutionary process searching for useful improvements. This approach, however, introduces a challenge for the search algorithm: what is the optimal number of neutral mutations that should be combined? Too much is likely to introduce errors and break the program while too little hampers the search process, inducing the classic tradeoff between exploration and exploitation. In the context of software improvement, this work considers MWRepair, an algorithm for enhancing mutation-based searches, which uses online learning to optimize the tradeoff between exploration and exploitation. The aggressiveness parameter governs how many individual mutations should be applied simultaneously to an individual between fitness evaluations. MWRepair is evaluated in the context of automated program repair problems, where the goal is repairing software bugs with minimal human involvement. The article analyzes the search space for automated program repair induced by neutral mutations, finding that the greatest probability of finding successful repairs often occurs when many neutral mutations are applied to the original program. Moreover, repair probability follows a characteristic, unimodal distribution. MWRepair uses online learning to leverage this property, finding both rare and multi-edit repairs to defects in the popular Defects4J benchmark set of buggy Java programs. © 2023 Copyright held by the owner/author(s).",automated program repair; multiplicative weights update; Neutral mutations; software mutational robustness,Automation; Computer software; Defects; E-learning; Evolutionary algorithms; Probability distributions; Program debugging; Repair; Automated program repair; Exploration and exploitation; Multiplicative weight update; Neutral mutation; Online learning; Software mutational robustness; Stochastic search; Synthesised; Weight update; Work programs; Stochastic systems
A Species-based Particle Swarm Optimization with Adaptive Population Size and Deactivation of Species for Dynamic Optimization Problems,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181002907&doi=10.1145%2f3604812&partnerID=40&md5=a5ff8af935740061f5ad9886cbf16828,"Population clustering methods, which consider the position and fitness of individuals to form sub-populations in multi-population algorithms, have shown high efficiency in tracking the moving global optimum in dynamic optimization problems. However, most of these methods use a fixed population size, making them inflexible and inefficient when the number of promising regions is unknown. The lack of a functional relationship between the population size and the number of promising regions significantly degrades performance and limits an algorithm’s agility to respond to dynamic changes. To address this issue, we propose a new species-based particle swarm optimization with adaptive population size and number of sub-populations for solving dynamic optimization problems. The proposed algorithm also benefits from a novel systematic adaptive deactivation component that, unlike the previous deactivation components, adapts the computational resource allocation to the sub-populations by considering various characteristics of both the problem and the sub-populations. We evaluate the performance of our proposed algorithm for the Generalized Moving Peaks Benchmark and compare the results with several peer approaches. The results indicate the superiority of the proposed method. © 2023 Copyright held by the owner/author(s).",Computational resource allocation; Evolutionary dynamic optimization; Particle swarm optimization; Single-objective dynamic optimization problems; Tracking moving global optimum,Benchmarking; Cluster analysis; Particle swarm optimization (PSO); Population statistics; Computational resource allocation; Computational resources; Dynamic optimization; Evolutionary dynamic optimization; Evolutionary dynamics; Globaloptimum; Optimization problems; Particle swarm; Particle swarm optimization; Resources allocation; Single objective; Single-objective dynamic optimization problem; Swarm optimization; Tracking moving global optimum; Resource allocation
Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180962513&doi=10.1145%2f3610536&partnerID=40&md5=1569222b3a2d2bd4245d33deaca7267d,"Hyperparameter optimization constitutes a large part of typical modern machine learning (ML) workflows. This arises from the fact that ML methods and corresponding preprocessing steps often only yield optimal performance when hyperparameters are properly tuned. But in many applications, we are not only interested in optimizing ML pipelines solely for predictive accuracy; additional metrics or constraints must be considered when determining an optimal configuration, resulting in a multi-objective optimization problem. This is often neglected in practice, due to a lack of knowledge and readily available software implementations for multi-objective hyperparameter optimization. In this work, we introduce the reader to the basics of multi-objective hyperparameter optimization and motivate its usefulness in applied ML. Furthermore, we provide an extensive survey of existing optimization strategies from the domains of evolutionary algorithms and Bayesian optimization. We illustrate the utility of multi-objective optimization in several specific ML applications, considering objectives such as operating conditions, prediction time, sparseness, fairness, interpretability, and robustness. © 2023 Copyright held by the owner/author(s).",Bayesian optimization; Multi-objective hyperparameter optimization; neural architecture search,Evolutionary algorithms; Multiobjective optimization; Bayesian optimization; Hyper-parameter optimizations; Large parts; Machine-learning; Modern machines; Multi objective; Multi-objective hyperparameter optimization; Neural architecture search; Neural architectures; Work-flows; Machine learning
"Editorial to the ""Evolutionary Reinforcement Learning"" Special Issue",2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174249498&doi=10.1145%2f3624559&partnerID=40&md5=eb1da4b0fcd3335485729d757031f502,[No abstract available],,Reinforcement learnings; Reinforcement learning
Curiosity Creates Diversity in Policy Search,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174310488&doi=10.1145%2f3605782&partnerID=40&md5=eec9e3e7b625d19af577154578ff667b,"When searching for policies, reward-sparse environments often lack sufficient information about which behaviors to improve upon or avoid. In such environments, the policy search process is bound to blindly search for reward-yielding transitions and no early reward can bias this search in one direction or another. A way to overcome this is to use intrinsic motivation in order to explore new transitions until a reward is found. In this work, we use a recently proposed definition of intrinsic motivation, Curiosity, in an evolutionary policy search method. We propose Curiosity-ES,1 an evolutionary strategy adapted to use Curiosity as a fitness metric. We compare Curiosity-ES with other evolutionary algorithms intended for exploration, as well as with Curiosity-based reinforcement learning, and find that Curiosity-ES can generate higher diversity without the need for an explicit diversity criterion and leads to more policies which find reward.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",evolutionary strategies; neural networks; policy search; quality diversity; Reinforcement learning,Evolutionary algorithms; Motivation; Evolutionary strategies; Intrinsic motivation; Neural-networks; Policy search; Quality diversity; Reinforcement learnings; Search method; Search process; Sparse environments; algorithm; artificial neural network; machine learning; policy making; Reinforcement learning
Combining Evolution and Deep Reinforcement Learning for Policy Search: A Survey,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174077008&doi=10.1145%2f3569096&partnerID=40&md5=54ae477603391b40d6ff7b9374ba6a82,"Deep neuroevolution and deep Reinforcement Learning have received a lot of attention over the past few years. Some works have compared them, highlighting their pros and cons, but an emerging trend combines them so as to benefit from the best of both worlds. In this article, we provide a survey of this emerging trend by organizing the literature into related groups of works and casting all the existing combinations in each group into a generic framework. We systematically cover all easily available papers irrespective of their publication status, focusing on the combination mechanisms rather than on the experimental results. In total, we cover 45 algorithms more recent than 2017. We hope this effort will favor the growth of the domain by facilitating the understanding of the relationships between the methods, leading to deeper analyses, outlining missing useful comparisons and suggesting new combinations of mechanisms.  © 2023 Association for Computing Machinery.",Evolutionary algorithms,Deep learning; Evolutionary algorithms; Combination mechanisms; Emerging trends; Generic frameworks; Neuro evolutions; Policy search; Reinforcement learnings; algorithm; comparative study; machine learning; Reinforcement learning
"P2P Energy Trading through Prospect Theory, Differential Evolution, and Reinforcement Learning",2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174285752&doi=10.1145%2f3603148&partnerID=40&md5=bd6c3996575594de8a167b7880eb28f1,"Peer-to-peer (P2P) energy trading is a decentralized energy market where local energy prosumers act as peers, trading energy among each other. Existing works in this area largely overlook the importance of user behavioral modeling and assume users' sustained active participation and full compliance in the decision-making process. To overcome these unrealistic assumptions, and their deleterious consequences, in this article, we propose an automated P2P energy-trading framework that specifically considers the users' perception by exploiting prospect theory. We formalize an optimization problem that maximizes the buyers' perceived utility while matching energy production and demand. We prove that the problem is NP-hard and we propose a Differential Evolution-based Algorithm for Trading Energy (DEbATE) heuristic. Additionally, we propose two automated pricing solutions to improve the sellers' profit based on reinforcement learning. The first solution, named Pricing mechanism with Q-learning and Risk-sensitivity (PQR), is based on Q-learning. Additionally, given the scalability issues of PQR, we propose a Deep Q-Network-based algorithm called ProDQN that exploits deep learning and a novel loss function rooted in prospect theory. Results based on real traces of energy consumption and production, as well as realistic prospect theory functions, show that our approaches achieve 26% higher perceived value for buyers and generate 7% more reward for sellers, compared to recent state-of-the-art approaches. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Deep Q-Network; differential evolution; dynamic pricing; non-linear optimization; Peer-to-peer energy trading; prospect theory; Q-learning,Behavioral research; Costs; Decision making; Deep learning; Energy utilization; Evolutionary algorithms; Nonlinear programming; Power markets; Deep Q-network; Differential Evolution; Dynamic pricing; Energy trading; Non-linear optimization; Peer to peer; Peer-to-peer energy trading; Prospect theory; Q-learning; Reinforcement learnings; algorithm; artificial neural network; automation; energy market; machine learning; optimization; Reinforcement learning
Covariance Matrix Adaptation Evolutionary Strategy with Worst-Case Ranking Approximation for Min-Max Optimization and Its Application to Berthing Control Tasks,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177816637&doi=10.1145%2f3603716&partnerID=40&md5=196e1d80ec92a10ec9ce4b23901efd6b,"In this study, we consider a continuous min-max optimization problem minx ∈ Xmaxy ∈ Y f(x, y) whose objective function is a black-box. We propose a novel approach to minimize the worst-case objective function F(x) = maxy∈ Y f(x, y) directly using a covariance matrix adaptation evolution strategy in which the rankings of solution candidates are approximated by our proposed worst-case ranking approximation mechanism. We develop two variants of worst-case ranking approximation combined with a covariance matrix adaptation evolution strategy and approximate gradient ascent as numerical solvers for the inner maximization problem. Numerical experiments show that our proposed approach outperforms several existing approaches when the objective function is a smooth strongly convex-concave function and the interaction between x and y is strong. We investigate the advantages of the proposed approach for problems where the objective function is not limited to smooth strongly convex-concave functions. The effectiveness of the proposed approach is demonstrated in the robust berthing control problem with uncertainty. © 2023 Copyright held by the owner/author(s).",Black-box min-max continuous optimization; covariance matrix adaptation evolution strategy; nonconvex-nonconcave function; robust berthing control problem; worst-case ranking approximation,Covariance matrix; Evolutionary algorithms; Bad-case ranking approximation; Black boxes; Black-box min-max continuous optimization; Case ranking; Continuous optimization; Control problems; Covariance matrix adaptation evolution strategies; Min-max; Nonconvex; Nonconvex-nonconcave function; Robust berthing control problem; computer simulation; control system; covariance analysis; mooring system; numerical model; optimization; port operation; uncertainty analysis; Optimization
Online Damage Recovery for Physical Robots with Hierarchical Quality-Diversity,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177872914&doi=10.1145%2f3596912&partnerID=40&md5=f4bf579e004f79cad7a43bcff79e742b,"In real-world environments, robots need to be resilient to damages and robust to unforeseen scenarios. Quality-Diversity (QD) algorithms have been successfully used to make robots adapt to damages in seconds by leveraging a diverse set of learned skills. A high diversity of skills increases the chances of a robot to succeed at overcoming new situations since there are more potential alternatives to solve a new task. However, finding and storing a large behavioural diversity of multiple skills often leads to an increase in computational complexity. Furthermore, robot planning in a large skill space is an additional challenge that arises with an increased number of skills. Hierarchical structures can help to reduce this search and storage complexity by breaking down skills into primitive skills. In this article, we extend the analysis of the Hierarchical Trial and Error algorithm, which uses a hierarchical behavioural repertoire to learn diverse skills and leverages them to make the robot adapt quickly in the physical world. We show that the hierarchical decomposition of skills enables the robot to learn more complex behaviours while keeping the learning of the repertoire tractable. Experiments with a hexapod robot both in simulation and the physical world show that our method solves a maze navigation task with up to, respectively, 20% and 43% less actions than the best baselines while having 78% less complete failures. © 2023 Copyright held by the owner/author(s).",Hierarchical learning; Quality-Diversity; robot learning,E-learning; Behavioral diversity; Damage recovery; Hierarchical learning; Hierarchical structures; Learn+; Physical robots; Physical world; Quality-diversity; Real world environments; Robot planning; algorithm; hierarchical system; Internet; machine learning; robotics; Robot programming
"Editorial to the ""Best of GECCO 2022"" Special Issue: Part I",2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177879980&doi=10.1145%2f3606034&partnerID=40&md5=eaf17d4e1d3500a4f9d6f7486f02b8ea,[No abstract available],,
Crossover for Cardinality Constrained Optimization,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177813110&doi=10.1145%2f3603629&partnerID=40&md5=27d3cce4699c643149fcecc95df56a63,"To understand better how and why crossover can benefit constrained optimization, we consider pseudo-Boolean functions with an upper bound B on the number of 1-bits allowed in the length-n bit string (i.e., a cardinality constraint). We investigate the natural translation of the OneMax test function to this setting, a linear function where B bits have a weight of 1+ 1/n and the remaining bits have a weight of 1. Friedrich et al. [TCS 2020] gave a bound of Θ(n2) for the expected running time of the (1+1) EA on this function.Part of the difficulty when optimizing this problem lies in having to improve individuals meeting the cardinality constraint by flipping a 1 and a 0 simultaneously. The experimental literature proposes balanced operators, preserving the number of 1-bits, as a remedy. We show that a balanced mutation operator optimizes the problem in O(n log n) if n-B = O(1). However, if n-B = Θ(n), we show a bound of ω (n2), just as for classic bit mutation. Crossover together with a simple island model gives running times of O(n2 / log n) (uniform crossover) and (3-ary majority vote crossover). For balanced uniform crossover with Hamming-distance maximization for diversity, we show a bound of O(n log n).As an additional contribution, we present an extensive analysis of different balanced crossover operators from the literature. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Balanced crossover; balanced mutation; constraint optimization; run time analysis.,Hamming distance; Balanced crossover; Balanced mutation; Cardinalities; Cardinality constraints; Constraint optimizations; Pseudo-Boolean function; Run time analyse.; Run-time analysis; Uniform crossovers; Upper Bound; experimental study; laboratory method; learning; literature review; mutation; optimization; teaching; Constrained optimization
Transformation-Interaction-Rational Representation for Symbolic Regression: A Detailed Analysis of SRBench Results,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174527220&doi=10.1145%2f3597312&partnerID=40&md5=e402ad81db873f4f12963e60fac13d3d,"Symbolic Regression searches for a parametric model with the optimal value of the parameters that best fits a set of samples to a measured target. The desired solution has a balance between accuracy and interpretability. Commonly, there is no constraint in the way the functions are composed in the expression or where the numerical parameters are placed, which can potentially lead to expressions that require a nonlinear optimization to find the optimal parameters. The representation called Interaction-Transformation alleviates this problem by describing expressions as a linear regression of the composition of functions applied to the interaction of the variables. One advantage is that any model that follows this representation is linear in its parameters, allowing an efficient computation. More recently, this representation was extended by applying a univariate function to the rational function of two Interaction-Transformation expressions, called Transformation-Interaction-Rational (TIR). The use of this representation was shown to be competitive with the current literature of Symbolic Regression. In this article, we make a detailed analysis of these results using the SRBench benchmark. For this purpose, we split the datasets into different categories to understand the algorithm behavior in different settings. We also test the use of nonlinear optimization to adjust the numerical parameters instead of Ordinary Least Squares. We find through the experiments that TIR has some difficulties handling high-dimensional and noisy datasets, especially when most of the variables are composed of random noise. These results point to new directions for improving the evolutionary search of TIR expressions. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",genetic programming; regression; Symbolic regression,Genetic algorithms; Genetic programming; Linear transformations; Nonlinear programming; Regression analysis; Best fit; Interpretability; Non-linear optimization; Numerical parameters; Optimal values; Parametric models; Rational representation; Regression; Regression search; Symbolic regression; data set; genetic algorithm; optimization; regression analysis; Rational functions
Factors Impacting Diversity and Effectiveness of Evolved Modular Robots,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165233737&doi=10.1145%2f3587101&partnerID=40&md5=e3b0279f57cc7a19cc50503c6f4e998c,"In many natural environments, different forms of living organisms successfully accomplish the same task while being diverse in shape and behavior. This biodiversity is what made life capable of adapting to disrupting changes. Being able to reproduce biodiversity in artificial agents, while still optimizing them for a particular task, might increase their applicability to scenarios where human response to unexpected changes is not possible. In this work, we focus on Voxel-based Soft Robots (VSRs), a form of robots that grants great freedom in the design of both morphology and controller and is hence promising in terms of biodiversity. We use evolutionary computation for optimizing, at the same time, morphology and controller of VSRs for the task of locomotion. We investigate experimentally whether three key factors - representation, Evolutionary Algorithm (EA), and environment - impact the emergence of biodiversity and if this occurs at the expense of effectiveness. We devise an automatic machine learning pipeline for systematically characterizing the morphology and behavior of robots resulting from the optimization process. We classify the robots into species and then measure biodiversity in populations of robots evolved in a multitude of conditions resulting from the combination of different morphology representations, controller representations, EAs, and environments. The experimental results suggest that, in general, EA and environment matter more than representation. We also propose a novel EA based on a speciation mechanism that operates on morphology and behavior descriptors and we show that it allows to jointly evolve morphology and controller of effective and diverse VSRs. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",diversity; evolutionary algorithms; Evolutionary robotics; neuroevolution; representation,Biodiversity; Controllers; Machine design; Modular robots; Morphology; Artificial agents; Diversity; Evolutionary robotics; Human response; Key factors; Living organisms; Natural environments; Neuro evolutions; Representation; Soft robot; algorithm; biodiversity; robotics; Evolutionary algorithms
Empirical analysis of PGA-MAP-Elites for Neuroevolution in Uncertain Domains,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177824216&doi=10.1145%2f3577203&partnerID=40&md5=b1e6c91ed6f6c93e2b5183247ecc3a04,"Quality-Diversity algorithms, among which are the Multi-dimensional Archive of Phenotypic Elites (MAP-Elites), have emerged as powerful alternatives to performance-only optimisation approaches as they enable generating collections of diverse and high-performing solutions to an optimisation problem. However, they are often limited to low-dimensional search spaces and deterministic environments. The recently introduced Policy Gradient Assisted MAP-Elites (PGA-MAP-Elites) algorithm overcomes this limitation by pairing the traditional Genetic operator of MAP-Elites with a gradient-based operator inspired by deep reinforcement learning. This new operator guides mutations toward high-performing solutions using policy gradients (PG). In this work, we propose an in-depth study of PGA-MAP-Elites. We demonstrate the benefits of PG on the performance of the algorithm and the reproducibility of the generated solutions when considering uncertain domains. We firstly prove that PGA-MAP-Elites is highly performant in both deterministic and uncertain high-dimensional environments, decorrelating the two challenges it tackles. Secondly, we show that in addition to outperforming all the considered baselines, the collections of solutions generated by PGA-MAP-Elites are highly reproducible in uncertain environments, approaching the reproducibility of solutions found by Quality-Diversity approaches built specifically for uncertain applications. Finally, we propose an ablation and in-depth analysis of the dynamic of the PG-based variation. We demonstrate that the PG variation operator is determinant to guarantee the performance of PGA-MAP-Elites but is only essential during the early stage of the process, where it finds high-performing regions of the search space. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",MAP-Elites; neuroevolution; policy gradients; Quality-Diversity; reinforcement learning; uncertain domains,Deep learning; Evolutionary algorithms; Quality control; Deterministics; Multi dimensional; Multi-dimensional archive of phenotypic elite; Neuro evolutions; Performance; Policy gradient; Quality-diversity; Reinforcement learnings; Search spaces; Uncertain domain; algorithm; empirical analysis; optimization; uncertainty analysis; Reinforcement learning
The Generation of Visually Credible Adversarial Examples with Genetic Algorithms,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177839966&doi=10.1145%2f3582276&partnerID=40&md5=158a4a2ae3e1eca5be81ac8417e1bc35,"An adversarial example is an input that a neural network misclassifies although the input differs only slightly from an input that the network classifies correctly. Adversarial examples are used to augment neural network training data, measure the vulnerability of neural networks, and provide intuitive interpretations of neural network output that humans can understand. Although adversarial examples are defined in the literature as similar to authentic input from the perspective of humans, the literature measures similarity with mathematical norms that are not scientifically correlated with human perception. Our main contributions are to construct a genetic algorithm (GA) that generates adversarial examples more similar to authentic input than do existing methods and to demonstrate with a survey that humans perceive those adversarial examples to have greater visual similarity than existing methods. The GA incorporates a neural network, and we test many parameter sets to determine which fitness function, selection operator, mutation operator, and neural network generate adversarial examples most visually similar to authentic input. We establish which mathematical norms are most correlated with human perception, which permits future research to incorporate the human perspective without testing many norms or conducting intensive surveys with human subjects. We also document a tradeoff between speed and quality in adversarial examples generated by GAs and existing methods. Although existing adversarial methods are faster, a GA provides higher-quality adversarial examples in terms of visual similarity and feasibility of adversarial examples. We apply the GA to the Modified National Institute of Standards and Technology (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) datasets. © 2023 Copyright held by the owner/author(s).",adversarial examples; CIFAR-10; Genetic algorithms; MNIST; neural networks,Network security; Neural networks; Adversarial example; CIFAR-10; Human perception; Modified national institute of standard and technology; National Institute of Standards and Technology; Neural networks trainings; Neural-networks; Parameter set; Training data; Visual similarity; artificial neural network; data set; feasibility study; future prospect; genetic algorithm; perception; vulnerability; Genetic algorithms
Explainable Regression Via Prototypes,2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163070563&doi=10.1145%2f3576903&partnerID=40&md5=88308325aa8a1e20d20d10e16f85fbad,"Model interpretability/explainability is increasingly a concern when applying machine learning to real-world problems. In this article, we are interested in explaining regression models by exploiting prototypes, which are exemplar cases in the problem domain. Previous works focused on finding prototypes that are representative of all training data but ignore the model predictions, i.e., they explain the data distribution but not necessarily the predictions. We propose a two-level model-agnostic method that considers prototypes to provide global and local explanations for regression problems and that account for both the input features and the model output. M-PEER (Multiobjective Prototype-basEd Explanation for Regression) is based on a multi-objective evolutionary method that optimizes both the error of the explainable model and two other ""semantics""-based measures of interpretability adapted from the context of classification, namely, model fidelity and stability. We compare the proposed method with the state-of-the-art method based on prototypes for explanation - ProtoDash - and with other methods widely used in correlated areas of machine learning, such as instance selection and clustering. We conduct experiments on 25 datasets, and results demonstrate significant gains of M-PEER over other strategies, with an average of 12% improvement in the proposed metrics (i.e., model fidelity and stability) and 17% in root mean squared error (RMSE) when compared to ProtoDash. © 2022 Association for Computing Machinery.",example-based explanations; explanation; interpretability; Regression,Evolutionary algorithms; Learning algorithms; Mean square error; Regression analysis; Semantics; Example based; Example-based explanation; Explanation; Interpretability; Machine-learning; Model stability; Modeling fidelity; Multi objective; Real-world problem; Regression; cluster analysis; data set; experimental study; machine learning; optimization; regression analysis; Machine learning
"Theoretical and Empirical Analysis of Parameter Control Mechanisms in the (1 + (λ, λ)) Genetic Algorithm",2023,ACM Transactions on Evolutionary Learning and Optimization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167891225&doi=10.1145%2f3564755&partnerID=40&md5=a4a71ed95f3fec3b88308c8149ff2c44,"The self-adjusting (1 + (λ, λ)) GA is the best known genetic algorithm for problems with a good fitness-distance correlation as in OneMax. It uses a parameter control mechanism for the parameter λ that governs the mutation strength and the number of offspring. However, on multimodal problems, the parameter control mechanism tends to increase λ uncontrollably.We study this problem for the standard Jumpk benchmark problem class using runtime analysis. The self-adjusting (1 + (λ, λ)) GA behaves like a (1 + n) EA whenever the maximum value for λ is reached. This is ineffective for problems where large jumps are required. Capping λ at smaller values is beneficial for such problems. Finally, resetting λ to 1 allows the parameter to cycle through the parameter space. We show that resets are effective for all Jumpk problems: the self-adjusting (1 + (λ, λ)) GA performs as well as the (1 + 1) EA with the optimal mutation rate and evolutionary algorithms with heavy-tailed mutation, apart from a small polynomial overhead.Along the way, we present new general methods for translating existing runtime bounds from the (1 + 1) EA to the self-adjusting (1 + (λ, λ)) GA. We also show that the algorithm presents a bimodal parameter landscape with respect to λ on Jumpk. For appropriate n and k, the landscape features a local optimum in a wide basin of attraction and a global optimum in a narrow basin of attraction. To our knowledge this is the first proof of a bimodal parameter landscape for the runtime of an evolutionary algorithm on a multimodal problem. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",evolutionary algorithms; Parameter control; parameter landscape; runtime analysis; theory,Computation theory; Parameter estimation; Basins of attraction; Control mechanism; Empirical analysis; Multimodal problems; Parameter control; Parameter landscapes; Run-time analysis; Runtimes; Self-adjusting; Theory; empirical analysis; genetic algorithm; machine learning; parameter estimation; Genetic algorithms
