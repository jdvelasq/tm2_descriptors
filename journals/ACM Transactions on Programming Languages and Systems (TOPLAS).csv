Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
Conjoining Specifications,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976854012&doi=10.1145%2f203095.201069&partnerID=40&md5=66fe67d319d5e884e207a1a8b533edb1,[No abstract available],,
Fast Strictness Analysis Based on Demand Propagation,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029407790&doi=10.1145%2f218570.218573&partnerID=40&md5=6cc720cfd194ebbd2539359faa872c6e,[No abstract available],,Algorithms; Computational linguistics; Computational methods; Optimization; Performance; Program compilers; Program processors; Programming theory; Code generation; Demand propagation; Denotational semantics; Fast strictness analysis; Lazy functional programming languages; Normal form evaluation; Polymorphism; Computer programming languages
Typechecking and Modules for Multimethods,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976688946&doi=10.1145%2f218570.218571&partnerID=40&md5=c6323ce98bb4acf9b9e01701cdcfcfcc,"Two major obstacles that hinder the wider acceptance of multimethods are (1) concerns over the lack of encapsulation and modularity and (2) the absence of static typechecking in existing multimethod-based languages. This article addresses both of these problems. We present a polynomial-time, static typechecking algorithm that checks the conformance, completeness, and consistency of a group of method implementations with respect to declared message signatures. This algorithm improves on previous algorithms by handling separate type and inheritance hierarchies, abstract classes, and graph-based method lookup semantics. We also present a module system that enables independently developed code to be fully encapsulated and statically typechecked on a per-module basis. To guarantee that potential conflicts between independently developed modules have been resolved, a simple well-formedness condition on the modules comprising a program is checked at link-time. The typechecking algorithm and module system are applicable to a range of multimethod-based languages, but the article uses the Cecil language as a concrete example of how they can be applied. © 1995, ACM. All rights reserved.",Encapsulation; inheritance; multimethods; static typechecking; subtyping,
A Polymorphic Record Calculus and Its Compilation,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029404987&doi=10.1145%2f218570.218572&partnerID=40&md5=791ee0e0dfa8030b4f590e631e27e715,[No abstract available],,Algorithms; Data structures; Indexing (of information); Inference engines; Program compilers; Programming theory; Translation (languages); Inference algorithm; Polymorphic record calculus; Polymorphism; Program compilation; Computer programming languages
Type Checking Concurrent I/O,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029309265&doi=10.1145%2f203095.203097&partnerID=40&md5=9c75543bfd267951aaadf3c12e376a8a,"In parallel programming languages multityped data structures may be shared by two or more processes. Process I/O to these structures is assumed to be physically interleaved but logically parallel. This article addresses a syntactic mechanism to specify a type for such structures and extends an example language and its type-checking algorithm to these structures. © 1995, ACM. All rights reserved.",Concurrency; event recognition; parallel programming; process communication; traces; type checking,Algorithms; Communication channels (information theory); Computer programming languages; Computer systems programming; Concurrency control; Data structures; Input output programs; Synchronization; Parallel programming; Process communication; Syntactic mechanism; Traces; Type checking; Parallel processing systems
An Evaluation of an Automatically Generated Compiler,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029370115&doi=10.1145%2f213978.213980&partnerID=40&md5=2c7bf4c80ebf013e2466c16b131c038a,"Cornpders or language trauhlators can be generated using a variety of formal specfrcation techniques. Whether generatlou 1s worthwhile depends on the effort requu-ed to specify the translat Ion task and the quahty of the generated conlpder A systemat IC comparison was conducted between a hand-coded translator for the Icon programming language and one generated by the Eh compiler construction system A du-ect comparison could be made since the generated program performs the same translatlou as the hand-coded program. The results of the comparlsou show that efficieut compilers can be generated from specifications that are much smaller and more problem oriented than the equivalent source code We also found that further work must be done to reduce the dynannc memory usage of the generated cornpders. Categories and Subject Descriptors C.4 [Performance of Systems] Lleasurement techniques, D 2 m [Software Engineering] Miscellaneous-r-eusabk software, D 3-1 [Programming Languages] Processors-translator writing systems [Ind compder generators. General Terms Experunelltatlon Languages Performance. © 1995, ACM. All rights reserved.",Compder generation,Computer hardware description languages; Computer programming languages; Performance; Program translators; Software engineering; Storage allocation (computer); Formal specification technique; Hand coded translator; Hand coding compilers; Icon programming language; Program compilers
Covariance and Contravariance: Conflict without a Cause,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976655461&doi=10.1145%2f203095.203096&partnerID=40&md5=5e78485d11e4c5d389e8342f4ace604c,"In type-theoretic research on object-oriented programming, the issue of “covarianceversus contravariance” is atopicof continuing debate. In this short notewe argue that covariance and contravariance appropriately characterize two distinct and independent mechanisme. The so-called contravariance rule correctly captures the subtyping relation (that relation which establishes which sets of functions can replace another given set in every context). A covariant relation, instead, characterizes the speczalizatzon of code (i.e., the definition of new code which replaces old definitions in some particular cases). Therefore, covariance and contravariance are not opposing views, but distinct concepts that each have their place inobject-oriented systems. Both can (and should) be integrated in a type-safe manner in object-oriented languages. We also show that the independence of the two mechanisms is not characteristic of aparticular model but is valid in general, since covariant specialization is present in record-based models, although it is hidden by a deficiency of all existing calculi that realize this model. Asanaside, weshowthat the calculus can betaken asthebmic calculus for both anoverloading-bmed and arecord-based model, Using this approach, onenotonly obtains amoreuniform vision ofobject-oriented type theories, but in the case of the record-based approach, one also gains multiple dispatching, a feature that existing record-based models do not capture. © 1995, ACM. All rights reserved.",Object-oriented languages; type theory,
Efficient Fault-Tolerant Algorithms for Distributed Resource Allocation,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029307011&doi=10.1145%2f203095.203101&partnerID=40&md5=3425360bfcfaa71f538dadc55f91c5e8,"Solutions to resource allocation problems and other related synchronization problems in distributed systems are examined with respect to the measures of response time, message complexity, and failure locality. Response time measures the time it takes for an algorithm to respond to the requests of a process; message complexity measures the number of messages sent and received by a process; and failure locality characterizes the size of the network that is affected by the failure of a single process. An algorithm for the resource allocation problem that achieves a constant failure locality of four along with a quadratic response time and a quadratic message complexity is presented. Applications of the algorithm to other process synchronization problems in distributed systems are also demonstrated. © 1995, ACM. All rights reserved.",Committee coordination; dining philosophers; distributed resource allocation; failure locality,Computational complexity; Computer networks; Computer systems programming; Concurrency control; Distributed computer systems; Fault tolerant computer systems; Performance; Reliability; Resource allocation; Response time (computer systems); Synchronization; Committee coordination; Concurrent programming; Failure locality; Fault tolerant algorithms; Message complexity; Algorithms
Lattice Frameworks for Multisource and Bidirectional Data Flow Problems,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976832033&doi=10.1145%2f213978.213989&partnerID=40&md5=3524bd0762953e6455bd1cce2d9e0a07,[No abstract available],,
Efficiently Computing 0-Nodes On-The-Fly,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976683699&doi=10.1145%2f203095.203099&partnerID=40&md5=b32243db3fdc566921c21efcea536ac0,"Recently, Static Single-Assignment Form and Sparse Evaluation Graphs have been advanced for the efficient solution of program optimization problems. Each method is provided with an initial set of flow graph nodes that inherently affect a problem's solution. Other relevant nodes are those where potentially disparate solutions must combine. Previously, these so-called ø-nodes were found by computing the iterated dominance frontiers of the initial set of nodes, a process that could take worst-case quadratic time with respect to the input flow graph. In this article we present an almost-linear algorithm for determining exactly the same set of ø-nodes. © 1995, ACM. All rights reserved.",Static Single-Assignment (SSA) form,
Efficient Instruction Scheduling for Delayed-Load Architectures,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029368698&doi=10.1145%2f213978.213987&partnerID=40&md5=eb2cfcc6e36164ae443f175bca647121,[No abstract available],,Algorithms; Codes (symbols); Heuristic programming; Optimization; Program compilers; Program processors; Scheduling; Storage allocation (computer); Code generation; Delayed load architecture; Expression tree scheduling; Integrated prepass scheduling; Register allocation; Reduced instruction set computing
Higher-Order Distributed Objects,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878155336&doi=10.1145%2f213978.213986&partnerID=40&md5=1c1dffb7c01bca285e471f6ea5a1615f,[No abstract available],,
BURS Automata Generation,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029308706&doi=10.1145%2f203095.203098&partnerID=40&md5=4ed6a798bc50516ac21c8a008d9db210,"A simple and efficient algorlthm for generating bottom-up rewrite system (BURS) tables 1s described. A small code-generator generator Implementation produces BURS tables efficiently, even for complex instruction set descriptions The algorlthm does not reqrure novel data structures or cornphcated algorithmic techniques Previously publmhed methods for on-the-fly ellmmatlon of states are generahzed and simphfied to create a new method, tmangle trzmmzng, that is employed m the algorlthm A prototype Implementation, burg, generates BURS tables very efficiently. © 1995, ACM. All rights reserved.",Code generation; code-generator generator; dynamic programming; tree pattern matchmg,Automata theory; Codes (symbols); Data structures; Dynamic programming; Optimization; Program compilers; Programming theory; Bottom up rewrite system; Code generation; Code generator; Tree pattern matching; Algorithms
Influence of Cross-Interferences on Blocked Loops: A Case Study with Matrix-Vector Multiply,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976754803&doi=10.1145%2f210184.210185&partnerID=40&md5=7f8f196dd0c323b438791cba16bc3482,"State-of-the art data locality optimizing algorithms are targeted for local memories rather than for cache memories. Recent work on cache interferences seems to indicate that these phenomena can severely affect blocked algorithms cache performance. Because of cache conflicts, it is not possible to know the precise gain brought by blocking. It is even d Micult to determine for which problem sizes blocking is useful. Computing the actual optimal block size is difficult because cache conflicts are highly irregular. In this article, we illustrate the issue of precisely evaluating cross-interferences in blocked loops with blocked matrix-vector multiply. Most significant interference phenomena are captured because unusual parameters such as array base addresses are being considered. The techniques used allow us to compute the precise improvement due to blocking and the threshold value of problem parameters for which the blocked loop should be preferred. It is also possible to derive an expression of the optimal block size as a function of problem parameters. Finally, it is shown that a precise rather than an approximate evaluation of cache conflicts is sometimes necessary to obtain near-optimal performance. © 1995, ACM. All rights reserved.",Blocklng; cache confllcts (interferences); cache performance; data locality optimization; numerical codes,
Experimental Results from Dynamic Slicing of C Proarams,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273331&doi=10.1145%2f201059.201062&partnerID=40&md5=3f603d51fdbeca7f9a65eadaa761160f,"Program slicing is a program analysis technique that has been studied in the context of several different applications in the construction, optimization, maintenance, testing, and debugging of programs. Algorithms are available for constructing slices for a particular execution of a program (dynamic slices), as well as to approximate a subset of the behavior over all possible executions of a program (static slices). However, these algorithms have been studied only in the context of small abstract languages. Program slicing is bound to remain an academic exercise unless one can not only demonstrate the feasibility of building a slicer for nontrivial programs written in a real programming language, but also verify that a type of slice is sufficiently thin, on the average, for the application for which it is chosen. In this article we present results from using SLICE, a dynamic program slicer for C programs, designed and implemented to experiment with several different kinds of program slices and to study them both qualitatively and quantitively. Several application programs, ranging in size (i.e., number of lines of code) over two orders of magnitude, were sliced exhaustively to obtain average worst-case metrics for the size of program slices. © 1995, ACM. All rights reserved.",Program analysis; program slice,Algorithms; Codes (symbols); Computer software; Data reduction; Optimization; Performance; Program compilers; Program debugging; Software engineering; Dynamic slicing; Program analysis; Program slice; Program testing; C (programming language)
Matching-Based Incremental Evaluators for Hierarchical Attribute Grammar Dialects,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273175&doi=10.1145%2f201059.201071&partnerID=40&md5=04929b4e54d99c1b88e99211d7619841,"Although attribute grammars have been very effective for defining individual modules of language translators, they have been rather ineffective for specifying large program-transformational systems. Recently, several new attribute grammar “dialects” have been developed that support the modular specification of these systems by allowing modules, each described by an attribute grammar, to be composed to form a complete system. Acceptance of these new hienzrchzcal attribute grammar dialects requires the availability of efficient batch andincremental evaluators for hierarchical specifications. This paper addresses the problem of developing efficient incremental evaluators for hierarchical specifications. A matching-based approaches taken in order to exploit existing optimal change propagation algorithms for nonhierarchical attribute grammars. A sequence of four new matching algorithms is presented, each increasing the number of previously computed attribute values that are made available for reuse during the incremental update. © 1995, ACM. All rights reserved.",Attribute grammar; environments; hierarchical specifications; incremental evaluation; language translation; translators,Algorithms; Computer aided language translation; Computer hardware description languages; Encoding (symbols); File editors; Hierarchical systems; Optimization; Program compilers; Program translators; Software engineering; Attribute grammars; Hierarchical specifications; Incremental evaluation; Translator writing systems; Computational grammars
"Combining Analysis, Combining Optimizations",1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273299&doi=10.1145%2f201059.201061&partnerID=40&md5=54a3969b0076d3e57fdb12a072f0b290,"Modern optimizing compilers use several passes over a program's intermediate representation to generate good code. Many of these optimization exhibit a phase-ordering problem. Getting the best code may require iterating optimizations until a fixed point is reached. Combining these phases can lead to the discovery of more facts about the program, exposing more opportunities for optimization. This article presents a framework for describing optimizations. It shows how to combine two such frameworks and how to reason about the properties of the resulting framework. The structure of the framework provides insight into when a combination yields better results. To make the ideas more concrete, this article presents a framework for combining constant propagation, value numbering, and unreachable-code elimination. It is an open question as to what other frameworks can be combined in this way. © 1995, ACM. All rights reserved.",Constant propagation; data-flow analysis; optimizing compilers; value numbering,Algorithms; Codes (symbols); Computation theory; Computer programming languages; Computer software; Data reduction; Iterative methods; Optimization; Constant propagation; Data flow analysis; Processors; Value numbering; Program compilers
Optimization of Functional Programs by Grammar Thinning,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029275592&doi=10.1145%2f201059.201067&partnerID=40&md5=e5fdcd4ee17b1fd3d684d4e23c066c2f,"Redescribe anew technique foroptimizing first-order functional programs. Programs arerepresented as graph grammars, and optimization proceeds by connterexample: when a graph generated by the grammar is found to contain an unnecessary computation, the optimizer attempts to reformulate the grammar so that it never again generates any graph that contains that counterexample. This kind of program reformulation corresponds to an interesting problem on context-free grammars. Our reformulation technique isderived from an (approximate) solution to this CFG problem. An optimizer called Thinner is the proof of concept for this technique. Thinner is a fully automatic, source-to-source optimizer for a Lisp-like language of purely functional, firstorder programs. Thinner rediscovers a wide variety of common compiler optimization. It also finds other more exotic transformations, including the well-known Fibonacci reformulation and the Knuth-Morris-Pratt optimization. © 1995, ACM. All rights reserved.",Functional languages; graph grammars; optimization,Approximation theory; Computational grammars; Computational methods; Context free grammars; Formal languages; Formal logic; Graph theory; LISP (programming language); Logic programming; Optimization; Program compilers; Theorem proving; Functional programs; Grammar thinning; Graph grammars; Language classification; Mathematical logic; Computer software
Backtracking without Trailing in CLP,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976825880&doi=10.1145%2f210184.210192&partnerID=40&md5=1bbae93d924615e2cae252a715eb3f04,"Existing CLP languages support backtracking by generalizing traditional Prolog implementatmns: modifications totheconstraint system aretrailed and restoredon backtracking. AItfmugh simple and efficient, trailing may be very demanding in memory space, since the constraint system may pmentmlly be saved at each chmce point. TM article proposes a new Implementation scheme for backtracking in CLP languages over Iinear(ratlonal or reali arithmetic. Thenewscheme. called semanttc fmcktmcktngq does not use trailing but rather exploits the semantics of the constramtsto undo the effect of newly added constraints. Semantic backtracking reciuces the space complexity compared to Implementations based ontrailing bymaking ltessentially independent of thenumber ofchoicepolnts. Inacfcfitlon, semantic backtracking introduces negligible space and time overhead on deterministic programs. The price forthls improvement is an increase in backtracfungtime. although constraint-solving time mayactually cfecrease Thescheme has been implemented aspartof acomplete CLP system CLP(LinJ and compared analytically and experlmentally with Optimlzed trailing Implementatlons Experimental results on small and real-hfeproblerm indicate that semantic backtracking produces significant reduction m memory space, while keeping the time overhead reasonably small. © 1995, ACM. All rights reserved.",Backtracking; constraint logic programmming; trailing,
A Worst Case of Circularity Test Algorithms for Attribute Grammars,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273220&doi=10.1145%2f201059.201064&partnerID=40&md5=329b79c2ef81b4314914c155a352fbf4,"Although the circularity test problem for attribute grammars (AGs) has been proven to be intrinsically exponential, to date, a worst case for the existing circularity test algorithms has yet to be presented. This note presents a worst-case AG in which the number of incomparable dependency graphs induced at the root is exponential. The worst case can help to clarify the complexity of the problem. © 1995, ACM. All rights reserved.",Attribute grammars; circularity test; dependency graphs,Computational complexity; Computational linguistics; Computer programming languages; Formal languages; Formal logic; Graph theory; Program compilers; Program debugging; Program translators; Theorem proving; Attribute grammars; Circularity test algorithms; Compiler generators; Dependency graphs; Formal definitions; Semantics; Translator writing systems; Algorithms
Error Repair in Shift-Reduce Parsers,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976733757&doi=10.1145%2f210184.210193&partnerID=40&md5=1e3a537da56588cc28f46f07057c0b76,"Local error repair of strings during CFG parskg requires the insertion and deletion of syrnbok in the region of a syntax error to produce a string that k error free. Rather than precalculating tables at parser generation time to assist in finding such repairs, this article shows how such repairs can be found during shifk-reduce parsing by using the parsing tables themselves. This results in a substantial space saving over methods that require precalculated tables. Furthermore, the article shows how the method can be integrated with Iookahead to avoid finding repairs that immediately result in further syntax errors. The article presents the resuks of experiments on a version of the LALR(1)-based parser generator Bison to which the algorlthm was added. © 1995, ACM. All rights reserved.",BiSon; error recovery; least cost; shift-reduce; Yacc,
On the Complexity of Dataflow Analysis of Logic Programs,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273133&doi=10.1145%2f201059.201068&partnerID=40&md5=2b3a800501d4504a3f3ac4d6dd00fe31,"It is widely held that there is a correlation between complexity and precision in dataflow analysis, in the sense that the more precise an analysis algorithm, the more computationally expensive it must be. The details of this relationship, however, appear to not have been explored extensively. This article reports some results on this correlation in the context of logic programs. A formal notion of the “precision” of an analysis algorithm is proposed, and this is used to characterize the worst-case computational complexity of a number of dataflow analyses with different degrees of precision. While this article considers the analysis of logic programs, the technique proposed, namely the use of “exactness sets” to study relationships between complexity and precision of analyses, is not specific to logic programming in any way, and is equally applicable to flow analyses of other language families. © 1995, ACM. All rights reserved.",Complexity; program analysis; Prolog,Algorithms; Computational complexity; Logic programming; Problem solving; Program compilers; PROLOG (programming language); Theorem proving; Dataflow analysis; Language classifications; Nonnumerical algorithms; Problem complexity; Proof procedures; Data reduction
A Complete Calculus for the Multialgebraic and Functional Semantics of Nondeterminism,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029275563&doi=10.1145%2f201059.201070&partnerID=40&md5=5cc2522dc55e1bb97ce32f0c03e2b9de,"The current algebraic models for nondeterminism focus on the notion of possibility rather than necessity and consequently equate (nondeterministic) terms that one would intuitively not consider equal. Furthermore, existing models for nondeterminism depart radically from the standard models for (equational) specifications of deterministic operators. One would prefer that a specification language for nondeterministic operators be based on an extension of the standard model concepts, preferably in such a way that the reasoning system for (possibly nondeterministic) operators becomes the standard equational one whenever restricted to the deterministic operators-the objective should be to minimize the departure from the standard frameworks. In this article we define a specification language for nondeterministic operators and multialgebraic semantics. The first complete reasoning system for such specifications is introduced. We also define a transformation of specifications of nondeterministic operators into derived specifications of deterministic ones, obtaining a “computational” semantics of nondeterministic specification by adopting the standard semantics of the derived specification as the semantics of the original one. This semantics turns out to be a refinement of multialgebra semantics. The calculus is shown to be sound and complete also with respect to the new semantics. © 1995, ACM. All rights reserved.",Algebraic specifications; reasoning with nondeterminism,Algebra; Computational linguistics; Computational methods; Computer simulation; Differentiation (calculus); Formal languages; Formal logic; Mathematical models; Mathematical operators; Algebraic specifications; Functional semantics; Nondeterminism; Nondeterministic languages; Nonprocedural languages; Computer hardware description languages
A Reexamination of “Optimization of Array Subscript Range Checks”,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029275562&doi=10.1145%2f201059.201063&partnerID=40&md5=b19e9b84a32ed7fe6797aa92a4fc252c,"Jonathan Asuru proposed recently an enhanced method for optimizing array subscript range checks. The proposed method is however unsafe and may generate optimized programs whose behavior is different from the original program. Two main flaws in Asuru's method are described, together with suggested remedies and improvements. © 1995, ACM. All rights reserved.",Backward checks propagation; integer programming; loop guard elimination; safe bound checks optimization,Computer programming languages; Computer system recovery; Data handling; Error analysis; Integer programming; Mathematical programming; Optimization; Program compilers; Reliability; Software engineering; Backward checks propagation; Error handling; Loop guard elimination; Safe bound checks optimization; Program debugging
Supporting Dynamic Data Structures on Distributed-Memory Machines,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029273301&doi=10.1145%2f201059.201065&partnerID=40&md5=806182b609fee2d85ffd156293027172,"Compiling for distributed-memory machines has been a very active research area in recent years. Much of this work has concentrated on programs that use arrays as their primary data structures. To date, little work has been done to address the problem of supporting programs that use pointerbased dynamic data structures. The techniques developed for supporting SPMD execution of array-breed programs rely on the fact that arrays are statically defined and directly addressable. Recursive data structures do not have these properties, so new techniqu= must be developed. In this article, we describe an execution model for supporting programs that use pointer-based dynamic data structumx. Thk model uses a simple mechanism for ruigrating a thread of control based on the layout of heap-allocated data and introduces parallelism using a technique based on futures and lazy task creation. We intend to exploit this execution model using compiler analyses and automatic parallelization techniques. We have implemented a prototype system, which we call olden, that runs on the Intel iPSC/860 and the Thinking Machines CM-5. We discuss our implementation and report on experiments with five benchmarks. © 1995, ACM. All rights reserved.",Dynamic data structures,Computer programming languages; Computer simulation; Computer software; Data storage equipment; Distributed computer systems; Parallel processing systems; Performance; Program compilers; Software prototyping; Storage allocation (computer); Distributed memory machines; Dynamic data structures; Parallel programming; Run time environments; Data structures
Extracting Task-Level Parallelism,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029336413&doi=10.1145%2f210184.210189&partnerID=40&md5=5f002a05f156736c77e262475d9820bf,"Automatlc detection of tusk (also referred to as functional. DA(+ unstructured or thread parallelism) at various levels of program granularltv E becornlng mcreasmgly Important for parallehzmg and back-end compders Parallelmlng compilers detect lteration-level or coarser granularity parallehsm which is suitable for parallel computers, detection of parallehsm at the statement or operation-level is essential for most modern microprocessors mcludmg superscalar and architectures In this article ve study the problem of detecting, expressing and cptlnnzmg task-level parallehsm where “task” refers to a program statement of arbitrary granularity Optlmlzmg the amount of functional parallelism (by allowing synchronization between arbitrary nodes) m sequential programs reques the notion of HI term of paths m graphs which Incorporate control and data dependence Precedences have been defined before In a dfferent context: however the defimtmn was dependent on the Ideas of parallel execution and time Ve show that the problem of determmmg precedences statically IS NP-complete Determmmg precedence relationships E useful m finding the essential data dependence show that there a unique mmlmum set of essential data dependence, finding tlms mmlmum set M NP-hard and NP-easy We also propose a heurlst]c algorithm for flndlng the set of esentlal data dependence Static analysls of a program in the Perfect Benchmarks vas done and we present some experimental results. © 1995, ACM. All rights reserved.",Code generatlou; control and data dependence parallelizing compders; synchroulzatlon,Algorithms; Computational complexity; Data structures; Heuristic programming; Iterative methods; Microcomputers; Optimization; Program compilers; Programming theory; Synchronization; Code generation; Completeness; Control and data dependences; Perfect benchmarks; Program granularity; Reducibility; Sequential programs; Task level parallelism; Parallel processing systems
Efficient Implementation of Adaptive Software,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029277801&doi=10.1145%2f201059.201066&partnerID=40&md5=e1248a5f722ba94c399ad5cd511a6865,"Adaptive programs compute with objects, just like object-oriented programs. Each task to be accomplished is specified by a so-called propagation pattern which traverses the receiver object. The object traversal is a recursive descent via the instance variables where information is collected or propagated along the way. A propagation pattern consists of (1) a name for the task, (2) a succinct specification of the parts of the receiver object that should be traversed, and (3) code fragments to be executed when specific object types are encountered The propagation patterns need to be complemented by a class graph which defines the detailed object structure. The separation of structure and behavior yields a degree of flexibility and understandability not present in traditional object-oriented languages For example, the class graph can be changed without changing the adaptive program at all. We present an efficient, implementation of adaptive programs. Given an adaptive program and a class graph, we generate an efficient object-oriented program, for example, in C++. Moreover, we prove the correctness of the core of this translation. A key assumption m the theorem is that the traversal specifications are consistent with the class graph. We prove the soundness of a proof system for conservatively checking consistency, and we show how to implement it efficiently. © 1995, ACM. All rights reserved.",Adaptive software; correctness proof; object traversal,Adaptive systems; C (programming language); Codes (symbols); Data structures; Graph theory; Object oriented programming; Program compilers; Recursive functions; Software engineering; Theorem proving; Adaptive software; Correctness proof; Object traversal; Reusable software; Computer software
A Type System Equivalent to Flow Analysis,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029336307&doi=10.1145%2f210184.210187&partnerID=40&md5=39fc8c2dd79b64ddd53fb804f2373cda,"Flow-baaed safety analysis of higher-order languages has been studied by Shivers. and Palsberg and Schwartzbach. Open untd now M the problem of finding a type system that accepts exactly the same programs as safety analysis. In this article we prove that Amadio and Cardelli's type system with sub typing and recurmve t ypes accepts the same programs as a cert am safety analysls. The proof involves mappings from types to flow mformatlon and back. As a result. we obtain an inference algorithm for the type system, thereby solving an open problem. © 1995, ACM. All rights reserved.",Constraints; flow analysis,Algorithms; Constraint theory; Programming theory; Theorem proving; Closure analysis; Flow analysis; Higher-order languages; Safety analysis; Type system; Computer programming languages
Local and Temporal Predicates in Distributed Systems,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029215349&doi=10.1145%2f200994.201005&partnerID=40&md5=0ad9c0585c31b06e20b2243f6c2b2348,"The definitions of the predicates Possibly ɸ and Definitely ɸ, where ɸ is a global predicate of a distributed computation, lead to the definitions of two predicate transformers P and D. We show that P plays the same role with respect to time as the predicate transformers Ki in knowledge theory play with respect to space. Pursuing this analogy, we prove that local predicates are exactly the fixed points of the Ki's while the stable predicates are the fixed points of P. In terms of the predicate transformers P and D, we define a new class of predicates that we call observer-independent predicates and for which the detection of Possibly ɸ and Definitely ɸ is quite easy. Finally, we establish a temporal counterpart to the knowledge change theorem of Chandy and Misra which formally proves that the global view of a distributed system provided by its various observations does not differ too much from its truth behavior. © 1995, ACM. All rights reserved.",Distributed computation; knowledge predicate; local predicate; observation; predicate; predicate transformer; temporal predicate,Computation theory; Computational methods; Program debugging; Distribution computation; Knowledge predicate; Local predicate; Observation; Predicate transformer; Temporal predicate; Distributed computer systems
Optimal Incremental Parsing,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029215348&doi=10.1145%2f200994.200996&partnerID=40&md5=ba53b7519495bd6d988f8f059fb17f3e,"This communication sets the problem of incremental parsing in the context of a complete incremental compiling system. It turns out that, according to the incrementally paradigm of the attribute evaluator and data-flow analyzer to be used, two definitions of optimal incrementality in a parser are possible. Algorithms for achieving both forms of optimality are given, both of them based on ordinary LALR1995 parse tables. Optimality and correctness proofs, which are merely outlined in this communication, are made intuitive thanks to the concept of a well-formed list of threaded trees, a natural extension of the concept of threaded tree found in earlier works on incremental parsing. © 1995, ACM. All rights reserved.",Incremental parsing; threaded trees,Algorithms; Computer programming; Data structures; Programming theory; Software engineering; Incremental parsing; Threaded trees; Program compilers
Notes on “A Methodology for Implementing Highly Concurrent Data Objects”,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029238261&doi=10.1145%2f200994.200999&partnerID=40&md5=14995ea291c05df1f43aa258a1ac067a,[No abstract available],,Computer architecture; Data storage equipment; Errors; Fault tolerant computer systems; Network protocols; Synchronization; Concurrent data objects; Storage layout; Object oriented programming
Deducing Fairness Properties in UNITY Logic—a New Completeness Result,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029216423&doi=10.1145%2f200994.200997&partnerID=40&md5=652e88a01f29487f6abe078ba11d3125,"We explore the use of UNITY logic in specifying and verifying fairness properties of UNITY and UNITY-like programs whose semantics can be modeled by weakly fair transition systems. For such programs, strong fairness properties in the form of “if p holds infinitely often then q also holds infinitely often [formula omitted], can be expressed as conditional UNITY properties of the form of “Hypothesis: [formula omitted]”. We show that UNITY logic is relatively complete for proving such properties; in the process, a simple inference rule is derived. Specification and verification of weak fairness properties are also discussed. © 1995, ACM. All rights reserved.",completeness; fairness properties; temporal logic; UNITY,Computational linguistics; Computer simulation; Computer software; Programming theory; Theorem proving; Completeness; Fairness properties; Inference rule; Temporal logic; UNITY logic; Formal logic
Safe: A Semantic Technique for Transforming Programs in the Presence of Errors,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029226260&doi=10.1145%2f200994.201002&partnerID=40&md5=037cf8a48e37c4f6d4bd79ea5e1a126a,"Language designers and implementors have avoided specifying and preserving the meaning of programs that produce errors. This is apparently because being forced to preserve error behavior limits severely the scope of program optimization, even for correct programs. However, error behavior preservation is desirable for debugging, and error behavior must be preserved in any language that permits user-generated errors 1995. This article presents a technique for expressing general program transformations for languages that possess a rich collection of distinguishable error values. This is accomplished by defining a higher-order function called Safe, which can be used to annotate those portions of a program that are guaranteed not to produce errors. It is shown that this facilitates the expression of very general program transformations, effectively giving program transformations in a language with many error values the same power and generality as program transformations in a language with only a single error value. Using the semantic properties of Safe, it is possible to provide some useful sufficient conditions for establishing the correctness of transformations in the presence of errors. In particular, a Substitutability theorem is proven, which can be used to justify “in-context” optimizations: transformations that alter the meanings of subexpressions without changing the meaning of the whole program. Finally, the effectiveness of the technique is demonstrated by some examples of its use in an optimizing compiler. © 1995, ACM. All rights reserved.",Equational reasoning; exceptions; program optimization; program transformation,Computer programming; Computer programming languages; Computer software; Errors; Program debugging; Programming theory; Equational reasoning; Exceptions; Program optimization; Program transformations; Computational linguistics
Closure Analysis in Constraint Form,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029239054&doi=10.1145%2f200994.201001&partnerID=40&md5=c5c992b3554caba4a26e674bf8766f41,"Flow analyses of untyped higher-order functional programs have in the past decade been presented by Ayers, Bondorf, Consel, Jones, Heintze, Sestoft, Shivers, Steckler, Wand, and others. The analyses are usually defined as abstract interpretations and are used for rather different tasks such as type recovery, globalization, and binding-time analysis. The analyses all contain a global closure analysis that computes information about higher-order control-flow. Sestoft proved in 1989 and 1991 that closure analysis is correct with respect to call-by-name and call-by-value semantics, but it remained open if correctness holds for arbitrary beta-reduction. This article answers the question; both closure analysis and others are correct with respect to arbitrary beta-reduction. We also prove a subject-reduction result: closure information is still valid after beta-reduction. The core of our proof technique is to define closure analysis using a constraint system. The constraint system is equivalent to the closure analysis of Bondorf, which in turn is based on Sestoft's. © 1995, ACM. All rights reserved.",Constraints; correctness proof; flow analysis,Computational linguistics; Computer programming; Constraint theory; Programming theory; Applicative languages; Beta reduction; Closure analysis; Constraints; Correctness proof; Flow analysis; Semantics; Computer programming languages
Improving Abstract Interpretations by Combining Domains,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029215597&doi=10.1145%2f200994.200998&partnerID=40&md5=908a3da528ec62d27bddc357d7ad8b37,"This article considers static analysis based on abstract interpretation of logic programs over combined domains. It is known that analyses over combined domains provide more information potentially than obtained by the independent analyses. However, the construction of a combined analysis often requires redefining the basic operations for the combined domain. A practical approach to maintain precision in combined analyses of logic programs which reuses the individual analyses and does not redefine the basic operations is illustrated. The advantages of the approach are that 1995 proofs of correctness for the new domains are not required and (2) implementations can be reused. The approach is demonstrated by showing that a combined sharing analysis—constructed from “old” proposals—compares well with other “new” proposals suggested in recent literature both from the point of view of efficiency and accuracy. © 1995, ACM. All rights reserved.",Abstract interpretation; logic programming; program analysis,Computer programming languages; Computer software; Efficiency; Programming theory; Abstract interpretation; Accuracy; Assertions; Invariants; Program analysis; Logic programming
Optimal Evaluation of Array Expressions on Massively Parallel Machines,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029238937&doi=10.1145%2f200994.201004&partnerID=40&md5=32b2d4643b5f3e6c02c99b9b099cac84,"We investigate the problem of evaluating Fortran 90-style array expressions on massively parallel distributed-memory machines. On such a machine, an elementwise operation can be performed in constant time for arrays whose corresponding elements are in the same processor. If the arrays are not aligned in this manner, the cost of aligning them is part of the cost of evaluating the expression tree. The choice of where to perform the operation then affects this cost. We describe the communication cost of the parallel machine theoretically as a metric space; we model the alignment problem as that of finding a minimum-cost embedding of the expression tree into this space. We present algorithms based on dynamic programming that solve the embedding problem optimally for several communication cost metrics: multidimensional grids and rings, hypercubes, fat-trees, and the discrete metric. We also extend our approach to handle operations that change the shape of the arrays. © 1995, ACM. All rights reserved.",array alignment; compact dynamic programming; data-parallel programming; distributed memory parallel processors; fixed topology Steiner tree; Fortran 90,Algorithms; Data structures; Dynamic programming; FORTRAN (programming language); Interconnection networks; Problem solving; Program compilers; Massively parallel machines; Multiple input multiple data; Single input multiple data; Parallel processing systems
Beyond Induction Variables: Detecting and Classifying Sequences Using a Demand-Driven SSA Form,1995,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029214850&doi=10.1145%2f200994.201003&partnerID=40&md5=66e5b3abb275894bc63888f47581b2c1,"Linear induction variable detection is usually associated with the strength reduction optimization. For restructuring compilers, effective data dependence analysis requires that the compiler detect and accurately describe linear and nonlinear induction variables as well as more general sequences. In this article we present a practical technique for detecting a broader class of linear induction variables than is usually recognized, as well as several other sequence forms, including periodic, polynomial, geometric, monotonic, and wrap-around variables. Our method is based on Factored Use-Def 1995 chains, a demand-driven representation of the popular Static Single Assignment (SSA) form. In this form, strongly connected components of the associated SSA graph correspond to sequences in the source program: we describe a simple yet efficient algorithm for detecting and classifying these sequences. We have implemented this algorithm in Nascent, our restructuring Fortran 90+ compiler, and we present some results showing the effectiveness of our approach. © 1995, ACM. All rights reserved.",Constant propagation; def-use chain; demand-driven; induction variable; static single assignment; strength reduction; wraparound variable,Algorithms; Computer programming languages; Computer software; Program compilers; Programming theory; Constant propagation; Def use chain; Demand driven; Induction variables; Static single assignment; Strength reduction; Wrap around variable; Data structures
Model Checking and Abstraction,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028513196&doi=10.1145%2f186025.186051&partnerID=40&md5=924c41e933a424a9f33bab2b89a11c2d,"We describe a method for using abstraction to reduce the complexity of temporal-logic model checking. Using techniques similar to those involved in abstract interpretation, we construct an abstract model of a program without ever examining the corresponding unabstracted model. We show how this abstract model can be used to verify properties of the original program. We have implemented a system based on these techniques, and we demonstrate their practicality using a number of examples, including a program representing a pipelined ALU circuit with over 101300 states. © 1994, ACM. All rights reserved.",abstract interpretation; binary decision diagrams (BDDs); model checking; temporal logic,Abstracting; Computational complexity; Computer simulation; Computer systems programming; Abstraction; Model checking; Temporal logic; Verification; Logic programming
Time-Constrained Buffer Specifications in CSP + T and Timed CSP,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028547085&doi=10.1145%2f197320.197322&partnerID=40&md5=09edc88872e9fd69742764a60453438e,"A finite buffer with time constraints on the rate of accepting inputs, producing outputs, and message latency is specified using both Timed CSP and a new real-time specification language, CSP + T, which adds expressive power to some of the sequential aspects of CSP and allows the description of complex event timings from within a single sequential process. On the other hand, Timed CSP encourages event-timing descriptions to be built up in a constraint-oriented manner with the parallel composition of several processes. Although these represent two complementary specification styles, both provide valuable insights into the specification of complex event timings. © 1994, ACM. All rights reserved.",Real-time algebraic languages,Computational linguistics; Computer hardware description languages; Constraint theory; Data communication systems; Real time systems; Specifications; Complex event timings; Real time algebraic languages; Real time specification language; Time constrained buffer specifications; Time constraints; Timed CSP (programming language); Software engineering
Efficiently Counting Program Events with Support for On-Line Queries,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028513181&doi=10.1145%2f186025.186027&partnerID=40&md5=4049ee8c8b99b5e7b5d2e6c07cfe5f12,"The ability to count events in a program's execution is required by many program analysis applications. We represent an instrumentation method for efficiently counting events in a program's execution, with support for on-line queries of the event count. Event counting differs from basic block profiling in that an aggregate count of events is kept rather than a set of counters. Due to this difference, solutions to basic block profiling are not well suited to event counting. Our algorithm finds a subset of points in a program to instrument, while guaranteeing that accurate event counts can be obtained efficiently at every point in the execution. © 1994, ACM. All rights reserved.",Control-flow graph; counting; instrumentation,Digital arithmetic; Input output programs; Parallel algorithms; Program debugging; Query languages; Basic block profiling; Instrumentation method; On line queries; Program events counting; Mathematical programming
Automatic Isolation of Compiler Errors,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028513182&doi=10.1145%2f186025.186103&partnerID=40&md5=770e86c7a531c2e2a38f90912feb1f17,"This paper describes a tool called vpoiso that was developed to isolate errors automatically in the vpo compiler system. The two general types of compiler errors isolated by this tool are optimization and nonoptimization errors. When isolating optimization errors, vpoiso relies on the vpo optimizer to identify sequences of changes, referred to as transformations, that result in semantically equivalent code and to provide the ability to stop performing improving 1994 transformations after a specified number have been performed. A compilation of a typical program by vpo often results in thousands of improving transformations being performed. The vpoiso tool can automatically isolate the first improving transformation that causes incorrect output of the execution of the compiled programs by using a binary search that varies the number of improving transformation performed. Not only is the illegal transformation automatically isolated, but vpoiso also identifies the location and instant the transformation is performed in vpo. Nonoptimization errors occur from problems in the front end, code generator, and necessary transformations in the optimizer. If another compiler is available that can produce correct (but perhaps more inefficient) code, then vpoiso can isolate nonoptimization errors to a single function. Automatic isolation of compiler errors facilitates retargeting a compiler to a new machine, maintenance of the compiler, and supporting experimentation with new optimizations. © 1994, ACM. All rights reserved.",automatic error isolation; diagnosis procedures; nonoptimization errors; optimization errors,Binary sequences; Codes (symbols); Errors; High level languages; Optimization; Automatic error isolation; Improving transformations; Nonoptimization errors; Optimization errors; Program compilers
The Undecidability of Aliasing,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028510908&doi=10.1145%2f186025.186041&partnerID=40&md5=f3678d2b46b46956635622a234829f3d,"Alias analysis is a prerequisite for performing most of the common program analyses such as reaching-definitions analysis or live-variables analysis. Landi [1992] recently established that it is impossible to compute statically precise alias information—either may-alias or must-alias—in languages with if statements, loops, dynamic storage, and recursive data structures: more precisely, he showed that the may-alias relation is not recursive, while the must-alias relation is not even recursively enumerable. This article presents simpler proofs of the same results. © 1994, ACM. All rights reserved.",alias analysis; pointer analysis,Computation theory; Data reduction; Data structures; Program compilers; Recursive functions; Alias analysis; L valued expressions; May alias; Must alias; Computer programming
Fixpoint Computation for Polyvariant Static Analyses of Higher-Order Applicative Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028510907&doi=10.1145%2f186025.186037&partnerID=40&md5=1211fc833f499a5a0465e4fe049f251d,"This paper presents an optimized general-purpose algorithm for polyvariant, static analyses of higher-order applicative programs. A polyvariant analysis is a very accurate form of analysis that produces many more abstract descriptions for a program than does a conventional analysis. It may also compute intermediate abstract descriptions that are irrelevant to the final result of the analysis. The optimized algorithm addresses this overhead while preserving the accuracy of the analysis. The algorithm is also parameterized over both the abstract domain and degree of polyvariance. We have implemented an instance of our algorithm and evaluated its performance compared to the unoptimized algorithm. Our implementation runs significantly faster on average than the other algorithm for benchmarks reported here. © 1994, ACM. All rights reserved.",abstract interpretation; fixpoint algorithm; program analysis,Abstracting; Algorithms; Computer aided analysis; Performance; Program processors; Fixpoint computation; Higher order applicative programs; Optimized algorithm; Polyvariant static analyses; High level languages
Two Issues in Parallel Language Design,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028549963&doi=10.1145%2f197320.197325&partnerID=40&md5=4267d4742fb04d36e268a4372f636c1a,"In this article, we discuss two programming language features that have value for expressibility and efficiency: nonstrictness and nondeterminism. Our work arose while assessing ways to enhance a currently successful language, SISAL [McGraw et al. 1985]. The questions of how best to include these features, if at all, has led not to conclusions but to an impetus to explore the answers in an objective way. We will retain strictness for efficiency reasons and explore the limits it may impose, and we will experiment with a carefully controlled form of nondeterminism to assess its expressive power. © 1994, ACM. All rights reserved.",nondeterminism; nonstrictness; SISAL,Computer architecture; Data structures; Efficiency; Parallel algorithms; Parallel processing systems; Programming theory; Software engineering; Concurrent programming structures; Expressibility; Nondeterminism; Nonstrictness; Parallel language design; SISAL; Computer programming languages
Polymorphic Type Inference and Abstract Data Types,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028507970&doi=10.1145%2f186025.186031&partnerID=40&md5=c1cfcf8eb579d42382e5b35d757b7d35,"Many statically typed programming languages provide an abstract data type construct, such as the module in Modula-2. However, in most of these languages, implementations of abstract data types are not first-class values. Thus, they cannot be assigned to variables, passed as function parameters, or returned as function results. Several higher-order functional languages feature strong and static type systems, parametric polymorphism, algebraic data types, and explicit type variables. Most of them rely on Hindley-Milner type inference instead of requiring explicit type declarations for identifiers. Although some of these languages support abstract data types, it appears that none of them directly provides light-weight abstract data types whose implementations are first-class values. We show how to add significant expressive power to statically typed functional languages with explicit type variables by incorporating first-class abstract types as an extension of algebraic data types. Furthermore, we extend record types to allow abstract components. The components of such abstract records are selected using the dot notation. Following Mitchell and Plotkin, we formalize abstract types in terms of existentially quantified types. We give a syntactically sound and complete type inference algorithm and prove that our type system is semantically sound with respect to standard denotational semantics. © 1994, ACM. All rights reserved.",dynamic dispatching; existentially quantified types; first-class abstract types; polymorphism; type inference; universally quantified types,Algorithms; Computational linguistics; Data structures; Expert systems; High level languages; Modula (programming language); Abstract data types; Dot notation; First class values; Higher order functional languages; Polymorphic type inference; Standard denotational semantics; Computer programming languages
A Unified Model of Pointwise Equivalence of Procedural Computations,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028549964&doi=10.1145%2f197320.197402&partnerID=40&md5=2a1316391f41f92a84613982615c3c19,"The execution of a program on a processor is viewed as a representation of that program going through a sequence of states. Each state change is manifested by the execution of a single instruction. Models that depend on this perspective are presented. The first is a static model of a description of a procedural computation. This model formalizes the description of the information in an executable module. Following this dynamic model of a procedural computation is given. This second model describes how a computation transitions from state to state and how the states of a computation are represented. Next, the state of a procedural computation is defined at certain well-defined points in its progression. These points represent potential points of correspondence to another instance of the computation. Then, the equivalence of these well-defined computation states is described. This refinement eliminates the nonmatching potential correspondences. The remaining points describe where the two computations are in the same state. These are precisely the points of equivalence of procedural computations. This final model of pointwise equivalence can be applied to the problem of migrating a computation from one processor to another 1994 processor. © 1994, ACM. All rights reserved.",dynamic migration; heterogeneous migration,Computational methods; Computer hardware; Computer operating procedures; Computer simulation; Computer software; Equivalence classes; Procedure oriented languages; Programming theory; Dynamic migration; Heterogeneous migration; Pointwise equivalence; Procedural computations; Processors; Software engineering
Axiomatic Bootstrapping: A Guide for Compiler Hackers,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028547149&doi=10.1145%2f197320.197336&partnerID=40&md5=c0fdbd13c9222d76c86db2b459f54e9f,"If a compiler for language L is implemented in L, then it should be able to compile itself. But for systems used interactively commands are compiled and immediately executed, and these commands may invoke the compiler; so there is the question of how ever to cross-compile for another architecture. Also, where the compiler writes binary files of static type information that must then be read in by the bootstrapped interactive compiler, how can one ever change the format of digested type information in binary files? Here I attempt an axiomatic clarification of the bootstrapping technique, using Standard ML of New Jersey as a case study. This should be useful to implementors of any self-applicable interactive compiler with nontrivial object-file and runtime-system compatibility problems. © 1994, ACM. All rights reserved.",Bootstrapping,Algorithms; Codes (symbols); Computer architecture; Computer operating procedures; Computer programming languages; Computer software selection and evaluation; File organization; Object oriented programming; Binary files; Bootstrapping; Compiling; Hackers; Interactive compiler; Object file; Program linkers; Program loaders; Program compilers
Strictness Optimization for Graph Reduction Machines (Why id Might Not Be Strict),1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028507971&doi=10.1145%2f186025.186040&partnerID=40&md5=ed81170a42bd7feeeb5e71da16b91861,"Strictness optimizations in the implementation of lazy functional languages are not always valid. In nonoptimized graph reduction, evaluation always takes place at the request of case analysis or a primitive operation. Hence, the result of a reduction is always a data value and never a function. This implies that in an implementation no argument satisfaction check is required. But in the presence of strict arguments, “premature” reduction may take place outside the scope of a case or primitive operation. This causes problems in graph reducers that use an aggressive take. Two solutions are presented, one based on a run-time argument satisfaction check, the other on a weakened strictness analyzer. Experimental results are used to compare the two solutions and show that the cost of the aggressive take can be arbitrarily high for specific programs. The experimental results enable a trade-off to be made by the reduction machine designer. © 1994, ACM. All rights reserved.",graph reduction; lazy evaluation; strictness analysis,Computer graphics; Computer programming; Data reduction; Optimization; Performance; Aggressive take; Graph reduction machines; Lazy functional languages; Run time argument satisfaction check; Strictness optimization; Weaked strictness analyzer; Computer programming languages
A Generalized Theory of bit Vector Data Flow Analysis,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028510748&doi=10.1145%2f186025.186043&partnerID=40&md5=8b8b5776ff709b8ad8db5cbabf94e3b3,"The classical theory of data flow analysis, which has its roots in unidirectional flows, is inadequate to characterize bidirectional data flow problems. We present a generalized theory of bit vector data flow analysis which explains the known results in unidirectional and bidirectional data flows and provides a deeper insight into the process of data flow analysis. Based on the theory, we develop a worklist-based generic algorithm which is uniformly applicable to unidirectional and bidirectional data flow problems. It is simple, versatile, and easy to adapt for a specific problem. We show that the theory and the algorithm are applicable to all bounded monotone data flow problems which possess the property of the separability of solution. The theory yields valuable information about the complexity of data flow analysis. We show that the complexity of worklist-based iterative analysis is the same for unidirectional and bidirectional problems. We also define a measure of the complexity of round-robin iterative analysis. This measure, called width, is uniformly applicable to unidirectional and bidirectional problems and provides a tighter bound for unidirectional problems than the traditional measure of depth. Other applications include explanation of isolated results in efficient solution techniques and motivation of new techniques for bidirectional flows. In particular, we discuss edge splitting and edge placement and develop a feasibility criterion for decomposition of a bidirectional flow into a sequence of unidirectional flows. © 1994, ACM. All rights reserved.",bidirectional data flows; data flow analysis; data flow frameworks,Binary sequences; Computational complexity; Data processing; Genetic algorithms; Iterative methods; Programming theory; Bidirectional data flows; Bit vector data flow analysis; Generalized theory; Round robin iterative analysis; Worklist based generic algorithm; Data reduction
Functions as Passive Constraints in LIFE,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028461639&doi=10.1145%2f183432.183526&partnerID=40&md5=915f17ae0c149eb42088277beda85be7,"LIFE is a programming language proposing to integrate logic programming, functional programming, and object-oriented programming. It replaces first-order terms with ѱ-terms, data structures that allow computing with partial information. These are approximation structures denoting sets of values. LIFE further enriches the expressiveness of ѱ-terms with functional dependency constraints. We must explain the meaning and use of functions in LIFE declaratively, as solving partial information constraints. These constraints do not attempt to generate their solutions but behave as demons filtering out anything else. In this manner, LIFE functions act as declarative coroutines. We need to show that the ѱ-term's approximation semantics is congruent with an operational semantics viewing functional reduction as an effective enforcing of passive constraints. In this article, we develop a general formal framework for entailment and disentailment of constraints based on a technique called relative simplification. We study its operational and semantical properties, and we use it to account for functional application over ѱ-terms in LIFE. © 1994, ACM. All rights reserved.",committed-choice languages; concurrent constraint programming; coroutining; first-order terms; matching; relative simplification; residuation; terms; unification,Computational linguistics; Constraint theory; Data structures; Formal languages; Formal logic; Logic programming; Object oriented programming; Trees (mathematics); Committed choice languages; Concurrent constraint programming; Coroutining; First order terms; LIFE programming language; Passive constraints; Relative simplification; Residuation; Unification; Computer programming languages
Optimally Profiling and Tracing Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028462563&doi=10.1145%2f183432.183527&partnerID=40&md5=b538b98b2a56cc914acf2e0b10c584db,"This paper describes algorithms for inserting monitoring code to profile and trace programs. These algorithms greatly reduce the cost of measuring programs with respect to the commonly used technique of placing code in each basic block. Program profiling counts the number of times each basic block in a program executes. Instruction tracing records the sequence of basic blocks traversed in a program execution. The algorithms optimize the placement of counting/tracing code with respect to the expected or measured frequency of each block or edge in a program's control-flow graph. We have implemented the algorithms in a profiling/tracing tool, and they substantially reduce the overhead of profiling and tracing. We also define and study the hierarchy of profiling problems. These problems have two dimensions: what is profiled 1994 or edges in a control-flow graph) and where the instrumentation code is placed (in blocks or along edges). We compare the optimal solutions to the profiling problems and describe a new profiling problem: basic-block profiling with edge counters. This problem is important because an optimal solution to any other profiling problem (for a given control-flow graph) is never better than an optimal solution to this problem. Unfortunately, finding an optimal placement of edge counters for vertex profiling appears to be a hard problem in general. However, our work shows that edge profiling with edge counters works well in practice because it is simple and efficient and finds optimal counter placements in most cases. Furthermore, it yields more information than a vertex profile. Tracing also benefits from placing instrumentation code along edges rather than on vertices. © 1994, ACM. All rights reserved.",control-flow graph; instruction tracing; instrumentation; profiling,Codes (symbols); Graph theory; Optimization; Program debugging; Program diagnostics; Software engineering; Control flow graph; Instruction tracing; Instrumentation; Profiling; Algorithms
The Definition of Dependence Distance,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028463098&doi=10.1145%2f183432.183440&partnerID=40&md5=83c4785999dfc1285c103c98a9c7107b,"Several definitions of dependence distance can be found in the literature. A single coherent definition is the vector distance between the iteration vectors of two iterations involved in a dependence relation. Different ways to associate iteration vectors with iterations can give different dependence distances to the same program, and have different advantages. © 1994, ACM. All rights reserved.",dependence analysis; dependence distance,Computer programming languages; Data structures; Iterative methods; Optimization; Programming theory; Dependence distance; Program compilers
Decompilation: The Enumeration of Types and Grammars,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028510855&doi=10.1145%2f186025.186093&partnerID=40&md5=edfd409cb48b9f78c8dd7469bf0ed352,"While a compiler produces low-level object code from high-level source code, a decompiler produces high-level code from low-level code and has applications in the testing and validation of safety-critical software. The decompilation of an object code provides an independent demonstration of correctness that is hard to better for industrial purposes 1994. But, although compiler compilers are in common use in the software industry, a decompiler compiler is much more unusual. It turns out that a data type specification for a programming-language grammar can be remolded into a functional program that enumerates all of the abstract syntax trees of the grammar. This observation is the springboard for a general method for compiling decompilers from the specifications of (nonoptimizing) compilers. This paper deals with methods and theory, together with an application of the technique. The correctness of a decompiler generated from a simple occam-like compiler specification is demonstrated. The basic problem of enumerating the syntax trees of grammars, and then stopping, is shown to have no recursive solution, but methods of abstract interpretation can be used to guarantee the adequacy and completeness of our technique in practical instances, including the decompiler for the language presented here. © 1994, ACM. All rights reserved.",abstract interpretation; attribute grammar; decompilation; functional programming; list comprehension; logic programming; reverse engineering,Computational grammars; Computer programming languages; Computer software; Logic programming; Recursive functions; Abstract interpretation; Decompilation; Functional programming; Occam like compiler specification; Programming language grammar; Program compilers
Avoidance and Suppression of Compensation Code in a Trace Scheduling Compiler,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028461905&doi=10.1145%2f183432.183446&partnerID=40&md5=87ddb6754b9d5fc906865f365ae393f9,"Trace scheduling is an optimization technique that selects a sequence of basic blocks as a trace and schedules the operations from the trace together. If an operation is moved across basic block boundaries, one or more compensation copies may be required in the off-trace code. This article discusses the generation of compensation code in a trace scheduling compiler and presents techniques for limiting the amount of compensation code: avoidance 1994 and suppression (analyzing the global flow of the program to detect when a copy is redundant). We evaluate the effectiveness of these techniques based on measurements for the SPEC89 suite and the Livermore Fortran Kernels, using our implementation of trace scheduling for a Multiflow Trace 7/300. The article compares different compiler models contrasting the performance of trace scheduling with the performance obtained from typical RISC compilation techniques. There are two key results of this study. First, the amount of compensation code generated is not large. For the SPEC89 suite, the average code size increase due to trace scheduling is 6%. Avoidance is more important than suppression, although there are some kernels that benefit significantly from compensation code suppression. Since compensation code is not a major issue, a compiler can be more aggressive in code motion and loop unrolling. Second, compensation code is not critical to obtain the benefits of trace scheduling. Our implementation of trace scheduling improves the SPEC mark rating by 30% over basic block scheduling, but restricting trace scheduling so that no compensation code is required improves the rating by 25%. This indicates that most basic block scheduling techniques can be extended to trace scheduling without requiring any complicated compensation code bookkeeping. © 1994, ACM. All rights reserved.",instruction-level parallelism; performance evaluation; SPEC89; trace scheduling,Codes (symbols); Computational complexity; Computer operating systems; Data structures; Error compensation; FORTRAN (programming language); Optimization; Redundancy; Compensation code; Trace scheduling compilers; Program compilers
Static Slicing in the Presence of Goto Statements,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028463408&doi=10.1145%2f183432.183438&partnerID=40&md5=247aad8196ff498410f4aa91b3441337,"A static program slice is an extract of a program which can help our understanding of the behavior of the program; it has been proposed for use in debugging, optimization, parallelization, and integration of programs. This article considers two types of static slices: executable and nonexecutable. Efficient and well-founded methods have been developed to construct executable slices for programs without goto statements; it would be tempting to assume these methods would apply as well in programs with arbitrary goto statements. We show why previous methods do not work in this more general setting, and describe our solutions that correctly and efficiently compute executable slices for programs even with arbitrary goto statements. Our conclusion is that goto statements can be accommodated in generating executable static slices. © 1994, ACM. All rights reserved.",debugging; program analysis; slicing; testing,Algorithms; Computer programming languages; Optimization; Program debugging; Program diagnostics; Software engineering; Debugging aids; Goto statements; Program analysis; Program testing; Static slicing; Computer software
Single-Pass Generation of Static Single-Assignment form for Structured Languages,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028548373&doi=10.1145%2f197320.197331&partnerID=40&md5=22198848c952c2d8b28c7b78a8347a1e,[No abstract available],dominator tree; static single-assignment form; structured languages,Algorithms; Computer software; Data structures; Optimization; Program compilers; Programming theory; Structured programming; Code generation; Dominator tree; Static single-assignment form; Structured control flow; Structured languages; High level languages
Optimal Code Motion: Theory and Practice,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028460367&doi=10.1145%2f183432.183443&partnerID=40&md5=fa27d4bf041c7bd8e8ad21a94c7970fc,"An implementation-oriented algorithm for lazy code motion is presented that minimizes the number of computations in programs while suppressing any unnecessary code motion in order to avoid superfluous register pressure. In particular, this variant of the original algorithm for lazy code motion works on flowgraphs whose nodes are basic blocks rather than single statements, since this format is standard in optimizing compilers. The theoretical foundations of the modified algorithm are given in the first part, where t-refined flowgraphs are introduced for simplifying the treatment of flow graphs whose nodes are basic blocks. The second part presents the “basic block” algorithm in standard notation and gives directions for its implementation in standard compiler environments. © 1994, ACM. All rights reserved.",code motion; computational optimality; critical edges; data flow analysis; elimination of partial redundancies; lifetime optimality; lifetimes of registers; nondeterministic flowgraphs; t-refined flow graphs,Algorithms; Computation theory; Computational complexity; Computational linguistics; Data reduction; Optimization; Program compilers; Redundancy; Shift registers; Computational optimality; Critical edges; Data flow analysis; Life time optimality; Nondeterministic flowgraphs; Optimal code motion; Partial redundancies; Registers lifetimes; Codes (symbols)
Static Analysis of Upper and Lower Bounds on Dependences and Parallelism,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028463475&doi=10.1145%2f183432.183525&partnerID=40&md5=09e1339a2f399502054a1df704ce3bcb,"Existing compilers often fail to parallelize sequential code, even when a program can be manually transformed into parallel form by a sequence of well-understood transformations 1994. These failures can occur for several reasons: the code transformations implemented in the compiler may not be sufficient to produce parallel code, the compiler may not find the proper sequence of transformations, or the compiler may not be able to prove that one of the necessary transformations is legal. When a compiler fails to extract sufficient parallelism from a program, the programmer may try to extract additional parallelism. Unfortunately, the programmer is typically left to search for parallelism without significant assistance. The compiler generally does not give feedback about which parts of the program might contain additional parallelism, or about the types of transformations that might be needed to realize this parallelism. Standard program transformations and dependence abstractions cannot be used to provide this feedback. In this paper, we propose a two-step approach to the search for parallelism in sequential programs. In the first step, we construct several sets of constraints that describe, for each statement, which iterations of that statement can be executed concurrently. By constructing constraints that correspond to different assumptions about which dependences might be eliminated through additional analysis, transformations, and user assertions, we can determine whether we can expose parallelism by eliminating dependences. In the second step of our search for parallelism, we examine these constraint sets to identify the kinds of transformations needed to exploit scalable parallelism. Our tests will identify conditional parallelism and parallelism that can be exposed by combinations of transformations that reorder the iteration space (such as loop interchange and loop peeling). This approach lets us distinguish inherently sequential code from code that contains unexploited parallelism. It also produces information about the kinds of transformations needed to parallelize the code, without worrying about the order of application of the transformations. Furthermore, when our dependence test is inexact we can identify which unresolved dependences inhibit parallelism by comparing the effects of assuming dependence or independence. We are currently exploring the use of this information in programmer-assisted parallelization. © 1994, ACM. All rights reserved.",array data-dependence analysis; automatic parallelization; compilation; dependence relation; Omega test; optimization; Presburger arithmetic,Codes (symbols); Constraint theory; Data reduction; Digital arithmetic; Iterative methods; Optimization; Parallel processing systems; Array data dependence analysis; Dependencies; Omega test; Parallelism; Presburger arithmetic; Program compilers
Software Merge: Semantics of Combining Changes to Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028549756&doi=10.1145%2f197320.197403&partnerID=40&md5=640ef658051678a5792954b464e76022,"We present a language-independent semantic model of the process of combining changes to programs. This model extends the domains used in denotational semantics 1994 to Boolean algebras, and represents incompatible modifications as well as compatible extensions. The model is used to define the intended semantics of change-merging operations on programs and to establish some general properties of software merging. We determine conditions under which changes to subprograms of a software system can be merged independently and illustrate cases where this is not possible. © 1994, ACM. All rights reserved.",domains; semantics; software change merging; software maintenance,Boolean algebra; Computational linguistics; Computer programming; Computer programming languages; Computer software; Maintenance; Modification; Programming theory; Domains; Language-independent semantic model; Semantics; Software change merging; Software maintenance; Software systems; Software engineering
Improving the Ratio of Memory Operations to Floating-Point Operations in Loops,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028549474&doi=10.1145%2f197320.197366&partnerID=40&md5=cf21b18f1adc69b5c2660366f417869f,"Over the past decade, microprocessor design strategies have focused on increasing the computational power on a single chip. Because computations often require more data from cache per floating-point operation than a machine can deliver and because operations are pipelined, idle computational cycles are common when scientific applications are executed. To overcome these bottlenecks, programmers have learned to use a coding style that ensures a better balance between memory references and floating-point operations. In our view, this is a step in the wrong direction because it makes programs more machine-specific. A programmer should not be required to write a new program version for each new machine; instead, the task of specializing a program to a target machine should be left to the compiler. But is our view practical? Can a sophisticated optimizing compiler obviate the need for the myriad of programming tricks that have found their way into practice to improve the performance of the memory hierarchy? In this paper we attempt to answer that question. To do so, we develop and evaluate techniques that automatically restructure program loops to achieve high performance on specific target architectures. These methods attempt to balance computation and memory accesses and seek to eliminate or reduce pipeline interlock. To do this, they estimate statically the balance between memory operations and floating-point operations for each loop in a particular program and use these estimates to determine whether to apply various loop transformations. Experiments with our automatic techniques show that integer-factor speedups are possible on kernels. Additionally, the estimate of the balance between memory operations and computation, and the application of the estimate are very accurate—experiments reveal little difference between the balance achieved by our automatic system that is made possible by hand optimization. © 1994, ACM. All rights reserved.",balance; unroll-and-jam,Buffer storage; Computational methods; Computer operating procedures; Computer programming; Computer programming languages; Data storage equipment; Estimation; Microprocessor chips; Optimization; Program compilers; Programming theory; Floating point operations; Integer-factor speedups; Kernels; Loops; Memory accesses; Memory hierarchy; Pipeline interlock; Software engineering
A Behavioral Notion of Subtyping,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028548263&doi=10.1145%2f197320.197383&partnerID=40&md5=1107042fad62e940d1d7ea8f42b50086,"The use of hierarchy is an important component of object-oriented design. Hierarchy allows the use of type families, in which higher level supertypes capture the behavior that all of their subtypes have in common. For this methodology to be effective, it is necessary to have a clear understanding of how subtypes and supertypes are related. This paper takes the position that the relationship should ensure that any property proved about supertype objects also holds for its subtype objects. It presents two ways of defining the subtype relation, each of which meets this criterion, and each of which is easy for programmers to use. The subtype relation is based on the specifications of the sub- and supertypes; the paper presents a way of specifying types that makes it convenient to define the subtype relation. The paper also discusses the ramifications of this notion of subtyping on the design of type families. © 1994, ACM. All rights reserved.",formal specifications; Larch; subtyping,Computational linguistics; Computer software; Data structures; Hierarchical systems; Programming theory; Software engineering; Specifications; Formal specifications; Larch; Object oriented design; Subtyping; Supertypes; Object oriented programming
Modular Logic Programming,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028460472&doi=10.1145%2f183432.183528&partnerID=40&md5=278fc61df50146f5b52268e78527ac4d,"Modularity is a key issue in the design of modern programming languages. When designing modular features for declarative languages in general, and for logic programming languages in particular, the challenge lies in avoiding the superimposition of a complex syntactic and semantic structure over the simple structure of the basic language. The modular framework defined here for logic programming consists of a small number of operations over modules which are 1994 logically defined and semantically justified in terms of the basic logic programming semantics. The operations enjoy a number of algebraic properties, thus yielding an algebra of modules. Despite its simplicity, the suite of operations is shown capable of capturing the core features of modularization: information hiding, import/export relationships, and construction of module hierarchies. A metalevel implementation and a compilation-oriented implementation of the operations are provided and proved sound with respect to the semantics. The compilation-oriented implementation is based on manipulation of name spaces and provides the basis for an efficient implementation. © 1994, ACM. All rights reserved.",composition operations; declarative semantics; logic programs; metalogic; modularity; program transformation,Boolean algebra; Computational linguistics; Computer programming languages; Data structures; Formal languages; Information analysis; Interfaces (computer); Mathematical operators; Composition operations; Declarative semantics; Metalogic; Modular logic programming; Program transformation; Logic programming
Operational Semantics-Directed Compilers and Machine Architectures,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028463582&doi=10.1145%2f183432.183458&partnerID=40&md5=0412cae871f7fead1e88d92594e8d902,"We consider the task of automatically constructing intermediate-level machine architectures and compilers generating code for these architectures, given operational semantics for source languages. We use operational semantics in the form of abstract machines given by rewrite systems in which the rewrite rules operate on terms representing states of computations. To construct compilers and new architectures we employ a particular strategy called pass separation, a form of staging transformation, that takes a program p and constructs a pair of programs p1, p2 such that p1994 = p2(p1(x), y)) for all x,y. If p represents an operational semantics for a language, with arguments x and y denoting a source program and its input data, then pass separation constructs programs p1 and p2 corresponding to a compiler and an executor. The compiler translates the source language into an intermediate-level target language, and the executor provides the definition for this language. Our use of pass separation supports the automatic definition of target languages or architectures, and the structure of these architectures is directed by the structure of the given source semantics. These architectures resemble abstract machine languages found in hand-crafted compilers. Our method is restricted to a limited class of abstract machines given as term-rewriting systems, but we argue that this class encompasses a large set of language definitions derived from more natural operational semantics. We provide two examples of our method by constructing compilers and target architectures for a simple functional language and a simple imperative language. Though we construct these architectures automatically, they bear a striking resemblance to existing architectures constructed by hand. © 1994, ACM. All rights reserved.",abstract machines; pass separation; semantics-based compilation,Computational linguistics; Computer architecture; Computer programming languages; Program interpreters; Programming theory; Abstract machines; Intermediate level machine architectures; Machine architectures; Operational semantics directed compilers; Pass separation; Semantics based compilation; Program compilers
Composing First-Class Transactions,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028550748&doi=10.1145%2f197320.197346&partnerID=40&md5=55ff900c4eb34563dca081cbf76cf8e5,[No abstract available],modules; persistence; recovery; serializability; skeins; Standard ML; threads; transactions; undoability,Computer programming languages; Computer simulation; Computer software; Data structures; Database systems; Fault tolerant computer systems; Recovery; Subroutines; Higher order functions; Modules; Persistence; Serializability; Skeins; Standard ML; Threads; Transactions; Undoability; Software engineering
Powerlist: A Structure for Parallel Recursion,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028548321&doi=10.1145%2f197320.197356&partnerID=40&md5=2f11b945e3de281bc2c69882c09d0cc0,"Many data-parallel algorithms—Fast Fourier Transform, Batcher's sorting schemes, and the prefix-sum—exhibit recursive structure. We propose a data structure called powerlist that permits succinct descriptions of such algorithms, highlighting the roles of both parallelism and recursion. Simple algebraic properties of this data structure can be explotied to derive properties of these algorithms and to establish equivalence of different algorithms that solve the same problem. © 1994, ACM. All rights reserved.",algebra of parallel programs; Batcher sort; Fast Fourier Transform; hypercube; parallel programs; prefix sum; recursion,Computer programming; Computer programming languages; Concurrent engineering; Fast Fourier transforms; Parallel algorithms; Parallel processing systems; Programming theory; Recursive functions; Software engineering; Sorting; Batcher sort; Concurrent programming; Hypercube; Parallel program algebra; Parallel programs; Prefix sum; Recursion; Data structures
Extending Attribute Grammars to Support Programming-in-the-Large,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028508058&doi=10.1145%2f186025.186091&partnerID=40&md5=762fb2d727145ae3a2df2e60456e1c4c,"Attribute grammars add specification of static semantic properties to context-free grammars, which, in turn, describe the syntactic structure of program units. However, context-free grammars cannot express programming-in-the-large features common in modern programming languages, including unordered collections of units, included units, and sharing of included units. We present extensions to context-free grammars, and corresponding extensions to attribute grammars, suitable for defining such features. We explain how batch and incremental attribute-evaluation algorithms can be adapted to support these extensions, resulting in a uniform approach to intraunit and interunit static semantic analysis and translation of multiunit programs. © 1994, ACM. All rights reserved.",attribute evaluation; attribute grammars; include files; programming-in-the-large; programming-in-the-many separate compilation; static semantics of programming languages,Algorithms; Computational linguistics; Computer programming; Computer programming languages; Context free grammars; Attribute evaluation; Attribute grammars; Include files; Programming in the large; Static semantics; Computational grammars
An Old-Fashioned Recipe for Real Time,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028512153&doi=10.1145%2f186025.186058&partnerID=40&md5=ebde33062dc589c3de2763e69bed7b54,"Traditional methods for specifying and reasoning about concurrent systems work for real-time systems. Using TLA 1994, we illustrate how they work with the examples of a queue and of a mutual-exclusion protocol. In general, two problems must be addressed: avoiding the real-time programming version of Zeno's paradox, and coping with circularities when composing real-time assumption/guarantee specifications. Their solutions rest on properties of machine closure and realizability. © 1994, ACM. All rights reserved.",composition; concurrent programming; liveness properties; real time; safety properties; temporal logic; Zeno,Computational linguistics; Computer systems programming; Distributed computer systems; Logic programming; Network protocols; Queueing theory; Mutual exclusion protocol; Old fashioned methods; Semantics; Temporal logic of actions; Zenos paradox; Real time systems
Transforming Acyclic Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028462119&doi=10.1145%2f183432.183434&partnerID=40&md5=f160ef9fd4f6133273b5baf831c13710,"An unfold/fold transformation system is a source-to-source rewriting methodology devised to improve the efficiency of a program. Any such transformation should preserve the main properties of the initial program: among them, termination. In the field of logic programming, the class of acyclic programs plays an important role in this respect, since it is closely related to the one of terminating programs. The two classes coincide when negation is not allowed in the bodies of the clauses. We prove that the Unfold/Fold transformation system defined by Tamaki and Sato preserves the acyclicity of the initial program. From this result, it follows that when the transformation is applied to an acyclic program, then the finite failure set for definite programs is preserved; in the case of normal programs, all major declarative and operational semantics are preserved as well. These results cannot be extended to the class of left-terminating programs without modifying the definition of the transformation. © 1994, ACM. All rights reserved.",Acyclic programs; terminating programs; termination,Artificial intelligence; Computation theory; Computational linguistics; Computer programming languages; Formal languages; Logic programming; Programming theory; Theorem proving; Acyclic programs; Program transformation; Source to source rewriting methodology; Terminating programs; Termination; Computer software
Efficient Register Allocation via Coloring Using Clique Separators,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028425184&doi=10.1145%2f177492.177499&partnerID=40&md5=88ad9cba8d69b4ada2b42a761cdcfdaf,"Although graph coloring is widely recognized as an effective technique for register allocation, memory demands can become quite high for large interference graphs that are needed in coloring. In this paper we present an algorithm that uses the notion of clique separators to improve the space overhead of coloring. The algorithm, based on a result by R. Tarjan regarding the colorability of graphs, partitions program code into code segments using clique separators. The interference graphs for the code partitions are constructed one at a time and colored independently. The colorings for the partitions are combined to obtain a register allocation for the entire program. This approach can be used to perform register allocation in a space-efficient manner. For straight-line code 1994, an optimal allocation can be obtained from optimal allocations for individual code partitions. Experimental results are presented demonstrating memory demand reductions for interference graphs when allocating registers using clique separators. © 1994, ACM. All rights reserved.",clique separators; graph coloring; interference graph; node priorities; spans; spill code,Algorithms; Codes (symbols); Computer programming; Computer programming languages; Data communication systems; Graph theory; Interfaces (computer); Optimization; Program compilers; Report generators; Clique separators; Code generation; Graph coloring; Interference graphs; Node priorities; Register allocation; Spans; Spill code; Storage allocation (computer)
The Temporal Logic of Actions,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028424892&doi=10.1145%2f177492.177726&partnerID=40&md5=2c8db0e22225ee7c7078868b4b549d06,"The temporal logic of actions 1994 is a logic for specifying and reasoning about concurrent systems. Systems and their properties are represented in the same logic, so the assertion that a system meets its specification and the assertion that one system implements another are both expressed by logical implication. TLA is very simple; its syntax and complete formal semantics are summarized in about a page. Yet, TLA is not just a logician's toy; it is extremely powerful, both in principle and in practice. This report introduces TLA and describes how it is used to specify and verify concurrent algorithms. The use of TLA to specify and reason about open systems will be described elsewhere. © 1994, ACM. All rights reserved.",concurrent programming; liveness properties; safety properties,Algorithms; Codes (symbols); Computer hardware description languages; Computer systems; Computer systems programming; Decision tables; Local area networks; Programming theory; Systems analysis; Theorem proving; Concurrent programming; Correctness proofs; Distributed spanning tree algorithm; Liveness properties; Safety properties; Specification techniques; Temporal logic of actions; Formal logic
Reasoning about Probabilistic Parallel Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028424891&doi=10.1145%2f177492.177724&partnerID=40&md5=1c1afd99194c7693fba1b03ea0743ac8,"The use of randomization in the design and analysis of algorithms promises simple and efficient algorithms to difficult problems, some of which may not have a deterministic solution. This gain in simplicity, efficiency, and solvability results in a trade-off of the traditional notion of absolute correctness of algorithms for a more quantitative notion: correctness with a probability between 0 and 1. The addition of the notion of parallelism to the already unintuitive idea of randomization makes reasoning about probabilistic parallel programs all the more tortuous and difficult. In this paper we address the problem of specifying and deriving properties of probabilistic parallel programs that either hold deterministically or with probability 1. We present a proof methodology based on existing proof systems for probabilistic algorithms, the theory of the predicate transformer, and the theory of UNITY. Although the proofs of probabilistic programs are slippery at best, we show that such programs can be derived with the same rigor and elegance that we have seen in the derivation of sequential and parallel programs. By applying this methodology to derive probabilistic programs, we hope to develop tools and techniques that would make randomization a useful paradigm in algorithm design. © 1994, ACM. All rights reserved.",correctness proofs; parallel programming; probabilistic algorithms; programming methodology; specification techniques; verification,Algorithms; Computational complexity; Computer hardware description languages; Parallel processing systems; Probabilistic logics; Programming theory; Software engineering; Theorem proving; Correctness proofs; Probabilistic algorithms; Probabilistic parallel programs; Randomization; Specification techniques; Verification; Computer systems programming
Metalevel Building Blocks for Modular Systems,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028424890&doi=10.1145%2f177492.177578&partnerID=40&md5=ab37c629e3cf8b7b87144a66dc17e0bd,"The formal definition of any namespace device found in a programming language can be given in terms of transformations on a semantic environment. It is worthwhile, therefore, to consider the implications of incorporating environments as bona fide data objects in a programming system. In this article, we propose a treatment of environments and the mechanism by which they are reified and manipulated, that addresses these concerns. The language described below 1994 permits environments to be reified into data structures, and data structures to be reflected into environments, but gives users great flexibility to constrain the extent and scope of these processes. We argue that the techniques and operators developed define a cohesive basis for building large-scale modular systems using reflective programming techniques. © 1994, ACM. All rights reserved.",higher-order programming; modularity; reflection,Computational linguistics; Computer programming; Computer software; Data structures; Formal languages; Formal logic; Applicative languages; Denotational semantics; Extensible languages; Higher order programming; Language constructs; Metalevel building blocks; Modular systems; Modularity; Reflection; High level languages
A Linear-Time Scheme for Version Reconstruction,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427645&doi=10.1145%2f177492.177705&partnerID=40&md5=d346694ad3f9674e02347c40cfa1291b,"An efficient scheme to store and reconstruct versions of sequential files is presented. The reconstruction scheme involves building a data structure representing a complete version, and then successively modifying this data structure by applying a sequence of specially formatted differential files to it. Each application of a differential file produces a representation of an intermediate version, with the final data structure representing the requested version. The scheme uses a linked list to represent an intermediate version, instead of a sequential array, as is used traditionally. A new format for differential files specifying changes to this linked list data structure is presented. The specification of each change points directly to where the change is to take place, thereby obviating a search. Algorithms are presented for using such a new format differential file to transform the representation of a version, and for reconstructing a requested version. Algorithms are also presented for generating the new format differential files, both for the case of a forward differential specifying how to transform the representation of an old version to the representation of a new version, and for the case of a reverse differential specifying how to transform the representation of a new version to the representation of an old version. The new version reconstruction scheme takes time linear in the sum of the size of the initial complete version and the sizes of the file differences involved in reconstructing the requested version. In contrast, the classical scheme for reconstructing versions takes time proportional to the sum of the sizes of the sequence of versions involved in the reconstruction, and therefore has a worst-case time that is quadratic in the sum of the size of the initial complete version and the sizes of the file differences. The time cost of the new differential file generation scheme is comparable to the time cost of the classical differential file generation scheme. © 1994, ACM. All rights reserved.",data structures; database systems; differential files; document preparation; software systems; textual objects; version control,Algorithms; Computer aided design; Computer software; Data acquisition; Data structures; File organization; Storage allocation (computer); Differential files; Document preparation; Linear time scheme; Textual objects; Version control; Version reconstruction; Database systems
Compositional Specification and Verification of Distributed Systems,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028400387&doi=10.1145%2f174662.174665&partnerID=40&md5=5034510ab70af7fcad74d1f1320cb937,"We present a method for specification and verification of distributed systems that communicate via asynchronous message passing. The method handles both safety and liveness properties. It is compositional, i.e., a specification of a composite system can be obtained from specifications of its components. Specifications are given as labeled transition systems with fairness properties, using a program-like notation with guarded multiple assignments. Compositionality is attained by partitioning the labels of a transition system into input events, which intuitively denote message receptions, and output events, which intuitively denote message transmissions. A specification denotes a set of allowed sequences of message transmissions and receptions, in analogy with the way finite automata are used as acceptors of finite strings. A lower-level specification implements a higher-level one. We present a verification technique which reduces the problem of verifying the correctness of an implementation to classical verification conditions. Safety properties are verified by establishing a simulation relation between transition systems. Liveness properties are verified using methods for proving termination under fairness assumptions. Since specifications can be given at various levels of abstraction, the method is suitable in a development process where a detailed implementation is developed from an abstract specification through a sequence of refinement steps. As an application of the method, an algorithm by Thomas for updating a distributed database is specified and verified. © 1994, ACM. All rights reserved.",assertional reasoning; compositionality; message passing; modular specification; specification; stepwise refinement,Algorithms; Computational linguistics; Computer hardware description languages; Data communication systems; Data processing; Distributed database systems; Software engineering; State assignment; Theorem proving; Assertional reasoning; Compositional specification and verification; Message passing; Stepwise refinement; Distributed computer systems
Suspension Analyses for Concurrent Logic Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427644&doi=10.1145%2f177492.177656&partnerID=40&md5=08c09d3c2f2ea42b2f89ca294afacea1,"Concurrent logic languages specify reactive systems which consist of collections of communicating processes. The presence of unintended suspended computations is a common programming error which is difficult to detect using standard debugging and testing techniques. We develop a number of analyses, based on abstract interpretation, which succeed if a program is definitely suspension free. If an analysis fails, the program may, or may not, be suspension free. Examples demonstrate that the analyses are practically useful. They are conceptually simple and easy to justify because they are based directly on the transition system semantics of concurrent logic programs. A naive analysis must consider all scheduling policies. However, it is proven that for our analyses it suffices to consider only one scheduling policy, allowing for efficient implementation. © 1994, ACM. All rights reserved.",abstract interpretation; concurrent logic programming; program analysis,Computational methods; Computer programming languages; Computer software; Data reduction; Errors; Formal logic; Invariance; Parallel processing systems; Program debugging; Program diagnostics; Scheduling; Abstract interpretation; Concurrent logic programs; Suspension analysis; Logic programming
Improvements to Graph Coloring Register Allocation,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429472&doi=10.1145%2f177492.177575&partnerID=40&md5=30c4ae7684b89e33a45e433637d05cc9,"We describe two improvements to Chaitin-style graph coloring register allocators. The first, optimistic coloring, uses a stronger heuristic to find a k-coloring for the interference graph. The second extends Chaitin's treatment of rematerialization to handle a larger class of values. These techniques are complementary. Optimistic coloring decreases the number of procedures that require spill code and reduces the amount of spill code when spilling is unavoidable. Rematerialization lowers the cost of spilling some values. This paper describes both of the techniques and our experience building and using register allocators that incorporate them. It provides a detailed description of optimistic coloring and rematerialization. It presents experimental data to show the performance of several versions of the register allocator on a suite of FORTRAN programs. It discusses several insights that we discovered only after repeated implementation of these allocators. © 1994, ACM. All rights reserved.",code generation; graph coloring; register allocation,Codes (symbols); Computer software; FORTRAN (programming language); Graph theory; Optimization; Program compilers; Program debugging; Program diagnostics; Code generation; Graph coloring; Register allocation; Rematerialization; Storage allocation (computer)
A Compiler Approach to Scalable Concurrent-Program Design,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429475&doi=10.1145%2f177492.177612&partnerID=40&md5=a90767356e283fc87da49b962a1ddc72,"We describe a compilation system for the concurrent programming language Program Composition Notation 1994. This notation provides a single-assignment programming model that permits concurrent-programming concerns such as decomposition, communication, synchronization, mapping, granularity, and load balancing to be addressed separately in a design. PCN is also extensible with programmer-defined operators, allowing common abstractions to be encapsulated and reused in different contexts. The compilation system incorporates a concurrent-transformation system that allows abstractions to be defined through concurrent source-to-source transformations; these convert programmer-defined operators into a core notation. Run-time techniques allow the core notation to be compiled into a simple concurrent abstract machine which can be implemented in a portable fashion using a run-time library. The abstract machine provides a uniform treatment of single-assignment and mutable data structures, allowing data sharing between concurrent and sequential program segments and permitting integration of sequential C and Fortran code into concurrent programs. This compilation system forms part of a program development toolkit that operates on a wide variety of networked workstations, multicomputers, and shared-memory multiprocessors. The toolkit has been used both to develop substantial applications and to teach introductory concurrent-programming classes, including a freshman course at Caltech. © 1994, ACM. All rights reserved.",monotonicity; program composition; programming abstractions; source-to-source transformations,C (programming language); Computer networks; Data structures; FORTRAN (programming language); Mathematical operators; Multiprocessing systems; Multiprogramming; Program translators; Systems analysis; Concurrent programming language PCN; Concurrent transformation system; Monotonicity; Program composition notation (PCN); Programmer defined operators; Programming abstractions; Run time environments; Scalable concurrent program design; Source to source transformations; Program compilers
On the Adequacy of Graph Rewriting for Simulating Term Rewriting,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429473&doi=10.1145%2f177492.177577&partnerID=40&md5=c96851bc6c7bb7f4117eed624278ecdb,[No abstract available],functional programming; graph rewriting; orthogonal term rewriting,Computational grammars; Computational linguistics; Computer programming; Finite automata; Formal logic; Graph theory; Mathematical models; Optimization; Functional languages; Graph rewriting adequacy; Term rewriting; Formal languages
Parallel programming with control abstraction,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429474&doi=10.1145%2f177492.177584&partnerID=40&md5=b6ea8539c599356093d342a4b0ce754e,"Parallel programming involves finding the potential parallelism in an application and mapping it to the architecture at hand. Since a typical application has more potential parallelism than any single architecture can exploit effectively, programmers usually limit their focus to the parallelism that the available control constructs express easily and that the given architecture exploits efficiently. This approach produces programs that exhibit much less parallelism that exists in the application, and whose performance depends critically on the underlying hardware and software. We argue for an alternative approach based on control abstraction. Control abstraction is the process by which programmers define new control constructs, specifying constraints on statement ordering separately from an implementation of that ordering. With control abstraction programmers can define and use a rich variety of control constructs to represent an algorithm's potential parallelism. Since control abstraction separates the definition of a construct from its implementation, a construct may have several different implementations, each exploiting a different subset of the parallelism admitted by the construct. By selecting an implementation for each control construct using annotations, a programmer can vary the parallelism in a program to best exploit the underlying hardware without otherwise changing the source code. This approach produces programs that exhibit most of the potential parallelism in an algorithm, and whose performance can be tuned simply by choosing among the various implementations for the control constructs in use. © 1994, ACM. All rights reserved.",architectural adaptability; closures; control abstraction; data abstraction; early reply; multiprocessors; parallel programming languages; performance tuning,Algorithms; Computer architecture; Computer programming languages; Control; Data handling; Parallel processing systems; Control abstraction; Prototype programming language; Source code; Multiprogramming
Controlled Grammatic Ambiguity,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427063&doi=10.1145%2f177492.177759&partnerID=40&md5=cae35a19fd267aace5e42c87125db823,"A new approach to ambiguity of context-free grammars is presented, and within this approach the LL and LR techniques are generalized to solve the following problems for large classes of ambiguous grammars: —Construction of a parser that accepts all sentences generated by the grammar, and which always terminates in linear time. —Identification of the structural ambiguity: a finite set of pairs of partial parse trees is constructed; if for each pair the two partial parse trees are semantically equivalent, the ambiguity of the grammar is semantically irrelevant. The user may control the parser generation so as to get a parser which finds some specific parse trees for the sentences. The generalized LL and LR techniques will still guarantee that the resulting parser accepts all sentences and terminates in linear time on all input. © 1994, ACM. All rights reserved.",grammatic ambiguity; semantic unambiguity,Algorithms; Computational linguistics; Data structures; Finite automata; Formal logic; Program processors; Programming theory; Trees (mathematics); Grammatic ambiguity; LL techniques; LR techniques; Rewriting systems; Semantic unambiguity; Context free grammars
Debugging Optimized Code Without Being Misled,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427062&doi=10.1145%2f177492.177517&partnerID=40&md5=a460a7143537fb9df99c783deba75667,"Correct optimization can change the behavior of an incorrect program; therefore at times it is necessary to debug optimized code. However, optimizing compilers produce code that impedes source-level debugging. Optimization can cause an inconsistency between where the user expects a breakpoint to be located and the breakpoint's actual location. This article describes a mapping between statements and breakpoint locations that ameliorates this problem. The mapping enables debugger behavior on optimized code that approximates debugger behavior on unoptimized code sufficiently closely for the user to use traditional debugging strategies. Optimization can also cause the value of a variable to be noncurrent—to differ from the value that would be predicted by a close reading of the source code. This article presents a method of determining when this has occurred, and shows how a debugger can describe the relevant effects of optimization. The determination method is more general than previously published methods; it handles global optimization and many flow graph transformations, and it is not tightly coupled to optimizations performed by a particular compiler. Necessary compiler support is also described. © 1994, ACM. All rights reserved.",,Codes (symbols); Computer operating systems; Computer software selection and evaluation; Mathematical transformations; Optimization; Program compilers; Program diagnostics; Software engineering; Code generation; Flow graph transformations; Optimized code debugging; Source level debugger; Verification; Program debugging
Path Analysis and the Optimization of Nonstrict Functional Languages,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028428310&doi=10.1145%2f177492.177497&partnerID=40&md5=ef4e5965f5d8a5da420c41d38c614b52,"The functional programming style is increasingly popular in the research world, but functional languages still execute slowly relative to imperative languages. This is largely because the power and flexibility of functional languages restrict the amount of information readily available to the compiler, hindering its ability to generate good code. This article demonstrates that information about order of evaluation of expressions can be statically inferred for nonstrict functional programs and that optimizations based on this information can provide substantial speedups at runtime. We present an exact, nonstandard semantics called path semantics that models order of evaluation in a nonstrict, sequential functional language, and its computable abstraction, path analysis. We show how the information inferred by path analysis can be used to implement destructive aggregate updating, in which updates on functional aggregates that are provably not live are done destructively. We also demonstrate a new approach to strictness analysis and show that strictness analysis is subsumed by path analysis. Benchmarks are presented. © 1994, ACM. All rights reserved.",abstract interpretation; aggregate update problem; nonstandard semantics,Computational linguistics; Computer programming; Computer programming languages; Data structures; Optimization; Program compilers; Abstract interpretation; Aggregate update problem; Nonstandard semantics; Nonstrict functional languages; Order of evaluation of expressions; Path analysis; Formal languages
Efficient Computation of Interprocedural Definition-Use Chains,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028400205&doi=10.1145%2f174662.174663&partnerID=40&md5=47d2dd4cf3a1b035825f47727200e87e,"The dependencies that exist among definitions and uses of variables in a program are required by many language-processing tools. This paper considers the computation of definition-use and use-definition chains that extend across procedure boundaries at call and return sites. Intraprocedural definition and use information is abstracted for each procedure and is used to construct an interprocedural flow graph. This intraprocedural data-flow information is then propagated throughout the program via the interprocedural flow graph to obtain sets of reaching definitions and/or reachable uses for reach interprocedural control point, including procedure entry, exit, call, and return. Interprocedural definition-use and/or use-definition chains are computed from this reaching information. The technique handles the interprocedural effects of the data flow caused by both reference parameters and global variables, while preserving the calling context of called procedures. Additionally, recursion, aliasing, and separate compilation are handled. The technique has been implemented using a Sun-4 Workstation and incorporated into an interprocedural data-flow tester. Results from experiments indicate the practicality of the technique, both in terms of the size of the interprocedural flow graph and the size of the data-flow sets. © 1994, ACM. All rights reserved.",dataflow testing; interprocedural dataflow analysis; interprocedural definition-use chains; interprocedural reachable uses; interprocedural reaching definitions,Computational linguistics; Computational methods; Computer graphics; Critical path analysis; Data processing; Flowcharting; Graph theory; Optimization; Procedure oriented languages; Program compilers; Program debugging; Recursive functions; Data flow testing; Interprocedural data flow analysis; Interprocedural definition use chains; Interprocedural reachable uses; Interprocedural reaching definitions; Algorithms
Program Optimization and Parallelization Using Idioms,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429055&doi=10.1145%2f177492.177494&partnerID=40&md5=64da05d3b612a9b9eafd3714ffe6a377,"Programs in languages such as Fortran, Pascal, and C were designed and written for a sequential machine model. During the last decade, several methods to vectorize such programs and recover other forms of parallelism that apply to more advanced machine architectures have been developed 1994. We propose and demonstrate a more powerful translation technique for making such programs run efficiently on parallel machines which support facilities such as parallel prefix operations as well as parallel and vector capabilities. This technique, which is global in nature and involves a modification of the traditional definition of the program dependence graph (PDG), is based on the extraction of parallelizable program structures (“idioms”) from the given (sequential) program. The benefits of our technique extend beyond the above-mentioned architectures and can be viewed as a general program optimization method, applicable in many other situations. We show a few examples in which our method indeed outperforms existing analysis techniques. © 1994, ACM. All rights reserved.",array data flow analysis; computational idioms; dependence analysis; graph rewriting; intermediate program representation; parallel prefix; parallelism; reduction; scan operations,Computational linguistics; Computer architecture; Computer programming; Computer programming languages; Data reduction; Data structures; Optimization; Parallel processing systems; Program compilers; Array data flow analysis; Dependence analysis; Graph rewriting; Idioms; Intermediate program representation; Parallel prefix; Parallelization; Program dependence graph; Program optimization; Scan operations; Computer software
Recognizing Substrings of LR(k) Languages in Linear Time,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429056&doi=10.1145%2f177492.177768&partnerID=40&md5=8172ec1b5f02adf92f51a4c2a5fa1d71,"LR parsing techniques have long been studied as being efficient and powerful methods for processing context-free languages. A linear-time algorithm for recognizing languages representable by LR1994 grammars has long been known. Recognizing substrings of a context-free language is at least as hard as recognizing full strings of the language, since the latter problem easily reduces to the former. In this article we present a linear-time algorithm for recognizing substrings of LR(k) languages, thus showing that the substring recognition problem for these languages is no harder than the full string recognition problem. An interesting data structure, the Forest-Structured Stack, allows the algorithm to track all possible parses of a substring without loosing the efficiency of the original LR parser. We present the algorithm, prove its correctness, analyze its complexity, and mention several applications that have been constructed. © 1994, ACM. All rights reserved.",LR parsing; substrings,Algorithms; Automata theory; Coding errors; Computational complexity; Computational grammars; Computational linguistics; Data structures; Equivalence classes; Error detection; Program compilers; Theorem proving; Forest structured stack; Linear time algorithm; LR parsing; Substrings; Translator writing systems; Context free languages
Live-Structure Dataflow Analysis for Prolog,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028401281&doi=10.1145%2f174662.174664&partnerID=40&md5=43eb753665389f79d641261f5b4a034c,"For the class of applicative programming languages, efficient methods for reclaiming the memory occupied by released data structures constitute an important aspect of current implementations. The present article addresses the problem of memory reuse for logic programs through program analysis rather than by run-time garbage collection. The aim is to derive run-time properties that can be used at compile time to specialize the target code for a program according to a given set of queries and to automatically introduce destructive assignments in a safe and transparent way so that fewer garbage cells are created. The dataflow analysis is constructed as an application of abstract interpretation for logic programs. An abstract domain for describing structure-sharing and liveness properties is developed as are primitive operations that guarantee a sound and terminating global analysis. We explain our motivation for the design of the abstract domain, make explicit the underlying implementation assumptions, and discuss the precision of the results obtained by a prototype analyzer. © 1994, ACM. All rights reserved.",abstract interpretation; compile-time garbage collection; liveness; program analysis; Prolog,Codes (symbols); Computer software; Critical path analysis; Data reduction; Formal logic; Program compilers; Program diagnostics; PROLOG (programming language); Storage allocation (computer); Theorem proving; Abstract interpretation; Compile time garbage collection; Live structure dataflow analysis; Liveness; Program analysis; Data structures
"A Bounded First-in, First-Enabled Solution to the l-Exclusion Problem",1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429290&doi=10.1145%2f177492.177731&partnerID=40&md5=a4e922b0f700c2080cef261623159f34,"This article presents a solution to the first-come, first-enabled[Formulla Omitted]-exclusionproblem of Fischer et al. [1979]. Unlike their solution, thissolution does not use powerful read-modify-write synchronizationprimitives and requires only bounded shared memory. Use of the concurrent timestamp system of Dolevand Shavir [1989] is key in solving the problem within bounded sharedmemory. © 1994, ACM. All rights reserved.",atomic registers; concurrency; timestamps,Computer software; Computer systems programming; Data acquisition; Data communication systems; Data structures; Reliability; Shift registers; Storage allocation (computer); Atomic registers; Concurrency; Mutual exclusion; Primitives; Timestamps; Computer operating systems
How to Securely Replicate Services,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429699&doi=10.1145%2f177492.177745&partnerID=40&md5=8365a48a023300b81744698c15e4d509,"We present a method for constructing replicated services that retain their availability and integrity despite several servers and clients being corrupted by an intruder, in addition to others failing benignly. We also address the issue of maintaining a causal order among client requests. We illustrate a security breach resulting from an intruder's ability to effect a violation of causality in the sequence of requests processed by the service and propose an approach to counter this attack. An important and novel feature of our techniques is that the client need not be able to identify or authenticate even a single server. Instead, the client is required to possess only a single public key for the service. We demonstrate the performance of our techniques with a service we have implemented using one of our protocols. © 1994, ACM. All rights reserved.",causality; replication; state machines; threshold cryptography,Computer networks; Computer operating systems; Cryptography; Data communication systems; Data handling; Data structures; Distributed computer systems; Finite automata; Information services; Network protocols; Sequential machines; Subroutines; Authentication; Causality; Cryptographic controls; Replication; State machines; Threshold cryptography; Security of data
Coordinating First-Order Multiparty Interactions,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429854&doi=10.1145%2f177492.177739&partnerID=40&md5=dcee2bf803d379eb673ab76b47e571da,"A first-order multiparty interaction is an abstraction mechanism that defines communication among a set of formal process roles. Actual processes participate in a first-order interaction by enroling into roles, and execution of the interaction can proceed when all roles are filled by distinct processes. As in CSP, enrolement statements can serve as guards in alternative commands. The enrolement guard-scheduling problem then is to enable the execution of first-order interactions through the judicious scheduling of roles to processes that are currently ready to execute enrolement guards. We present a fully distributed and message-efficient algorithm for the enrolement guard-scheduling problem, the first such solution of which we are aware. We also describe several extensions of the algorithm, including: generic roles; dynamically changing environments, where processes can be created and destroyed at run time; and nested-enrolement, which allows interactions to be nested. © 1994, ACM. All rights reserved.",committee coordination; distributed algorithms; distributed languages; first-order interaction; interaction scheduling; IP; multiparty interaction; rendezvous,Algorithms; Computer programming languages; Data communication systems; Data structures; Input output programs; Interactive computer systems; Multiprocessing systems; Scheduling; Security of data; Synchronization; Systems analysis; Committee coordination; Concurrent programming; Distributed languages; Enrolement guard scheduling problem; First order multiparty interactions; Formal process roles; Message sending; Multiprogramming
Some Comments on “A Denotational Semantics for Prolog”,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028426189&doi=10.1145%2f177492.177605&partnerID=40&md5=19ed75378ba90de75e80500ae0d01424,"Two independently derived denotational semantics for Prolog are contrasted, Arbab and Berry's for the full language and Nicholson and Foo's for a databaseless language. Using the ideas suggested by the former, the latter can be easily extended to include the database operations. © 1994, ACM. All rights reserved.",denotational semantics; logic programming; operational semantics,Database systems; Formal logic; Logic programming; Program interpreters; Programming theory; PROLOG (programming language); Denotational semantics; Operational semantics; Computational linguistics
On the Occur-Check-Free Prolog Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028429698&doi=10.1145%2f177492.177673&partnerID=40&md5=74944ab06eb11df22e1240f9e6a867de,"In most PROLOG implementations, for efficiency occur-check is omitted from the unification algorithm. This paper provides natural syntactic conditions that allow the occur-check to be safely omitted. The established results apply to most well-known PROLOG programs, including those that use difference lists, and seem to explain why this omission does not lead in practice to any complications. When applying these results to general programs, we show their usefulness for proving absence of floundering. Finally, we propose a program transformation that transforms every program into a program for which only the calls to the built-in unification predicate need to be resolved by a unification algorithm with the occur-check. © 1994, ACM. All rights reserved.",moded programs; occur-check problem; PROLOG programs; unification algorithm,Algorithms; Data reduction; Logic programming; Program debugging; Program diagnostics; Program processors; Programming theory; PROLOG (programming language); Software engineering; Theorem proving; Correctness proofs; Floundering; Occur check free PROLOG programs; Unification algorithm; Computer software
TransformGen: Automating the Maintenance of Structure-Oriented Environments,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028425381&doi=10.1145%2f177492.177697&partnerID=40&md5=12e895f62c0c2e0a022599bbd47b7ea1,"A serious problem for programs that use persistent data is that information created and maintained by the program becomes invalid if the persistent types used in the program are modified in a new release. Unfortunately, there has been little systematic treatment of the problem; current approaches are manual, ad hoc, and time consuming both for programmers and users. In this article we present a new approach. Focusing on the special case of managing abstract syntax trees in structure-oriented environments, we show how automatic transformers can be generated in terms of an implementor's changes to the grammar of these environments. © 1994, ACM. All rights reserved.",schema evolution; structure-oriented environments; type evolution,Coding errors; Computational grammars; Computer systems programming; Logic programming; Program debugging; Software engineering; Structured programming; Trees (mathematics); Abstract syntax trees; Rapid prototyping; Scheme evolution; Structure oriented environments; TransformGen; Type evolution; Data structures
Adding Fair Choice to Dijkstra's Calculus,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028430329&doi=10.1145%2f177492.177727&partnerID=40&md5=e823d5c2ba8426e576f94eec399b4896,"The paper studies the incorporation of a fair nondeterministic choice operator into a generalization of Dijkstra's calculus of guarded commands. The generalization drops the law of the excluded miracle to allow commands that correspond to partial relations. Because of fairness, the new operator is not monotonic for the orderings that are generally used for proving the existence of least fixed points for recursive definitions. To prove the existence of fixed points it is necessary to consider several orderings at once, and to restrict the class of recursive definitions. © 1994, ACM. All rights reserved.",dovetail; fairness; guarded commands; law of the excluded miracle; nondeterminism; partial commands; semantics,Boolean algebra; Computational complexity; Computer programming languages; Data structures; Mathematical operators; Programming theory; Recursive functions; State assignment; Theorem proving; Alternation; Concurrent programming structures; Dijkstra's calculus; Dovetail; Excluded miracle law; Fair choice; Guarded commands; Nondeterminism; Partial commands; Semantics; Computational linguistics
Model Checking and Modular Verification,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427381&doi=10.1145%2f177492.177725&partnerID=40&md5=af98f0a9dd0c1a17061d22b80ae3a173,"We describe a framework for compositional verification of finite-state processes. The framework is based on two ideas: a subset of the logic CTL for which satisfaction is preserved under composition, and a preorder on structures which captures the relation between a component and a system containing the component. Satisfaction of a formula in the logic corresponds to being below a particular structure 1994 in the preorder. We show how to do assume-guarantee-style reasoning within this framework. Additionally, we demonstrate efficient methods for model checking in the logic and for checking the preorder in several special cases. We have implemented a system based on these methods, and we use it to give a compositional verification of a CPU controller. © 1994, ACM. All rights reserved.",computer-aided verification; CTL; formal verification; model checking; Moore machines; temporal logics,Computer aided software engineering; Computer programming languages; Data structures; Decision tables; Formal logic; Logic programming; Program debugging; Programming theory; Sequential machines; Computer aided verification; Formal verification; Model checking; Modular verification; Moore machines; Temporal logics; Algorithms
Denotational Abstract Interpretation of Logic Programs,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028427829&doi=10.1145%2f177492.177650&partnerID=40&md5=fb8b8f21faf92122dac8bf5d2ac02667,"Logic-programming languages are based on a principle of separation “logic” and “control.”. This means that they can be given simple model-theoretic semantics without regard to any particular execution mechanism 1994. Although the separation is desirable from a semantical point of view, it makes sound, efficient implementation of logic-programming languages difficult. The lack of “control information” in programs calls for complex data-flow analysis techniques to guide execution. Since data-flow analysis furthermore finds extensive use in error-finding and transformation tools, there is a need for a simple and powerful theory of data-flow analysis of logic programs. This paper offers such a theory, based on F. Nielson's extension of P. Cousot and R. Cousot's abstract interpretation. We present a denotational definition of the semantics of definite logic programs. This definition is of interest in its own right because of its compactness. Stepwise we develop the definition into a generic data-flow analysis that encompasses a large class of data-flow analyses based on the SLD execution model. We exemplify one instance of the definition by developing a provably correct groundness analysis to predict how variables may be bound to ground terms during execution. We also discuss implementation issues and related work. © 1994, ACM. All rights reserved.",abstract interpretation; Boolean functions; dataflow analysis; global analysis; groundness analysis,Computational linguistics; Control; Data reduction; Formal logic; Optimization; Program compilers; Programming theory; Assertions; Data flow analysis; Denotational abstract interpretation; Logic programming
Lazy and Incremental Program Generation,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028426611&doi=10.1145%2f177492.177750&partnerID=40&md5=f52cb6b842e9c35c2b9ad22f49e3cd58,"Current program generators usually operate in a greedy manner in the sense that a program must be generated in its entirety before it can be used. If generation time is scarce, or if the input to the generator is subject to modification, it may be better to be more cautious and to generate only those parts of the program that are indispensable for processing the particular data at hand. We call this lazy program generation. Another, closely related strategy is incremental program generation. When its input is modified, an incremental generator will try to make a corresponding modification in its output rather than generate a completely new program. It may be advantageous to use a combination of both strategies in program generators that have to operate in a highly dynamic and/or interactive environment. © 1994, ACM. All rights reserved.",greedy; incremental program generation; lazy; lazy and incremental compilation; lazy and incremental generation of lexical scanners; lazy and incremental generation of parsers; program generator,Computational linguistics; Computer programming languages; Computer software; Computer systems programming; Interactive computer systems; Program compilers; Program translators; Report generators; Automatic programming; Greedy; Incremental program generation; Lazy program generation; Lexical scanners; Parsing; Program generators; Algorithms
Cost Analysis of Logic Programs,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027697266&doi=10.1145%2f161468.161472&partnerID=40&md5=fa8d5dd83bddbf0f1d8b7eea5e684752,"Cost analysis of programs has been studied in the context of imperative and functional programming languages. For logic programs, the problem is comphcated by the fact that programs may be nondeterministic and produce multiple solutions. A related problem is that because failure of execution is not an abnormal situation, it is possible to write programs where irnphclt failures have to be dealt with exphcitly in order to get meaningful results. This paper addresses these problems and develops a method for (semi-)automatlc analysls of the worst-case cost of a large class of logic programs. The prl mary contribution of this paper is the development of techmques to deal with nondeterminism and the generation of multiple solutions via backtracking. Apphcations include program transformation and synthesis, software engineering, and in parallelizing compilers. © 1993, ACM. All rights reserved.",complexity; program analysis; PROLOG,Analysis; Costs; Logic programming; Performance; Cost analysis; Logic programs; Computer software
A Calculus for Access Control in Distributed Systems,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027667638&doi=10.1145%2f155183.155225&partnerID=40&md5=3fcd416d59013a95ba1d97b7df97d9ab,"We study some of the concepts, protocols, and algorithms for access control in distributed systems, from a logical perspective. We account for how a principal may come to believe that another principal is making a request, either on his own or on someone else's behalf. We also provide a logical language for accesss control lists and theories for deciding whether requests should be granted. © 1993, ACM. All rights reserved.",Cryptographic protocols; cryptography; modal logic; Security; Theory,Computation theory; Cryptography; Data acquisition; Formal languages; Formal logic; Network protocols; Security of data; Access control; Cryptographic protocols; Modal logic; Distributed computer systems
Cliché-Based Program Editors,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028320065&doi=10.1145%2f174625.174628&partnerID=40&md5=fd1479dd33e4ea962ddea897ffaf9115,[No abstract available],abstract syntax tree schemas; computer-aided software engineering (CASE); plan diagrams; reuse,Algorithmic languages; Algorithms; Computational linguistics; Computer aided software engineering; Computer programming; Computer software; Flowcharting; Knowledge based systems; Program debugging; Subroutines; Trees (mathematics); Vectors; Abstract syntax tree schemas; Ace editor; Cliche based program editors; Plan diagrams; Reuse; Tempest editor; File editors
Mathematical Foundations for Time Warp Systems,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027695497&doi=10.1145%2f161468.161470&partnerID=40&md5=de8e9ca7bd144893655f67ec876c0579,"We develop a simple formal model of the Time Warp approach to distributed computation, prove several important properties of the model, and devise some extensions to Time Warp that provide improved termination behavior. Our model consists of processes that communicate solely via message passing. One of the basic process steps is a rollback operation that includes message retraction via transmission of antimessages. In the model, we consider three problems: safety, progress, and termination. By safety, we mean that for a given system of processes, if a run of the system terminates, then the final system state of the run is identical to the final system state of a rollback-free run. We give premises that imply safety, and a counterexample that shows how safety can fail. By progress, we mean that, as a run of a system proceeds, the minimum timestamp of an unprocessed message always eventually increases. We state three axioms that imply the progress property. By termination, we mean that, if all rollback-free runs of a system terminate, then all runs terminate. The termination property is generally false in existing implementations of Time Warp systems due to the possibility of Time Warp vortices. We define additional mechanisms that can guarantee the termination property for most Time Warp applications. © 1993, ACM. All rights reserved.",Checkpoint; concurrency control; rollback; termination detection; Time Warp,Algorithms; Distributed computer systems; Models; Simulation; Concurrency control; Rollback; Termination detection; Time warp systems; Computer programming
Subtyping Recursive Types,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027667776&doi=10.1145%2f155183.155231&partnerID=40&md5=0a5232844828baf869abe175db90242f,"We investigate the interactions of subtyping and recursive types, in a simply typed λ-calculus. The two fundamental questions here are whether two 1993types are in the subtype relation and whether a term has a type. To address the first question, we relate various definitions of type equivalence and subtyping that are induced by a model, an ordering on infinite trees, an algorithm, and a set of type rules. We show soundness and completeness among the rules, the algorithm, and the tree semantics. We also prove soundness and a restricted form of completeness for the model. To address the second question, we show that to every pair of types in the subtype relation we can associate a term whose denotation is the uniquely determined coercion map between the two types. Moreover, we derive an algorithm that, when given a term with implicit coercions, can infer its least type whenever possible. © 1993, ACM. All rights reserved.",coercions; lambda-calculus; partial-equivalence relations; recursive types; regular trees; subtyping; tree orderings; type equivalence; typechecking algorithm,Computation theory; Computational linguistics; Equivalence classes; Formal languages; Mathematical models; Object oriented programming; Recursive functions; Theorem proving; Trees (mathematics); Coercions; Lambda calculus; Partial equivalence relations; Subtyping; Tree orderings; Typechecking algorithm; Computer programming languages
Determinacy Testing for Nondeterminate Logic Programming Languages,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028338032&doi=10.1145%2f174625.174626&partnerID=40&md5=780b4e6dc4e8d82480083f27c64f2e1b,"This paper describes an algorithm for the code generation of determinacy testing for nondeterminate flat concurrent logic programming languages. Languages such as Andorra and Pandora require that procedure invocations suspend if there is more than one candidate clause potentially satisfying the goal. The algorithm described has been developed specifically for a variant of flat Pandora based on FGHC, although the concepts are general. We have extended Kliger and Shapiro's decision-graph construction algorithm to compile “don't-know” procedures that must suspend for nondeterminate goal invocation. The determinacy test is compiled into a decision graph quite different from those of committed-choice procedures: They are more similar to decision trees optimized by code sharing. We present both empirical data of compilation results 1994, and a correctness proof for our code-generation algorithm. © 1994, ACM. All rights reserved.",Andorra model; decision graphs; Pandora,Algorithms; Codes (symbols); Computational linguistics; Decision theory; Graph theory; Logic programming; Mathematical models; Program compilers; PROLOG (programming language); Theorem proving; Trees (mathematics); Andorra model; Code generation; Decision graphs; Determinacy testing; Nondeterminate logic programming languages; Pandora; Computer programming languages
The POLYLITH Software Bus,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028257008&doi=10.1145%2f174625.174629&partnerID=40&md5=3748c1961c49d0e42bcc1e02676f315e,"We describe a system called POLYLITH that helps programmers prepare and interconnect mixed-language software components for execution in heterogeneous environments. POLYLITH's principal benefit is that programmers are free to implement functional requirements separately from their treatment of interfacing requirements; this means that once an application has been developed for use in one execution environment 1994 it can be adapted for reuse in other environments (such as a shared-memory multiprocessor) by automatic techniques. This flexibility is provided without loss of performance. We accomplish this by creating a new run-time organization for software. An abstract decoupling agent, called the software bus, is introduced between the system components. Heterogeneity in language and architecture is accommodated since program units are prepared to interface directly to the bus and not to other program units. Programmers specify application structure in terms of a module interconnection language (MIL); POLYLITH uses this specification to guide packaging (static interfacing activities such as stub generation, source program adaptation, compilation, and linking). At run time, an implementation of the bus abstraction may assist in message delivery, name service, or system reconfiguration. © 1994, ACM. All rights reserved.",,Computational complexity; Computer architecture; Computer operating systems; Computer programming; Computer programming languages; Computer software portability; Distributed computer systems; Interfaces (computer); Architecture specification; Language constructs; Mixed language software components; POLYLITH software bus; Computer software
Experimental Evaluation of a Generic Abstract Interpretation Algorithm for PROLOG,1994,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028257009&doi=10.1145%2f174625.174627&partnerID=40&md5=3468cac12563afc41872fc863b5edc01,"Interpretation of PROLOG programs has attracted many researchers in recent years, partly because of the potential for optimization in PROLOG compilers and partly because of the declarative nature of logic programming languages that make them more amenable to optimization than procedural languages. Most of the work, however, has remained at the theoretical level, focusing on the developments of frameworks and the definition of abstract domains. This paper reports our effort to verify experimentally the practical value of this area of research. It describes the design and implementation of the generic abstract interpretation algorithm GAIA that we originally proposed in Le Charlier et al. [1991], its instantiation to a sophisticated abstract domain 1994 containing modes, types, sharing, and aliasing, and its evaluation both in terms of performance and accuracy. The overall implementation (over 5000 lines of Pascal) has been systematically analyzed on a variety of programs and compared with the complexity analysis of Le Charlie et al. [1991] and the specific analysis systems of Hickey and Mudambi [1989], Taylor [1989; 1990], Van Roy and Despain [1990], and Warren et al. [1988]. © 1994, ACM. All rights reserved.",abstract interpretation; fixpoint algorithm; PROLOG,Computational complexity; Mathematical models; Optimization; Pascal (programming language); Program compilers; PROLOG (programming language); Fixpoint algorithm; Generic abstract interpretation algorithm (GAIA); Algorithms
Reasoning About Naming Systems,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027695738&doi=10.1145%2f161468.161471&partnerID=40&md5=73d06545011e403959d4b76bf4c199c1,"This paper reasons about naming systems as specialized inference mechanisms, It describes a preference)-zierarch.v that can be used to specify the structure of a naming system�s inference mechanism and defines criteria by which different naming systems can be evaluated, For example, the preference hierarchy allows one to compare naming systems based on how dkcrzmznating they are and to identify the class of names for which a given naming system is sound and complete. A study of several example naming systems demonstrates how the preference hierarchy can be used as a formal tool for designing naming systems. © 1993, ACM. All rights reserved.",descriptive naming systems; inference mechanisms,Database systems; Design; Information management; Query languages; Software engineering; Inference mechanisms; Naming systems; Computer systems
A Formal Definition of Priority in CSP,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027666587&doi=10.1145%2f155183.155221&partnerID=40&md5=afa6044adaa2af2047af78d9ed595b22,"The process models of Ada and occam are formally based on the CSP process algebra. However, for fine-tuning real-time performance, they include “prioritized” constructs that have no counterparts in CSP. These constructs therefore lack any formal definition, a situation that leaves room for misunderstandings. We extend CSP with a formal definition of the notion of priority. The definition is then used to assess the transputer implementation of priority in occam and the definition of priority in Ada. © 1993, ACM. All rights reserved.",Ada; Communicating Sequential Processes; occam; Priority; real-time programming,Ada (programming language); Boolean algebra; Computational complexity; Computational linguistics; Computer programming; Formal languages; Mathematical operators; Multiprocessing systems; Programming theory; Real time systems; Communicating sequential processes; Occam; Priority; Real time programming; Transputers; Computer programming languages
Procedural Implementation of Algebraic Specification,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027693965&doi=10.1145%2f161468.161473&partnerID=40&md5=d18813d60fbfcb2d6f246a6069f880f5,"An implementation of an algebraic specification in an imperative programming language consists of a representation type, together with an invariant and an equivalence relation over it, and a procedure for each operator in the specification. A formal technique is developed to check the correctness of an implementation with respect to its specification. Here “correctness” means that the implementation satisfies the axioms and preserves the behavior of the specification. Within legal representing value space, a correct implementation behaves like a desirable model of the specification. A notion of implementation refinement is also proposed, and it is shown that the correctness relation between implementations and specifications is preserved by implementation refinement. In the extreme case the procedures in an implementation may be pre-post-condition pairs. Such abstract implementations can be refined into executable code by refining the abstract procedures in it. In this way a formal link between the algebraic and the pre- post-condition specification techniques is established. © 1993, ACM. All rights reserved.",abstract implementation; procedural abstraction; program refinement,Algebra; Computer programming; Logic programming; Algebraic specification; Procedural implementation; Software engineering
A Methodology for Implementing Highly Concurrent Data Objects,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027695171&doi=10.1145%2f161468.161469&partnerID=40&md5=d5edf8de6a9f440e715ad324112f60cc,"A concurrent object is a data structure shared by concurrent processes. Conventional techniques for implementing concurrent objects typically rely on critical sections; ensuring that only one process at a time can operate on the object. Nevertheless, critical sections are poorly suited for asynchronous systems: if one process is halted or delayed in a critical section, other, nonfaulty processes will be unable to progress. By contrast, a concurrent object implementation is lock free if it always guarantees that some process will complete an operation in a finite number of steps, and it is wait free if it guarantees that each process will complete an operation in a finite number of steps. This paper proposes a new methodology for constructing lock-free and wait-free implementations of concurrent objects. The object's representation and operations are written as stylized sequential programs, with no explicit synchronization. Each sequential operation is atutomatically transformed into a lock-free or wait-free operation using novel synchronization and memory management algorithms. These algorithms are presented for a multiple instruction/multiple data 1993 architecture in which n processes communicate by applying atomic read, write, load_linked, and store_conditional operations to a shared memory. © 1993, ACM. All rights reserved.",,Algorithms; Computer architecture; Data structures; Management; Performance; Concurrent data objects; Computer software
A Further Note on Hennessy's “Symbolic Debugging of Optimized Code”,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027573845&doi=10.1145%2f169701.214526&partnerID=40&md5=e63af30b0df89fddf4bbcde9928c539c,"When attempting to debug optimized programs, most debuggers may give misleading information about the value of variables at breakpoints. Hennessy proposed a set of algorithms for generating optimized code and determining when, in the generated code, the reported values would be misleading�and under certain circumstances actually recovering the �expected� value of the variable (i.e., one that would not be misleading). We point out where the assumptions made by Hennessy need to be revised due to advances in compiler and debugger technology, and give references for current work on this revised problem. © 1993, ACM. All rights reserved.",,Algorithms; Codes (symbols); Optimization; Program compilers; Optimized code; Symbolic debugging; Program debugging
On the Type Structure of Standard ML,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027573846&doi=10.1145%2f169701.169696&partnerID=40&md5=627ed433280c2352d9cdbcd5d60edf83,"Standard ML is a useful programming language with a polymorphic type system and a flexible module facility. One notable feature of the core expression language of ML is that it is implicdy typed: no explicit type information need be supplied by the programmer. In contrast, the module language of ML is explicitly typed; in particular, the types of parameters in parametric modules must be supplied by the programmer. We study the type structure of Standard ML by giving an explicitly-typed, polymorphic function calculus that captures many of the essential aspects of both the core and module language. In this setting, implicitly-typed core language expressions are regarded as a convenient short-hand for an explicitly-typed counterpart in our function calculus. In contrast to the Girard-Reynolds polymorphic calculus, our function calculus is predzcatiw: the type system may be built up by induction on type levels. We show that, in a precise sense, the language becomes inconsistent if restrictions imposed by type levels are relaxed. More specifically, we prove that the important programming features of ML cannot be added to any impredicative language, such as the Girard-Reynolds calculus, without implicitly assuming a type of all types. © 1993, ACM. All rights reserved.",,Classification (of information); Computation theory; Computational linguistics; Data structures; Formal languages; Formal logic; Logic programming; Mathematical techniques; Modula (programming language); Denotational semantics; Girard Reynolds polymorphic calculus; Lambda calculus; Operational semantics; Standard ML programming language; Computer programming languages
Compiling Nested Data-Parallel Programs for Shared-Memory Multiprocessors,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027632582&doi=10.1145%2f169683.174152&partnerID=40&md5=01c6961d36afa9b655e80d80b9dccf1e,[No abstract available],compilers; data parallelism; shared-memory multiprocessors,Algorithms; Data structures; Multiprogramming; Optimization; Parallel processing systems; Compilers; Data parallelism; Nested data parallel programs; Shared memory multiprocessors; Multiprocessing systems
An Alternative Solution to a Problem on Self-Stabilization,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027662844&doi=10.1145%2f155183.155228&partnerID=40&md5=5305085d18225ad8507422f119f4ac03,"Dijkstra [4, 5] introduced the problem of self-stabilization in distributed systems as an interesting exercise for achieving global convergence through local actions. In [4] he presented three solutions to a specific version of the self-stabilization problem, one of which was proved in [6]. This paper presents an alternative solution of his self-stabilization problem with four-state machines. © 1993, ACM. All rights reserved.",distributed algorithms; self-stabilization; synthesis,Algorithms; Computer system recovery; Convergence of numerical methods; Finite automata; Invariance; Stabilization; State assignment; Synchronization; System stability; Self stabilization problem; Distributed computer systems
Parameterized Partial Evaluation,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027629465&doi=10.1145%2f169683.174155&partnerID=40&md5=532c22a213d6d488dd7f3e607b751e62,[No abstract available],,Computer programming languages; Information retrieval systems; Information theory; Online searching; Online systems; Offline partial evaluation; Program specialization; Symbolic values; Evaluation
Analysis of Or-Parallel Execution Models,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027659656&doi=10.1145%2f155183.155220&partnerID=40&md5=85ca451a2cd490bc3297f9ae2aa88e11,"We discuss fundamental limitations of or-parallel execution models of nondeterministic programming languages. Or-parallelism corresponds to the execution of different nondeterministic computational paths in parallel. A natural way to represent the state of 1993 execution of a nondeterministic program is by means of an or-parallel tree. We identify three important criteria that underlie the design of or-parallel implementations based on the or-parallel tree: constant-time access to variables, constant-time task creation, and constant-time task switching, where the term constant-time means that the time for these operations is independent of the number of nodes in the or-parallel tree, as well as the size of each node. We prove that all three criteria cannot be simultaneously satisfied by any or-parallel execution model based on a finite number of processors but unbounded memory. We discuss in detail the application of our result to the class of logic programming languages and show how our result can serve as a useful way to categorize the various or-parallel methods proposed in this field. We also discuss the suitability of different or-parallel implemenation strategies for different parallel architectures. © 1993, ACM. All rights reserved.",,Logic programming; Mathematical models; Parallel processing systems; Program processors; Programming theory; Theorem proving; Trees (mathematics); Backtracking; Nondeterminism; Or parallel execution models; Computer programming languages
Type Reconstruction in the Presence of Polymorphic Recursion,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027574110&doi=10.1145%2f169701.169687&partnerID=40&md5=b6f0c2f3347619506ccd91b2c97d43ae,"We study the problem of type-checking functional programs in three extensions of ML. One distinguishing feature of these extensions is that they allow recursive definitions to be polymorphically typed. Although the motivation for these extensions comes from pragmatic considerations of programming language design, we show that the typability problem for each one of these extensions is polynomial-time equivalent to the Semi-Unification Problem and, therefore, undecidable. © 1993, ACM. All rights reserved.",fixpoint operator; polymorphic abstraction; polymorphic recursion; semiunification,ALGOL (programming language); Computation theory; Computer programming languages; Formal languages; Formal logic; Mathematical operators; Program compilers; Recursive functions; Fixpoint operator; Polymorphic abstraction; Polymorphic recursion; Semiunification; Typability problem; Computer programming
Scheduling Time-Critical Instructions on RISC Machines,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027659116&doi=10.1145%2f155183.155190&partnerID=40&md5=501e8fbdf2fe9702ce9aadb0250f6a24,"We present a polynomial time algorithm for constructing a minimum completion time schedule of instructions from a basic block on RISC machines such as the Sun SPARC, the IBM 801, the Berkeley RISC machine, and the HP Precision Architecture. Our algorithm can be used as a heuristic for RISC processors with longer pipelines, for which there is no known optimal algorithm. Our algorithm can also handle time-critical instructions, which are instructions that have to be completed by a specific time. Time-critical instructions occur in some real-time computations, and can also be used to make shared resources such as registers quickly available for reuse. We also prove that in the absence of time-critical constraints, a greedy scheduling algorithm always produces a schedule for a target machine with multiple identical pipelines that has a length less than twice that of an optimal schedule. The behavior of the heuristic is of interest because, as we show, the instruction scheduling problem becomes NP-hard for arbitrary length pipelines, even when the basic block of code being input consists of only several independent streams of straightline code, and there are no time-critical constraints. Finally, we prove that the problem becomes NP-hard even for small pipelines, no time-critical constraints, and input of several independent streams of straightline code if either there is only a single register or if no two instructions are allowed to complete simultaneously because of some shared resource such as a bus. © 1993, ACM. All rights reserved.",compiler optimization; deadline; greedy algorithm; instruction scheduling; latency; NP-complete; pipeline processor; register allocation; RISC machine scheduling,Computational complexity; Heuristic programming; Optimization; Pipeline processing systems; Polynomials; Program compilers; Reduced instruction set computing; Scheduling; Compiler optimization; Instruction scheduling; Polynomial time algorithm; Register allocation; RISC machine scheduling; Algorithms
Technical correspondence: A Correction to the Denotational Semantics for the Prolog of Nicholson and Foo,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976805356&doi=10.1145%2f151646.151652&partnerID=40&md5=6ea4adb562b25abcc68829f675d4370a,[No abstract available],,
Interprocedural Optimization: Eliminating Unnecessary Recompilation,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027632052&doi=10.1145%2f169683.169678&partnerID=40&md5=08abcc311800ac995ef3ff7dcb18e0a5,[No abstract available],data-flow analysis; interprocedural analysis and optimization; recompilation analysis,Algorithms; Data reduction; Information retrieval systems; Software engineering; Compilers; Dataflow analysis; Interprocedural analysis; Recompilation analysis; Optimization
Type Inference with Polymorphic Recursion,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027579091&doi=10.1145%2f169701.169692&partnerID=40&md5=ecda9d020d729ae7f6a7f672bc5986c3,[No abstract available],polymorphism; recursion; semiunification; type inference,Algorithms; Computational linguistics; Computer programming languages; Data structures; Inference engines; Logic programming; Mathematical techniques; Recursive functions; Damas Milner calculus; Lambda calculus; Milner Mycroft calculus; Milner's semantics; Polymorphic recursion; Semiunification algorithm; Type inference; Computation theory
A Superimposition Control Construct for Distributed Systems,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027577162&doi=10.1145%2f169701.169682&partnerID=40&md5=f61ac6300d51b731748d0536cd0719b3,"A control structure called a superimposition is proposed. The structure contains schematic abstractions of processes called roletypes in its declaration. Each roletype may be bound to processes from a basic distributed algorithm, and the operations of the roletype will then execute interleaved with those of the basic processes, over the same state space. This structure captures a kind of modularity natural for distributed programming, which previously has been treated using a macro-like implantation of code. The elements of a superimposition are identified, a syntax is suggested, correctness criteria are defined, and examples are presented. © 1993, ACM. All rights reserved.",control construct; distributed programming; formal and actual processes; modularity; roletype; superimposition,Algorithms; Codes (symbols); Computer programming languages; Control; Distributed computer systems; Concurrent programming; Control construct; Distributed programming; Formal and actual processes; Modularity; Roletypes; Superimposition; Computer programming
Defining Context-Dependent Syntax Without Using Contexts,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027629386&doi=10.1145%2f169683.174159&partnerID=40&md5=f2bd04c0dda5391342176edab8026314,"A method for defining context-dependent syntax is presented. The method, like many others, builds on a context-free grammar that defines a superset of a given language, mapping each string in the language to a derivation tree. The context-free language is subsequently restricted by imposing conformity criteria on derivation trees. These criteria are expressed with logic predicates, called context rules, which characterize the form of conformant derivation trees. A text belongs to the defined language if and only if its derivation tree is a model of all context rules. This approach avoids the use of explicit data structures for contextual information and tends to yield very concise formal definitions. It has been applied with good results in the formal definition of the programming language Oberon. © 1993, ACM. All rights reserved.",context-dependent syntax; programming language definition,Design; Digital arithmetic; Logic design; Mathematical logic; Context dependent syntax; Formal language; Parsing; Programming language definition; Computer programming languages
The Design of the E Programming Language,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027632416&doi=10.1145%2f169683.174157&partnerID=40&md5=f5da4968a038d12f9ae60c5697316200,[No abstract available],extensible database systems; persistent object management,Database systems; Design; Management; Object oriented programming; Extensible database systems; Persistent object management; Computer programming languages
An Elimination Algorithm for Bidirectional Data Flow Problems Using Edge Placement,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027576068&doi=10.1145%2f169701.169684&partnerID=40&md5=00894664fa07662fc72b2961064d9599,"Bidirectional data flow problems, useful in a wide range of optimizing transformations, are conventionally solved using the iterative approach. Thm paper shows that use of the edge placement technique makes bidirectional data flow problems amenable to effkient solution. An elimination algorithm for bidirectional data flow problems using edge placement is presented, and its complexity is shown to be ldentlcal to the complexity of elimination algorithms for unidirectional data flows. © 1993, ACM. All rights reserved.",bidirectional dependencies; data flow analysis; elimination algorithm; interval analysis,Computational complexity; Data reduction; Iterative methods; Optimization; Program compilers; Program processors; Bidirectional dependencies; Data flow analysis; Edge placement technique; Elimination algorithm; Interval analysis; Algorithms
Leader Election in Uniform Rings,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027632091&doi=10.1145%2f169683.174161&partnerID=40&md5=15957f4a1498816e8b103e7b3a374d49,[No abstract available],protocols; self-stabilization,Digital arithmetic; Operating systems (computer); Protocols; Reliability; Telecommunication networks; Theory; Self stabilization; Algorithms
A General Framework for Semantics-Based Bottom-Up Abstract Interpretation of Logic Programs,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027347820&doi=10.1145%2f151646.151650&partnerID=40&md5=e8da0845dadbf1fc8ae5c422eccb0cfe,"The theory of abstract interpretation provides a formal framework to develop advanced dataflow analysis tools. The idea is to define a nonstandard semantics which is able to compute, in finite time, an approximated model of the program. In this paper, we define an abstract interpretation framework based on a fixpoint approach to the semantics. This leads to the definition, by means of a suitable set of operators, of an abstract fixpoint characterization of a model associated with the program. Thus, we obtain a specializable abstract framework for bottom-up abstract interpretations of definite logic programs. The specialization of the framework is shown on two examples, namely, gound-dependence analysis and depth-k analysis. © 1993, ACM. All rights reserved.",abstract interpretation; logic programming; program analysis,Computational linguistics; Finite automata; Logic programming; Mathematical models; Program compilers; Theorem proving; Abstract fixpoint characterization; Logic programs; Program analysis; Semantics based bottom up interpretation; Computer software
Lazy Caching,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027347715&doi=10.1145%2f151646.151651&partnerID=40&md5=bafd064e928fc8077704f62c6de959a6,"This paper examines cache consistency conditions for multiprocessor shared memory systems. It states and motivates a weaker condition than is normally implemented. An algorithm is presented that exploits the weaker condition to achieve greater concurrency. The algorithm is shown to satisfy the weak consistency condition. Other properties of the algorithm and possible extensions are discussed. © 1993, ACM. All rights reserved.",cache coherence; sequential consistency; shared memory,Algorithms; Computer architecture; Computer systems programming; Multiprocessing systems; Parallel processing systems; Storage allocation (computer); Cache coherence; Multiple instruction stream multiple data stream processors; Sequential consistency; Shared memory; Random access storage
Composing Specifications,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027342022&doi=10.1145%2f151646.151649&partnerID=40&md5=64ba52f331196fe0d533bd516cd99d00,"A rigorous modular specification method requires a proof rule asserting that if each component behaves correctly in isolation, then it behaves correctly in concert with other components. Such a rule is subtle because a component need behave correctly only when its environment does, and each component is part of the others' environments. We examine the precise distinction between a system and its environment, and provide the requisite proof rule when modules are specified with safety and liveness properties. © 1993, ACM. All rights reserved.",compositionality; concurrent programming; liveness properties; modular specification; safety properties,Computer hardware description languages; Computer programming; Computer programming languages; Computer software; Formal logic; Hierarchical systems; Software engineering; Compositionality; Concurrent programming; Liveness properties; Modular specification; Safety properties; Transition axiom method; Theorem proving
An Adaptive Tenuring Policy for Generation Scavengers,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026470338&doi=10.1145%2f111186.116734&partnerID=40&md5=e6a6cb87f012a45c4d6b45845599b22e,"One of the more promising automatic storage reclamation techniques, generation scavenging, suffers poor performance if many objects live for a fairly long time and then die. We have investigated the severity of this problem by simulating a two-generation scavenger using traces taken from actual 4-h sessions. There was a wide variation in the sample runs, with garbage-collection overhead ranging from insignificant, during three of the runs, to severe, during a single run. All runs demonstrated that performance could be improved with two techniques: segregating large bitmaps and strings, and adapting the scavenger's tenuring policy according to demographic feedback. We therefore incorporated these ideas into a commercial Smalltalk implementation. These two improvements deserve consideration for any storage reclamation strategy that utilizes a generation scavenger. © 1992, ACM. All rights reserved.",,Object oriented programming; Storage allocation (computer); Smalltalk (programming language); Software development; Software engineering
The Concurrency Workbench: A Semantics-Based Tool for the Verification of Concurrent Systems,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027342054&doi=10.1145%2f151646.151648&partnerID=40&md5=aae5e73fb7c0bd91828bf4c9941f81a6,"The Concurrency Workbench is an automated tool for analyzing networks of finite-state processes expressed in Milner's Calculus of Communicating Systems. Its key feature is its breadth: a variety of different verification methods, including equivalence checking, preorder checking, and model checking, are supported for several different process semantics. One experience from our work is that a large number of interesting verification methods can be formulated as combinations of a small number of primitive algorithms. The Workbench has been applied to the verification of communications protocols and mutual exclusion algorithms and has proven a valuable aid in teaching and research. © 1993, ACM. All rights reserved.",automatic verification; concurrency; finite-state systems; process algebra,Algorithms; Boolean algebra; Computational linguistics; Computer hardware description languages; Distributed computer systems; Finite automata; Network protocols; Automatic verification; Concurrency workbench; Concurrent systems verification; Finite state systems; Milner's calculus of communicating systems; Primitive algorithms; Process algebra; Computer networks
The Derivation of Distributed Termination Detection Algorithms from Garbage Collection Schemes,1993,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027342053&doi=10.1145%2f151646.151647&partnerID=40&md5=4b47a5f8a46605a83eedab32cb25869e,"It is shown that the termination detection problem for distributed computations can be modeled as an instance of the garbage collection problem. Consequently, algorithms for the termination detection problem are obtained by applying transformations to garbage collection algorithms. The transformation can be applied to collectors of the “mark-and-sweep” type as well as to reference-counting protocol of Lermen and Maurer, the weighted-reference-counting protocol, the local-reference-counting protocol, and Ben-Ari's mark-and-sweep collector into termination detection algorithms. Known termination detection algorithms as well as new variants are obtained. © 1993, ACM. All rights reserved.",Distributed algorithms; distributed termination detection; garbage collection; program transformations,Computation theory; Computer operating systems; Computer systems programming; Distributed computer systems; Network protocols; Storage allocation (computer); Ben-Ari's mark and sweep collector; Distributed termination detection algorithms; Garbage collection schemes; Lermen and Maurer distributed reference counting protocols; Local reference counting protocol; Program transformations; Weighted reference counting protocol; Algorithms
Epochs,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026449034&doi=10.1145%2f111186.116785&partnerID=40&md5=95165f9f6386647fde68b883c9c58de1,"To date, the implementation of message passing languages has required hte communications variables 1992 either to be limited to the number of physical communications registers in the machine or to be mapped to memory. Neither solution is satisfactory. Limiting the number of variables decreases modularity and efficiency of parallel programs. Mapping variables to memory increases the cost of communications and the granularity of parallelism. We present here a new programming language construct called epochs. Epochs are a scoping mechanism within which the programmer can declare communications variables, which are live only during the scope of that epoch. To limit the range of time a register has to be allocated for a communications variable, the compiler ensures that all processors enter an epoch simultaneously. The programming style engendered fits somewhere between the SIMD data parallel and the MIMD process spawning models. We describe an implementation for epochs including an efficient synchronization mechanism, a means of statically binding registers to communications variables, and a method of fusing epochs to reduce synchronization overhead. © 1992, ACM. All rights reserved.",,Algorithms; Parallel processing systems; Program compilers; Concurrent programming; Process management; Computer architecture
Computer-assisted microanalysis of parallel programs,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026483518&doi=10.1145%2f111186.126699&partnerID=40&md5=4fad17614d5275b1ed90c411cd640095,"This paper consists of two parts: the first provides the theoretical foundations for analyzing parallel programs and illustrates how the theory can be applied to estimate the execution time of a class of parallel programs being executed on a MIMD computer. The second part describes a program analysis system, based on the theoretical model, which allows a user to interactively analyze the results of executing 1992 of such parallel programs. Several examples illustrating the use of the tool are presented. A novel contribution is the separation (both at the conceptual and the implementation levels) of the machine-independent and the machine-dependent parts of the analysis. This separation enables the users of the system to establish speed-up curves for machines having varying characteristics. © 1992, ACM. All rights reserved.",event graph; execution graph; execution trace; microanalysis; speed up,Computational complexity; Mathematical models; Parallel processing systems; Software engineering; Performance measures; Software development; Computer architecture
Denotational Semantics of a Goal-Directed Language,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026481737&doi=10.1145%2f111186.104659&partnerID=40&md5=4610d6fca312bce95724d5ae8d5b07e4,"Goal-directed evaluation is a very expressive programming language paradigm that is supported in relatively few languages. It is characterized by evaluation of expressions in an attempt to meet some goal, with resumption of previous expressions on failure. This paradigm is found in SNOBL4 in its pattern-matching facilities, and in Icon as a general part of the language. This paper presents a denotational semantics of Icon and shows how Icon is in fact a combination of two distinct paradigms, goal-directed evaluation and functional application. The two paradigms are not supported separately in different contexts, but integrated fully into a single evaluation mechanism. © 1992, ACM. All rights reserved.",generators; goal-directed evaluation; programming language paradigms,Computer programming languages; Denotational semantics; Goal-directed languages; Programming theory
Incremental Generation of Lexical Scanners,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026932950&doi=10.1145%2f133233.133240&partnerID=40&md5=b1691b6f02f2935cfb3ec002171fdde5,"It is common practice to specify textual patterns by means of a set of regular expressions and to transform this set into a finite automaton to be used for the scanning of input strings. In many applications, the cost of this preprocessing phase can be amortized over many uses of the constructed automaton. In this paper new techniques for lazy and incremental scanner generation are presented. The lazy technique postpones the construction of parts of the automaton until they are really needed during the scanning of input. The incremental technique allows modifications to the original set of regular expressions to be made and reuses major parts of the previous automaton. This is interesting in applications such as environments for the interactive development of language definitions in which modifications to the definition of lexical syntax and the uses of the generated scanners alternate frequently. © 1992, ACM. All rights reserved.",finite automaton; lazy and incremental generation of lexical scanners; program generator; subset construction,Algorithms; Finite automata; Performance; Program processors; Lexical scanners; Computer programming
Incremental Global Reoptimization of Programs,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026846020&doi=10.1145%2f128861.128865&partnerID=40&md5=8de75c4bdf9ba5b3d4f267803e9cdddd,"Although optimizing compilers have been quite successful in producing excellent code, two factors that limit their usefulness are the accompanying long compilation times and the lack of good symbolic debuggers for optimized code. One approach to attaining faster recompilations is to reduce the redundant analysis that is performed for optimization in response to edits, and in particulars, small maintenance changes, without affecting the quality of the generated code. Although modular programming with separate compilation aids in eliminating unnecessary recompilation and reoptimization, recent studies have discovered that more efficient code can be generated by collapsing a modular program through procedure inlining. To avoid having to reoptimize the resultant large procedures, this paper presents techniques for incrementally incorporating changes into globally optimized code. An algorithm is given for determining which optimizations are no longer safe after a program change, and for discovering which new optimizations can be performed in order to maintain a high level of optimization. An intermediate representation is incrementally updated to reflect the current optimizations in the program. Analysis is performed in response to changes rather than in preparation for possible changes, so analysis is not wasted if an edit has no far-reaching effects. The techniques developed in this paper have also been exploited to improve on the current techniques for symbolic debugging of optimized code. © 1992, ACM. All rights reserved.",compiler optimization; incremental data flow analysis; incremental reoptimization; optimization dependencies,Algorithms; Computer programming languages; Program compilers; Code generation; Compiler optimization; Software engineering
A Stepwise Refinement Heuristic for Protocol Construction,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026886045&doi=10.1145%2f129393.129394&partnerID=40&md5=70ed324a86b8b9e57387c73d415b63b6,"A stepwise refinement heuristic to construct distributed systems is presented. The heuristic is based on a conditional refinement relation between system specifications, and a “Marking”. It is applied to construct four sliding window protocols that provide reliable data transfer over unreliable communication channels. The protocols use modulo-N sequence numbers. The first protocol is for channels that can only lose messages in transit. By refining this protocol, we obtain three protocols for channels that can lose, reorder, and duplicate messages in transit. The protocols herein are less restrictive and easier to implement than sliding window protocols previously studied in the protocol verification literature. © 1992, ACM. All rights reserved.",assertional reasoning; conditional refinement; cyclic sequence numbers; interfaces; message lifetimes; sliding window protocols; stepwise refinement,Computer architecture; Digital communication systems; Real time systems; Software engineering; Protocol verification; Network protocols
Guest Editor's Introduction to the Special Section on the Third International Conference on Computer Languages,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976822260&doi=10.1145%2f128861.128863&partnerID=40&md5=26b1e64c9833f365508ebaa15062ef23,[No abstract available],,
"Type Matching, Type-Graphs, and the Schanuel Conjecture",1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026932166&doi=10.1145%2f133233.133247&partnerID=40&md5=a26a32e9ec4596049d5ef816a391e31b,"This work considers type systems that are defined by type-graphs 1992, which are rooted directed graphs with order among the edges leaving each node. Tgraphs are uniquely mapped into polynomials which, in turn, are each evaluated at a special point to yield an irrational number named the tgraph's magic number. This special point is chosen using the Schanuel conjecture. It is shown that each tgraph can be uniquely represented by this magic number; namely, types are equal if and only if the corresponding magic numbers are equal. Since irrational numbers require infinite precision, the algorithm for generating magic numbers is carried out using a double-precision floating-point approximation. This approximation is viewed as a hashing scheme, mapping the infinite domain of the irrational numbers into finite computer words. The proposed hashing scheme was investigated experimentally, with the conclusion that it is a good and practical hashing method. In tests involving over a million randomly chosen tgraphs, we have not encountered a single collision. We conclude that this method for representation and management of types is practical, and offers novel possibilities for enforcing strict type matching at link time among separately compiled modules. © 1992, ACM. All rights reserved.",compilers; graph hashing; mapping graphs to numbers; Schanuel conjecture; type matching; type-graphs; types,Data structures; Program compilers; Data types; Schanuel conjecture; Computer programming languages
The Euclidean Definition of the Functions div and mod,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026845445&doi=10.1145%2f128861.128862&partnerID=40&md5=dcc006768541a34e1a21fc92695e3c2f,"The definitions of the functions div and mod in the computer science literature and in programming languages are either similar to the Algol of Pascal definition 1992 or based on division by truncation (T-definition) or division by flooring as defined by Knuth (F-definition). The differences between various definitions that are in common usage are discussed, and an additional one is proposed, which is based on Euclid's theorem and therefore is called the Euclidean definition (E-definition). Its distinguishing feature is that 0 ≤ D mod d < | d | irrespective of the signs of D and d. It is argued that the E- and F-definitions are superior to all other ones in regularity and useful mathematical properties and hence deserve serious consideration as the standard convention at the applications and language level. It is also shown that these definitions are the most suitable ones for describing number representation systems and the realization of arithmetic operations at the architecture and hardware level. © 1992, ACM. All rights reserved.",decimation; div function; Euclid's theorem; hardware description; integer division; interpolation; mod function; number representation; predefined functions; remainder; residue; sampling,Data structures; Digital arithmetic; Interpolation; Standards; Number representation; Computer programming languages
An Object-Based Programming Model for Shared Data,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026844994&doi=10.1145%2f128861.128866&partnerID=40&md5=97a8b357e83b96a5265d86b98f1dc3be,"The classical object model supports private data within objects and clean interfaces between objects, and by definition does not permit sharing of data among arbitrary objects. This is a problem for real-world applications, such as advanced financial services and integrated network management, where the same data logically belong to multiple objects and may be distributed over multiple nodes on the network. Rather than give up the advantages of encapsulated objects in modeling real-world entities, we propose a new object model that supports shared data in a distributed environment. The key is separating distribution of computation units from information-hiding concerns. Minimal units of data and control, called facets, may be shared among multiple objects and are grouped into processes. Thus, a single object, or information-hiding unit, may be distributed among multiple processes, or computation units. In other words, different facets of the same object may reside in different address spaces on different machines. We introduce our new object model, describe a motivating example from the financial domain, and then explain facets, objects, and processes, followed by timing and synchronization concerns. © 1992, ACM. All rights reserved.",coordination language; daemons; financial applications; object-based; real-time; sharing,Computer programming languages; Data structures; Query languages; Abstract data types; Concurrent programming; Query processing; Object oriented programming
Cache Behavior of Combinator Graph Reduction,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026846080&doi=10.1145%2f128861.128867&partnerID=40&md5=f45eb0881a3646ebf3db1e15da3ee0b9,"The results of cache-simulation experiments with an abstract machine for reducing combinator graphs are presented. The abstract machine, called TIGRE, exhibits reduction rates that, for similar kinds of combinator graphs on similar kinds of hardware, compare favorably with previously reported techniques. Furthermore, TIGRE maps easily and efficiently onto standard computer architectures, particularly those that allow a restricted form of self-modifying code. This provides some indication that the conventional “stored program” organization of computer systems is not necessarily an inappropriate one for functional programming language implementations. This is not to say, however, that present day computer systems are well equipped to reduce combinator graphs. In particular, the behavior of the cache memory has a significant effect on performance. In order to study and quantify this effect, trace-driven cache simulations of a TIGRE graph reducer running on a reduced instruction-set computer are conducted. The results of these simulations are presented with the following hardware-cache parameters varied: cache size, block size, associativity, memory update policy, and write-allocation policy. To begin with, the cache organization of a commercially available system is used and then the performance sensitivity with respect to variations of each parameter are measured. From the results of the simulation study, a conclusion is made that combinator-graph reduction using TIGRE runs most efficiently when using a cache memory with an allocate-on-write-miss strategy, moderately large block size 1992, and copy-back memory updates. © 1992, ACM. All rights reserved.",abstract machine; combinators; graph reduction; self-modifying code,Combinatorial mathematics; Computer operating systems; Computer simulation; Graph theory; Cache memories; Computational models; Storage allocation (computer)
M-LISP: A Representation-Independent Dialect of LISP with Reduction Semantics,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026931388&doi=10.1145%2f133233.133254&partnerID=40&md5=fe2c66b082f0941e8ced2cac12789606,"In this paper we introduce M-LISP, a dialect of LISP designed with an eye toward reconciling LISP's metalinguistic power with the structural style of operational semantics advocated by Plotkin [28]. We begin by reviewing the original definition of LISP [20] in an attempt to clarify the source of its metalinguistic power. We find that it arises from a problematic clause in this definition. We then define the abstract syntax and operational semantics of M-LISP, essentially a hybrid of M-expression LISP and Scheme. Next, we tie the operational semantics to the corresponding equational logic. As usual, provable equality in the logic implies operational equality. Having established this framework we then extend M-LISP with the metalinguistic eval and reify operators 1992. These operators encapsulate the matalinguistic representation conversions that occur globally in S-expression LISP. We show that the naive versions of these operators render LISP's equational logic inconsistent. On the positive side, we show that a naturally restricted form of the eval operator is confluent and therefore a conservative extension of M-LISP. Unfortunately, we must weaken the logic considerably to obtain a consistent theory of reification. © 1992, ACM. All rights reserved.",fexprs; metalinguistic constructs; reflection; reification; unquote,Formal languages; Formal logic; Programming theory; Operational semantics; LISP (programming language)
Experience with a Software-Defined Machine Architecture,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026889760&doi=10.1145%2f129393.129395&partnerID=40&md5=af5177dca769e511e745776ff18f495e,"We have built a system in which the compiler back end and the linker work together to present an abstract machine at a considerably higher level than the actual machine. The intermediate language translated by the back end is the target language of all high-level compilers and is also the only assembly language generally available. This lets us do intermodule register allocation, which would be harder if some of the code in the program had come from a traditional assembler, out of sight of the optimizer. We do intermodule register allocation and pipeline instruction scheduling at link time, using information gathered by the compiler back end. The mechanism for analyzing and modifying the program at link time is also useful in a wide array of instrumentation tools. © 1992, ACM. All rights reserved.",graph coloring; intermediate language; interprocedural; optimization; pipeline scheduling; profiling; register allocation; register windows; RISC,Computer software; Interfaces (computer); Program compilers; High-level assembly languages; Mahler (programming language); Computer architecture
Trace-Based Network Proof Systems: Expressiveness and Completeness,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026884658&doi=10.1145%2f129393.129396&partnerID=40&md5=60f5b0a9948cf2f968fe708935ded1eb,"We consider incomplete trace-based network proof systems for safety properties, identifying extensions that are necessary and sufficient to achieve relative completeness. We investigate the expressiveness required of any trace logic to encode these extensions. © 1992, ACM. All rights reserved.",process networks; safety properties; temporal logics; trace logics,Computability and decidability; Computer programming; Formal logic; Software engineering; Concurrent programming; Reasoning; Theorem proving
A Model Parametric Real-Time Logic,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026932786&doi=10.1145%2f133233.129397&partnerID=40&md5=2a2a0d58e0b572ad0718d932f2c9a547,"TRIO is a formal notation for the logic-based specification of real-time systems. In this paper the language and its straightforward model-theoretic semantics are briefly summarized. Then the need for assigning a consistent meaning to TRIO specifications is discussed, with reference to a variety of underlying time structures such as infinite-time structures 1992 and finite-time structures. The main motivation is the ability to validate formal specifications. A solution to this problem is presented, which gives a new, model-parametric semantics to the language. An algorithm for constructively verifying the satisfiability of formulas in the decidable cases is defined, and several important temporal properties of specifications are characterized. © 1992, ACM. All rights reserved.",first-order logic; formal specifications; model-theoretic semantics; real-time systems; requirements validation; temporal logic,Formal languages; Formal logic; Formal specifications; Real time systems
Subsequence References: First-Class Values for Substrings,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026931730&doi=10.1145%2f133233.133234&partnerID=40&md5=6f18b61da880117bb02e554a184e413a,"Arrays of characters are a basic data type in many programming languages, but strings and substrings are seldom accorded first-class status as parameters and return values. Such status would enable a routine that calls a search function to readily access context on both sides of a return value. To enfranchise substrings, this paper describes a new data type for substrings as a special case of one for general subsequences. The key idea is that values are not sequences or references to positions in sequences, but rather references to subsequences. Primitive operations on the data type are constants, concatenation, and four new functions—base, start, next, and extent—which map subsequence references to subsequence references. This paper informally presents the data type, demonstrates its convenience for defining search functions, and shows how it can be concisely implemented. Examples are given in Ness, a language incorporating the new data type, which is implemented as part of the Andrew User Interface System. © 1992, ACM. All rights reserved.",Andrew Toolkit; ATK; AUIS; document processing; Ness; programming language design; sequences; string searching; strings; subsequences; substrings,Data structures; Online searching; Pattern recognition; Word processing; Document processing; Computer programming languages
A Self-Applicable Partial Evaluator for the Lambda Calculus: Correctness and Pragmatics,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026845597&doi=10.1145%2f128861.128864&partnerID=40&md5=0ae874de5ff8510007a1fb8974607ecf,"We describe theoretical and a few practical aspects of an implemented self-applicable partial evaluator for the untyped lambda calculus with constants, conditionals, and a fixed point operator. The purpose of this paper is first to announce the existence of 1992 a partial evaluator that is both higher-order and self-applicable; second to describe a surprisingly simple solution to the central problem of binding time analysis, and third to prove that the partial evaluator yields correct answers. While λ-mix (the name of our system) seems to have been the first higher-order self-applicable partial evaluator to run on a computer, it was developed mainly for research purposes. Two recently developed systems are much more powerful for practical use, but also much more complex: Similix[3,5] and Schism[7]. Our partial evaluator is surprisingly simple, completely automatic, and has been implemented in a side effect-free subset of Scheme. It has been used to compile, generate compilers and generate a compiler generator. © 1992, ACM. All rights reserved.",compiler generation; lambda calculus; partial evaluation; self-application,Formal logic; Program compilers; Compiler generation; Lambda calculus; Computer programming languages
The CLP(R) Language and System,1992,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026884407&doi=10.1145%2f129393.129398&partnerID=40&md5=bbd6ce50cab644928aec01ab67efbc07,"The CLPR programming language is defined, its underlyingphilosophy and programming methodology are discussed, importantimplementation issues are explored in detail, and finally, a prototypeinterpreter is described. CLPR is designed to be an instance of the Constraint LogicProgramming Scheme, a family of rule-based constraint programminglanguages defined by Jaffar and Lassez. The domain of computation R of this particular instance is the algebraic structureconsisting of uninterpreted functors over real numbers. An importantproperty of CLP R is that the constraints are treated uniformly in thesense that they are used to specify the input parameters to a program,they are the only primitives used in the execution of a program, andthey are used to describe the output of a program. Implementation of a CLP language, and of CLPR in particular, raises new problems in the design of aconstraint-solver. For example, the constraint solver must be incremental in the sensethat solving additional constraints must not entail the resolving of oldconstraints. In our system, constraints are filtered through aninference engine, an engine/solver interface, an equation solver and aninequality solver. This sequence of modules reflects a classificationand prioritization of the classes of constraints. Modules solving higherpriority constraints are isolated from the complexities of modulessolving lower priority constraints. This multiple-phase solving ofconstraints, together with a set of associated algorithms, gives rise toa practical system. © 1992, ACM. All rights reserved.",constraints; logic programming,Computer programming languages; Interfaces (computer); Numerical methods; Constraint logic programming (CLP) scheme; Logic programming
Data Flow Analysis of Communicating Finite State Machines,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976803100&doi=10.1145%2f117009.117015&partnerID=40&md5=0160ec6284bb8153748a9fe990fc80c8,"Let (P1, P2, … Pn) be a network of n finite state machines, communicating with each other asynchronously using typed messages over unbounded FIFO channels, In this paper we present a data flow approach to analyzing these communicating machines for nonprogress properties (deadlock and unspecified reception). We set up flow equations to compute the set of pending messages in the queues at any given state of such a network, The central technical contribution of this paper is an algorithm to compute approximations to solutions for the ensuing equations We then show how these approximate solutions can be used to check that interactions between the processes are free of nonprogress errors. We conclude with a number of example protocols that our algorithm certifies to be free of nonprog-ess errors. Included in the examples is a specification of X25 call establishment/clear protocol. © 1991, ACM. All rights reserved.",communicating finite state machines; static analysis,
Type-Extension Type Test Can be Performed in Constant Time,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976654194&doi=10.1145%2f115372.115297&partnerID=40&md5=cafc5bfa676e7928cccc19926620c001,[No abstract available],class; descriptor; display; extensible data type; inheritance; membership test; object-oriented programming; type extension; type test,
Reply to “Type-Extension Tests Can Be Performed in Constant Time”,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976748104&doi=10.1145%2f115372.214521&partnerID=40&md5=3a1267f9ca5d412d9fe5c110794ae509,[No abstract available],,
Techniques for Debugging Parallel Programs with Flowback Analysis,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026244475&doi=10.1145%2f115372.115324&partnerID=40&md5=c307664384018ee3c2f30459f508e402,[No abstract available],debugging; flowback analysis; incremental tracing; parallel program; program dependence graph; semantic analysis,Computer Programming Languages - C; Computer Systems Programming - Multiprocessing Programs; Mathematical Techniques - Graph Theory; Flowback Analysis; Incremental Tracing; Parallel Programs; PPD System; Semantic Analysis; Computer Programming
A First-Come-First-Served Mutual-Exclusion Algorithm with Small Communication Variables,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976678603&doi=10.1145%2f115372.115370&partnerID=40&md5=e5bf3fcc31185925bf255d7e5bf254f3,"We present an algorithm for the mutual-exclusion problem that satisfies the �first-come-firstserved� property and requires only five shared bits per participant. The algorithm works in a model of concurrency that does not assume atomic operations. © 1991, ACM. All rights reserved.",critical selection; distributed systems; nonatomic operations,
A Fully Abstract Semantics for a First-Order Functional Language with Logic Variables,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976862458&doi=10.1145%2f115372.115371&partnerID=40&md5=f23f80caff26f853f036dc29d584ffa9,[No abstract available],declarative languages; full abstraction; functional languages; logic variables; semantics,
Subtypes and Quantification,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976769391&doi=10.1145%2f115372.214523&partnerID=40&md5=e8af4a223afdf0e4a981f061c6563f4f,[No abstract available],,
Automatic Generation and Use of Abstract Structure Operators,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976853812&doi=10.1145%2f115372.115369&partnerID=40&md5=6afe75c02251137d8375b31f0b12b424,"Structures are those structures definable by parametric and recursive type equations. Manipulation of the instances of such structures is often expressed as recursive functions. These functions can be quite complex and tedious to write, especially for types needed to model complex objects found in many modern applications. We define a set of operators for computing over abstract structures that provide a clean interface with large functionality. These operations have many of the good properties found in the relational algebra such as abstraction, algebraic manipulation, and specification, but operate over a much larger class of values. Concrete definitions of these operators for specific types can be automatically generated as a by-product of type declaration and are thus made available to the user at no programming cost. © 1991, ACM. All rights reserved.",automatic type directed operation generation; classes; reflection,
Efficiently Computing Static Single Assignment form and the Control Dependence Graph,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026243790&doi=10.1145%2f115372.115320&partnerID=40&md5=ea674840749a04a7726e47de43531443,[No abstract available],control dependence; control flow graph; def-use chain; dominator; optimizing compilers,Computer Programming - Algorithms; Computer Software - Optimization; Data Processing - Data Structures; Mathematical Techniques - Graph Theory; Control Dependence Graphs; Control Flow Graphs; Program Optimization; Static Single Assignment Form; Computer Operating Systems
Incremental Attribute Evaluation: A Flexible Algorithm for Lazy Update,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976739714&doi=10.1145%2f117009.117012&partnerID=40&md5=879e4d36efbc90be4380fe90ced3a2b7,"This paper introduces a new algorithm for incremental attribute evaluation. The algorithm is lazy: Itevaluates only theattributes that are both affected byachange andthat are directly or indirectly observable by the user. In this way, the wasted work of computing values that are never actually used is avoided. Although the algorithm is not optimal, it performs better than the standard �optimal� algorithm in cases where expensive but optional computations need to be supported. Furthermore, the algorithm does not have some of the limitations of other algorithms. It works for general attributed graphs as well as for standard attributed trees. In addition, it does not presume any special editing model, and it supports multiple change points without loss of efficiency. © 1991, ACM. All rights reserved.",attribute grammars; incremental attribute evaluation; interactive systems; lazy evaluation,
Collecting Interpretations of Expressions,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976737077&doi=10.1145%2f103135.103139&partnerID=40&md5=4509cdca671b82d7ff525e3e9e65c12b,"A collecting interpretation of expressions is an interpretation of a program that allows one to answer questions of the sort: “What are all possible values to which an expression might evaluate during program execution?” Answering such questions in a denotational framework is akin to traditional data flow analysis and, when used in the context of abstract interpretation, allows one to infer properties that approximate the run-time behavior of expression evaluation. Exact collecting interpretations of expressions are developed for three abstract functional languages: a strict first-order language, a nonstrict first-order language, and a nonstrict higher order language 1991. It is argued that the method is simple (in particular, no powerdomains are needed), Natural (it captures the intuitive operational behavior of a cache), yet more expressive than existing methods (it is the first exact collecting interpretation for either nonstrict higher order languages). Correctness of the interpretations with respect to the standard semantics is shown via a generalization of the notion of strictness. It is further shown how to form abstractions of these exact interpretations, using as an example a collecting strictness analysis which yields compile-time information not previously captured by conventional strictness analyses. © 1991, ACM. All rights reserved.",theory,
Production Trees: A Compact Representation of Parsed Programs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025226377&doi=10.1145%2f77606.77609&partnerID=40&md5=79aa51d12790f8ccaf55c4cfc87288ad,"Abstract syntax trees were devised as a compact alternative to parse trees, because parse trees are known to require excessive amounts of storage to represent parsed programs. However, the savings that abstract syntax trees actually achieve have never been precisely described because the necessary analysis has been missing. Without it, one can only measure particular cases that may not adequately represent all the possible behaviors. We introduce a data structure, production trees, that are more compact than either abstract syntax trees or parse trees. Further, we develop the necessary analysis to characterize the storage requirements of parse trees, abstract syntax trees, and production trees and relate the size of all three to the size of the program's text. The analysis yields the parameters needed to characterize these storage behaviors over their entire range. We flesh out the analysis by measuring these parameters for a sample of “C” programs. For these programs, production trees were from 1/15 to 1/23 the size of the corresponding parse tree, l/2.7 the size of a 1990 abstract syntax tree, and averaged only 2.83 times the size of the program text. © 1990, ACM. All rights reserved.",,Computer Programming; Data Processing - Data Structures; Mathematical Techniques - Trees; Parse Trees; Parsed Programs; Production Trees; Computer Programming Languages
On Iterative Constructs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025209116&doi=10.1145%2f77606.214517&partnerID=40&md5=fb4f42a5afc8cde8ec62542b53536d3b,"The wheel is repeatedly reinvented because it is a good idea. Perhaps Anson's A Generalized Iterative Construct and Its Semantics [1] confirms that “A Generalized Control Structure and Its Formal Definition” [2], and the earlier “An Alternative Control Structure and its Formal Definition” [3] presented good ideas. However, there are several misstatements in [1] that should be corrected. As Anson points out, [2] contained definitions of constructs equivalent to both DO TERM and DO UPON. However, he is incorrect when he suggests that it emphasized DO TERM because of efficiency considerations. By writing “There is a pragmatic justification for either definition! “, I made it clear that that was not the reason for my choice. DO TERM has two, quite different, advantages. 1990 DO TERM is more general. An implementation of DO TERM may, in fact, be DO UPON if desired. Further, a programmer using DO TERM can achieve the effects of DO UPON by choosing his guards accordingly. (b) DO TERM, like Dijkstra's do od, eases the verification of programs by maintaining independence of guarded commands. The verification procedure for such constructs as do od and DO TERM is (1) verify that the union of the guards is true in all states where the program will be invoked; (2) verify that each guarded command, on its own, will do no wrong. For DO UPON the second step is complicated by the need to consider the terminating commands in the list when considering an iterating command. Anson argues that the semantics of DO TERM are more complex. The minor syntactic difference between his two definitions is a consequence of the clumsiness of wp semantics. In the relational semantics used in [2], the change from DO UPON to DO TERM meant the addition of one simple definition. As Mills' [4] has explained, programmers should not be deriving the semantics of their programs from the text as Anson's analysis suggests. We do not write programs arbitrarily and then try to determine their semantics. Instead, programmers should be verifying that the program they have written has the semantics that they set out to achieve. Fortunately, this verification is much easier than the inductive derivation of semantics described in [1]. As explained above, verification is easier for DO TERM than DO UPON. Anson suggests that a stronger weakest-precondition “seems to imply a weaker construct.” On the contrary, DO TERM can describe algorithms that cannot be described with DO UPON. Anson also suggests that in DO TERM termination is more difficult to obtain. Programmers can obtain the behavior that they want in either. With DO TERM the guards may be longer. For those that want to reduce the length of the guards, [2] offered a third alternative, a deterministic construct. This construct forced left-to-right consideration of the commands. This alternative has the verification disadvantages of DO UPON (the guarded command semantics are not independent), but, by putting the terminating commands first, one can achieve everything that Anson values in DO UPON. In fact, with the deterministic construct, one can often achieve guards that are shorter than they would be with DO UPON. DO UPON seems to be a compromise between DO TERM and the deterministic construct, a compromise with some of the disadvantages of both extremes and the advantages of neither. Anson has not provided the full semantics of the constructs in question. It has been known for many years (e.g., Majster [5]) that wp alone does not define the semantics of a program. Two programs with the same wp can differ in their behavior in important ways. To provide a complete semantics of the constructs one must define both wp and wlp. That was one of the reasons for using a relational semantics in [2] and [3]. When I wrote [2] I deliberately chose DO TERM over DO UPON because I felt that the simplicity of verification compensated for the longer guards. I also valued the ability to describe the algorithms that cannot be described with DO UPON. I continue to prefer the syntax used in [2]. I believe that readers who consider the facts above will make the same choice. The discussion of these issues is made a bit academic by the four-year delay between Anson's submission of his paper (which apparently coincided with the publication of [2]) and the publication of [1]. In that time a generalization of both schemes has been published as a Technical Report [6] and has been submitted for publication. In this generalization the decision about whether a command is iterating or terminating can be made during execution, and the semantics must be that of DO TERM. Further generalizations make the seman tics of the constructs more practical, since side-effects are accurately treated in all cases. A method for reducing the length of guards and avoiding duplicated subexpressions is also provided. © 1990, ACM. All rights reserved.",,Iterative Constructs; Computer Programming Languages
A Modular Technique for the Design of Efficient Distributed Leader Finding Algorithms,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025209115&doi=10.1145%2f77606.77610&partnerID=40&md5=14876f45071bfdc7b157fcbb9f4cc260,"A general, modular technique for designing efficient leader finding algorithms in distributed, asynchronous networks is developed. This technique reduces the problem of efficient leader finding to a simpler problem of efficient serial traversing of the corresponding network. The message complexity of the resulting leader finding algorithms is bounded by [f1990 + n)(log2k + 1) (or (f(m) + n)(log2k + 1)], where n is the number of nodes in the network [m is the number of edges in the network], k is the number of nodes that start the algorithm, and f (n) [f(m)] is the message complexity of traversing the nodes [edges] of the network. The time complexity of these algorithms may be as large as their message complexity. This technique does not require that the FIFO discipline is obeyed by the links. The local memory needed for each node, besides the memory needed for the traversal algorithm, is logarithmic in the maximal identity of a node in the network. This result achieves in a unified way the best known upper bounds on the message complexity of leader finding algorithms for circular, complete, and general networks. It is also shown to be applicable to other classes of networks, and in some cases the message complexity of the resulting algorithms is better by a constant factor than that of previously known algorithms. © 1990, ACM. All rights reserved.",Algorithms; Asynchronous leader election; Design; modularity; optimal message complexity; traversal algorithms,"Computer Systems, Digital - Distributed; Algorithm Design; Distributed Algorithms; Leader Finding Algorithms; Traversal Algorithms; Computer Programming"
An Ad Hoc Approach to the Implementation of Polymorphism,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976655200&doi=10.1145%2f117009.117017&partnerID=40&md5=373c20bb2675f4ac20f2ec8d8cca131e,[No abstract available],,
An Improved Storage Management Scheme for Block Structured Languages,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976693169&doi=10.1145%2f117009.117016&partnerID=40&md5=e2de1b1ae7ad832ec291645f412757f3,"The conventional storage allocation scheme for block structured languages requires the allocation of stack space and the building of a dmplay with each procedure call. Several techniques have been proposed for analyzing the call graph of a program that make it possible to eliminate these operations from many call sequences. In this paper. we compare these techniques and propose an improved allocation scheme which can substantially reduce allocation overhead, even in the presence of recursion and support for separate compilation. © 1991, ACM. All rights reserved.",activation records; call graphs; internal analysis; procedure call overhead,
Practical Adaption of the Global Optimization Algorithm of Morel and Renvoise,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976800698&doi=10.1145%2f103135.214520&partnerID=40&md5=0bfd3abb9182e91b9abd9091249a3c67,[No abstract available],,
Dynamic Typing in a Statically Typed Language,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976752728&doi=10.1145%2f103135.103138&partnerID=40&md5=f8f8656e8ac278635e772d03fb2cf3eb,"Statically typed programming languages allow earlier errorchecking, better enforcement of diciplined programming styles, and thegeneration of more efficient object code than languages where all typeconsistency checks are performed at run time. However, even instatically typed languages, there is often the need to deal with datawhose type cannot be determined at compile time. To handlesuch situations safely, we propose to add a typeDynamic whose values are pairs of a valuev and a type tagT where vhas the type denoted by T. Instances ofDynamic are built with an explicittagging construct and inspected with a type safetypecase construct. This paper explores the syntax, operational semantics, and denotational semantics of a simple language that includes the typeDynamic. We give examples of howdynamically typed values can be used in programming. Then we discuss anoperational semantics for our language and obtain a soundness theorem. Wepresent two formulations of the denotational semantics of this languageand relate them to the operational semantics. Finally, we consider theimplications of polymorphism and some implementation issues. © 1991, ACM. All rights reserved.",theory,
INC: A Language for Incremental Computations,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976799337&doi=10.1145%2f103135.103137&partnerID=40&md5=97281c0a50ac3de13f1e7929cd0689d1,"An incremental computation is one that is performed repeatedly on nearly identical inputs. Incremental computations occur naturally in many environments, such as compilers, language-based editors, spreadsheets, and formatters. This article describes a proposed tool for making it easy to write incremental programs. The tool consists of a programming language, INC, and a set of compile-time transformations for the primitive elements of INC. A programmer defines an algorithm in INC without regard to efficient incremental execution. The transformations automatically convert this algorithm into an efficient incremental algorithm. INC is a functional language. The implementation of an INC program is a network of processes. Each INC function is transformed into a process that receives and transmits messages describing changes to its inputs and outputs. We give an overview to the language and illustrate the incremental techniques employed by INC. We present the static and incremental complexity bounds for the primitive INC functions. We also present some example programs illustrating INC's flexibility. © 1991, ACM. All rights reserved.",dynamic algorithms; finite differencing; incremental complexity; incrementality; static complexity,
Wait-Free Synchronization,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025917643&doi=10.1145%2f114005.102808&partnerID=40&md5=0cdc1e97a8b98d4b58d38aa83546d90e,"A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes. The problem of constructing a wait-free implementation of one data object from another lies at the heart of much recent work in concurrent algorithms, concurrent data structures, and multiprocessor architectures. First, we introduce a simple and general technique, based on reduction to a concensus protocol, for proving statements of the form, “there is no wait-free implementation of X by Y.” We derive a hierarchy of objects such that no object at one level has a wait-free implementation in terms of objects at lower levels. In particular, we show that atomic read/write registers, which have been the focus of much recent attention, are at the bottom of the hierarchy: thay cannot be used to construct wait-free implementations of many simple and familiar data types. Moreover, classical synchronization primitives such astest&set and fetch&add, while more powerful than read and write, are also computationally weak, as are the standard message-passing primitives. Second, nevertheless, we show that there do exist simple universal objects from which one can construct a wait-free implementation of any sequential object. © 1991, ACM. All rights reserved.",linearization; wait-free synchronization,"Automata Theory; Computer Operating Systems; Computer Programming Languages; Computer Systems, Digital - Multiprocessing; Computer operating systems; Computer programming languages; Data structures; Abstract Data Types; Atomic Read/Write Registers; Concurrent Programming; Mutual Exclusion; Wait-Free Synchronization; abstract data types; Concurrent programming; Mutual execlusion; Computer Programming; Computer systems programming"
"The Concurrent Language, Shared Prolog",1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025917644&doi=10.1145%2f114005.102807&partnerID=40&md5=50ddecedafc9bddd9cd80a47114ca38d,"Shared Prolog is a new concurrent logic language. A Shared Prolog system is composed of a set of parallel agents that are Prolog programs extended by a guard mechanism. The programmer controls the granularity of parallelism, coordinating communication and synchronization of the agents via a centralized data structure. The communication mechanism is inherited from the blackboard model of problem solving. Intuitively, the granularity of the logic processes to be elaborated in parallel is large, while the resources shared on the blackboard can be very fined grained. An operational semantics for Shared Prolog is given in terms of a distributed model. Through an abstract notion of computation, the kinds of parallelism supported by the language, as well as properties of infinite computations, such as local deadlocks, are studied. The expressiveness of the language is shown with respect to the specification of two classes of applications: metaprogramming and blackboard systems. © 1991, ACM. All rights reserved.",blackboard; distributed programming; languages for distributed programming; logic programming; metainterpretation; parallel programming; transition systems,Computer Programming Languages - PROLOG; Logic programming; Parallel processing systems; PROLOG (programming language); Concurrent Language; Distributed Programming; Metainterpretation; Operational Semantics; Shared Prolog; Computational models; Concurrent programming; Shared PROLOG; Computer Programming; Computer systems programming
Efficient Construction of LR(k) States and Tables,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025917645&doi=10.1145%2f114005.102809&partnerID=40&md5=3d084b25d13f0ed3c0bfa5bae0daf9d2,"A new method for building LR1991 states and parsing tables is presented. The method aims at giving a feasible construction of a collection of LR(k) parsing tables, especially when k > 1. for nontrivial grammars. To this purpose, the algorithm first attempts to build a set of normal states for the given grammar, each one associated to a single parsing action in {accept, reduce, shift}. When such an action cannot be uniquely determined, that is, when up to k input symbols have to be examined (inadequacy), further states, belonging to a new type, called look-ahead states, are computed. The action associated with inadequate states is a new parsing action, look. States are built without actual computation of the FIRSTk and EFFk functions; that is, nonterminals are kept in the context string of items composing each state, and their expansion to terminals is deferred until indispensable to solve inadequacy. The aforementioned method is illustrated; then the canonical collection of states and the canonical tables are compared with those obtained from the proposed method. A sufficient condition is stated, by which the size of parsing tables, obtained by applying this new method, is smaller than that of canonical tables. Experimental results show that such a condition is verified by the grammars of several programming languagues and that significant speed is gained by avoiding the computation of the FIRSTk function. © 1991, ACM. All rights reserved.",LR(k) grammars; parsing tables; set of items,Automata Theory - Formal Languages; Computer Operating Systems - Program Compilers; Algorithms; Computational grammars; Program compilers; Compiler Generators; LR(k) Grammars; Mathematical Logic; Parsing Tables; Translator Writing Systems; Compiler generators; Computer Programming Languages; Computer programming languages
Linking Programs Incrementally,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025917646&doi=10.1145%2f114005.102804&partnerID=40&md5=f73a94d77b481ca6d2603c4886ff0ab0,"Linking is traditionally a batch process that resolves cross-references between object modules and run-time libraries to produce a stand-alone executable image. Because most program changes only involve a small part of the program, we have implemented an incremental linker, named Inclink, that processes only the changed modules. Inclink generates a new executable in time proportional to the size of change; in contrast, a batch linker generates an executable in time proporitonal to the size of the program. To minimize updates to the executable, Inclink allocates extra space for every module. By allocating 24 percent more space in the executable for overflows, Inclink can update a module in place over 97 percent of the time. Measurements show that Inclink is more than an order of magnitude faster than the UNIX [2] batch linker and that 88 percent of all links will take less than 2 s of CPU time on a MicroVAX-2, independent of program size. © 1991, ACM. All rights reserved.",Algorithms Measurement; Incremental linking; Performance; programming tools; turnaround time,Computer Programming Languages; Computer Software - Software Engineering; Data Processing - Batch Processing; Algorithms; Computer operating systems; Computer programming languages; Performance; Batch Linking; Incremental Linking; Turnaround Time; UNIX Linker; Incremental linking; Computer Operating Systems; Software engineering
Automatic Transformation of Series Expressions into Loops,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025917647&doi=10.1145%2f114005.102806&partnerID=40&md5=daf836f734d0b23cfdb45508f5b4c2a4,"The benefits of programming in a functional style are well known. In particular, algorithms that are expressed as compositions of functions operating on sequences/vectors/streams of data elements are easier to understand and modify than equivalent algorithms expressed as loops. Unfortunately, this kind of expression is not used anywhere near as often as it could be, for at least three reasons: 1991 most programmers are less familiar with this kind of expression than with loops; (2) most programming languages provide poor support for this kind of expression; and (3) when support is provided, it is seldom effcient. In any programming language, the second and third problems can be largely solved by introducing a data type called series, a comprehensive set of procedures operating on series, and a preprocessor (or compiler extension) that automatically converts most series expressions into efficient loops. A set of restrictions specifies which series expressions can be optimized. If programmers stay within the limits imposed, they are guaranteed of high efficiency at all times. A common Lisp macro package supporting series has been in use for some time. A prototype demonnstrates that series can be straightforwardly supported in Pascal. © 1991, ACM. All rights reserved.",sequences; series; streams; vectors,Artificial Intelligence; Computer Programming Languages; Data Processing - Data Structures; Artificial intelligence; Data structures; Pascal (programming language); Automatic Programming; Functional Programming; Implicit Mapping; Language Constructs; Program Transformation; Automatic programming; Functional programming; Computer Programming; Computer programming
Table Compression for Tree Automata,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976692331&doi=10.1145%2f117009.117013&partnerID=40&md5=019058bc4b98a8dfb4b8c1052bacc76d,[No abstract available],sparse tables; table compression; tree automata,
Interprocedural Slicing Using Dependence Graphs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025228221&doi=10.1145%2f77606.77608&partnerID=40&md5=2cc6725ec22ef14168064e3eecd28d21,"The notion of a program slice, originally introduced by Mark Weiser, is useful in program debugging, automatic parallelization, and program integration. A slice of a program is taken with respect to a program point p and a variable x; the slice consists of all statements of the program that might affect the value of x at point p. This paper concerns the problem of interprocedural slicing—generating a slice of an entire program, where the slice crosses the boundaries of procedure calls. To solve this problem, we introduce a new kind of graph to represent programs, called a system dependence graph, which extends previous dependence representations to incorporate collections of procedures 1990 rather than just monolithic programs. Our main result is an algorithm for interprocedural slicing that uses the new representation. (It should be noted that our work concerns a somewhat restricted kind of slice: rather than permitting a program to be sliced with respect to program point p and an arbitrary variable, a slice must be taken with respect to a variable that is defined or used at p.) The chief difficulty in interprocedural slicing is correctly accounting for the calling context of a called procedure. To handle this problem, system dependence graphs include some data dependence edges that represent transitive dependences due to the effects of procedure calls, in addition to the conventional direct-dependence edges. These edges are constructed with the aid of an auxiliary structure that represents calling and parameter-linkage relationships. This structure takes the form of an attribute grammar. The step of computing the required transitive-dependence edges is reduced to the construction of the subordinate characteristic graphs for the grammar's nonterminals. © 1990, ACM. All rights reserved.",,Computer Programming - Algorithms; Mathematical Techniques - Graph Theory; Dependence Graphs; Interprocedural Slicing; Procedure Calls; Computer Programming Languages
Compilation of Functional Languages by Program Transformation,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025717644&doi=10.1145%2f114005.102805&partnerID=40&md5=b49994b2f3a6688c565cf13d650db5ad,"One of the most important issues concerning functional languages is the efficiency and the correctness of their implementation. We focus on sequential implementations for conventional von Neumann computers. The compilation process is described in terms of program transformations in the functional framework. The original functional expression is transformed into a functional term that can be seen as a traditional machine code. The two main steps are the compilation of the computation rule by the introduction of continuation functions and the compilation of the environment management using combinators. The advantage of this approach is that we do not have to introduce an abstract machine, which makes correctness proofs much simpler. As far as efficiency is concerned, this approach is promising since many optimizations can be described and formally justified in the functional framework. © 1991, ACM. All rights reserved.",combinators; continuations; program transformation,Computer Operating Systems - Program Compilers; Computer Programming Languages; Optimization; Program compilers; Software engineering; Functional Languages; Functional Programming; Program Transformation; Program Verification; Functional programming; Program transformation; Computer Programming; Computer programming
A Correctness Proof for Combinator Reduction with Cycles,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025207710&doi=10.1145%2f77606.77612&partnerID=40&md5=0cb329bd373fd17fc64299863f86d953,"Turner popularized a technique of Wadsworth in which a cyclic graph rewriting rule is used to implement reduction of the fixed point combinator Y. We examine the theoretical foundation of this approach. Previous work has concentrated on proving that graph methods are, in a certain sense, sound and complete implementations of term methods. This work is inapplicable to the cyclic Y rule, which is unsound in this sense since graph normal forms can exist without corresponding term normal forms. We define and prove the correctness of combinator head reduction using the cyclic Y rule; the correctness of normal reduction is an immediate consequence. Our proof avoids the use of infinite trees to explain cyclic graphs. Instead, we show how to consider reduction with cycles as an optimization of reduction without cycles. © 1990, ACM. All rights reserved.",,Mathematical Techniques - Graph Theory; Combinator Reduction; Correctness Proofs; Cyclic Graphs; Functional Programming Languages; Graph Reduction; Term Rewriting Systems; Computer Programming Languages
Type Extension Through Polymorphism,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025207711&doi=10.1145%2f77606.214515&partnerID=40&md5=4ad25db3fb2530c6d637c09fd569f709,"A record data type can be extended by addition of more fields. The extended type is a subtype of the original, in that any value of the extended type can be regarded as a value of the original type by ignoring the additional fields. This results in a type hierarchy. Milner [3] has proposed a polymorphic type system. With the Milner approach, the type of a function may contain type variables. This also results in a type hierarchy. In a language with a polymorphic type system, if it is anticipated that a record type will need to be extended, then the record type can be defined to have a dummy extension field. In the parent type, the extension field will have null contents of type void. The type of the extension field can differ with different subtypes. The approach can be extended to allow a type to be subtype of two or more parent types. To a limited extent, this approach can be used in Ada and other languages with generic program units. © 1990, ACM. All rights reserved.",,Data Types; Polymorphism; Type Extension; Computer Programming Languages
Constant Propagation with Conditional Branches,1991,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976709672&doi=10.1145%2f103135.103136&partnerID=40&md5=0ecd97c40841d018548730bd52c018cc,"Constant propagation is a well-known global flow analysis problem. The goal of constant propagation is to discover values that are constant on all possible executions of a program and to propagate these constant values as far foward through the program as possible. Expressions whose operands are all constants can be evaluated at compile time and the results propagated further. Using the algorithms presented in this paper can produce smaller and faster compiled programs. The same algorithms can be used for other kinds of analyses 1991. We present four algorithms in this paper, all conservitive in the sense that all constants may not be found, but each constant found is constant over all possible executions of the program. These algorithms are among the simplest, fastest, and most powerful global constant propagation algorithms known. We also present a new algorithm that performs a form of interprocedural data flow analysis in which aliasing information is gathered in conjunction with constant progagation. Several variants of this algorithm are considered. © 1991, ACM. All rights reserved.",abstract interpretation; code optimization; constant propagation; control flow graph; interprocedural analysis; procedure integration; static single assignment form; type determination,
A Mechanism for Environment Integration,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025235571&doi=10.1145%2f77606.77607&partnerID=40&md5=c37ed0b9883d44416c49f5707b0b6fe8,"This paper describes research associated with the development and evaluation of Odin-an environment integration system based on the idea that tools should be integrated around a centralized store of persistent software objects. The paper describes this idea in detail and then presents the Odin architecture, which features such notions as the typing of software objects, composing tools out of modular tool fragments, optimizing the storage and rederivation of software objects, and isolating tool interconnectivity information in a single centralized object. The paper then describes some projects that have used Odin to integrate tools on a large scale. Finally, it discusses the significance of this work and the conclusions that can be drawn about superior software environment architectures. © 1990, ACM. All rights reserved.",Environment integration; Experimentation; Languages; persistent objects; software object management,Computer Programming; Object Oriented Programming; Odin; Software Development Environments; Software Object Management; Software Tools; Computer Software
A Distributed Deadlock Detection Algorithm for CSP-Like Communication,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025225133&doi=10.1145%2f77606.77611&partnerID=40&md5=5be3302e5398e0e410ee77e6cf176405,"An algorithm for detecting deadlocks in distributed systems with CSP-like communication is proposed. Unlike previous work, the proposed algorithm avoids periodically sending deadlock-detecting messages by the processes and requires no local storage for the processes with size predetermined by the number of processes in the system. The algorithm is proven to have the following properties: 1990 it never detects false deadlocks; (1) it has only one process in a knot report the deadlock; and (2) it detects every true deadlock in finite time. © 1990, ACM. All rights reserved.",,"Computer Programming - Algorithms; Mathematical Techniques - Graph Theory; Communicating Sequential Processes; Communication Deadlock; CSP; Deadlock Detection Algorithms; Distributed Deadlock Detection; Knot Detection; Computer Systems, Digital"
An Interval-Based Approach to Exhaustive and Incremental Interprocedural Data-Flow Analysis,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025461033&doi=10.1145%2f78969.78963&partnerID=40&md5=c58bc953ce6952fb8d83a8c965db634a,"We reformulate interval analysis so that it can he applied to any monotone data-flow problem, including the nonfast problems of flow-insensitive interprocedural analysis. We then develop an incremental interval analysis technique that can be applied to the same class of problems. When applied to flow-insensitive interprocedural data-flow problems, the resulting algorithms are simple, practical, and efficient. With a single update, the incremental algorithm can accommodate any sequence of program changes that does not alter the structure of the program call graph. It can also accommodate a large class of structural changes. For alias analysis, we develop an incremental algorithm that obtains the exact solution as computed by an exhaustive algorithm. Finally, we develop a transitive closure algorithm that is particularly well suited to the very sparse matrices associated with the problems we address. © 1990, ACM. All rights reserved.",,Mathematical Techniques--Graph Theory; Data Flow Problems; Interval Analysis; Sparse Matrices; Computer Programming
win and sin: Predicate Transformers for Concurrency,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025460470&doi=10.1145%2f78969.78970&partnerID=40&md5=27dfaadca92d9a99b6acb482b6476b67,"The weakest liberal precondition and strongest postcondition predicate transformers are generalized to the weakest invariant and strongest invariant. These new predicate transformers are useful for reasoning about concurrent programs containing operations in which the grain of atomicity is unspecified. They can also be used to replace behavioral arguments with more rigorous assertional ones. © 1990, ACM. All rights reserved.",,Computer Programming--Theory; Concurrent Programming; Predicate Transformers; Computer Metatheory
The Priority-Based Coloring Approach to Register Allocation,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025505849&doi=10.1145%2f88616.88621&partnerID=40&md5=6e322d3dce8f6a2cdd7029f1c47fa4e6,"Global register allocation plays a major role in determining the efficacy of an optimizing compiler. Graph coloring has been used as the central paradigm for register allocation in modern compilers. A straightforward coloring approach can suffer from several shortcomings. These shortcomings are addressed in this paper by coloring the graph using a priority ordering. A natural method for dealing with the spilling emerges from this approach. The detailed algorithms for a priority-based coloring approach are presented and are contrasted with the basic graph-coloring algorithm. Various extensions to the basic algorithms are also presented. Measurements of large programs are used to determine the effectiveness of the algorithm and its extensions, as well as the causes of an imperfect allocation. Running time of the allocator and the impact of heuristics aimed at reducing that time are also measured. © 1990, ACM. All rights reserved.",,Computer Programming - Algorithms; Mathematical Techniques - Graph Theory; Graph Coloring; Optimizing Compilers; Register Allocation; Computer Operating Systems
Using Symbolic Execution for Verification of Ada Tasking Programs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025505206&doi=10.1145%2f88616.96551&partnerID=40&md5=48a00d72395a27a3d0d0bf9e36efdefe,"A method is presented for using symbolic execution to generate the verification conditions required for proving correctness of programs written in a tasking subset of Ada. The symbolic execution rules are derived from proof systems that allow tasks to be verified independently in local proofs, which are then checked for cooperation. The isolation nature of this approach to symbolic execution of concurrent programs makes it better suited to formal verification than the more traditional interleaving approach, which suffers from combinatorial problems. The criteria for correct operation of a concurrent program include partial correctness, as well as more general safety properties, such as mutual exclusion and freedom from deadlock. © 1990, ACM. All rights reserved.",,Computer Programming; Ada Tasking Programs; Program Correctness; Software Verification; Symbolic Execution; Computer Programming Languages
Linearizability: A Correctness Condition for Concurrent Objects,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025460579&doi=10.1145%2f78969.78972&partnerID=40&md5=ae620ad8bf3812a3a82401ac19183313,"A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable. © 1990, ACM. All rights reserved.",,Computer Metatheory--Programming Theory; Concurrent Objects; Linearizability; Computer Programming
An Exercise in the Formal Derivation of Parallel Programs: Maximum Flows in Graphs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025416412&doi=10.1145%2f78942.78945&partnerID=40&md5=9e78086c4e62dbfa25da4af38dcd4013,"We apply a new method for the development of parallel programs to the problem of finding maximum flows in graphs. The method facilitates concurrent program design by separating the concerns of correctness from those of hardware and implementation. It uses predicate transformer semantics to define a set of basic operators for the specification and verification of programs. From an initial specification program development proceeds by a series of refinement steps, each of which constitutes a strengthening of the specification of the previous refinement. The method is completely formal in the sense that all reasoning steps are performed within predicate calculus. A program is viewed as a mathematical object enjoying certain properties, rather than in terms of its possible executions. We demonstrate the usefulness of the approach by deriving an efficient algorithm for the Maximum Flow Problem in a top-down manner. © 1990, ACM. All rights reserved.",,"Computer Systems, Digital - Parallel Processing; Mathematical Techniques - Graph Theory; Distributed Algorithms; Maximum Flow Problem; Parallel Algorithms; Stepwise Refinement; Computer Programming"
An Approach to Support Automatic Generation of User Interfaces,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025505629&doi=10.1145%2f88616.214518&partnerID=40&md5=02afaca129f87b8714f2ab35b4427fe4,"In traditional interactive programming environments, each application individually manages its interaction with the human user. The result is duplication of effort in implementing user interface code and nonuniform—hence confusing—input conventions. This paper presents an approach to support automatic generation of user interfaces in environments based on algebraic languages. The approach supports the editing model of interaction, which allows a user to view all applications as data that can be edited. An application interacts with a user by submitting variables 1990 to a dialogue manager, which displays their presentations to the user and offers type-directed editing of these presentations. Applications and dialogue managers communicate through a protocol that allows a presentation to be kept consistent with the variable it displays. A particular implementation of the approach, called Dost, has been constructed for the Xerox development environment and the Mesa programming language. Dost is used as a concrete example to describe the editing model, the primitives to support it, and our preliminary experience with these primitives. The approach is compared with related work, its shortcomings are discussed, and suggestions for future work are made. © 1990, ACM. All rights reserved.",,"Computer Interfaces; Automatic Interface Generation; User Interfaces; Computer Systems, Digital"
Adding Liveness Properties to Coupled Finite-State Machines,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025418560&doi=10.1145%2f78942.78948&partnerID=40&md5=ac94bac58481a8db3d5642987c6383ed,"Informal specifications of protocols are often imprecise and incomplete and are usually not sufficient to ensure the correctness of even very simple protocols. Consequently, formal specification methods, such as finite-state models, are increasingly being used. The selection/resolution 1990 model is a finite-state model with a powerful communication mechanism that makes it easy to describe complex protocols as a collection of simple finite-state machines. A software environment, called SPANNER, has been developed to specify and analyze protocols specified with the S/R model. SPANNER provides the facility to compute the joint behavior of a number of finite-state machines and to check if the “product” machine has inaccessible states, states corresponding to deadlocks, and loops corresponding to livelocks. So far, however, SPANNER has had no facility to systematically deal with liveness conditions. For example, one might wish to specify that, although a communication channel is unreliable, a message will get through if it is sent infinitely often, and to check that the infinite behavior of the protocol viewed as an infinite sequence will always be in some ω-regular set (possibly specified in terms of a formula in temporal logic or as an ω-automata). In this paper we show that with very minor modifications to the implemented system it is possible to substantially extend the type of properties that can be specified and checked by SPANNER. This is done by extending the S/R model to include acceptance conditions found in automatons on infinite words, which permits the incorporation of arbitrary liveness conditions into the model. We show how these extensions can be easily incorporated into SPANNER (and into essentially any finite-state verification system) and how the resulting system is used to automatically verify the correctness of protocols. © 1990, ACM. All rights reserved.",,Automata Theory - Finite Automata; Liveness; Protocols; Selection/Resolution Model; SPANNER Software Environment; Computer Software
On Kilbury's Modification of Earley's Algorithm,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025508880&doi=10.1145%2f88616.88637&partnerID=40&md5=16f5bd6e250889db0427bcabc2a3cfcc,"We improve on J. Kilbury's proposal to interchange “predictor” and “scanner” in Earley's parser. This modification of Earley's parser can trivially be combined with those suggested by S. Graham, M. Harrison, and W. Ruzzo, leading to smaller parse tables and almost the power of lookahead 1. Along these lines we can also obtain Earley-parsers having partial lookahead r ≥ 1, without storing right contexts. Parse trees with shared structure can be stored in the parse tables directly, rather than constructing the trees from “dotted rules.”. © 1990, ACM. All rights reserved.",,Mathematical Techniques - Trees; Parse Tables; Parse Trees; Computer Programming
A method for Specializing Logic Programs,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025414487&doi=10.1145%2f78942.78947&partnerID=40&md5=0fc2eb9e608aca1261eec7797717965a,"A specialization method for logic programs that allows one to restrict a general program to special cases by means of constraint predicates is presented. A set of basic transformation operations, which are shown to produce equivalent programs, is defined. The method uses these operations for propagating the constraint information through the program and for consequently simplifying it whenever possible. Some examples of specializations are given, and some improvements and developments of the method are discussed. © 1990, ACM. All rights reserved.",,Artificial Intelligence; Automatic Programming; Logic Programs; Program Transformation; Transformation Programming; Computer Programming
"Creating User Interfaces Using Programming by Example, Visual Programming, and Constraints",1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025419788&doi=10.1145%2f78942.78943&partnerID=40&md5=97054a836dfebb38869dd38ed416c507,"Peridot is an experimental tool that allows designers to create user interface components without conventional programming. The designer draws pictures of what the interface should look like and then uses the mouse and other input devices to demonstrate how the interface should operate. Peridot generalizes from these example pictures and actions to create parameterized procedures, such as those found in conventional user interface libraries such as the Macintosh Toolbox. Peridot uses visual programming, programming by example, constraints, and plausible inferencing to allow nonprogrammers to create menus, buttons, scroll bars, and many other interaction techniques easily and quickly. Peridot created its own interface and can create almost all of the interaction techniques in the Macintosh Toolbox. Therefore, Peridot demonstrates that it is possible to provide sophisticated programming capabilities to nonprogrammers in an easy-to-use manner and still have sufficient power to generate interesting and useful programs. © 1990, ACM. All rights reserved.",,Computer Graphics; Computer Interfaces; Peridot; Programming by Example; User Interfaces; Visual Programming; Computer Programming
Search Direction by Goal Failure in Goal-Oriented Programming,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025416279&doi=10.1145%2f78942.78946&partnerID=40&md5=c5bbb50da5f830be9a5c87a5a4e9442d,"A new approach to goal-oriented programming is described, whereby the search for values of variables to satisfy a goal is invariably directed by that goal or by information provided by its failure. This goal-directed approach is in contrast to that employed by logic programming systems, which attempt to satisfy a goal that has failed by resatisfying an already tested goal, and which furthermore do this in a way determined solely by the order of facts and rules in the database and without reference to the goal that has failed. Proposed changes in the control structure of logic programs designed to improve their execution serve more to reduce the search space than to add goal direction. A goal-directed language that embodies the new approach is presented. It is at the same time a functional programming language and a specification interpreter for the direct execution and testing of functional specifications, and permits the user to write executable program descriptions in which some of the constituent functions are fully defined while others are “merely” specified. The language has been successfully tested on examples drawn from such fields as deductive question answering and problem solving, where it compares favorably with the logic programming languages. © 1990, ACM. All rights reserved.",,Computer Programming; Goal Directed Programming; Goal Oriented Programming; Search Methods; Computer Programming Languages
A Comparative Evaluation of Object Definition Techniques for Large Prototype Systems,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025507334&doi=10.1145%2f88616.88639&partnerID=40&md5=35355b2415ce2e3b1e6e54e1bbb0fa9e,"Although prototyping has long been touted as a potentially valuable software engineering activity, it has never achieved widespread use by developers of large-scale, production software. This is probably due in part to an incompatibility between the languages and tools traditionally available for prototyping 1990 and the needs of large-scale-software developers, who must construct and experiment with large prototypes. The recent surge of interest in applying prototyping to the development of large-scale, production software will necessitate improved prototyping languages and tools appropriate for constructing and experimenting with large, complex prototype systems. We explore techniques aimed at one central aspect of prototyping that we feel is especially significant for large prototypes, namely that aspect concerned with the definition of data objects. We characterize and compare various techniques that might be useful in defining data objects in large prototypesystems, after first discussing some distinguishing characteristics of large prototype systems and identifying some requirements that they imply. To make the discussion more concrete, we describe our implementations of three techniques that represent different possibilities within the range of object definition techniques for large prototype systems. © 1990, ACM. All rights reserved.",,Computer Programming - Object Oriented Programming; Software Prototyping; Computer Software
Linguistic Support for Atomic Data Types,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025413853&doi=10.1145%2f78942.78944&partnerID=40&md5=f37413db1d105453fb34086687d8a475,"The problems of concurrency and failures in distributed systems can be addressed by implementing applications in terms of atomic data types: data types whose objects provide serializability and recoverability for transactions using them. The specifications of the types can be used to permit high levels of concurrency among transactions while still ensuring atomicity. However, highly concurrent implementations can be quite complicated. In this paper we analyze the expressive power of existing proposals for language features intended to support the implementation of atomic types. We illustrate several limitations of existing proposals and propose a new approach that avoids these problems. © 1990, ACM. All rights reserved.",,"Computer Systems, Digital - Distributed; Database Systems - Distributed; Atomic Data Types; Concurrency; Linguistic Support; Serializability; Computer Programming Languages"
Remote Evaluation,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025505149&doi=10.1145%2f88616.88631&partnerID=40&md5=36e4bb24fa194703562d686bb260289e,"A new technique for computer-to-computer communication is presented that can increase the performance of distributed systems. This technique, called remote evaluation, lets one computer send another computer a request in the form of a program. A computer that receives such a request executes the program in the request and returns the results to the sending computer. Remote evaluation provides a new degree of flexibility in the design of distributed systems. In present distributed systems that use remote procedure calls, server computers are designed to offer a fixed set of services. In a system that uses remote evaluation, server computers are more properly viewed as programmable processors. One consequence of this flexibility is that remote evaluation can reduce the amount of communication that is required to accomplish a given task. In this paper we discuss the semantics of remote evaluation and its effect on distributed system design. We also summarize our experience with a prototype implementation. © 1990, ACM. All rights reserved.",,"Computer Programming Languages; Computers - Data Communication Systems; Data Processing - Security of Data; Message Passing; Remote Evaluation; Remote Procedure Calls; Computer Systems, Digital"
Efficient Evaluation of Circular Attribute Grammars,1990,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025463242&doi=10.1145%2f78969.78971&partnerID=40&md5=f3e3a35b8b73d75ed4ebde058c561c6a,"We present efficient algorithms for exhaustive and incremental evaluation of circular attributes under any conditions that guarantee finite convergence. The algorithms are derived from those for noncircular attribute grammars by partitioning the underlying attribute dependency graph into its strongly connected components and by ordering the evaluations to follow a topological sort of the resulting directed acyclic graph. The algorithms are efficient in the sense that their worst-case running time is proportional to the cost of computing the fixed points of only those strongly connected components containing affected attributes or attributes directly dependent on affected attributes. When the attribute grammar is noncircular or the specific dependency graph under consideration is acyclic, both algorithms reduce to the standard optimal algorithms for noncircular attribute evaluation. © 1990, ACM. All rights reserved.",,Computer Programming--Algorithms; Mathematical Techniques--Graph Theory; Attribute Grammars; Circular Attribute Grammars; Directed Acyclic Graphs; Incremental Attribute Evaluation; Automata Theory
Efficient Implementation of the First-Fit Strategy for Dynamic Storage Allocation,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024700241&doi=10.1145%2f65979.65981&partnerID=40&md5=e956bf5f44890e58a00d91d00025a44d,"We describe an algorithm that efficiently implements the first-fit strategy for dynamic storage allocation. The algorithm imposes a storage overhead of only one word per allocated block (plus a few percent of the total space used for dynamic storage), and the time required to allocate or free a block is O(log W), where W is the maximum number of words allocated dynamically. The algorithm is faster than many commonly used algorithms, especially when many small blocks are allocated, and has good worst-case behavior. It is relatively easy to implement and could be used internally by an operating system or to provide run-time support for high-level languages such as Pascal and Ada. A Pascal implementation is given in the Appendix. © 1989, ACM. All rights reserved.",Dispose; dynamic memory management; dynamic storage allocation; first-fit strategy; heaps; new; trees,Computer Programming--Algorithms; Dynamic Storage Allocation; First-Fit Strategy; Performance Modeling; Computer Operating Systems
Integrating Noninterfering Versions of Programs,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024700474&doi=10.1145%2f65979.65980&partnerID=40&md5=9f80ad5b5d30f19a0f649a2d779049e6,"The need to integrate several versions of a program into a common one arises frequently, but it is a tedious and time consuming task to integrate programs by hand. To date, the only available tools for assisting with program integration are variants of text-based differential file comparators; these are of limited utility because one has no guarantees about how the program that is the product of an integration behaves compared to the programs that were integrated. This paper concerns the design of a semantics-based tool for automatically integrating program versions. The main contribution of the paper is an algorithm that takes as input three programs A, B, and Base, where A and B are two variants of Base. Whenever the changes made to Base to create A and B do not “interfere” (in a sense defined in the paper), the algorithm produces a program M that integrates A and B. The algorithm is predicated on the assumption that differences in the behavior of the variant programs from that of Base, rather than differences in the text, are significant and must be preserved in M. Although it is undecidable whether a program modification actually leads to such a difference, it is possible to determine a safe approximation by comparing each of the variants with Base. To determine this information, the integration algorithm employs a program representation that is similar (although not identical) to the dependence graphs that have been used previously in vectorizing and parallelizing compilers. The algorithm also makes use of the notion of a program slice to find just those statements of a program that determine the values of potentially affected variables. The program-integration problem has not been formalized previously. It should be noted, however, that the integration problem examined here is a greatly simplified one; in particular, we assume that expressions contain only scalar variables and constants, and that the only statements used in programs are assignment statements, conditional statements, and while-loops. © 1989, ACM. All rights reserved.",,Computer Programming--Algorithms; Programming Environment; Computer Software
I-Structures: Data Structures for Parallel Computing,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024751383&doi=10.1145%2f69558.69562&partnerID=40&md5=27f6489a8e032f4e66b9b85676480f58,"It is difficult to achieve elegance, efficiency, and parallelism simultaneously in functional programs that manipulate large data structures. We demonstrate this through careful analysis of program examples using three common functional data-structuring approaches-lists using Cons, arrays using Update (both fine-grained operators), and arrays using make-array (a “bulk” operator). We then present I-structure as an alternative and show elegant, efficient, and parallel solutions for the program examples in Id, a language with I-structures. The parallelism in Id is made precise by means of an operational semantics for Id as a parallel reduction system. I-structures make the language nonfunctional, but do not lose determinacy. Finally, we show that even in the context of purely functional languages, I-structures are invaluable for implementing functional data abstractions. © 1989, ACM. All rights reserved.",Functional languages; parallelism,"Computer Programming Languages; Computer Systems, Digital--Parallel Processing; I-Structures; Operational Semantics; Data Processing"
Code Generation Using Tree Matching and Dynamic Programming,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024750286&doi=10.1145%2f69558.75700&partnerID=40&md5=c9212f8b894c4a93c30df45fcb817ec8,"Compiler-component generators, such as lexical analyzer generators and parser generators, have long been used to facilitate the construction of compilers. A tree-manipulation language called twig has been developed to help construct efficient code generators. Twig transforms a tree-translation scheme into a code generator that combines a fast top-down tree-pattern matching algorithm with dynamic programming. Twig has been used to specify and construct code generators for several experimental compilers targeted for different machines. © 1989, ACM. All rights reserved.",Code generation; code generator-generator; code optimization; dynamic programming; pattern matching,Computer Programming; Mathematical Techniques--Trees; Code Generation; Code Optimization; Dynamic Programming; Pattern Matching Algorithms; Tree Matching; Twig Programming Language; Computer Programming Languages
Uniform Self-Stabilizing Rings,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024646930&doi=10.1145%2f63264.63403&partnerID=40&md5=7804efda1315d1c36c1685cb6a82d755,"A self-stabilizing system has the property that, no matter how it is perturbed, it eventually returns to a legitimate configuration. Dijkstra originally introduced the self-stabilization problem and gave several solutions for a ring of processors in his 1974 Communications of the ACM paper. His solutions use a distinguished processor in the ring, which effectively acts as a controlling element to drive the system toward stability. Dijkstra has observed that a distinguished processor is essential if the number of processors in the ring is composite. We show, by presenting a protocol and proving its correctness, that there is a self-stabilizing system with no distinguished processor if the size of the ring is prime. The basic protocol uses Θ (n2) states in each processor when n is the size of the ring. We modify the basic protocol to obtain one that uses Θ (n2/ln n) states. © 1989, ACM. All rights reserved.",Self-stabilization,"Computer Networks--Protocols; Protocol Correctness; Ring Networks; Uniform Self Stabilizing Rings; Computer Systems, Digital"
A Generalization of Dijkstra's Calculus,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024752060&doi=10.1145%2f69558.69559&partnerID=40&md5=981fc2825c9a30fc5135c11aa76bb4ff,"Dijsktra's calculus of guarded commands can be generalized and simplified by dropping the law of the excluded miracle. This paper gives a self-contained account of the generalized calculus from first principles through the semantics of recursion. The treatment of recursion uses the fixpoint method from denotational semantics. The paper relies only on the algebraic properties of predicates; individual states are not mentioned (except for motivation). To achieve this, we apply the correspondence between programs and predicates that underlies predicative programming. The paper is written from the axiomatic semantic point of view, but its contents can be described from the denotational semantic point of view roughly as follows: The Plotkin-Apt correspondence between wp semantics and the Smyth powerdomain is extended to a correspondence between the full wp/wlp semantics and the Plotkin powerdomain extended with the empty set. © 1989, ACM. All rights reserved.",,Mathematical Techniques--Algebra; Calculus of Guarded Commands; Denotational Semantics; Fixpoint Method; Computer Programming Languages
Local atomicity properties: Modular concurrency control for abstract data types,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024646243&doi=10.1145%2f63264.63518&partnerID=40&md5=25f1e4d86bcc710cf053299ca190d16d,"Atomic actions (or transactions) are useful for coping with concurrency and failures. One way of ensuring atomicity of actions is to implement applications in terms of atomic data types: abstract data types whose objects ensure serializability and recoverability of actions using them. Many atomic types can be implemented to provide high levels of concurrency by taking advantage of algebraic properties of the type's operations, for example, that certain operations commute. In this paper we analyze the level of concurrency permitted by an atomic type. We introduce several local constraints on individual objects that suffice to ensure global atomicity of actions; we call these constraints local atomicity properties. We present three local atomicity properties, each of which is optimal: no strictly weaker local constraint on objects suffices to ensure global atomicity for actions. Thus, the local atomicity properties define precise limits on the amount of concurrency that can be permitted by an atomic type. © 1989, ACM. All rights reserved.",Abstract data types; atomic actions; atomic types; concurrency; transactions,"Computer Systems, Digital--Distributed; Database Systems--Distributed; Abstract Data Types; Atomic Actions; Local Atomicity; Modular Concurrency Control; Computer Programming"
On the Productivity of Recursive List Definitions,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024751480&doi=10.1145%2f69558.69563&partnerID=40&md5=8d1ec83005c3735573d475c2327edc8d,"Several related notions of the productivity are presented for functional languages with lazy evaluation. The notion of productivity captures the idea of computability, of progress of infinite-list programs. If an infinite-list program is productive, then every element of the list can be computed in finite “time.” These notions are used to study recursive list definitions, that is, lists defined by l where l = fl. Sufficient conditions are given in terms of the function f that either guarantee the productivity of the list or its unproductivity. Furthermore, a calculus is developed that can be used in verifying that lists defined by l where l< = f I are productive. The power and the usefulness of our theory are demonstrated by several nontrivial examples. Several observations are given in conclusion. © 1989, ACM. All rights reserved.",,Computer Metatheory--Computability and Decidability; Computer Programming; Functional Languages; Lazy Evaluation; Recursive List Definitions; Computer Programming Languages
A Denotational Semantics for Prolog,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024755281&doi=10.1145%2f69558.69564&partnerID=40&md5=55a6331b3c27bdf4b0408de1c2432a24,"A denotational semantics is presented for the language Pro.og. Metapredicates are not considered. Conventional control sequencing is assumed for Prolog's execution. The semantics is nonstandard, and goal continuations are used to explicate the sequencing. © 1989, ACM. All rights reserved.",Denotational semantics; logic programming,Denotational Semantics; Goal Continuations; Logic Programming; Metapredicates; Prolog; Computer Programming Languages
ECCS and LIPS: Two languages for OSI systems specification and verification,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024646555&doi=10.1145%2f63264.63402&partnerID=40&md5=3362f37ec9225e0c4a462bd49bf0bcf5,"An issue of current interest in the Open Systems Interconnection (OSI) field is the choice of a language well suited to specification and verification. For this purpose, two languages based on Milner's communication calculi are proposed, respectively intended for the specification of asynchronous and synchronous OSI systems. A formal verification method, relying upon the algebraic foundations of the two languages, is introduced and illustrated by means of examples based on nontrivial protocols and services. © 1989, ACM. All rights reserved.",Calculus of communicating systems; communication protocols and services; observation; Open Systems Interconnection reference model (OSI); synchronous/asynchronous systems,Computer Networks; Calculus of Communicating Systems; ECCS Language; LIPS Language; Open Systems Interconnection; OSI Systems Specification; OSI Systems Verification; Computer Programming Languages
Incremental dynamic semantics for language-based programming environments,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024647368&doi=10.1145%2f63264.63400&partnerID=40&md5=8558ed5eae205f9d7e1bc1742e706620,"Attribute grammars are a formal notation for expressing the static semantics of programming languages—those properties that can be derived from inspection of the program text. Attribute grammars have become popular as a mechanism for generating language-based programming environments that incrementally perform symbol resolution, type checking, code generation, and derivation of other static semantic properties as the program is modified. However, attribute grammars are not suitable for expressing dynamic semantics—those properties that reflect the history of program execution and/or user interactions with the programming environment. This paper presents action equations, an extension of attribute grammars suitable for specifying the static and the dynamic semantics of programming languages. It describes how action equations can be used to generate language-based programming environments that incrementally derive static and dynamic properties as the user modifies and debugs the program. © 1989, ACM. All rights reserved.",Algorithms; Design; dynamic semantics; Experimentation; generation of languagebased environments; interpreters; Languages; Reliability; Theory; Verification Additional Key Words and Phrases: Attribute grammars,Computer Programming Languages; Action Equations; Attribute Grammars; Incremental Dynamic Semantics; Language Base Programming Environments; Computer Programming
On Lamport's Interprocessor Communication Model,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024700207&doi=10.1145%2f65979.65982&partnerID=40&md5=fce70cfecbe805c25254947eba8f6e33,"Leslie Lamport presented a set of axioms in 1979 that capture the essential properties of the temporal relationships between complex and perhaps unspecified activities within any system, and proceeded to use this axiom system to prove the correctness of sophisticated algorithms for reliable communication and mutual exclusion in systems without shared memory. As a step toward a more complete metatheory of Lamport's axiom system, this paper determines the extent to which that system differs from systems based on “atomic,” or indivisible, actions. Theorem 1 shows that only very weak conditions need be satisfied in addition to the given axioms to guarantee the existence of an atomic “model,” while Proposition 1 gives sufficient conditions under which any such model must be a “faithful” representation. Finally, Theorem 2 restates a result of Lamport showing exactly when a system can be thought of as made up of a set of atomic events that can be totally ordered temporally. A new constructive proof is offered for this result. © 1989, ACM. All rights reserved.",Nonatomic operations,Computer Metatheory--Formal Logic; Computer Operating Systems--Program Processors; Concurrent Programming; Interprocessor Communication Model; Performance Analysis; Computer Systems Programming
Functional Computations in Logic Programs,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024702578&doi=10.1145%2f65979.65984&partnerID=40&md5=fbc4d8203cb4f5fb822e56072615e093,"Although the ability to simulate nondeterminism and to compute multiple solutions for a single query is a powerful and attractive feature of logic programming languages, it is expensive in both time and space. Since programs in such languages are very often functional, that is, they do not produce more than one distinct solution for a single input, this overhead is especially undesirable. This paper describes how programs may be analyzed statically to determine which literals and predicates are functional, and how the program may then be optimized using this information. Our notion of “functionality” subsumes the notion of “determinacy” that has been considered by various researchers. Our algorithm is less reliant on language features such as the cut, and thus extends more easily to parallel execution strategies, than others that have been proposed. © 1989, ACM. All rights reserved.",Dataflow analysis; determinancy; functional dependency; PROLOG,Artificial Intelligence; Computer Metatheory--Formal Logic; Computer Operating Systems--Program Compilers; Dataflow Analysis; Functional Dependency; Logic Programs; Programming Language PROLOG; Computer Programming Languages
Efficient high-level iteration with accumulators,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024647118&doi=10.1145%2f63264.63401&partnerID=40&md5=48c605cbfc13806438cf0849cfce915f,"Accumulators are proposed as a new type of high-level iteration construct for imperative languages. Accumulators are user-programmed mechanisms for successively combining a sequence of values into a single result value. The accumulated result can either be a simple numeric value such as the sum of a series or a data structure such as a list. Accumulators naturally complement constructs that allow iteration through user-programmed sequences of values such as the iterators of CLU and the generators of Alphard. A practical design for high-level iteration is illustrated by way of an extension to Modula-2 called Modula Plus. The extension incorporates both a redesigned mechanism for iterators as well as the accumulator design. Several applications are illustrated including both numeric and data structure accumulation. It is shown that the design supports efficient iteration both because it is amenable to implementation via in-line coding and because it allows high-level iteration concepts to be implemented as encapsulations of efficient low-level manipulations. © 1989, ACM. All rights reserved.",Accumulation; accumulators; generators; iteration; iterators; loop constructs; mapping functions; Modula; reduce operator,Accumulators; Alphard; CLU; High Level Iteration; Computer Programming Languages
Designing families of data types using exemplars,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024646382&doi=10.1145%2f63264.63265&partnerID=40&md5=805e43f76e367d3b89c04ef3f19a3d43,"Designing data types in isolation is fundamentally different from designing them for integration into communities of data types, especially when inheritance is a fundamental issue. Moreover, we can distinguish between the design of families—integrated types that are variations of each other—and more general communities where totally different but cohesive collections of types support specific applications (e.g., a compiler). We are concerned with the design of integrated families of data types as opposed to individual data types; that is, on the issues that arise when the focus is intermediate between the design of individual data types and more general communities of data types. We argue that design at this level is not adequately served by systems providing only class-based inheritance hierarchies and that systems which additionally provide a coupled subtype specification hierarchy are still not adequate. We propose a system that provides an unlimited number of uncoupled specification hierarchies and illustrate it with three: a subtype hierarchy, a specialization/generalization hierarchy, and a like hierarchy. We also resurrect a relatively unknown Smalltalk design methodology that we call programming-by-exemplars and argue that it is an important addition to a designer's grab bag of techniques. The methodology is used to show that the subtype hierarchy must be decoupled from the inheritance hierarchy, something that other researchers have also suggested. However, we do so in the context of exemplar-based systems to additionally show that they can already support the extensions required without modification and that they lead to a better separation between users and implementers, since classes and exemplars can be related in more flexible ways. We also suggest that class-based systems need the notion of private types if they are to surmount their current limitations. Our points are made in the guise of designing a family of List data types. Among these is a new variety of lists that havenever been previously published: prefix-sharing lists. We also argue that there is a need for familial classes to serve as an intermediary between users and the members of a family. © 1989, ACM. All rights reserved.",Classes; communities of data types; exemplars; exemplary programming; families of data types; inheritance; object-oriented systems; programming-in-the-large,Computer Programming Languages; Data Types; Programming by Exemplars; Smalltalk; Computer Programming
Concurrency in Heavily Loaded Neighborhood-Constrained Systems,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024749885&doi=10.1145%2f69558.69560&partnerID=40&md5=2a9b5da5782378eed1c7f2c63c3adde2,"Let G be a connected undirected graph in which each node corresponds to a process and two nodes are connected by an edge if the corresponding processes share a resource. We consider distributed computations in which processes are constantly demanding all of their resources in order to operate, and in which neighboring processes may not operate concurrently. We advocate that such a system is general enough for representing a large class of resource-sharing systems under heavy load. We employ a distributed scheduling mechanism based on acyclic orientations of G and investigate the amount of concurrency that it provides. We show that this concurrency is given by a number akin to G's chromatic and multichromatic numbers, and that, among scheduling schemes which require neighbors in G to alternate in their turns to operate, ours is the one that potentially provides the greatest concurrency. However, we also show that the decision problem corresponding to optimizing concurrency is NP-complete. © 1989, ACM. All rights reserved.",Concurrency measures; dining philosophers problem; graph colorings; graph multicolorings,"Mathematical Techniques--Graph Theory; Optimization; Scheduling; Concurrency Measures; Dining Philosophers Problem; Graph Colorings; Undirected Graphs; Computer Systems, Digital"
Synchronization of Asynchronous Processes in CSP,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024751969&doi=10.1145%2f69558.69561&partnerID=40&md5=4d919e8ed6acc27a5e34e5b4c425ef41,"Many concurrent programming languages including CSP and Ada use synchronous message-passing to define communication between a pair of asynchronous processes. Suggested primitives like the generalized alternative command for CSP and the symmetric select statement for Ada allow a process to nondeterministically select one of several communication statements for execution. The communication statement may be either an input or an output statement. We propose a simple algorithm to implement the generalized alternative command and show that it uses fewer messages than existing algorithms. © 1989, ACM. All rights reserved.",CSP; guarded commands; nondeterminism; output guards; parallel programming; process communication; symmetric select statements,"Computer Programming--Algorithms; Computer Systems, Digital--Distributed; Communicating Sequential Processes; Concurrent Programming Languages; CSP; Guarded Commands; Message Passing; Synchronization; Computer Programming Languages"
Some Comments on “A Solution to a Problem with Morel and Renvoise's ‘Global Optimization by Suppression of Partial Redundancies'”,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343794366&doi=10.1145%2f69558.214513&partnerID=40&md5=a2d0f4810c01d8bca6627028ebea66c0,"Drechsler and Stadel presented a solution to a problem with Morel and Renvoise's “Global Optimization by Suppression of Partial Redundancies.” We cite some earlier generalizations of Morel and Renvoise's algorithm that solve the same problem, and we comment on their applicability. © 1989, ACM. All rights reserved.",Code hoisting; Morel and Renvoise's algorithm; partial redundancy suppression,
Static Inference of Modes and Data Dependencies in Logic Programs,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024700858&doi=10.1145%2f65979.65983&partnerID=40&md5=4e32ada939e84ab96631df23660b8399,"Mode and data dependency analyses find many applications in the generation of efficient executable code for logic programs. For example, mode information can be used to generate specialized unification instructions where permissible, to detect determinacy and functionality of programs, generate index structures more intelligently, reduce the amount of runtime tests in systems that support goal suspension, and in the integration of logic and functional languages. Data dependency information can be used for various source-level optimizing transformations, to improve backtracking behavior and to parallelize logic programs. This paper describes and proves correct an algorithm for the static inference of modes and data dependencies in a program. The algorithm is shown to be quite efficient for programs commonly encountered in practice. © 1989, ACM. All rights reserved.",data dependency; Dataflow analysis; mode; Prolog; static inference,Artificial Intelligence; Computer Metatheory--Programming Theory; Data Dependencies; Logic Programs; Computer Programming Languages
Control Predicates are Better Than Dummy Variables for Reasoning About Program Control,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023999816&doi=10.1145%2f42190.42348&partnerID=40&md5=475c088f98bbfbc0eebaf62a556e535a,"When explicit control predicates rather than dummy variables are used, the Owicki-Gries method for proving safety properties of concurrent programs can be strengthened, making it easier to construct the required program annotations. © 1988, ACM. All rights reserved.",concurrent programming; invariance; noninterference; Owicki-Gries method; safety properties,COMPUTER PROGRAMMING - Control; CONCURRENT PROGRAMMING; OWICKI-GRIES METHOD; COMPUTER PROGRAMMING LANGUAGES
Efficient synchronization of multiprocessors with shared memory,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024101778&doi=10.1145%2f48022.48024&partnerID=40&md5=01d7db8d70c122f4cf1fe7d1da1b9350,"A new formalism is given for read-modify-write (RMW) synchronization operations. This formalism is used to extend the memory reference combining mechanism introduced in the NYU Ultracomputer, to arbitrary RMW operations. A formal correctness proof of this combining mechanism is given. General requirements for the practicality of combining are discussed. Combining is shown to be practical for many useful memory access operations. This includes memory updates of the form mem_val := mem_val op val, where op need not be associative, and a variety of synchronization primitives. The computation involved is shown to be closely related to parallel prefix evaluation. © 1988, ACM. All rights reserved.",Architecture correctness; fetch-and-add; interconnection network; memory reference combining; parallel prefix; parallel processing; read-modify-write (RMW),"COMPUTER ARCHITECTURE; MEMORY REFERENCE COMBINING; MULTIPLE DATA STREAM ARCHITECTURES; NYU ULTRACOMPUTER; PARALLEL PREFIX; READ-MODIFY-WRITE SYNCHRONIZATION; SHARED MEMORY; COMPUTER SYSTEMS, DIGITAL"
A simple interprocedural register allocation algorithm and its effectiveness for LISP,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024304650&doi=10.1145%2f59287.59289&partnerID=40&md5=e4b1313b8e4035f5f86d396f22b71b82,"Register allocation is an important optimization in many compilers, but with per-procedure register allocation, it is often not possible to make good use of a large register set. Procedure calls limit the improvement from global register allocation, since they force variables allocated to registers to be saved and restored. This limitation is more pronounced in LISP programs due to the higher frequency of procedure calls. An interprocedural register allocation algorithm is developed by simplifying a version of interprocedural graph coloring. The simplification corresponds to a bottom-up coloring of the interference graph. The scheme is evaluated using a number of LISP programs. The evaluation considers the scheme's limitations and compares these “software register windows” against the hardware register windows used in the Berkeley RISC and SPUR processors. © 1989, ACM. All rights reserved.",Graph coloring; interprocedural; LISP; register allocation; register windows,Computer Programming Languages--LISP; Mathematical Techniques--Graph Theory; Compiler Optimization; Graph Coloring Heuristic; Interprocedural Register Allocation; Register Allocation; Register Windows; Computer Operating Systems
Verifying temporal properties without temporal logic,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024303044&doi=10.1145%2f59287.62028&partnerID=40&md5=be0280247c1f521ed79269ed55fa103f,"An approach to proving temporal properties of concurrent programs that does not use temporal logic as an inference system is presented. The approach is based on using Buchi automata to specify properties. To show that a program satisfies a given property, proof obligations are derived from the Buchi automata specifying that property. These obligations are discharged by devising suitable invariant assertions and variant functions for the program. The approach is shown to be sound and relatively complete. A mutual exclusion protocol illustrates its application. © 1989, ACM. All rights reserved.",Assertional reasoning about programs; Buchi automata; liveness properties; program verification; proving temporal logic; safety properties,"Automata Theory--Finite Automata; Computer Metatheory--Boolean Algebra; Assertional Reasoning About Programs; Buchi Automata; Concurrent Programs; Liveness Properties; Temporal Logic; Computer Systems, Digital"
Efficient implementation of lattice operations,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024304651&doi=10.1145%2f59287.59293&partnerID=40&md5=e04815f95219268c759eba0a48176665,"Lattice operations such as greatest lower bound (GLB), least upper bound (LUB), and relative complementation (BUTNOT) are becoming more and more important in programming languages supporting object inheritance. We present a general technique for the efficient implementation of such operations based on an encoding method. The effect of the encoding is to plunge the given ordering into a boolean lattice of binary words, leading to an almost constant time complexity of the lattice operations. A first method is described based on a transitive closure approach. Then a more space-efficient method minimizing code-word length is described. Finally a powerful grouping technique called modulation is presented, which drastically reduces code space while keeping all three lattice operations highly efficient. This technique takes into account idiosyncrasies of the topology of the poset being encoded that are quite likely to occur in practice. All methods are formally justified. We see this work as an original contribution towards using semantic (vz., in this case, taxonomic) information in the engineering pragmatics of storage and retrieval of (vz., partially or quasi-ordered) information. © 1989, ACM. All rights reserved.",Inheritance; lattice operations; partially-ordered objects,Computer Metatheory--Boolean Algebra; Information Retrieval Systems; Boolean Lattice; Greatest Lower Bound; Lattice Operations; Least Upper Bound; Object Inheritance; Partially Ordered Objects; Computer Programming Languages
Analysis of functional programs to detect run-time garbage cells,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024099495&doi=10.1145%2f48022.48025&partnerID=40&md5=3b080d9c56c3c977ad9c49bc69d5810e,"We propose a method for detecting the generation of garbage cells by analyzing a source text written in a functional programming language which uses ordinary linked lists to implement list-type values. For a subexpression such as F(G(&)) in a program where the function values of F and G are of list type, if a cell c is created during the computation of G and if c does not appear in a list-type value of F, then c becomes a garbage cell at the end of the computation of F. We discuss this problem on the basis of formal languages derived from the functional program text and show some sufficient conditions that predict the generation of garbage cells. Also, we give an efficient algorithm to detect at compile time the generation of garbage cells which are linearly linked. We have implemented these algorithms in an experimental LISP system. By executing several sample programs on the system, we conclude that our method is effective in detecting the generation of garbage cells. © 1988, ACM. All rights reserved.",Created occurrences; garbage collection; noninherited occurrences,AUTOMATA THEORY - Formal Languages; COMPUTER PROGRAMMING - Algorithms; APPLICATIVE LANGUAGES; FUNCTIONAL PROGRAMS; GARBAGE COLLECTION; NONINHERITED OCCURRENCES; RUN-TIME GARBAGE CELLS; COMPUTER PROGRAMMING LANGUAGES
Distributed Cooperation with Action Systems,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024103791&doi=10.1145%2f48022.48023&partnerID=40&md5=e9ac57664d01e025a354d023649fe7f1,"Action systems provide a method to program distributed systems that emphasizes the overall behavior of the system. System behavior is described in terms of the possible interactions (actions) that the processes can engage in, rather than in terms of the sequential code that the processes execute. The actions provide a symmetric communication mechanism that permits an arbitrary number of processes to be synchronized by a common handshake. This is a generalization of the usual approach, employed in languages like CSP and Ada, in which communication is asymmetric and restricted to involve only two processes. Two different execution models are given for action systems: a sequential one and a concurrent one. The sequential model is easier to use for reasoning, and is essentially equivalent to the guarded iteration statement by Dijkstra. It is well suited for reasoning about system properties in temporal logic, but requires a stronger fairness notion than it is reasonable to assume a distributed implementation will support. The concurrent execution model reflects the true concurrency that is present in a distributed execution, and corresponds to the way in which the system is actually implemented. An efficient distributed implementation of action systems on a local area network is described. The fairness assumptions of the concurrent model can be guaranteed in this implementation. The relationship between the two execution models is studied in detail in the paper. For systems that will be called fairly serializable, the two models are shown to be equivalent. Proof methods are given for verifying this property of action systems. It is shown that for fairly serializable systems, properties that hold for any concurrent execution of the system can be established by temporal proofs that are conducted entirely within the simpler sequential execution model. © 1988, ACM. All rights reserved.",Broadcasting networks; distributed systems; fairness; guarded commands; handshaking mechanisms; models of concurrency; multiprocess communication; program verification; programming languages; scheduling; temporal logic; true concurrency,"COMPUTER PROGRAMMING LANGUAGES; COMPUTER SYSTEMS, DIGITAL - Distributed; ACTION SYSTEMS; CONCURRENT PROGRAMMING; DISTRIBUTED COOPERATION; EXECUTION MODELS; SEQUENTIAL PROGRAMMING; COMPUTER PROGRAMMING"
The Specification Statement,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024036510&doi=10.1145%2f44501.44503&partnerID=40&md5=9b6d595f783112b8efc1951787c20f7c,"Dijkstra's programming language is extended by specification statements, which specify parts of a program “yet to be developed.” A weakest precondition semantics is given for these statements so that the extended language has a meaning as precise as the original. The goal is to improve the development of programs, making it closer to manipulations within a single calculus. The extension does this by providing one semantic framework for specifications and programs alike: Developments begin with a program (a single specification statement) and end with a program (in the executable language). And the notion of refinement or satisfaction, which normally relates a specification to its possible implementations, is automatically generalized to act between specifications and between programs as well. A surprising consequence of the extension is the appearance of miracles: program fragments that do not satisfy Dijkstra's Law of the Excluded Miracle. Uses for them are suggested. © 1988, ACM. All rights reserved.",Development calculus; guarded commands; miracles; procedural abstraction; program refinement; weakest preconditions,Computer Metatheory--Programming Theory; Development Calculus; Dijkstra's Programming Language; Procedural Abstraction; Program Refinement; Specification Techniques; Weakest Preconditions; Computer Software
Abstract Types Have Existential Type,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024038082&doi=10.1145%2f44501.45065&partnerID=40&md5=894492993b9e53d6205c207535e6f420,"data type declarations appear in typed programming languages like Ada, Alphard, CLU and ML. This form of declaration binds a list of identifiers to a type with associated operations, a composite “value” we call a data algebra. We use a second-order typed lambda calculus SOL to show how data algebras may be given types, passed as parameters, and returned as results of function calls. In the process, we discuss the semantics of abstract data type declarations and review a connection between typed programming languages and constructive logic. © 1988, ACM. All rights reserved.",Abstract data types; lambda calculus; polymorphism; programming languages; types,Computer Operating Systems--Program Compilers; Abstract Data Types; Denotational Semantics; Lambda Calculus; Operational Semantics; Polymorphism; Computer Programming Languages
Tichy's response to R. W. Schwanke and G. E. Kaiser's “Smarter Recompilation”,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976760003&doi=10.1145%2f48022.214507&partnerID=40&md5=f380c54ad3ef7bd44eb664c7c9cf1403,[No abstract available],,
Constrained Expressions: Toward Broad Applicability of Analysis Methods for Distributed Software Systems,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024037393&doi=10.1145%2f44501.44502&partnerID=40&md5=97869c001eac94a74eb93ce23fbfa18a,"It is extremely difficult to characterize the possible behaviors of a distributed software system through informal reasoning. Developers of distributed systems require tools that support formal reasoning about properties of the behaviors of their systems. These tools should be applicable to designs and other preimplementation descriptions of a system, as well as to completed programs. Furthermore, they should not limit a developer's choice of development languages. In this paper we present a basis for broadly applicable analysis methods for distributed software systems. The constrained expression formalism can be used with a wide variety of distributed system development notations to give a uniform closed-form representation of a system's behavior. A collection of formal analysis techniques can then be applied with this representation to establish properties of the system. Examples of these formal analysis techniques appear elsewhere. Here we illustrate the broad applicability of the constrained expression formalism by showing how constrained expression representations are obtained from descriptions of systems in three different notations: SDYMOL, CSP, and Petri nets. Features of these three notations span most of the significant alternatives for describing distributed software systems. Our examples thus offer persuasive evidence for the broad applicability of the constrained expression approach. © 1988, ACM. All rights reserved.","Constrained expressions; CSP; distributed software systems; event-based analysis of software designs; Petri net languages; Petri nets; SDYMOL, software design tools","Computer Software--Design; Mathematical Techniques--Graph Theory; Concurrent Programming; Constrained Expressions; Distributed Software Systems; Petri Nets; Software Design Tools; Computer Systems, Digital"
Distributed FIFO allocation of identical resources using small shared space,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024302122&doi=10.1145%2f59287.59292&partnerID=40&md5=f89c4fbbd8f6278fb99182d74a56389c,"We present a simple and efficient algorithm for the FIFO allocation of k identical resources among asynchronous processes that communicate via shared memory. The algorithm simulates a shared queue but uses exponentially fewer shared memory values, resulting in practical savings of time and space as well as program complexity. The algorithm is robust against process failure through unannounced stopping, making it attractive also for use in an environment of processes of widely differing speeds. In addition to its practical advantages, we show that for fixed k, the shared space complexity of the algorithm as a function of the number N of processes is optimal to within a constant factor. © 1989, ACM. All rights reserved.",Asynchronous system; distributed computing; FIFO; lower bound; queue; resource allocation; shared memory; space complexity,"Computer Networks; Computer Systems Programming; Computers--Data Communication Systems; Asynchronous Processes; Colored Ticket Algorithm; Distributed FIFO Allocation; Resource Allocation; Shared Memory; Shared Queue; Computer Systems, Digital"
Director strings as combinators,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024101750&doi=10.1145%2f48022.48026&partnerID=40&md5=f87a78a6c0019bbdcca17afbcde461c3,"A simple calculus (the Director String Calculus-DSC) for expressing abstractions is introduced, which captures the essence of the “long reach” combinators introduced by Turner. We present abstraction rules that preserve the applicative structure of the original lambda term, and that cannot increase the number of subterms in the translation. A translated lambda term can be reduced according to the evaluation rules of DSC. If this terminates with a DSC normal form, this can be translated into a lambda term using rules presented below. We call this process of abstracting a lambda term, reducing to normal form in the space of DSC terms, and translating back to a lambda term an implementation. We show that our implementation of the lambda calculus is correct: For lambda terms with a normal form that contains no lambdas (ground terms), the implementation is shown to yield a lambda calculus normal form. For lambda terms whose normal forms represent functions, it is shown that the implementation yields lambda terms that are beta-convertible in zero or more steps to the normal form of the original lambda term. In this sense, our implementation involves weak reduction according to Hindley et al. [9]. © 1988, ACM. All rights reserved.",Combinators; eta optimization; implementation of functional languages; lambda calculus; weak reduction,COMPUTER METATHEORY; APPLICATIVE LANGUAGES; COMBINATORS; DIRECTOR STRING CALCULUS; LAMBDA CALCULUS; COMPUTER PROGRAMMING LANGUAGES
Abstract Interaction Tools: A Language for User Interface Management Systems,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023998106&doi=10.1145%2f42190.42191&partnerID=40&md5=68124b441fd1b5f16d3f7d7baaeb11c8,"A language model is presented for the specification of User Interface Management Systems. The model, called the Abstract Interaction Tool (AIT) model, offers a tree-like hierarchy of interaction objects. Each object represents a subtree and can be considered as an abstract input device containing a syntax-like specification of the required input pattern. The hierarchy of specifications amounts to a system of syntactical productions with multiple control. Terminal nodes of the AIT tree represent the interface to the physical interaction devices. The AIT model features hierarchical output resource management. At the higher, more abstract, level the input-output is loosely coupled. At lower levels the coupling becomes increasingly tight. At the upper levels, AITs model the functions (what) required by the user, whereas at the lower levels the way to accomplish them (how) is stressed. The AIT model has modes for multithread and multiple-device user interaction. There are facilities for context-dependent prompting, echoing, feedback, error correction, and expertise levels. A special section in the AIT provides for links to application modules. As a model for general interactive systems, AITs can be applied to graphics, process control, dialogue, and real-time systems. AITs can also be used to define controlled production rules in knowledge-based systems. In addition the model can provide tools for the software engineering phases specification and prototyping. © 1988, ACM. All rights reserved.",Controlled production system; dialogue control; input expression; input hierarchy; input specification; interaction language generator; interaction modules; user interface management,COMPUTER SOFTWARE; ABSTRACT INTERACTION TOOL; AIT MODEL; USER INTERFACE MANAGEMENT SYSTEM; COMPUTER PROGRAMMING LANGUAGES
Determining the Extent of Lookahead in Syntactic Error Repair,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024038236&doi=10.1145%2f44501.44505&partnerID=40&md5=2e4ef22db95f130083b123d8fc57c2b2,"Many syntactic error repair strategies examine several additional symbols of input to guide the choice of a repair; a problem is determining how many symbols to examine. The goal of gathering all relevant information is discussed and shown to be impractical; instead we can gather all information relevant to choosing among a set of “minimal repairs.” We show that finding symbols with the property “Moderate Phrase-Level Uniqueness” is sufficient to establish that all information relevant to these minimal repairs has been seen. Empirical results on the occurrence of such symbols in Pascal are presented. © 1988, ACM. All rights reserved.",Error repair; forward move; syntax error,Computer Programming Languages; Equivalent Repairs; Syntactic Error Repair; Syntax Error; Computer Operating Systems
A solution to a problem with Morel and Renvoise's “Global optimization by suppression of partial redundancies”,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976860830&doi=10.1145%2f48022.214509&partnerID=40&md5=b580ddb073d48be8c5191b7520fa17f1,"Morel and Renvoise have previously described a method for global optimization and code motion by suppression of partial redundancies [l]. Morel and Renvoise use data flow analysis to determine expression computations that should be inserted at the end of certain basic blocks and to determine redundant computations that can be eliminated. The execution of these techniques results in the movement of loop invariant expressions out of the loop. In addition to [l] Morel and Renvoise's techniques can also be applied to subexpressions of larger expressions. Then, however, in certain special cases these optimization techniques move expressions to places where some of its subexpressions are neither available nor moved together with the expression. In this paper we present a modification of Morel and Renvoise's algorithm that avoids the above described situations. © 1988, ACM. All rights reserved.",Code motion; data flow analysis,
Scheduling expressions on a pipelined processor with a maximal delay of one cycle,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024304123&doi=10.1145%2f59287.59291&partnerID=40&md5=47e8f1fb3582a44533c08d892b85b6d4,"Consider a pipelined machine that can issue instructions every machine cycle. Sometimes, an instruction that uses the result of the instruction preceding it in a pipe must be delayed to ensure that a program computes a right value. We assume that issuing of such instructions is delayed by at most one machine cycle. For such a machine model, given an unbounded number of machine registers and memory locations, an algorithm to find a shortest schedule of the given expression is presented and analyzed. The proposed algorithm is a modification of Coffman-Graham's algorithm [7], which provides an optimal solution to the problem of scheduling tasks on two parallel processors. © 1989, ACM. All rights reserved.",Pipelined processors,"Automata Theory--Sequential Machines; Computer Architecture; Computer Systems, Digital--Scheduling; Labeling Algorithm; Pipelined Processor; Computer Systems Programming"
An Ada Package for Dimensional Analysis,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023997316&doi=10.1145%2f42190.42346&partnerID=40&md5=fcea707f9cc1be258da10864c7765ff1,"This paper illustrates the use of Ada's abstraction facilities—notably, operator overloading and type parameterization—to define an oft-requested feature: a way to attribute units of measure to variables and values. The definition given allows the programmer to specify units of measure for variables, constants, and parameters; checks uses of these entities for dimensional consistency; allows arithmetic between them, where legal; and provides scale conversions between commensurate units. It is not constrained to a particular system of measurement (such as the metric or English systems). Although the definition is in standard Ada and requires nothing special of the compiler, certain reasonable design choices in the compiler, discussed here at some length, can make its implementation particularly efficient. © 1988, ACM. All rights reserved.",Dimensional analysis; language design; units,COMPUTER OPERATING SYSTEMS - Program Compilers; UNITS OF MEASUREMENT - Reliability; DIMENSIONAL ANALYSIS; COMPUTER PROGRAMMING LANGUAGES
Row replacement algorithms for screen editors,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024305023&doi=10.1145%2f59287.59290&partnerID=40&md5=5baddac341eda275477ba4136a6cb756,"Interactive screen editors repeatedly determine terminal command sequences to update a screen row. Computing an optimal command sequence differs from the traditional sequence comparison problem in that there is a cost for moving the cursor over unedited characters and the cost of an n-character command is not always the cost of n one-character commands. For example, on an ANSI-standard terminal, it takes nine bytes to insert one character, ten to insert two, eleven to insert three, and so on. This paper presents an O(MN) dynamic programming algorithm for row replacement where an n-character command costs αn + β for constants α and β. M is the length of the original row and N is the length of its replacement. Also given is an O(Cost × (M + N)) “greedy” algorithm for optimal row replacement. Here Cost is the optimal cost (in bytes) of the replacement, so the algorithm is fast when the required update is small. Though the algorithm is rather complicated, it is fast enough to be useful in practice. © 1989, ACM. All rights reserved.",Dynamic programming; greedy algorithm; row replacement; screen editor,"Computer Graphics--Interactive; Computer Systems Programming; Mathematical Programming, Dynamic; Dynamic Programming Algorithm; Greedy Algorithm; Row Replacement Algorithms; Screen Editors; Computer Peripheral Equipment"
Smarter recompilation,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976831614&doi=10.1145%2f48022.214505&partnerID=40&md5=cbc80acb8dd3cdc99b86cb9ed1a1c6b9,"Tichy's Smart Recompilation method can be made smarter by permitting benign type inconsistencies between separately compiled modules. This enhanced method helps the programmer to make far-reaching changes in small, manageable steps. © 1988, ACM. All rights reserved.",Intelligent software tools; overloading; separate compilation; type checking,
Efficient Incremental LR Parsing for Syntax-Directed Editors,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024037520&doi=10.1145%2f44501.214503&partnerID=40&md5=f49ad981db7197be9351d6b1aa51f1a0,"A technique for generating parsers which is an extension to LR techniques and is based on parsing table splitting, is presented. Then this technique is slightly extended to support incremental syntax analysis. Given a context-free grammar and a set “IC” of nonterminals devised to be incremental, a set of subtables is generated to drive the analysis of program fragments derivable from nonterminals in IC. The proposed technique generates parsing tables which are considerably smaller than the standard ones, even when incrementality is not exploited. Thus, these tables may be stored as arrays permitting faster access and accurate error handling. Furthermore, our tables are suitable for generating syntax-directed editors which provide a full analytic mode. The efficiency of the analytic component of a syntax-directed editor obtained in this way and its easy integration with the generative component stress the advantages of incremental program writing. © 1988, ACM. All rights reserved.",Context-free grammars; generators of syntax-directed editors; incremental LR parsing,Automata Theory--Formal Languages; Computer Metatheory; Context Free Grammars; Incremental LR Parsing; Program Editors; Rewriting Systems; Syntax-Directed Editors; Computer Software
On the (non-) Relationship Between SLR(1) and NQLALR(1) Grammars,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023999969&doi=10.1145%2f42190.42276&partnerID=40&md5=f23c2fd98dcc1f356e41a11e9ab0d10f,"A popular but “not-quite” correct technique for computing LALR(1) look-ahead sets has been formalized by DeRemer and Pennello and dubbed NQLALR(l). They also claim that the class of SLR(l) grammars is a subset of the class of NQLALR(1) grammars. We prove here that no such relationship exists between those two classes. We do so with a counterexample that, ironically, appeared in DeRemer and Pennello's own paper. © 1988, ACM. All rights reserved.",Context-free grammar; LALR(l); NQLALR(l); SLR(l),LALR(1) LOOK-AHEAD SETS; LOOK-AHEAD SETS; NQLALR(1) GRAMMAR; SLR(1) GRAMMAR; AUTOMATA THEORY
"Simple, Efficient, Asynchronous Parallel Algorithms for Maximization",1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023999968&doi=10.1145%2f42190.42278&partnerID=40&md5=d9bfdb1904ea827aa161fd35a61e8851,"The problem of computing the maximum of n inputs on an asynchronous parallel computer is considered. In general, the inputs may arrive staggered in time, the number of processors available to the maximization algorithm may vary during its execution, and the number of inputs, n, may be initially unknown. Two simple, efficient algorithms to compute the maximum are presented. Each algorithm may be invoked asynchronously, as new inputs and processors arrive. Performance measures that account for the response times of the invocations are introduced, and the algorithms are analyzed under these measures. © 1988, ACM. All rights reserved.",Asynchronous algorithms; maximization; response times,COMPUTER SYSTEMS PROGRAMMING - Multiprogramming; ASYNCHRONOUS ALGORITHM; MAXIMIZATION PROBLEM; PARALLEL ALGORITHM; COMPUTER PROGRAMMING
Fairness in Parallel Programs: The Transformational Approach,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024036372&doi=10.1145%2f44501.44504&partnerID=40&md5=c612f68f888bd16efc4b3e5aaa4fb4ae,"Program transformations are proposed as a means of providing fair parallelism semantics for parallel programs with shared variables. The transformations are developed in two steps. First, abstract schedulers that implement the various fairness policies are introduced. These schedulers use random assignments z := ? to represent the unbounded nondeterminism induced by fairness. Concrete schedulers are derived by suitably refining the ?. The transformations are then obtained by embedding the abstract schedulers into the parallel programs. This embedding is proved correct on the basis of a simple transition semantics. Since the parallel structure of the original program is preserved, the transformations also provide a basis for syntax-directed proofs of total correctness under the fairness assumption. These proofs make use of infinite ordinals. © 1988, ACM. All rights reserved.","Fairness, implementation; infinite ordinals; Owicki-Gries method; parallel programs; proof rules; schedulers; shared variables; transformational semantics","Computer Operating Systems; Computer Systems Programming; Abstract Schedulers; Concurrent Programming; Parallel Programs; Transformational Semantics; Computer Systems, Digital"
Typed representation of objects by functions,1989,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024304154&doi=10.1145%2f59287.77345&partnerID=40&md5=bf8e9dd3ff1506c69f3725288ddd937b,"A systematic representation of objects grouped into types by constructions similar to the composition of sets in mathematics is proposed. The representation is by lambda expressions, which supports the representation of objects from function spaces. The representation is related to a rather conventional language of type descriptions in a way that is believed to be new. Ordinary control-expressions (i.e.,case- and let-expressions) are derived from the proposed representation. © 1989, ACM. All rights reserved.",Functional objects; functional type; lambda calculus,Automata Theory--Formal Languages; Computer Metatheory; Functional Object Representation; Lambda Calculus; Type Description Language; Computer Programming Languages
Conversion from Data-Driven to Synchronous Execution in Loop Programs,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023439316&doi=10.1145%2f29873.31334&partnerID=40&md5=da48b53c0e1f5f362dfd6dc6f7d546b2,"Conversion algorithms are presented that would enable programmers to write programs in a high-level, data flow language and then run those programs on a synchronous machine. A model of interprocess communication systems is developed in which both data-driven and synchronous execution modes are represented. Balancing equations are used to characterize a subclass of parallel programs, called loop programs, for which conversions are possible. We show that all loop programs having the finite buffer property can be converted into synchronous mode. Finally two algorithms for the conversion of loop programs are presented and discussed. © 1987, ACM. All rights reserved.",Data-driven computation; parallel languages; parallel program optimization,"COMPUTER ARCHITECTURE; COMPUTER PROGRAMMING LANGUAGES; COMPUTER SYSTEMS, DIGITAL - Parallel Processing; DATA-DRIVEN COMPUTATION; MULTIPLE DATA STREAM ARCHITECTURE; COMPUTER OPERATING SYSTEMS"
"Specification and Verification of Liveness Properties of Cyclic, Concurrent Processes",1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023852844&doi=10.1145%2f42192.42195&partnerID=40&md5=84b4831f4e7c8c6586976748b74ba4f1,"A technique is described for software specification and verification of concurrent, distributed systems. The complete specification of a program is given in terms of a hierarchical structure of module specifications. Module external specifications are abstract; module internal specifications are descriptions of internal implementations, either in terms of submodules or actual code. The verification that an implementation satisfies its specification is language independent for the former and language dependent for the latter. Distinguishing the liveness properites provided by a module and the liveness properties required by a module (from its comodules) allows the specification and verification of a given module to be independent from the specification and verification of its comodules. © 1988, ACM. All rights reserved.",CSP; Multiprocessing,COMPUTER OPERATING SYSTEMS - Reliability; COMPUTER SOFTWARE - Software Engineering; CONCURRENT PROCESSES; CORRECTNESS PROOFS; COMPUTER SYSTEMS PROGRAMMING
An Overview of the SR Language and Implementation,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023842589&doi=10.1145%2f42192.42324&partnerID=40&md5=a9dbb605d6ad743661801fd20131bc05,"SR is a language for programming distributed systems ranging from operating systems to application programs. On the basis of our experience with the initial version, the language has evolved considerably. In this paper we describe the current version of SR and give an overview of its implementation. The main language constructs are still resources and operations. Resources encapsulate processes and variables that they share; operations provide the primary mechanism for process interaction. One way in which SR has changed is that both resources and processes are now created dynamically. Another change is that inheritance is supported. A third change is that the mechanisms for operation invocation—call and send—and operation implementation—proc and in—have been extended and integrated. Consequently, all of local and remote procedure call, rendezvous, dynamic process creation, asynchronous message passing, multicast, and semaphores are supported. We have found this flexibility to be very useful for distributed programming. Moreover, by basing SR on a small number of well-integrated concepts, the language has proved easy to learn and use, and it has a reasonably efficient implementation. © 1988, ACM. All rights reserved.",Distributed programming languages,"COMPUTER NETWORKS; COMPUTER OPERATING SYSTEMS - Reliability; COMPUTER PROGRAMMING LANGUAGES - Design; COMPUTERS, DIGITAL - Data Communication Systems; COMPUTER-COMMUNICATION NETWORKS; DISTRIBUTED PROGRAMMING LANGUAGES; COMPUTER SYSTEMS, DIGITAL"
Embedding Continuations in Procedural Objects,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023436733&doi=10.1145%2f29873.30392&partnerID=40&md5=efab25d46ed48ccddb547f4060bda697,"Continuations, when available as first-class objects, provide a general control abstraction in programming languages. They liberate the programmer from specific control structures, increasing programming language extensibility. Such continuations may be extended by embedding them in procedural objects. This technique is first used to restore a fluid environment when a continuation object is invoked. We then consider techniques for constraining the power of continuations in the interest of security and efficiency. Domain mechanisms, which create dynamic barriers for enclosing control, are implemented using fluids. Domains are then used to implement an unwind-protect facility in the presence of first-class continuations. Finally, we present two mechanisms, wind-unwind and dynamic-wind, that generalize unwind-protect. © 1987, ACM. All rights reserved.",Continuations; escapes; first-class objects; labels,COMPUTER SOFTWARE - Software Engineering; LANGUAGE CONSTRUCTS; PROCEDURAL OBJECTS; COMPUTER PROGRAMMING LANGUAGES
Graph Translation Schemes to Generate Compiler Parts,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023436732&doi=10.1145%2f29873.29874&partnerID=40&md5=0f683b60f2226b8b6c4ed730e7e44450,"Graph translation schemes (GTSs) are a generalization of attribute grammars and of some ideas in Koster's language CDL2 They are specially designed to support a compiler writer in defining parts of the back-end of his compiler, but they can also be useful for the specification of the analysis pass of a compiler. GTSs combine elements of functional and of algorithmic specification techniques to allow iterative attribute evaluation and attributing of program graphs. GTSs consist of only a few syntactical elements. We present operational semantics and discuss improvements in the efficiency of the proposed implementation of GTSs. © 1987, ACM. All rights reserved.",Attribute grammars; data flow analysis; grammars; graph-oriented intermediate languages; program graphs,COMPUTER PROGRAMMING LANGUAGES - Design; ATTRIBUTE GRAMMARS; REWRITING SYSTEMS; COMPUTER OPERATING SYSTEMS
A Data-Driven Model for a Subset of Logic Programming,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023437381&doi=10.1145%2f29873.31333&partnerID=40&md5=8a770be9617c09e16bc556aec1bcee5d,"There is a direct correspondence between semantic networks and a subset of logic programs, restricted only to binary predicates. The advantage of the latter is that it can describe not only the nodes and arcs comprising a semantic net, but also the data-retrieval operations applied to such nets. The main objective of this paper is to present a data-driven model of computation that permits this subset of logic programs to be executed on a highly parallel computer architecture. We demonstrate how logic programs may be converted into collections of data-flow graphs in which resolution is viewed as a process of finding matches between certain graph templates and portions of the data-flow graphs. This graph fitting process is carried out by messages propagating asynchronously through the data-flow graph; thus computation is entirely data driven, without the need for any centralized control and centralized memory. This permits a potentially large number of independent processing elements to cooperate in solving a given query. © 1987, ACM. All rights reserved.",Data-driven computation; parallel logic programming,"ARTIFICIAL INTELLIGENCE; COMPUTER ARCHITECTURE; COMPUTER PROGRAMMING; DATA-DRIVEN COMPUTATION; DATA-FLOW ARCHITECTURE; KNOWLEDGE REPRESENTATION; LOGIC PROGRAMMING; COMPUTER SYSTEMS, DIGITAL"
Efficient and Correct Execution of Parallel Programs that Share Memory,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023994389&doi=10.1145%2f42190.42277&partnerID=40&md5=afbe2621f3dff063ecef878be76dfbdf,"In this paper we consider an optimization problem that arises in the execution of parallel programs on shared-memory multiple-instruction-stream, multiple-data-stream (MIMD) computers. A program on such machines consists of many sequential program segments, each executed by a single processor. These segments interact as they access shared variables. Access to memory is asynchronous, and memory accesses are not necessarily executed in the order they were issued. An execution is correct if it is sequentially consistent: It should seem as if all the instructions were executed sequentially, in an order obtained by interleaving the instruction streams of the processors. Sequential consistency can be enforced by delaying each access to shared memory until the previous access of the same processor has terminated. For performance reasons, however, we want to allow several accesses by the same processor to proceed concurrently. Our analysis finds a minimal set of delays that enforces sequential consistency. The analysis extends to interprocessor synchronization constraints and to code where blocks of operations have to execute atomically. We use a conflict graph similar to that used to schedule transactions in distributed databases. Our graph incorporates the order on operations given by the program text, enabling us to do without locks even when database conflict graphs would suggest that locks are necessary. Our work has implications for the design of multiprocessors; it offers new compiler optimization techniques for parallel languages that support shared variables. © 1988, ACM. All rights reserved.",Networks; parallel languages; PRAM; shared memory; shared variables,"COMPUTER PROGRAMMING - Optimization; COMPUTER SYSTEMS, DIGITAL - Parallel Processing; MIMD COMPUTERS; SHARED MEMORY PROGRAMS; COMPUTER SYSTEMS PROGRAMMING"
Incremental Data-Flow Analysis Algorithms,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976680637&doi=10.1145%2f42192.42193&partnerID=40&md5=1a70be4d565ab88a2c9b60009220656d,"An incremental update algorithm modifies the solution of a problem that has been changed, rather than re-solving the entire problem. ACINCF and ACINCB are incremental update algorithms for forward and backward data-flow analysis, respectively, based on our equations model of Allen-Cocke interval analysis. In addition, we have studied their performance on a “nontoy” structured programming language L. Given a set of localized program changes in a program written in L, we identify a priori the nodes in its flow graph whose corresponding data-flow equations may be affected by the changes. We characterize these possibly affected nodes by their corresponding program structures and their relation to the original change sites, and do so without actually performing the incremental updates. Our results can be refined to characterize the reduced equations possibly affected if structured loop exit mechanisms are used, either singly or together, thereby relating richness of programming language usage to the ease of incremental updating. © 1988, ACM. All rights reserved.",Data-flow analysis; elimination methods,
Automatic Translation of FORTRAN Programs to Vector Form,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023438847&doi=10.1145%2f29873.29875&partnerID=40&md5=dac274d16b01eab2fa0dc549f6164ee8,"The recent success of vector computers such as the Cray-1 and array processors such as those manufactured by Floating Point Systems has increased interest in making vector operations available to the FORTRAN programmer. The FORTRAN standards committee is currently considering a successor to FORTRAN 77, usually called FORTRAN 8x, that will permit the programmer to explicitly specify vector and array operations. Although FORTRAN 8x will make it convenient to specify explicit vector operations in new programs, it does little for existing code. In order to benefit from the power of vector hardware, existing programs will need to be rewritten in some language (presumably FORTRAN 8x) that permits the explicit specification of vector operations. One way to avoid a massive manual recoding effort is to provide a translator that discovers the parallelism implicit in a FORTRAN program and automatically rewrites that program in FORTRAN 8x. Such a translation from FORTRAN to FORTRAN 8x is not straightforward because FORTRAN DO loops are not always semantically equivalent to the corresponding FORTRAN 8x parallel operation. The semantic difference between these two constructs is precisely captured by the concept of dependence. A translation from FORTRAN to FORTRAN 8x preserves the semantics of the original program if it preserves the dependences in that program. The theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form. Dependence is defined and characterized in terms of the conditions that give rise to it; accurate tests to determine dependence are presented; and transformations that use dependence to uncover additional parallelism are discussed. © 1987, ACM. All rights reserved.",detection of parallelism; FORTRAN; language translators; vector computing,COMPUTER PROGRAMMING LANGUAGES - FORTRAN; AUTOMATIC PROGRAMMING; CONCURRENT PROGRAMMING; VECTOR COMPUTING; COMPUTER OPERATING SYSTEMS
Algorithmic Specifications: A Constructive Specification Method for Abstract Data Types,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023438848&doi=10.1145%2f29873.30399&partnerID=40&md5=3f2ac1b321ccc6c4ba804f3b6b341e71,"This paper presents a new specification method for abstract data types and a pertaining logic. The specification method proposed differs from the classical algebraic one by its constructive, yet abstract nature. Although it leads to a different style in specification, the method avoids some fundamental problems inherent in the algebraic specification method. The logic proposed is essentially a first-order logic for strict (partial) functions. It allows in particular the expression of the semantic conditions guaranteeing the consistency of a specification. © 1987, ACM. All rights reserved.",Algebraic specification; constructive specification; specification language,COMPUTER PROGRAMMING LANGUAGES; DATA PROCESSING - Data Structures; ABSTRACT DATA TYPES (ADT); ALGEBRAIC SPECIFICATION; PROGRAM CONSTRUCTS; COMPUTER SOFTWARE
Efficient Algorithms for Automatic Construction and Compactification of Parsing,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023439377&doi=10.1145%2f29873.29876&partnerID=40&md5=34e5b91b5a2af615a0e1317f18f3a5b9,"Several computational problems about grammars are studied. Efficient algorithms are presented for the problems of (1) determining, for a given semantic grammar, if there exists a related parsing grammar in some specified grammar class, and (2) finding such a related parsing grammar when one exists. The two grammars are to be related by mergers of nonterminals and/or terminals. Efficient algorithms are presented for most of the grammar classes used in compilers. We also study the problem of (3) determining which terminals of a grammar are good candidates for merger into common lexical tokens of the corresponding parsing grammar. © 1987, ACM. All rights reserved.","Grammar coverings; grammar design; grammar homomorphism; grammar interpretation; grammar transformation; lexical tokens, LL(l); LR(l); precedence grammars; SLR(1)",COMPUTER OPERATING SYSTEMS - Program Compilers; COMPUTER PROGRAMMING - Algorithms; PARSING; AUTOMATA THEORY
ACE: An Automatic Complexity Evaluator,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023994930&doi=10.1145%2f42190.42347&partnerID=40&md5=3ed4b8246d3b3675175736ccc83b5c32,"There has been a great deal of research done on the evaluation of the complexity of particular algorithms; little effort, however, has been devoted to the mechanization of this evaluation. The ACE (Automatic Complexity Evaluator) system is able to analyze reasonably large programs, like sorting programs, in a fully mechanical way. A time-complexity function is derived from the initial functional program. This function is transformed into its nonrecursive equivalent according to MacCarthy's recursion induction principle, using a predefined library of recursive definitions. As the complexity is not a decidable property, this transformation will not be possible in all cases. The richer the predefined library is, the more likely the system is to succeed. The operations performed by ACE are described and the use of the system is illustrated with the analysis of a sorting algorithm. Related works and further improvements are discussed in the conclusion. © 1988, ACM. All rights reserved.",Mechanical analysis; program transformation; recursion induction principle; worst-case complexity,COMPUTER PROGRAMMING - Algorithms; ACE SYSTEM; ALGORITHM COMPLEXITY EVALUATION; AUTOMATIC COMPLEXITY EVALUATOR; COMPUTER SOFTWARE
"Systems Semantics: Principles, Applications, and Implementation",1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023844052&doi=10.1145%2f42192.45067&partnerID=40&md5=e13901fd693261cf2983e1ad1e6c7282,"Systems semantics extends the denotational semantics of programming languages to a semantics for the description of arbitrary systems, including objects that are not computations in any sense. By defining different meaning functions, the same formal description may be used to denote different system properties, such as structure, behavior, component cost, and performance aspects (e.g., timing). The definition of these semantic functions also provides guidance in language design, in particular for the match between language constructs and the system concepts to be expressed. Aiming at compositionality ensures useful properties for formal manipulation. In this fashion, the meaning functions can be made sufficiently simple to serve not only as a direct implementation on a machine but also as rules for reasoning about systems in a transformational manner. As the applications show, however, compositionality can be ensured only through careful consideration of the characteristics of the flow of information inside the system. Two classes of application are discussed: Unidirectional systems, in particular digital systems without feedback (combinational) and with feedback (sequential), and a certain class of analog systems. Nonunidirectional systems, in particular two-port analog networks. The emphasis will be on the functional style of description and on formal reasoning (theorem proving, derivation of properties). Implementation and rapid prototyping strategies in various system description environments are also briefly discussed. These would permit the concepts of system semantics to be explored without the need for a complete implementation. © 1988, ACM. All rights reserved.",Analog circuits; behavioral interpretation; bidirectional systems; digital circuits; formal description; models; structural interpretation; system semantics; unidirectional systems,COMPUTER AIDED ENGINEERING; COMPUTER HARDWARE DESCRIPTION LANGUAGES; COMPUTER PROGRAMMING LANGUAGES; COMPUTER SOFTWARE - Software Engineering; KNOWLEDGE REPRESENTATION; SOFTWARE DEVELOPMENT ENVIRONMENT; SYSTEMS SEMANTICS; LOGIC DESIGN
Type Extensions,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023994278&doi=10.1145%2f42190.46167&partnerID=40&md5=bde7a2aa65f3e90b6ccd513ac00088a1,"Software systems represent a hierarchy of modules. Client modules contain sets of procedures that extend the capabilities of imported modules. This concept of extension is here applied to data types. Extended types are related to their ancestor in terms of a hierarchy. Variables of an extended type are compatible with variables of the ancestor type. This scheme is expressed by three language constructs only: the declaration of extended record types, the type test, and the type guard. The facility of extended types, which closely resembles the class concept, is defined in rigorous and concise terms, and an efficient implementation is presented. © 1988, ACM. All rights reserved.",Extensible data type; Modula-2,COMPUTER PROGRAMMING LANGUAGES; DATA TYPES; TYPE EXTENSION; COMPUTER SOFTWARE
A Mathematical Approach to Nondeterminism in Data Types,1988,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023825717&doi=10.1145%2f42192.42194&partnerID=40&md5=f559701e7f40664d7a20186490a2a7d5,"The theory of abstract data types is generalized to the case of nondeterministic operations (set-valuedfunctions). Since the nondeterminism of operations may be coupled, signatures are extended so that operations can have results in Cartesian products. Input/output behavior is used to characterize implementation of one model by another. It is described by means of accumulated arrows, which form a generalization of the term algebra. Morphisms of nondeterministic models are introduced. Both innovations prove to be powerful tools in the analysis of input/output behavior. Extraction equivalence and observable equivalence of values are investigated. Quotient models for such equivalence relations are constructed. The equivalence relations are compared with each other, with separation of values by means of experiments, and with the separation property that characterizes a terminal model. Examples are given to show that the four concepts are different. In deterministic models the concepts coincide. © 1988, ACM. All rights reserved.",Abstract data type; behavioral equivalence; distinguishable; extraction equivalence; nondeterminism; nondeterministic data type; observable equivalence; signature; term algebra; terminal model; value consistency,AUTOMATA THEORY - Finite Automata; DATA PROCESSING - Data Structures; MATHEMATICAL TECHNIQUES - Applications; ABSTRACT DATA TYPES; COMPUTATION BY ABSTRACT DEVICES; COMPUTER PROGRAMMING LANGUAGES
A Generalized Iterative Construct and Its Semantics,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023437042&doi=10.1145%2f29873.30391&partnerID=40&md5=503778b2086d6c7975858c721abc07d9,"A new programming language construct, called DOupon, subsumes Dijkstra's selective (IF) and iterative (DO) constructs. DOupon has a predicate transformer approximately equivalent in complexity to that for DO. In addition, it simplifies a wide variety of algorithms, in form as well as in discovery and proof. Several theorems are demonstrated that are useful for correctness proofs and for optimization and that are not applicable to DO or IF. The general usefulness of DOupon derives from a separation of the concerns of invariance, through iteration, from those of termination. © 1987, ACM. All rights reserved.",Iterative constructs; predicate transformer,COMPUTER PROGRAMMING LANGUAGES - Theory; COMPUTER PROGRAM VERIFICATION; CORRECTNESS PROOFS; ITERATIVE CONSTRUCTS; COMPUTER SOFTWARE
An Editor for Revision Control,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023330867&doi=10.1145%2f22719.22948&partnerID=40&md5=85e4e32d72443fde1f0061fe528e2422,"Programming environments support revision control in several guises. Explicitly, revision control software manages the trees of revisions that grow as software is modified. Implicitly, editors retain past versions by automatically saving backup copies and by allowing users to undo commands. This paper describes an editor that offers a uniform solution to these problems by never destroying the old version of the file being edited. It represents files using a generalization of AVL trees called “AVL dags,” which makes it affordable to automatically retain past versions of files. Automatic retention makes revision maintenance transparent to users. The editor also uses the same command language to edit both text and revision trees. © 1987, ACM. All rights reserved.",Editor; persistent data type; revision control; undo command,DATA PROCESSING - Data Structures; APPLICATIVE PROGRAMMING; PROGRAMMING ENVIRONMENTS; TEXT PROCESSING; COMPUTER SOFTWARE
Soundness of Hoare's logic: An Automated Proof Using LCF,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023246901&doi=10.1145%2f9758.11326&partnerID=40&md5=2f88c0fe2beadf9dabb1de650de3902b,"This paper presents a natural deduction proof of Hoare's logic carried out by the Edinburgh LCF theorem prover. The emphasis is on the way Hoare's theory is presented to the LCF, which looks very much like an exposition of syntax and semantics to human readers; and on the programmable heuristics (tactics). We also discuss some problems and possible improvements to the LCF. © 1987, ACM. All rights reserved.",Automatic proof; Edinburgh LCF; Hoare's logic; soundness,ARTIFICIAL INTELLIGENCE; AUTOMATA THEORY - Theorem Proving; AUTOMATIC PROOF; FORMAL LANGUAGES; HOARE'S LOGIC; COMPUTER METATHEORY
A Methodology for Synthesis of Recursive Functional Programs,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023386653&doi=10.1145%2f24039.24071&partnerID=40&md5=ccd0a371ab23b345a043023fc9c3bd95,"John Backus introduced the Functional Programming (FP) system, the variable-free applicative system having reduction semantics. Backus has also introduced a unique expansion technique for reasoning about a class of recursive FP programs. As a natural outgrowth of this expansion technique, an FP program synthesis methodology is described in this paper. The methodology synthesizes recursive FP programs of the form f = p →, q; E(f. h) from their preformulated case-by-case descriptions, which in turn come from given input-output example specifications. After explaining the methodology informally, formalization in the form of a definition and a synthesis theorem is introduced. A sufficient condition for the functional form E, for successful synthesis under the present methodology, is obtained structurally. Several illustrative examples of synthesis are also included. © 1987, ACM. All rights reserved.",Example specification; FP systems; least fixed point; recursive program; transformation,AUTOMATA THEORY; COMPUTER PROGRAMMING; COMPUTER SOFTWARE - Software Engineering; DENOTATIONAL SEMANTICS; FUNCTIONAL PROGRAMMING (FP); PROGRAM SYNTHESIS; RECURSIVE FUNCTIONAL PROGRAMS; COMPUTER METATHEORY
Data Descriptors: A Compile-Time Model of Data and Addressing,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023386084&doi=10.1145%2f24039.24051&partnerID=40&md5=5a39789caf515933ac1f8374fc1f135a,"Data descriptors, which have evolved from Wilcox's value descriptors [16], are a notation for representing run-time data objects at compile time. One of the principal reasons for developing this notation was to aid in the rapid construction of code generators, especially for new microprocessors. Each data descriptor contains a base, a displacement, and a level of indirection. For example, a variable x lying at displacement 28 from base register B3 is represented by this data descriptor: @B3.28. The general form of a data descriptor is @kb.d.i where k gives the number of levels of indirection, b is a base, d is a displacement, and I is an index. Data descriptors are convenient for representing addressing in Fortran (with static allocation and common blocks), in Pascal and Turing (with automatic allocation and stack frames), and in more general languages such as Euclid and PL/I. This generality of data descriptors allows code generation to be largely independent of the source language. Data descriptors are able to encode the addressing modes of typical computer architectures such as the IBM 360 and the PDP-11. This generality of data descriptors allows code generation to be largely machine independent. This paper gives a machine independent method of storage allocation that uses data descriptors. Techniques are given for local optimization of basic arithmetic and addressing code using data descriptors. Target machine dependencies are isolated so that the part of the code generator that handles high-level addressing (such as subscripting) is machine independent. The techniques described in this paper have proven effective in the rapid development of a number of production code generators. © 1987, ACM. All rights reserved.",Addressability; addressing modes; array subscripting; base displacement addressing; code generation; code optimization; compiler structure; compilers; data alignment; data descriptor; display based addressing; language translators; machine idioms; machineindependent code generation; optimal addition; portable compiler; storage allocation,COMPUTER OPERATING SYSTEMS - Storage Allocation; DATA DESCRIPTORS; HIGH-LEVEL ADDRESSING; PRODUCTION CODE GENERATORS; VALUE DESCRIPTORS; WILCOX'S VALUE DESCRIPTORS; COMPUTER PROGRAMMING LANGUAGES
Sublinear-Space Evaluation Algorithms for Attribute Grammars,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023386083&doi=10.1145%2f24039.214529&partnerID=40&md5=d7bb799885b0247482466876c657c9c3,"A major drawback of attribute-grammar-based systems is that they are profligate consumers of storage. This paper concerns new storage-management techniques that reduce the number of attribute values retained at any stage of attribute evaluation; it presents an algorithm for evaluating an n-attribute tree that never retains more than O(log n) attribute values. This method is optimal, although it may require nonlinear time. A second algorithm, which never retains more than O(<√n) attribute values, is also presented, both as an introduction to the O(log n) method and because it works in linear time. © 1987, ACM. All rights reserved.",Attribute evaluation; attribute grammar; language-based editor; spill file,AUTOMATA THEORY - Context Free Grammars; COMPUTER OPERATING SYSTEMS - Storage Allocation; COMPUTER PROGRAMMING - Algorithms; ATTRIBUTE GRAMMAR; LANGUAGE-BASED EDITOR; SEMANTICS; SPILL FILE; COMPUTER METATHEORY
DIB—A Distributed Implementation of Backtracking,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023331176&doi=10.1145%2f22719.24067&partnerID=40&md5=10390c7cbea2f1e1b8f81dfadc01dad0,"DIB is a general-purpose package that allows a wide range of applications such as recursive backtrack, branch and bound, and alpha-beta search to be implemented on a multicomputer. It is very easy to use. The application program needs to specify only the root of the recursion tree, the computation to be performed at each node, and how to generate children at each node. In addition, the application program may optionally specify how to synthesize values of tree nodes from their children's values and how to disseminate information (such as bounds) either globally or locally in the tree. DIB uses a distributed algorithm, transparent to the application programmer, that divides the problem into subproblems and dynamically allocates them to any number of (potentially nonhomogeneous) machines. This algorithm requires only minimal support from the distributed operating system. DIB can recover from failures of machines even if they are not detected. DIB currently runs on the Crystal multicomputer at the University of Wisconsin-Madison. Many applications have been implemented quite easily, including exhaustive traversal (N queens, knight's tour, negamax tree evaluation), branch and bound (traveling salesman) and alpha-beta search (the game of NIM). Speedup is excellent for exhaustive traversal and quite good for branch and bound. © 1987, ACM. All rights reserved.",Backtracking; branch and bound; distributed algorithms; localarea networks; networks of workstations,"COMPUTER NETWORKS - Local Networks; COMPUTER OPERATING SYSTEMS - Reliability; COMPUTER SYSTEMS, DIGITAL - Distributed; BACKTRACKING; CONCURRENT PROGRAMMING STRUCTURES; DISTRIBUTED ALGORITHMS; COMPUTERS, DIGITAL"
The Multiway Rendezvous,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023384865&doi=10.1145%2f24039.24050&partnerID=40&md5=9350a880344edaab6cc6592494d806a3,"The multiway rendezvous is a natural generalization of the rendezvous in which more than two processes may participate. The utility of the multiway rendezvous is illustrated by solutions to a variety of problems. To make their simplicity apparent, these solutions are written using a construct tailor-made to support the multiway rendezvous. The degree of support for multiway rendezvous applications by several well-known languages that support the two-way rendezvous is examined. Since such support for the multiway rendezvous is found to be inadequate, well-integrated extensions to these languages are considered that would help provide such support. © 1987, ACM. All rights reserved.",Communication; concurrency; data encapsulation; rendezvous; synchronization,COMPUTER PROGRAMMING LANGUAGES - Ada; DATABASE SYSTEMS - Query Languages; COMPACT; DATA ENCAPSULATION; LANGUAGE CONSTRUCTS; MULTIWAY RENDEZVOUS; SYNCHRONIZATION; COMPUTER SYSTEMS PROGRAMMING
The Program Dependence Graph and Its Use in Optimization,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023385308&doi=10.1145%2f24039.24041&partnerID=40&md5=32383da6f852c370ba502b3aa4ed9ef5,"In this paper we present an intermediate program representation, called the program dependence graph (PDG), that makes explicit both the data and control dependences for each operation in a program. Data dependences have been used to represent only the relevant data flow relationships of a program. Control dependences are introduced to analogously represent only the essential control flow relationships of a program. Control dependences are derived from the usual control flow graph. Many traditional optimizations operate more efficiently on the PDG. Since dependences in the PDG connect computationally related parts of the program, a single walk of these dependences is sufficient to perform many optimizations. The PDG allows transformations such as vectorization, that previously required special treatment of control dependence, to be performed in a manner that is uniform for both control and data dependences. Program transformations that require interaction of the two dependence types can also be easily handled with our representation. As an example, an incremental approach to modifying data dependences resulting from branch deletion or loop unrolling is introduced. The PDG supports incremental optimization, permitting transformations to be triggered by one another and applied only to affected dependences. © 1987, ACM. All rights reserved.",branch deletion; code motion; Data flow; debugging; dependence analysis; incremental data flow analysis; intermediate program representation; internal program form; loop fusion; loop unrolling; node splitting; parallelism; slicing; vectorization,COMPUTER METATHEORY; COMPUTER SYSTEMS PROGRAMMING - Theory; DATA PROCESSING - Data Structures; MATHEMATICAL TECHNIQUES - Graph Theory; COMPILER OPTIMIZATION; CONTROL FLOW GRAPH; INCREMENTAL DATA FLOW ANALYSIS; INTERMEDIATE PROGRAM REPRESENTATION; PROGRAM DEPENDENCE GRAPH (PDG); COMPUTER OPERATING SYSTEMS
On the Algebraic Definition of Programming Languages,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023213115&doi=10.1145%2f9758.10501&partnerID=40&md5=53d67a387274fe8f1ba52006731e392a,"The algebraic specification of the semantics of programming languages is outlined. Particular emphasis is given to the problem of specifying least-fixed points by first-order conditional equations. To cover this issue, the theory of specifying partial heterogeneous algebras by abstract data types is slightly extended by a more general notion of homomorphism. In this framework the semantics of programming languages can be uniquely specified in a purely algebraic way, using particular models of a hierarchy of abstract types. This approach is demonstrated for a simple procedural programming language. Several increasingly complex versions of iterations are treated and analyzed with respect to their theoretical consequences. Finally, as a complementary algebraic technique, transformational semantics is explained and applied to our examples. © 1987, ACM. All rights reserved.",Algebraic specification; program transformation; semantics,COMPUTER METATHEORY - Programming Theory; ALGEBRAIC SPECIFICATIONS; COMPUTER PROGRAMMING LANGUAGES
The Geometry of Semaphore Programs,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023213116&doi=10.1145%2f9758.9759&partnerID=40&md5=4359f0f42f69e9590d83c3de4e7ef5c6,"Synchronization errors in concurrent programs are notoriously difficult to find and correct. Deadlock, partial deadlock, and unsafeness are conditions that constitute such errors. A model of concurrent semaphore programs based on multidimensional, solid geometry is presented. While previously reported geometric models are restricted to two-process mutual exclusion problems, the model described here applies to a broader class of synchronization problems. The model is shown to be exact for systems composed of an arbitrary, yet fixed number of concurrent processes, each consisting of a straight line sequence of arbitrarily ordered semaphore operations. © 1987, ACM. All rights reserved.",semaphore programs; Static deadlock detection,COMPUTER SYSTEMS PROGRAMMING; CONCURRENT PROGRAMMING; SEMAPHORE PROGRAMS; STATIC DEADLOCK DETECTION; COMPUTER OPERATING SYSTEMS
Writing Larch Interface Language Specifications,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023215093&doi=10.1145%2f9758.10500&partnerID=40&md5=7069763ec10f338ba8f461370271aa68,"Current research in specifications is emphasizing the practical use of formal specifications in program design. One way to encourage their use in practice is to provide specification languages that are accessible to both designers and programmers. With this goal in mind, the Larch family of formal specification languages has evolved to support a two-tiered approach to writing specifications. This approach separates the specification of state transformations and programming language dependencies from the specification of underlying abstractions. Thus, each member of the Larch family has a subset derived from a programming language and another subset independent of any programming languages. We call the former interface languages, and the latter the Larch Shared Language. This paper focuses on Larch interface language specifications. Through examples, we illustrate some salient features of Larch/CLU, a Larch interface language for the programming language CLU. We give an example of writing an interface specification following the two-tiered approach and discuss in detail issues involved in writing interface specifications and their interaction with their Shared Language components. © 1987, ACM. All rights reserved.",CLU; Larch Shared Language; two-tiered specification approach,COMPUTER PROGRAMMING LANGUAGES - Design; FORMAL SPECIFICATION LANGUAGES; COMPUTER SOFTWARE
Language Support for the Specification and Development of Composite Systems,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023326967&doi=10.1145%2f22719.22947&partnerID=40&md5=bd5b31c996e9ab32cae415a02414207d,"When a complex system is to be realized as a combination of interacting components, development of those components should commence from a specification of the behavior required of the composite system. A separate specification should be used to describe the decomposition of that system into components. The first phase of implementation from a specification in this style is the derivation of the individual component behaviors implied by these specifications. The virtues of this approach to specification are expounded, and specification language features that are supportive of it are presented. It is shown how these are incorporated in the specification language Gist, which our group has developed. These issues are illustrated in a development of a controller for elevators serving passengers in a multistory building. © 1987, ACM. All rights reserved.",Composite systems; distributed decomposition; interactive systems,"COMPUTER PROGRAMMING LANGUAGES - Design; COMPUTER SYSTEMS, DIGITAL - Interactive Operation; COMPOSITE SYSTEMS; SOFTWARE DEVELOPMENT; SPECIFICATION TECHNIQUES; COMPUTER SOFTWARE"
IDL: Sharing Intermediate Representations,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023383221&doi=10.1145%2f24039.24040&partnerID=40&md5=5e5a3735cd2c2aeea2189a8dc922a0d2,"IDL (Interface Description Language) is a practical and useful tool for controlling the exchange of structured data between different components of a large system. IDL is a notation for describing collections of programs and the data structures through which they communicate. Using IDL, a designer gives abstract descriptions of data structures, together with representation specifications that specialize the abstract structures for particular programs. A tool, the IDL translator, generates readers and writers that map between concrete internal representations and abstract exchange representations. © 1987, ACM. All rights reserved.",Data representation; data structures; input/output; software engineering; system design,COMPUTER PROGRAMMING LANGUAGES; COMPUTER SOFTWARE - Software Engineering; DATABASE SYSTEMS - Management; MATHEMATICAL TECHNIQUES - Graph Theory; ABSTRACT DESCRIPTIONS; DATA REPRESENTATION; IDL; IDL TRANSLATOR; INTERFACE DESCRIPTION LANGUAGE; DATA PROCESSING
Parsing and Compiling Using Prolog,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023327429&doi=10.1145%2f22719.22946&partnerID=40&md5=2e51b24b76852a75a0397577a0115cb4,"This paper presents the material needed for exposing the reader to the advantages of using Prolog as a language for describing succinctly most of the algorithms needed in prototyping and implementing compilers or producing tools that facilitate this task. The available published material on the subject describes one particular approach in implementing compilers using Prolog. It consists of coupling actions to recursive descent parsers to produce syntax-trees which are subsequently utilized in guiding the generation of assembly language code. Although this remains a worthwhile approach, there is a host of possibilities for Prolog usage in compiler construction. The primary aim of this paper is to demonstrate the use of Prolog in parsing and compiling. A second, but equally important, goal of this paper is to show that Prolog is a labor-saving tool in prototyping and implementing many non-numerical algorithms which arise in compiling, and whose description using Prolog is not available in the literature. The paper discusses the use of unification and nondeterminism in compiler writing as well as means to bypass these (costly) features when they are deemed unnecessary. Topics covered include bottom-up and top-down parsers, syntax-directed translation, grammar properties, parser generation, code generation, and optimizations. Newly proposed features that are useful in compiler construction are also discussed. A knowledge of Prolog is assumed. © 1987, ACM. All rights reserved.",Code generation; grammar properties; optimization; parsing,COMPUTER PROGRAMMING LANGUAGES; COMPUTER SOFTWARE - Software Engineering; CODE GENERATION; LOGIC PROGRAMMING; PARSING; PROLOG; COMPUTER OPERATING SYSTEMS
Retargetable Microcode Synthesis,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023330961&doi=10.1145%2f22719.23717&partnerID=40&md5=561e695638fc27dc5be2e1ae48ee8ab8,"Most work on automating the translation of high-level microprogramming languages into microcode has dealt with lexical and syntactic analysis and the use of manually produced macro tables for code generation. We describe an approach to and some results on the formalization and automation of the more difficult problem of retargeting local code generation in a machine-independent, optimizing microcode synthesis system. Whereas this problem is similar in many ways to that of retargeting local code generation in high-level language compilers, there are some major differences that call for new approaches. The primary issues addressed in this paper are the representation of target microprogrammable machines, the intermediate representation of local microprogram function, and general algorithmic methods for deriving local microcode from target machine and microcode function specifications. Of particular interest are the use of formal semantics and data flow principles in achieving both a general and reasonably efficient solution. Examples of the modeling of a representative horizontal machine (the PUMA) and the generation of microcode for the PUMA machine model from our working implementation are presented. © 1987, ACM. All rights reserved.",Data antidependency; data dependency; flow graph; machine description; microcode compaction; microcode generation; microinstruction set processors; microprogramming,COMPUTER ARCHITECTURE - Microprogramming; COMPUTER PROGRAMMING LANGUAGES - Design; COMPILER GENERATORS; MACHINE-INDEPENDENT MICROCODE GENERATION; TRANSLATOR WRITING SYSTEMS; COMPUTER OPERATING SYSTEMS
A Practical Method for LR and LL Syntactic Error Diagnosis and Recovery,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023327026&doi=10.1145%2f22719.22720&partnerID=40&md5=68ab4765e4e350850e53790280ce6aa4,"This paper presents a powerful, practical, and essentially language-independent syntactic error diagnosis and recovery method that is applicable within the frameworks of LR and LL parsing. The method generally issues accurate diagnoses even where multiple errors occur within close proximity, yet seldom issues spurious error messages. It employs a new technique, parse action deferral, that allows the most appropriate recovery in cases where this would ordinarily be precluded by late detection of the error. The method is practical in that it does not impose substantial space or time overhead on the parsing of correct programs, and in that its time efficiency in processing an error allows for its incorporation in a production compiler. The method is language independent, but it does allow for tuning with respect to particular languages and implementations through the setting of language-specific parameters. © 1987, ACM. All rights reserved.",LL parser; LR parser; syntactic error diagnosis; syntactic error recovery; syntactic error repair,COMPUTER OPERATING SYSTEMS; ERROR RECOVERY; PARSING; PROGRAMMING ENVIRONMENTS; COMPUTER SOFTWARE
An Axiomatic Treatment of Exception Handling in an Expression-Oriented Language,1987,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023384419&doi=10.1145%2f24039.24052&partnerID=40&md5=5ddfb0c6902cee88e0157b4b0d0d18cc,"An axiomatic semantic definition is given of the replacement model of exception handling in an expression-oriented language. These semantics require only two new proof rules for the most general case. An example is given of a program fragment using this model of exception handling, and these rules are used to verify the consistency of the fragment and its specification. © 1987, ACM. All rights reserved.",Algol 68; aliasing; axiomatic semantics; exception handling; expression language; program specification; replacement model; side effect,COMPUTER METATHEORY - Programming Theory; COMPUTER SOFTWARE - Software Engineering; ABSTRACT DATA TYPES; ALGOL 68; AXIOMATIC SEMANTICS; EXPRESSION LANGUAGE; REPLACEMENT MODEL; COMPUTER PROGRAMMING LANGUAGES
The ML Approach to the Readable All-Purpose Language,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022705915&doi=10.1145%2f5397.5918&partnerID=40&md5=d0a79baea9b9080c21022693142ae46a,"The ideal computer language is seen as one that would be as readable as natural language, and so adaptable that it could serve as the only language a user need ever know. An approach to language design has emerged that shows promise of allowing one to come much closer to that ideal than might reasonably have been expected. Using this approach, a language referred to as ML has been developed, and has been implemented as a language-creation system in which user-defined procedures invoked at translation time translate the source to some object code. In this way the user can define both the syntax and the semantics of the source language. Both language and implementation are capable of further development. This paper describes the approach, the language, and the implementation and recommends areas for further work. © 1986, ACM. All rights reserved.",Adaptability; compile-time procedures; context; environment; extensibility; language design; language-creation systems; macro expansion; readability; textual domains,COMPUTER OPERATING SYSTEMS - Program Processors; LANGUAGE-CREATION SYSTEMS; PROGRAMMING ENVIRONMENTS; COMPUTER PROGRAMMING LANGUAGES
The Concept of a Supercompiler,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022754405&doi=10.1145%2f5956.5957&partnerID=40&md5=c5af749196179cd3db37163539522f61,"A supercompiler is a program transformer of a certain type. It traces the possible generalized histories of computation by the original program, and compiles an equivalent program, reducing in the process the redundancy that could be present in the original program. The nature of the redundancy that can be eliminated by supercompilation may be various, e.g., some variables might have predefined values (as in partial evaluation), or the structure of control transfer could be made more efficient (as in lazy evaluation), or it could simply be the fact that the same variable is used more than once. The general principles of supercompilation are described and compared with the usual approach to program transformation as a stepwise application of a number of equivalence rules. It is argued that the language Refal serves the needs of supercompilation best. Refal is formally defined and compared with Prolog and other languages. Examples are given of the operation of a Refal supercompiler implemented at CCNY on an IBM/370. © 1986, ACM. All rights reserved.",driving; lazy evaluation; metasystem transition; Program transformation; Prolog; Refal; supercompiler,COMPUTER OPERATING SYSTEMS - Program Compilers; COMPUTER PROGRAMMING LANGUAGES - Design; LAZY EVALUATION; SUPERCOMPILERS; COMPUTER METATHEORY
Correctness Proofs of Distributed Termination Algorithms,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022757530&doi=10.1145%2f5956.6000&partnerID=40&md5=03683f74b3ef3574f0af3ac2bf8962a6,"The problem of correctness of the solutions to the distributed termination problem of Francez [7] is addressed. Correctness criteria are formalized in the customary framework for program correctness. A very simple proof method is proposed and applied to show correctness of a solution to the problem. It allows us to reason about liveness properties of temporal logic (see, e.g., Manna and Pnueli [12]) using a new notion of weak total correctness. © 1986, ACM. All rights reserved.",CSP; deadlock; global invariant; weak total correctness,COMPUTER METATHEORY - Programming Theory; COMPUTER SOFTWARE - Software Engineering; COMPUTER PROGRAM VERIFICATION; CONCURRENT PROGRAMMING; COMPUTER PROGRAMMING
Comments on Georgeff's “Transformations and Reduction Strategies for Typed Lambda Expressions”,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976699777&doi=10.1145%2f5956.215007&partnerID=40&md5=f5e27f5df64ad4470d0aa306f3829aa8,"In his recent paper, Georgeff [1] considers the evaluation of lambda expres sions (with reducing reflexive types) on a variant of Landin's SECD machine. It is observed that for so-called simple expressions the SECD machine will construct stack-like environment structures, whereas, in general, they are tree-like. Georgeff then explores the idea of transforming any (typed) lambda expression into simple form and then using the SECD machine for these expressions. However, such transformations might be undesirable if the language is going to be interpreted directly. This leads Georgeff to modify the SECD machine such that it constructs stack-like environments for all expressions. Briefly, the idea in this modification is to let the machine construct over-applied closures for function-valued expressions in operand positions and to let it apply the closure in situ in the case of function-valued expressions in operator positions. The construction of overapplied closures implies that tree- like environment structures are avoided. Georgeff claims that by applying expressions in operator positions in situ it is avoided that operand values are “needlessly popped from the stack during creation of the overapplied closure, only to be reinstated on entry to the closure” [ 1, p. 620]. However, the example of Figure 1 shows that Georgeff's construction does not overcome this problem: the transitions 14, 15, and 16 move the on constant 3 from the stack to the closure and back to the stack. Intuitively, the reason is that the construction does not recognize correctly whether a sub-expression in operator position is in fact “basic-valued.” An expression (or, more precisely, its closure) occurring in operator position will look for its remaining arguments on the current stack and on the stacks of the dump. The prediction of the number of available arguments is important in order to determine whether the expression is “basic-valued,” and should therefore be treated specially. Georgeff suggests the following function for counting the number of avail-able arguments on the stacks:def totapps (ST)let (S, E, C, D) = STlet n = (napps C)if n = 0 then nelse (+ n (totapps D))endwhere the function (napps C) returns the number of consecutive apply operators at the beginning of the control C. For the configuration of line 14 of Figure 1 this gives totapps (…) = 2 napps (AάA) = 1 and totapps (d1) = 1 — this means that the closure [(βγ), u, (2), e1] can find 2 arguments on the stacks although its functionality is 1 Hence, the predicate, basic-valued, fails, although it ought to succeed. We suggest replacing the function above with def totapps (ST)let (S, E, C, D) = STlet n = (napps C)if length C ≠ n then, nelse (+ n (totapps D))endwhere length C is the length of the list C. The intuition behind this suggestion is that, if the control C of some configuration is not just a list of apply symbols, then the subexpression at hand will be turned into operand position before a basic value can be returned. Returning to the example mentioned above, note that we now get totapps (…) = 1 because napps (AάA) = 1 and length (AάA) ≠ 1, and the needless movements on the stack are avoided. © 1986, ACM. All rights reserved.",,
A Structural View of the Cedar Programming Environment,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022795698&doi=10.1145%2f6465.6466&partnerID=40&md5=8e129089984d08468738dfd6b0ac11fa,"This paper presents an overview of the Cedar programming environment, focusing on its overall structure—that is, the major components of Cedar and the way they are organized. Cedar supports the development of programs written in a single programming language, also called Cedar. Its primary purpose is to increase the productivity of programmers whose activities include experimental programming and the development of prototype software systems for a high-performance personal computer. The paper emphasizes the extent to which the Cedar language, with run-time support, has influenced the organization, flexibility, usefulness, and stability of the Cedar environment. It highlights the novel system features of Cedar, including automatic storage management of dynamically allocated typed values, a run-time type system that provides run-time access to Cedar data type definitions and allows interpretive manipulation of typed values, and a powerful device-independent imaging modelthat supports the user interface facilities. Using these discussions to set the context, the paper addresses the language and system features and the methodologies used to facilitate the integration of Cedar applications. A comparison of Cedar with other programming environments further identifies areas where Cedar excels and areas where work remains to be done. © 1986, ACM. All rights reserved.",Experimental programming; integrated programming environment; open operating system; strongly typed programming language,COMPUTER OPERATING SYSTEMS; COMPUTER PROGRAMMING LANGUAGES - Design; INTEGRATED PROGRAMMING ENVIRONMENT; OPEN OPERATING SYSTEMS; STRONGLY TYPED PROGRAMMING LANGUAGES; COMPUTER SOFTWARE
Proving Systolic Systems Correct,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022757367&doi=10.1145%2f5956.5999&partnerID=40&md5=f03dcf3fb3a6f51d3dc226b1239f9bb3,"A language for describing communicating systems is described. It is sufficiently expressive to describe both the desired behavior of systems, their specifications, and their actual implementations in terms of simpler components. We say I satisfies S if 1 is a correct implementation of the specification S. We briefly discuss a semantic treatment of this notion of satisfaction, but the main emphasis of the paper is on a proof technique for proving statements of the form I satisfies S, based on syntactic transformations and induction. Two examples are given, both systolic systems from the literature. © 1986, ACM. All rights reserved.",Implementation; proof system; specification; systolic systems,COMPUTER METATHEORY - Programming Theory; COMPUTER SOFTWARE - Software Engineering; INTEGRATED CIRCUITS; COMMUNICATION SYSTEMS; COMPUTER PROGRAM VERIFICATION; SYSTOLIC SYSTEMS; COMPUTER PROGRAMMING LANGUAGES
An Example of Stepwise Refinement of Distributed Programs: Quiescence Detection,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022757368&doi=10.1145%2f5956.5958&partnerID=40&md5=475eb4be8d93df26086f78481f04e023,"We propose a methodology for the development of concurrent programs and apply it to an important class of problems: quiescence detection. The methodology is based on a novel view of programs. A key feature of the methodology is the separation of concerns between the core problem to be solved and details of the forms of concurrency employed in the target architecture and programming language. We begin development of concurrent programs by ignoring issues dealing with concurrency and introduce such concerns in manageable doses. The class of problems solved includes termination and deadlock detection. © 1986, ACM. All rights reserved.",Deadlock detection; program development; stepwise refinement; termination detection,COMPUTER METATHEORY - Programming Theory; COMPUTER OPERATING SYSTEMS - Program Processors; CONCURRENT PROGRAMMING; DEADLOCK DETECTION; PROGRAM DEVELOPMENT; STEPWISE REFINEMENT; COMPUTER PROGRAMMING
Automatic Verification of Finite-State Concurrent Systems Using Temporal Logic Specifications,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022706656&doi=10.1145%2f5397.5399&partnerID=40&md5=f68980632dc5eaa404c772af2b253b80,"We give an efficient procedure for verifying that a finite-state concurrent system meets a specification expressed in a (propositional, branching-time) temporal logic. Our algorithm has complexity linear in both the size of the specification and the size of the global state graph for the concurrent system. We also show how this approach can be adapted to handle fairness. We argue that our technique can provide a practical alternative to manual proof construction or use of a mechanical theorem prover for verifying many finite-state concurrent systems. Experimental results show that state machines with several hundred states can be checked in a matter of seconds. © 1986, ACM. All rights reserved.",Computation tree logic; finite-state concurrent systems; model checking; temporal logic,AUTOMATA THEORY - Formal Languages; COMPUTER METATHEORY - Formal Logic; COMPUTER SOFTWARE - Software Engineering; CONCURRENT PROGRAMMING; MATHEMATICAL LOGIC; TEMPORAL LOGIC; COMPUTER PROGRAMMING
The PSG System: From Formal Language Definitions to Interactive Programming Environments,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022795201&doi=10.1145%2f6465.20890&partnerID=40&md5=f1b42013bd5a2d9b17bd4e0a83cf8d86,"The PSG programming system generator developed at the Technical University of Darmstadt produces interactive, language-specific programming environments from formal language definitions. All language-dependent parts of the environment are generated from an entirely nonprocedural specification of the language's syntax, context conditions, and dynamic semantics. The generated environment consists of a language-based editor, supporting systematic program development by named program fragments, an interpreter, and a fragment library system. The major component of the environment is a full-screen editor, which allows both structure and text editing. In structure mode the editor guarantees prevention of both syntactic and semantic errors, whereas in textual mode it guarantees their immediate recognition. PSG editors employ a novel algorithm for incremental semantic analysis which is based on unification. The algorithm will immediately detect semantic errors even in incomplete program fragments. The dynamic semantics of the language are defined in denotational style using a functional language based on the lambda calculus. Program fragments are compiled to terms of the functional language which are executed by an interpreter. The PSG generator has been used to produce environments for Pascal, ALGOL 60, MODULA-2, and the formal language definition language itself. © 1986, ACM. All rights reserved.",Hybrid editor; unification-based incremental semantic analysis,"ARTIFICIAL INTELLIGENCE; AUTOMATA THEORY - Formal Languages; COMPUTER SYSTEMS, DIGITAL - Interactive Operation; COMPUTER PROGRAMMING ENVIRONMENT; PROGRAMMING SYSTEM GENERATOR(PSG); COMPUTER SOFTWARE"
Generating editing environments based on relations and attributes,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022795276&doi=10.1145%2f6465.6512&partnerID=40&md5=5dea79c41f3d51d69602d84a998a70f0,"The ability to generate language-based editors depends on the existence of a powerful, language-independent model of editing. A model is proposed in which programs are represented as attributed abstract-syntax trees with an associated relational database. Relations can depend on the state of the attributed tree, and attributes can depend on the values in relations, provided there are no circular dependencies. The power and the limitations of relational operations are demonstrated with respect to the support of static-semantic checking, anomaly detection, an interrogation facility, and the ability to define alternative program displays. The advantages of the hybrid system over both the purely relational and purely attribute-based systems are presented, and new algorithms are given for query evaluation and incremental view updating motivated by the efficiency requirements of interactive editing under the defined model. A prototype implementation of an editor generator is described, and suggestions for future research are made. © 1986, ACM. All rights reserved.",Attribute grammar; generating language-based editors; incremental view updating; relational database,AUTOMATA THEORY - Formal Languages; DATABASE SYSTEMS - Relational; COMPUTER PROGRAMMING ENVIRONMENT; COMPUTER SOFTWARE
The PegaSys System: Pictures as Formal Documentation of Large Programs,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022791519&doi=10.1145%2f6465.6478&partnerID=40&md5=5744db2082e7580f95d93eeed40f02fd,"PegsSys is an experimental system in which a user formally describes how a program is put together by means of a hierarchically structured collection of pictures, called formal dependency diagrams (FDDs). Icons in an FDD denote a wide range of data and control dependencies among the relatively coarse-grained entities contained in large programs. Dependencies considered atomic with respect to one level in a hierarchy can be decomposed into a number of dependencies at a lower level. Each dependency can be a predefined primitive of the FDD language or it can be defined by a PegaSys user in terms of the primitives. A PegsSys user is given the illusion that logical formulas do not exist, even though PegaSys reasons about them internally. This involves (1) checking whether an FDD is meaningful syntactically, (2) determining whether hierarchical refinements of an FDD are methodologically sound, and (3) deciding whether an FDD hierarchy is logically consistent with the program that it is intended to describe. The techniques used to provide these capabilities are discussed along with the logical properties that enable PegaSys to maintain the user illusion. © 1986, ACM. All rights reserved.",Ada; data and control dependencies; design hierarchy; graphical formalism; mechanical decision procedure; programming in the large,COMPUTER SYSTEMS PROGRAMMING - Documentation; COMPUTER PROGRAMMING ENVIRONMENT; FORMAL SOFTWARE DEVELOPMENT; PROGRAMMING SYSTEM GENERATOR(PSG); COMPUTER SOFTWARE
Smart Recompilation,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022756451&doi=10.1145%2f5956.5959&partnerID=40&md5=a573769c9f3ff98f6a17132a43348c13,"With current compiler technology, changing a single line in a large software system may trigger massive recompilations. If the change occurs in a file with shared declarations, all compilation units depending upon that file must be recompiled to assure consistency. However, many of those recompilations may be redundant, because the change may affect only a small fraction of the overall system. Smart recompilation is a method for reducing the set of modules that must be recompiled after a change. The method determines whether recompilation is necessary by isolating the differences among program modules and analyzing the effect of changes. The method is applicable to languages with and without overloading. A prototype demonstrates that the method is efficient and can be added with modest effort to existing compilers. © 1986, ACM. All rights reserved.",Intelligent software tools; overloading; separate compilation; type checking,COMPUTER PROGRAMMING LANGUAGES - Design; COMPUTER SOFTWARE - Software Engineering; PROGRAMMING ENVIRONMENT; COMPUTER OPERATING SYSTEMS
Toward Compiler Implementation Correctness Proofs,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022700871&doi=10.1145%2f5397.30847&partnerID=40&md5=4e3835a6f14d8f9671d1994bb992d7c8,"Aspect of the interaction between compiler theory and practice is addressed. Presented is a technique for the syntax-directed specification of compilers together with a method for proving the correctness of their parse-driven implementations. The subject matter is presented in an order-algebraic framework; while not strictly necessary, this approach imposes beneficial structure and modularity on the resulting specifications and implementation correctness proofs. Compilers are specified using an order-algebraic definition of attribute grammars. A practical class of compiler implementations is considered, consisting of those driven by LR(k) or LL(k) parsers which cause a sequence of translation routine activations to modify a suitably initialized collection of data structures (called a translation environment). The implementation correctness criterion consists of appropriately comparing, for each source program, the corresponding object program (contained in the final translation environment) produced by the compiler implementation to the object program dictated by the compiler specification. Provided that suitable intermediate assertions (called translation invariants) are supplied, the program consisting of the (parse-induced) sequence of translation routine activations can be proven partially correct via standard inductive assertion methods. © 1986, ACM. All rights reserved.",Attribute grammar; compiler correctness; compiler implementation; compiler specification; program correctness; program specification,COMPUTER PROGRAMMING LANGUAGES; COMPUTER SOFTWARE - Software Engineering; COMPILER CORRECTNESS; SEMANTICS OF PROGRAMMING LANGUAGES; COMPUTER OPERATING SYSTEMS
A Short Proof of a Conjecture of DeRemer and Pennello,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022705091&doi=10.1145%2f5397.30850&partnerID=40&md5=ca083d09d0d3a47b9ad14ab051e7f1be,"In this paper we offer a short proof of the DeRemer-Pennello conjecture that if the LR(0) automaton for a grammar G contains a state p and a nonterminal A such that (p, A) is a nonterminal transition, (p, A) includes+ (p, A) and Read(p, A) is not empty, then grammar G is not LR(k) for any k. © 1986, ACM. All rights reserved.",,AUTOMATA THEORY - Formal Languages; COMPUTER METATHEORY - Formal Logic; MATHEMATICAL LOGIC; REWRITING SYSTEMS; COMPUTER PROGRAMMING LANGUAGES
The Impact of Interprocedural Analysis and Optimization in the Rn Programming Environment,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022793229&doi=10.1145%2f6465.6489&partnerID=40&md5=b5f4a91071c1eb82a420e36575aeb039,"In spite of substantial progress in the theory of interprocedural data flow analysis, few practical compiling systems can afford to apply it to produce more efficient object programs. To perform interprocedural analysis, a compiler needs not only the source code of the module being compiled, but also information about the side effects of every procedure in the program containing that module, even separately compiled procedures. In a conventional batch compiler system, the increase in compilation time required to gather this information would make the whole process impractical. In an integrated programming environment, however, other tools can cooperate with the compiler to compute the necessary interprocedural information incrementally. as the program is being developed, decreasing both the overall cost of the analysis and the cost of individual compilations. A central goal of the Rn project at Rice University is to construct a prototype software development environment that is designed to build whole programs, rather than just individual modules. It employs interprocedural analysis and optimization to produce high-quality machine code for whole programs. This paper presents an overview of the methods used by the environment to accomplish this task and discusses the impact of these methods on the various environment components. The responsibilities of each component of the environment for the preparation and use of interprocedural information are presented in detail. © 1986, ACM. All rights reserved.",Data flow analysis,COMPUTER OPERATING SYSTEMS - Program Compilers; COMPUTER PROGRAMMING LANGUAGES; COMPUTER PROGRAMMING ENVIRONMENT; DATA FLOW ANALYSIS; COMPUTER SOFTWARE
MULTILISP: A language for concurrent symbolic computation,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976721284&doi=10.1145%2f4472.4478&partnerID=40&md5=75504c10f0055365f31a2da1bdcb9cdc,"Multilisp is a version of the Lisp dialect Scheme extended with constructs for parallel execution. Like Scheme, Multilisp is oriented toward symbolic computation. Unlike some parallel programming languages, Multilisp incorporates constructs for causing side effects and for explicitly introducing parallelism. The potential complexity of dealing with side effects in a parallel context is mitigated by the nature of the parallelism constructs and by support for abstract data types: a recommended Multilisp programming style is presented which, if followed, should lead to highly parallel, easily understandable programs. Multilisp is being implemented on the 32-processor Concert multiprocessor; however, it is ultimately intended for use on larger multiprocessors. The current implementation, called Concert Multilisp, is complete enough to run the Multilisp compiler itself and has been run on Concert prototypes including up to eight processors. Concert Multilisp uses novel techniques for task scheduling and garbage collection. The task scheduler helps control excessive resource utilization by means of an unfair scheduling policy; the garbage collector uses a multiprocessor algorithm based on the incremental garbage collector of Baker. © 1985, ACM. All rights reserved.",Garbage collection; process scheduling,
Proving Liveness for Networks of Communicating Finite State Machines,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022609669&doi=10.1145%2f5001.5002&partnerID=40&md5=1029430928e77cb08d8b0f072a558c77,"Consider a network of communicating finite state machines that exchange messages over unbounded FIFO channels. Each machine in the network can be defined by a directed graph whose nodes represent the machine states and whose edges represent its transitions. In general, for a node in one of the machines to be live (i.e., encountered infinitely often during the course of communication), each machine in the network should progress in some fair fashion. We define three graduated notions of fair progress (namely, node fairness, edge fairness, and network fairness), and on this basis we define three corresponding degrees of node liveness. We discuss techniques to verify that a given node is live under each of these fairness assumptions. These techniques can be automated; and they are effective even if the network under consideration has an infinite number of reachable states. We use our techniques to establish the liveness of some practical communication protocols; these include an unbounded start-stop protocol, an unbounded alternating bit protocol, and a simplified version of the CSMA/CD protocol for local area networks. © 1986, ACM. All rights reserved.",Alternating bit protocol; closed covers; communication protocols; CSMA/CD protocol; fairness; finite state machines; liveness; start-stop protocol,"Carrier sense multiple access; Network architecture; AUTOMATA THEORY - Finite Automata; COMPUTER PROGRAMMING; COMPUTER SOFTWARE - Software Engineering; COMPUTERS, DIGITAL - Data Communication Systems; Communicating finite state machines; Communications protocols; CSMA/CD; Degree of nodes; FIFO channels; Infinite numbers; Liveness; Machine state; Network fairness; FINITE STATE MACHINES; Directed graphs; COMPUTER NETWORKS"
Program Abstraction and Instantiation,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976830845&doi=10.1145%2f3916.3986&partnerID=40&md5=cb6ab8f88b26f2284b0673bd2a4e448c,"Our goal is to develop formal methods for abstracting a given set of programs into a program schemaand for instantiating a given schema to satisfy concrete specifications. Abstraction and instantiationare two important phases in software development which allow programmers to apply knowledgelearned in the solutions of past problems when faced with new situations. For example, from twoprograms using a linear (or binary) search technique, an abstract schema can be derived that embodiesthe shared idea and that can be instantiated to solve similar new problems. Along similar lines, thedevelopment and application of program transformations are considered. We suggest the formulation of analogies as a basic tool in program abstraction. An analogy is firstsought between the specifications of the given programs; this yields an abstract specification thatmay be instantiated to any of the given concrete specifications. The analogy is then used as a basisfor transforming the existing programs into an abstract schema that represents the embeddedtechnique, with the invariant assertions and correctness proofs of the given programs helping toverify and complete the analogy. A given concrete specification of a new problem may then becompared with the abstract specification of the schema to suggest an instantiation of the schemathat yields a correct program. © 1985, ACM. All rights reserved.",Abstraction; analogy; instantiation; program schemata,
Axioms for Memory Access in Asynchronous Hardware Systems,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022582940&doi=10.1145%2f5001.5007&partnerID=40&md5=0ddfbbc0d9dad4dccb285ff22c1f4ce9,"The problem of concurrent accesses to registers by asynchronous components is considered. A set of axioms about the values in a register during concurrent accesses is proposed. It is shown that if these axioms are met by a register, then concurrent accesses to it may be viewed as nonconcurrent, thus making it possible to analyze asynchronous algorithms without elaborate timing analysis of operations. These axioms are shown, in a certain sense, to be the weakest. Motivation for this work came from analyzing low-level hardware components in a VLSI chip which concurrently accesses a flip-flop. © 1986, ACM. All rights reserved.",Concurrent access,COMPUTER HARDWARE; COMPUTER PROGRAMMING LANGUAGES; Asynchronous algorithms; Asynchronous components; Asynchronous hardware; Concurrent access; Hardware components; Hardware system; Memory access; Timing Analysis; VLSI chip; CONCURRENT PROGRAMMING; COMPUTER PROGRAMMING; Flip flop circuits
Symmetric intertask communication,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976684629&doi=10.1145%2f4472.4475&partnerID=40&md5=74961706203484d462d3473fdef232d7,"We argue for the need of supporting a symmetric select construct, in which entry calls as well as accepts can be alternatives. We present several situations in which a symmetric select leads to a more natural programming style. We show that several semantic principles are violated by a nonsymmetric select, while being satisfied by a symmetric one. In particular, the suggested symmetric intertask communication mechanism is fully abstract and composable, and has a distributed termination rule which reduces the risk of deadlock. Our discussion is in terms of Ada#8482;. © 1985, ACM. All rights reserved.",Ada; guards; inverted communication; rendezvous; semantics,
Affix grammar driven code generation,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976680663&doi=10.1145%2f4472.4486&partnerID=40&md5=cf262dc008dcf43a7ac910b1402ea670,"Affix grammars are used to describe the instruction set of a target architecture for purposes of compiler code generation. A code generator is obtained automatically for a compiler using attributed parsing techniques. A compiler built on this model can automatically perform most popular machine-dependent optimizations, including peephole optimizations. Code generators based on this model demonstrate retargetability for the VAX1-11, iAPX2-86, Z-80003, PDP4-11, MC-68000, NS32032, FOM, and IBM-370 architectures. © 1985, ACM. All rights reserved.",Code generation; code optimization; code-generator-generator; compiler compiler; intermediate representation; machine description; machine-dependent optimization,
A note on Cohen's “eliminating redundant recursive calls”,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976742032&doi=10.1145%2f4472.215006&partnerID=40&md5=ed594302fd159ed632301dfb1c8bfa1b,[No abstract available],,
Program Transformations in a Denotational Setting,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976812347&doi=10.1145%2f3916.3917&partnerID=40&md5=d2acd23a782cd7d28bf7b896cbd95d19,"Program transformations are frequently performed by optimizing compilers, and the correctness of applying them usually depends on data flow information. For language-to-same-language transformations, it is shown how a denotational setting can be useful for validating such program transformations. Strong equivalence is obtained for transformations that exploit information from a class of forward data flow analyses, whereas only weak equivalence is obtained for transformations that exploit information from a class of backward data flow analyses. To obtain strong equivalence, both the original and the transformed program must be data flow analysed, but consideration of a transformation-exploiting liveness of variables indicates that a more satisfactory approach may be possible. © 1985, ACM. All rights reserved.",abstract interpretation; Data flow analysis; program transformation,
Data Types Are Values,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976727961&doi=10.1145%2f3916.3987&partnerID=40&md5=bb97a3c5b28a16b32e497a345b32e3af,"An important goal of programming language research is to isolate the fundamenal concepts of languages, those basic ideas that allow us to understand the relationships among various language features. This paper examines one of these underlying notions, that of data type, with particular attention to the treatment of generic or polymorphic procedures and static type-checking. © 1985, ACM. All rights reserved.",Data types; polymorphism,
Procedures as persistent data objects,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976677599&doi=10.1145%2f4472.4477&partnerID=40&md5=6bfe8e539a3926c68d6a0999c5db86ce,"A persistent programming environment, together with a language that supports first class procedures, may be used to provide the semantic features of other object modeling languages. In particular, the two concepts may be combined to implement abstract data types, modules, separate compilation, views, and data protection. Furthermore, the ideas may be used in system construction and version control, as demonstrated here. © 1985, ACM. All rights reserved.",first class procedures; Persistent programming,
Applicative Caching,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022581421&doi=10.1145%2f5001.5004&partnerID=40&md5=10aca26255e4efe26bdcf1236f5681a9,"The “referential transparency” principle of applicative language expressions stipulates that a single value exists for all occurrences of an expression in a given context (where a context is a set of bindings of variables to values). In principle, each such value therefore need to be computed only once. However, in applicative language systems supporting recursive programming or tasking notions, the bindings are not all precomputed and explicit. As a result, textual recognition of all multipleoccurrences is precluded, with the unfortunate consequence that such occurrences are recomputed. We elaborate upon the early notion of “memo function” for solving this problem. We suggest syntactic and semantic constructs providing programmer control for avoiding recomputation, which is incorporated into a “building-block” approach. © 1986, ACM. All rights reserved.",Applicative programming; caching; distributed processing; functional programming; higher order functions; memo functions; parallel evaluation; pragmas,"COMPUTER PROGRAMMING LANGUAGES; DATA STORAGE, DIGITAL; Computer programming languages; Block approach; Building blockes; Memo-functions; Recomputation; Recursive programming; Referential transparency; Single-value; CONCURRENT PROGRAMMING; FUNCTIONAL PROGRAMMING; COMPUTER PROGRAMMING; Semantics"
Virtual Time,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976728787&doi=10.1145%2f3916.3988&partnerID=40&md5=de70409bc5ef3119ba660003ad014cea,"Virtual time is a new paradigm for organizing and synchronizing distributed systems which can be applied to such problems as distributed discrete event simulation and distributed database concurrency control. Virtual time provides a flexible abstraction of real time in much the same way that virtual memory provides an abstraction of real memory. It is implemented using the Time Warp mechanism, a synchronization protocol distinguished by its reliance on lookahead-rollback, and by its implementation of rollback via antimessages. © 1985, ACM. All rights reserved.",Concurrency control; simulation; Time Warp,
Efficient Demand-Driven Evaluation. Part 2,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022613628&doi=10.1145%2f5001.5003&partnerID=40&md5=c9546654b8ff7f4793b6cbe106873f5d,"In Part 1 of this paper [5], we presented a scheme whereby a compiler could propagate demands through programs in a powerful stream language L. A data-driven evaluation of the transformed program performed exactly the same computation as a demand-driven evaluation of the original program. In this paper we explore a different transformation, which trades the complexity of demand propagation for a bounded amount of extra computation on some data lines. © 1986, ACM. All rights reserved.",Data-driven evaluation; dataflow; demand propagation; demand-driven evaluation; functional languages; lazy evaluation; program transformations; streams,Computer hardware description languages; Program compilers; COMPUTER PROGRAMMING LANGUAGES - Design; Data driven; Data line; Demand propagation; Demand-driven; Extra computations; Stream languages; CONCURRENT PROGRAMMING; DATA-DRIVEN EVALUATION; FUNCTIONAL PROGRAMMING; LAZY EVALUATION; Metadata; COMPUTER PROGRAMMING
Editing by example,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976723725&doi=10.1145%2f4472.4476&partnerID=40&md5=750802d1c969b5f238a87f810665e6ca,"An editing by example system is an automatic program synthesis facility embedded in a text editor that can be used to solve repetitive text editing problems. The user provides the editor with a few examples of a text transformation. The system analyzes the examples and generalizes them into a program that can perform the transformation to the rest of the user's text. This paper presents an overview of the design, analysis, and implementation of a practical editing by example system. It studies the problem of synthesizing a text processing program that generalizes the transformation implicitly described by a small number of input/output examples. A class of text processing programs called gap programs is defined and the problems associated with synthesizing them from examples are examined, leading to an efficient heuristic that provably synthesizes a gap program from examples of its input/output behavior. The editing by example system derived from this analysis has been embedded in a production text editor. By developing an editing by example system that solves a useful class of text processing problems, this work demonstrates that program synthesis is feasible in the domain of text editing. © 1985, ACM. All rights reserved.",Automatic programming; gap patterns; grammatical inference; inductive inference; text editing,
A Formal Approach to Undo Operations in Programming Languages,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022582048&doi=10.1145%2f5001.5005&partnerID=40&md5=40f9e0f17169099fcd04988c63df2b13,"A framework is presented for adding a general Undo facility to programming languages. A discussion of relevant literature is provided to show that the idea of Undoing pervades several areas in computer science, and even other disciplines. A simple model of computation is introduced, and it is augmented with a minimal amount of additional structure needed for recovery and reversal. Two different interpretations of Undo are motivated with examples. Then, four primitives are defined in a language-independent manner; they are sufficient to support a wide range of Undo capability. Two of these primitives carry out state saving, and the others mirror the two versions of the Undo operation. Properties of and relationships between these primitives are explored, and there are some preliminary remarks on how one could implement a system based on this formalism. The main conclusion is that the notions of recovery and reversal of actions can become part of the programming process. © 1986, ACM. All rights reserved.",Checkpoint; language constructs; preprocessors; recovery; reverse execution; undo,ARTIFICIAL INTELLIGENCE; COMPUTER OPERATING SYSTEMS - Reliability; COMPUTER SOFTWARE - Software Engineering; DATABASE SYSTEMS; Additional structures; Formal approach; Language independents; Model of computation; Programming process; Property; Simple modeling; State saving; PROBLEM SOLVING; PROGRAMMING ENVIRONMENT; UNDO; COMPUTER PROGRAMMING LANGUAGES; Computer programming languages
PARLOG: Parallel Programming in Logic,1986,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022582049&doi=10.1145%2f5001.5390&partnerID=40&md5=5ba5ecc22c735aadb51d97399f020c4c,"PARLOG is a logic programming language in the sense that nearly every definition and query can be read as a sentence of predicate logic. It differs from PROLOG in incorporating parallel modes of evaluation. For reasons of efficient implementation, it distinguishes and separates and-parallel and or-parallel evaluation. PARLOG relations are divided into two types: single-solution relations and all-solutions relations. A conjunction of single-solution relation calls can be evaluated in parallel with shared variables acting as communication channels for the passing of partial bindings. Only one solution to each call is computed, using committed choice nondeterminism. A conjunction of all-solutions relation calls is evaluated without communication of partial bindings, but all the solutions may be found by an or-parallel exploration of the different evaluation paths. A set constructor provides the main interface between single-solution relations and all-solutions relations. This paper is a tutorial introduction to PARLOG. It assumes familiarity with logic programming. Categories and Subject Descriptors: D.l.l [Programming Techniques]: Applicative (Functional). © 1986, ACM. All rights reserved.",And-parallelism; logic programming; nondeterminism; or-parallelism; parallel programming,ARTIFICIAL INTELLIGENCE; COMPUTER PROGRAMMING LANGUAGES; Computer circuits; Functional programming; Logic programming; PROLOG (programming language); All solutions; Communications channels; Efficient implementation; Logic programming languages; Non Determinism; Parallel evaluation; Parallel exploration; Parallel mode; Predicate logic; Shared variables; CONCURRENT PROGRAMMING; FUNCTIONAL PROGRAMMING; LOGIC PROGRAMMING; PARLOG PROGRAMMING LANGUAGE; COMPUTER PROGRAMMING; Parallel programming
Side effects and aliasing can have simple axiomatic descriptions,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976857746&doi=10.1145%2f4472.4474&partnerID=40&md5=8a36fb945a0de66b0d5e2afdfd9d6725,"We present a different style of axiomatic definition for programming languages. It is oriented toward imperative languages, such as Algol 68, that do not distinguish between statements and expressions. Rather than basing the logic on a notion of pre- or postcondition, we use the value of a programming language expression as the underlying primitive. A number of language constructs are examined in this framework. We argue that this style of definition gives us a significantly different view of the notion of “easy axiomatixability.” Side effects in expressions as well as aliasing between variables are shown to be “easily axiomatizable” in our system. © 1985, ACM. All rights reserved.",Algol 68; aliasing; completeness; expression language; LISP; side effect,
Noncorrecting Syntax Error Recovery,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976653480&doi=10.1145%2f3916.4019&partnerID=40&md5=2bf2b4d5cd2bef56eca40afb8b487574,"A parser must be able to continue parsing after encountering a syntactic error to check the remainder of the input. To achieve this, it is not necessary to perform corrections on either the input text or the stack contents. A formal framework is provided in which noncorrecting syntax error recovery concepts are defined and investigated. The simplicity of these concepts allows the statement of provable properties, such as the absence of spurious error messages or the avoidance of skipping input text. These properties are due to the fact that no assumptions about the nature of the errors need be made to continue parsing. © 1985, ACM. All rights reserved.",Error recovery; syntax error,
Describing and Analyzing Distributed Software System Designs,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976723311&doi=10.1145%2f3916.3989&partnerID=40&md5=25c98218144f0989409551af1b9a6989,"In this paper we outline an approach to describing and analyzing designs for distributed software systems. A descriptive notation is introduced, and analysis techniques applicable to designs expressed in that notation are presented. The usefulness of the approach is illustrated by applying it to a realistic distributed software-system design problem involving mutual exclusion in a computer network. © 1985, ACM. All rights reserved.",Analysis of software design; design notation; distributed mutual exclusion; distributed software systems; software design tools,
The denotational semantics of dynamic networks of processes,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976664137&doi=10.1145%2f4472.4473&partnerID=40&md5=5194cdb60ce75f586a30186a499fa0bd,"DNP (dynamic networks of processes) is a variant of the language introduced by Kahn and MacQueen [11, 12]. In the language it is possible to create new processes dynamically. We present a complete, formal denotational semantics for the language, along the lines sketched by Kahn and MacQueen. An informal explanation of the formal semantics is also given. © 1985, ACM. All rights reserved.",Continuation semantics; denotational semantics; parallel coroutines; parallellism; recursively defined processes,
A Distributed Alternative to Finite-State-Machine Specifications,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0007803513&doi=10.1145%2f2363.2365&partnerID=40&md5=5e26088e25fb43557ddcb3773f01bf03,"A specification technique, formally equivalent to finite-state machines, is offered as an alternative because it is inherently distributed and more comprehensible. When applied to modules whose complexity is dominated by control, the technique guides the analyst to an effective decomposition of complexity, encourages well-structured error handling, and offers an opportunity for parallel computation. When applied to distributed protocols, the technique provides a unique perspective and facilitates automatic detection of some classes of error. These applications are illustrated by a controller for a distributed telephone system and the full-duplex alternating-bit protocol for data communication. Several schemes are presented for executing the resulting specifications. © 1985, ACM. All rights reserved.",,
Detecting Global Variables in Denotational Specifications,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976808753&doi=10.1145%2f3318.3323&partnerID=40&md5=7ec7096d2cd38898c5fd7a42ccba997b,"Sufficient criteria are given for replacing all occurrences of the store argument in a Scott-Strachey denotational definition of a programming language by a single global variable. The criteria and transformation are useful for transforming denotational definitions into compilers and interpreters for imperative machines, for optimizing applicative programs, and for judging the suitability of semantic notations for describing imperative languages. An example transformation of a semantics of a repeat-loop language to one which uses a global store variable is given to illustrate the technique. © 1985, ACM. All rights reserved.",,
A Modular Verifiable Exception Handling Mechanism,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976749735&doi=10.1145%2f3318.3320&partnerID=40&md5=06a2cca2356071547688cc19bf244507,"This paper presents a new model for exception handling, called the replacement model. The replacement model, in contrast to other exception-handling proposals, supports all the handler responses of resumption, termination, retry, and exception propagation, within both statements and expressions, in a modular, simple, and uniform fashion. The model can be embedded in any expression-oriented language and can also be adapted to languages which are not expression oriented with almost all the above advantages. This paper presents the syntactic extensions for embedding the replacement model into Algol 68 and its operational semantics. An axiomatic semantic definition for the model can be found in [27]. © 1985, ACM. All rights reserved.",,
Towards Monolingual Programming Environments,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976758294&doi=10.1145%2f3318.3321&partnerID=40&md5=dd634470cb4e2aed9998378da828f93c,"Most programming environments are much too complex. One way of simplifying them is to reduce the number of mode-dependent languages the user has to be familiar with. As a first step towards this end, the feasibility of unified command/programming/debugging languages, and the concepts on which such languages have to be based, are investigated. The unification process is accomplished in two phases. First, a unified command/programming framework is defined and, second, this framework is extended by adding an integrated debugging capability to it. Strict rules are laid down by which to judge language concepts presenting themselves as candidates for inclusion in the framework during each phase. On the basis of these rules many of the language design questions that have hitherto been resolved this way or that, depending on the taste of the designer, lose their vagueness and can be decided in an unambiguous manner. © 1985, ACM. All rights reserved.",,
Information-Flow and Data-Flow Analysis of While-Programs,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976850518&doi=10.1145%2f2363.2366&partnerID=40&md5=86f815b0ace08e5d67e5ca6e57e93fa4,"Until recently, information-flow analysis has been used primarily to verify that information transmission between program variables cannot violate security requirements. Here, the notion of information flow is explored as an aid to program development and validation. Information-flow relations are presented for while-programs, which identify those program statements whose execution may cause information to be transmitted from or to particular input, internal, or output values. It is shown with examples how these flow relations can be helpful in writing, testing, and updating programs; they also usefully extend the class of errors which can be detected automatically in the “static analysis” of a program. © 1985, ACM. All rights reserved.",,
Generative Communication in Linda,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976826320&doi=10.1145%2f2363.2433&partnerID=40&md5=77d1d376a065d9ed31a36bc240b49025,"Generative communication is the basis of a new distributed programming langauge that is intended for systems programming in distributed settings generally and on integrated network computers in particular. It differs from previous interprocess communication models in specifying that messages be added in tuple-structured form to the computation environment, where they exist as named, independent entities until some process chooses to receive them. Generative communication results in a number of distinguishing properties in the new language, Linda, that is built around it. Linda is fully distributed in space and distributed in time; it allows distributed sharing, continuation passing, and structured naming. We discuss these properties and their implications, then give a series of examples. Linda presents novel implementation problems that we discuss in Part II. We are particularly concerned with implementation of the dynamic global name space that the generative communication model requires. © 1985, ACM. All rights reserved.",,
"CIRCAL and the Representation of Communication, Concurrency, and Time",1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976660535&doi=10.1145%2f3318.3322&partnerID=40&md5=d95042488ea657e6e5cd7ab553d1dfaf,"The CIRCAL calculus is presented as a mathematical framework in which to describe and analyze concurrent systems, whether hardware or software. The dot operator is used to compose CIRCAL descriptions, and it is this operator which permits the natural modeling of asynchronous and simultaneous behavior, thus allowing the representation and analysis of system timing properties such as those found in circuits. The CIRCAL framework uses an abstraction operator to permit the modeling of a system at different levels of detail. Behavioral complexity of real systems makes abstraction crucial when producing a tractable model, and we illustrate how abstraction introduces nondeterminisim into system representations. An operational semantics, acceptance semantics, is introduced, and it is in terms of this active experimentation that meaning is given to the CIRCAL syntax, thus allowing proof of system properties to be constructed. © 1985, ACM. All rights reserved.",,
A New Analysis of LALR Formalisms,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976860320&doi=10.1145%2f2363.2527&partnerID=40&md5=985401db2d9b1dbe6f9c31b16fcae33d,"The traditional LALR analysis is reexamined using a new operator and an associated graph. An improved method that allows factoring out a crucial part of the computation for defining states of LR(0) canonical collection and for computing LALR(1) lookahead sets is presented. This factorization leads to significantly improved algorithms with respect to execution time as well as storage requirements. Experimental results including comparison with other known methods are presented. © 1985, ACM. All rights reserved.",,
Proofs as Programs,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976754350&doi=10.1145%2f2363.2528&partnerID=40&md5=cb55b3f623ef1a8aae6a4dd47503330d,"The significant intellectual cost of programming is for problem solving and explaining, not for coding. Yet programming systems offer mechanical assistance for the coding process exclusively. We illustrate the use of an implemented program development system, called PRL (“pearl”), that provides automated assistance with the difficult part. The problem and its explained solution are seen as formal objects in a constructive logic of the data domains. These formal explanations can be executed at various stages of completion. The most incomplete explanations resemble applicative programs, the most complete are formal proofs. © 1985, ACM. All rights reserved.",,
Efficient Demand-Driven Evaluation. Part 1,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976797971&doi=10.1145%2f3318.3480&partnerID=40&md5=83644e1a486d987c7f6c4b25dd64430d,"We describe a program transformation technique for programs in a general stream language L whereby a data-driven evaluation of the transformed program performs exactly the same computation as a demand-driven evaluation of the original program. The transformational technique suggests a simple denotational characterization of demand-driven evaluation. © 1985, ACM. All rights reserved.",,
"Implementation of Resilient, Atomic Data Types",1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976745459&doi=10.1145%2f3318.3319&partnerID=40&md5=fe2d4d23a0ee92ded588b995ea569e31,"A major issue in many applications is how to preserve the consistency of data in the presence of concurrency and hardware failures. We suggest addressing this problem by implementing applications in terms of abstract data types with two properties: Their objects are atomic (they provide serializability and recoverability for activities using them) and resilient (they survive hardware failures with acceptably high probability). We define what it means for abstract data types to be atomic and resilient. We also discuss issues that arise in implementing such types, and describe a particular linguistic mechanism provided in the Argus programming language. © 1985, ACM. All rights reserved.",,
On Convergence Toward a Database of Program Transformations,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976810094&doi=10.1145%2f2363.2364&partnerID=40&md5=3ef812f857333be88715600f3f2c6d85,"Several fairly large sets of programming rules have been developed recently. It is natural to ask whether the process of developing such rule bases may converge. Having developed sets of rules for specific programming tasks and domains, will they be helpful when other tasks and domains are considered? While it is too early to give definitive answers, experience with the rules of the PECOS system has been positive. Both during the process of developing the rule set and while developing rules for another domain, the existence of already codified rules proved very helpful. © 1985, ACM. All rights reserved.",,
Optimal Parallel Generation of a Computation Tree form,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976661881&doi=10.1145%2f3318.3478&partnerID=40&md5=6ce2e21763b524049319fbd056c12f54,"Given a general arithmetic expression, we find a computation binary tree representation in O(log n) time using n/log n processors on a concurrent-read, exclusive-write, parallel random-access machine. A new algorithm is introduced for this purpose. Unlike previous serial and parallel solutions, it is not based on using a stack. © 1985, ACM. All rights reserved.",,
Generalizing Specifications for Uniformly Implemented Loops,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976656004&doi=10.1145%2f2363.2708&partnerID=40&md5=fb7b55313b074e8fc87117eddabfb4dd,"The problem of generalizing functional specifications for while loops is considered. This problem occurs frequently when trying to verify that an initialized loop satisfies some functional specification, i.e., produces outputs which are some function of the program inputs. The notion of a valid generalization of a loop specification is defined. A particularly simple valid generalization, a base generalization, is discussed. A property of many commonly occurring while loops, that of being uniformly implemented, is defined. A technique is presented which exploits this property in order to systematically achieve a valid generalization of the loop specification. Two classes of uniformly implemented loops that are particularly susceptible to this form of analysis are defined and discussed. The use of the proposed technique is illustrated with a number of applications. Finally, an implication of the concept of uniform loop implementation for the validation of the obtained generalization is explained. © 1985, ACM. All rights reserved.",,
A Note on Hennessy's “Symbolic Debugging of Optimized Code”,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976801509&doi=10.1145%2f2363.215005&partnerID=40&md5=929df9517d615fc849042247a2100f60,[No abstract available],,
Optimal Prepaging and Font Caching,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038683085&doi=10.1145%2f2363.2367&partnerID=40&md5=15df5175aefa1daa21cfac049b9a964b,"An efficient algorithm for communicating letter-shape information from a high-speed computer with a large memory to a typesetting device that has a limited memory is presented. The encoding is optimum, in the sense that the total time for typesetting is minimized, using a model that generalizes well-known “demand paging” strategies to the case where changes to the cache are allowed before the associated information is actually needed. Extensive empirical data show that good results are obtained even when difficult technical material is being typeset on a machine that can store information concerning only 100 characters. The methods of this paper are also applicable to other hardware and software caching applications with restricted lookahead. © 1985, ACM. All rights reserved.",,
Dealing with World-Model-Based Programs,1985,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976755880&doi=10.1145%2f3318.3479&partnerID=40&md5=f0e493f514aeafe9bbfb9ff376341bbf,"We introduce POINTY, an interactive system for constructing world-model-based programs for robots. POINTY combines an interactive programming environment with the teaching-by-guiding methodology that has been successful in industrial robotics. Owing to its ability to control robots in real time, and to interact with the user, POINTY provides a friendly and powerful programming environment for robot applications. In the past few years, POINTY has been in use at Stanford to write, test, and debug various robot programs. © 1985, ACM. All rights reserved.",,
Global Data Flow Analysis Problems Arising in Locally Least-Cost Error Recovery,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976825657&doi=10.1145%2f2993.357243&partnerID=40&md5=fa4e905ad638d841e0099ab5a5558960,"Locally least-cost error recovery is a technique for recovering from syntax errors by editing the input string at the point of error detection. A scheme for its implementation in recursive descent parsers, which in principle embodies a process of passing a parameter to each procedure in the parser for each terminal symbol in the grammar, has been suggested. For this scheme to be practical it is vital that as much parameterization as possible is eliminated from the recursive descent parser. This oPtimization problem and how it may be split into three separate global data flow analysis problems-- classifying terminal symbols and the so-called min and max follow cost problems--are discussed. The max follow cost problem is a particularly difficult one to solve. The application of Gaussian elimination to its solution is shown by expressing it as a continuous data flow problem, and it is also related to an “idiosyncratic” data flow problem arising in the optimization of very high level languages. Classifying terminal symbols is also difficult since the problem is unsolvable in general. However, for the class of LL(1) grammars, the problem is shown to be expressible as a distributive data flow problem and so may be solved using, say, Gauss-Seidel iteration. © 1984, ACM. All rights reserved.",Code optimization; compiling; error correction; error recovery; error repair; Gauss-Seidel iteration; Gaussian elimination; global flow analysis; lattice; LL grammar; parser generator; path problem; regular algebra; shortest path,
ACM Algorithms Policy,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976802135&doi=10.1145%2f579.357256&partnerID=40&md5=a22d78332dab9c3a71ca434b948cf74f,[No abstract available],,
The promotion and accumulation strategies in transformational programming,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976761504&doi=10.1145%2f1780.1781&partnerID=40&md5=da13d4d959bbab3dc55bc3ad5d3d7cfe,"The promotion strategy in transformational programming is a general method for achieving efficiency by exploiting the recursive structure in the dominant term of an algorithmic expression. For it to be carried out successfully, the original problem often has to be generalized by the inclusion of an extra parameter, a technique known as accumulation. These strategies are illustrated by deriving algorithms for two nontrivial problems: (1) determining whether a given digraph is acyclic, and (2) constructing the longest subsequence of a given sequence of vertices that forms a connected path in a given digraph. The derivations also serve to emphasize the usefulness of certain notational devices in applicative expressions, especially infix operators. Not only do such operators enhance the succinctness and readability of expressions, they also allow many transformations to be formulated as algebraic laws about their distributive and other properties. © 1984, ACM. All rights reserved.",algorithm refinement; operators; Transformational programming,
Distributed algorithms for finding centers and medians in networks,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976800574&doi=10.1145%2f579.585&partnerID=40&md5=c3861706a0484f11a5d68040daedb243,[No abstract available],,
Proving Failure-Free Properties of Concurrent Systems Using Temporal Logic,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976705657&doi=10.1145%2f2993.357245&partnerID=40&md5=cae94ba5ffc467cc5ca4e29bedb20e2f,"In a failure-free concurrent system, no process is delayed forever by any of the system synchronization primitives. Previously, it was difficult to prove even the simplest concurrent system failure free, let alone attempt such a proof for a “real” operating system. First for semaphores and then for monitors, necessary and sufficient conditions for failure-free systems are derived. In both cases, the important properties of the system are stated using temporal logic, a concise formalism that allows reasoning about the future progress of program computations. Temporal logic permits a precise and explicit statement of exactly those properties necessary to establish that a concurrent system is truly failure free. In conclusion, a short example is given and then the applicability of these results to several existing systems and languages (UNIX o, MODULA and MESA) is examined. © 1984, ACM. All rights reserved.",deadlock; monitors; semaphores; starvation; Temporal logic,
Real-Time Synchronization of Interprocess Communications,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976694230&doi=10.1145%2f2993.357244&partnerID=40&md5=907e7ec5b69c206bb83b071023898968,"This paper considers a fixed (possibly infinite) set of distributed asynchronous processes, which at various times are willing to communicate with each other. Each process has various ports, each of which is used for communication with a distinct neighbor process. Each process can have at most one port open at any time, and its other ports must be closed. Two processes handshake over a time interval A if their respective ports are open for mutual communication during this interval. Note that the handshake relation is a matching. Successful communication requires a handshake of at least one step of each process; during the one-step overlap a message can be transmitted between processes. The problem is to synchronize processes (via a distributed scheduler) so that they can successfully handshake at their will, given that the means of synchronization is some low-level construct that does not guarantee the handshake property if used in an unsophisticated way. Probabilistic distributed algorithms for synchronizing processes so that they can handshake at will are described. A process is considered to be tame over a time interval A if its speed varies within certain arbitrarily fixed nonzero bounds. Our synchronization algorithms are shown to have real-time response: If a pair of processers are mutually willing to communicate within a time interval A of length at least a given constant and the pair are tame on A, then they establish communication within A with high likelihood (for the worst case behavior of the system), and the expected time for establishment of communication is also constant. Our model and algorithms are applied to solve a large class of real-time resource allocation problems, as well as real-time implementation of the synchronization primitives of Hoare's multiprocessing language CSP. © 1984, ACM. All rights reserved.",asynchronous systems; communicating sequential processes; expected time; handshake protocols; Interprocess communication; probabilistic choice; randomized algorithms; response time; symmetry; synchronization,
Communicating Sequential Processes for Centralized and Distributed Operating System Design,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976675576&doi=10.1145%2f2993.2381&partnerID=40&md5=80f5ddc4c3fdcd70c7f38adb4fe4cd4e,"This paper demonstrates how the notation of Communicating Sequential Processes may be used in the design of an operating system. It goes further to show how such an approach assists in the design and development of a system distributed over a network of computers. The technique uses a welldefined design methodology. © 1984, ACM. All rights reserved.",communicating sequential processes; distributed systems; Operating systems; parallel programming; program design,
Technical Correspondence: Comments on Soisalon-Soininen's “Inessential Error Entries and Their Use in LR Parser Optimization”,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976807660&doi=10.1145%2f579.357255&partnerID=40&md5=9723dc5cf1be9f9fc2fdec55c1fe7087,[No abstract available],,
Translation of attribute grammars into procedures,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976834694&doi=10.1145%2f579.586&partnerID=40&md5=a24ef29b10d45357d1ae1e8863e108de,[No abstract available],,
Algorithms for on-the-fly garbage collection,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976781789&doi=10.1145%2f579.587&partnerID=40&md5=dcf5767f808903192b11c0da62b18a05,[No abstract available],,
Magma2: A language oriented toward experiments in control,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976764646&doi=10.1145%2f1780.1784&partnerID=40&md5=165fd6baf2d31b3712b7c2ba5a9fa9d0,"The design of a programming language, Magma2, is outlined. The language provides the facilities for programming new control regimes and encapsulating them into appropriate modules. The general paradigm of abstraction of control is applied to sequential control regimes. The language is presented via a formal model and a few examples of its use. The semantic model has a denotational flavor and can be used to describe the semantics of languages with unconventional control features. © 1984, ACM. All rights reserved.",computation agents; Control abstractions; control environments,
A Directly Executable Encoding for APL,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976729514&doi=10.1145%2f579.580&partnerID=40&md5=204ee726a1ddc7117edfa61c291938d8,[No abstract available],,
Jump Minimization in Linear Time,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976818925&doi=10.1145%2f1780.357262&partnerID=40&md5=187447776cf372f29c9e937a5135253a,"Unlike other instructions, which compute or test values, unconditional branch instructions do no useful work. Rather, they are artifacts of the translation from a flow graph to the linear form of conventional machine language. Careful ordering of the basic blocks of a program can decrease the number of branches required by allowing a basic block to “fall through” to a successor. It is shown that although the general problem of minimizing the number of branches is NP-complete, an efficient algorithm is possible for “structured” programs--those written without goto statements. More specifically, an algorithm is presented that produces an optimal ordering of the basic blocks of any program that uses only the control structures if-then-else, loop, and exit. The running time of the algorithm is proportional to the length of the program, provided the number of loops exited by any exit statement can be bounded by a constant. © 1984, ACM. All rights reserved.",code reordering; goto statements; Unconditional branches,
Using message passing for distributed programming: Proof rules and disciplines,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976779730&doi=10.1145%2f579.583&partnerID=40&md5=7adc50206991e3f02895e919a3bb43e9,[No abstract available],,
Transformations and reduction strategies for typed lambda expressions,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976719905&doi=10.1145%2f1780.1803&partnerID=40&md5=aaba131eb0f3d38ecbcc5127df441e3f,"A scheme is described that allows languages supporting higher order functions to be efficiently implemented using a standard run-time stack. A machine for evaluating typed lambda expressions is first constructed. In essence, the machine simply extends the standard SECD machine to allow partial application of abstractions representing multiadic functions. Some transformations of these typed lambda expressions into a so-called simple form are then described. Evaluation of simple-form expressions on the extended SECD machine produces stacklike environment structures rather than the treelike structures produced by expressions of arbitrary form. This allows implementation of the machine using a standard runtime stack. The SECD machine is then further modified so that closures are applied “in situ” rather than returned as values. The order of reduction is also changed so that the evaluation of function-valued expressions is deferred until they can be applied to sufficient arguments to allow reduction to nonfunctional values. It is shown that this function-deferring machine can be implemented using a standard run-time stack and thus can evaluate arbitrary lambda expressions without prior transformation to simple form. Finally, application of the above schemes to standard programming languages, such as ALGOL, Pascal, Ada, and LISP, is considered. © 1984, ACM. All rights reserved.",efficient implementation; evaluation schemes; Higher order functions,
Axiomatic semantics of communicating sequential processes,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976862263&doi=10.1145%2f1780.1805&partnerID=40&md5=32cacbbcf99b7f03d25f4bdbb305001a,"A simple definition of the axiomatic semantics of Communicating Sequential Processes is presented. The most important aspect of the approach is that it allows dealing with the individual processes of a program in isolation from the other processes. The axiomatic semantics is used to prove the correctness of a program for partitioning sets. © 1984, ACM. All rights reserved.",Absence of deadlock; axiomatic semantics; communicating processes; CSP; distributed termination; partial correctness,
"The “Hoare Logic'’ of CSP, and All That",1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976755236&doi=10.1145%2f2993.357247&partnerID=40&md5=19b8818eb4e6d9eb7c48da63b4355338,"Generalized Hoare Logic is a formal logical system for deriving invariance properties of programs. It provides a uniform way to describe a variety of methods for reasoning about concurrent programs, including noninterference, satisfaction, and cooperation proofs. We describe a simple recta-rule of the Generalized Hoare Logic--the Decomposition Principle--and show how all these methods can be derived using it. © 1984, ACM. All rights reserved.",communicating sequential processes; decomposition principle; Generalized Hoare Logic; Invariance; message-passing; noninterference; safety properties,
Using Time Instead of Timeout for Fault-Tolerant Distributed Systems,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976782029&doi=10.1145%2f2993.2994&partnerID=40&md5=f25fb161c9d35aa924c85bab61df5e82,"A general method is described for implementing a distributed system with any desired degree of faulttolerance. Instead of relying upon explicit timeouts, processes execute a simple clock-driven algorithm. Reliable clock synchronization and a solution to the Byzantine Generals Problem are assumed. © 1984, ACM. All rights reserved.",Byzantine Generals Problem; Clocks; intractive consistency; timestamps; transaction commit,
Encapsulation constructs in systems programming languages,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976755076&doi=10.1145%2f2993.69615&partnerID=40&md5=b28b718bd6202e4ef4cad600fbc25ca0,"This paper investigates the desirable properties of programming language constructs that support encapsulation of environments and abstract data types. These properties are illustrated by using a simple multiuser file system as a model. The requirements for such a file system are outlined; then the model file system design is described by a hierarchy of encapsulated abstract data types and environments. The high-level language constructs necessary to directly implement the model file system design are identified. It is concluded that environment encapsulation and abstract data types must be supported by different constructs, and the desirable properties of such constructs are outlined. A superset of Ada e that effectively supports both environments and abstract data types is introduced and used to implement the model file system. The encapsulation constructs of several modern systems programming languages are evaluated. Each of these languages is shown to be insufficient for a direct implementation of the model file system design. © 1984, ACM. All rights reserved.",Encapsulation; file systems; systems programming languages,
Optimization of parser tables for portable compilers,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976758346&doi=10.1145%2f1780.1802&partnerID=40&md5=cf274a26dc7fa8603441090d2a70fa8e,"Six methods for parser table compression are compared. The investigations are focused on four methods that allow the access of table entries with a constant number of index operations. The advantage of these methods is that the access to the compressed tables can be programmed efficiently in portable high-level languages like Pascal or FORTRAN. The results are related to two simple methods based on list searching. Experimental results on eleven different grammars show that, on the average, a method based on graph coloring turns out best. © 1984, ACM. All rights reserved.",Graph coloring; sparse matrices; table compression,
Annotations to Control Parallelism and Reduction Order in the Distributed Evaluation of Functional Programs,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976848802&doi=10.1145%2f2993.357241&partnerID=40&md5=334d3d4a89fed8130412b6678baca738,"When evaluating a functional program on a network of processors, it is necessary to decide when parallelism is desirable, which work may be transferred to another processor, and in what form the work is to be transferred. If the wrong decisions are made, a parallel evaluation may require asymptotically more time than a sequential evaluation, owing to communication costs. The introduction of annotations to give the programmer control over the above decisions is proposed. The annotations and their effects are defined in terms of the lambda calculus. Each application must have one of three annotations. No other annotations are required. Examples and possible extensions to this work, including annotated combinators, are briefly considered. © 1984, ACM. All rights reserved.",,
Modeling the distributed termination convention of CSP,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976774662&doi=10.1145%2f579.584&partnerID=40&md5=d5d40338e8e1a7b8ccc79f64c1dace6c,[No abstract available],,
An APL Compiler for a Vector Processor,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976798337&doi=10.1145%2f579.357248&partnerID=40&md5=bd378b9316d79a07dda0d20046fdabc0,[No abstract available],,
"Technical Correspondence: On Tanenbaum, van Staveren, and Stevenson's “Using Peephole Optimization on Intermediate Code”",1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976852990&doi=10.1145%2f2166.357220&partnerID=40&md5=8a84cabd065a66bc6ae7f0617b067c0a,[No abstract available],,
Unassigned objects,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976698571&doi=10.1145%2f1780.1785&partnerID=40&md5=0ca308e7cce0cbca94268ca37057ffee,"There are various ways in which programming languages may deal with the use of objects that have no value. They may or may not treat such uses as errors and may or may not trap such errors. The evolution from the preliminary version of Ada TM to the 1980 version and then to the 1982 version is a case in point. A basis for investigation resting on the desire for more reliable software is presented. Ways of declaring types with and without the value unassigned, derivations from such types, and the meaning of unassigned for composite types are all investigated. Static and dynamic assignment of the value unassigned are introduced, and the interaction of these with other design factors, especially unassigned composite objects, is detailed. It is shown that the typical dual view of composite objects, both as objects and composites of other objects, leads to inconsistencies in the dynamic treatment of unassigned composites and to significant implementation inefficiencies. © 1984, ACM. All rights reserved.",NO_VALUE_ERROR; preliminary Ada; Unassigned variables; uninitialized variables,
Assessing Test Data Adequacy through Program Inference,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976818971&doi=10.1145%2f69575.357231&partnerID=40&md5=1f89d11c57797b379292291a6eb1535e,"Despite the almost universal reliance on testing as the means of locating software errors and its long history of use, few criteria have been proposed for deciding when software has been thoroughly tested. As a basis for the development of usable notions of test data adequacy, an abstract definition is proposed and examined, and approximations to this definition are considered. © 1983, ACM. All rights reserved.",inductive inference; program inference; Program testing; software testing; test data adequacy,
Selective and locally controlled transport of privileges,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976701444&doi=10.1145%2f1780.1786&partnerID=40&md5=2df86e1e31e17ed0a1c580e4380a8846,"In a system based on authorization, the ability of a subject to operate on the system is a function of the privileges that he possesses. In this paper a mechanism, called Send-Receive, for the transport of such privileges, is introduced and studied. The control provided by this mechanism over the movement of privileges has two notable properties. --The control is selective, in the sense that it permits the creation of transport channels, which allow for the movement of only certain types of privileges and only between certain kinds of subjects. --The control is local, in the sense that every movement of privileges into and out of the domain of a given subject must be authorized by privileges already in his domain. The proposed transport mechanism is shown to allow the imposition of a local upper bound on the power of any given subject. This bound is independent of the rest of the system and can, therefore, be viewed as an intrinsic property of the subject. The ability to impose such bounds is considered essential for effective modularization of computer systems. In addition, the locality of our control has beneficial global effects on the flow of privileges. In particular, it helps remove the undesirable symmetry of transport, exhibited by the conventional Take-Grant mechanism. © 1984, ACM. All rights reserved.",localization of power; operation control; Power structure; the safety problem,
A Syntax-Error-Handling Technique and Its Experimental Analysis,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039675918&doi=10.1145%2f69575.357232&partnerID=40&md5=7fbbf17f286c4c2c19880d9aa2498f4b,"A syntax-error-handling technique is defined as an extension of LR parsing. The technique is automatic, and the generation of the error-handling algorithm is based only on the context-free grammar and the lexical description of the language. The heart of the algorithm is a “phrase-lever” error-recovery strategy, which is an improvement upon the basic strategy of Leinius. The notion of phrase-level recovery is further generalized such that “local correction” is included within the basic framework. Special attention is paid to diagnostic aspects, such as the generation of descriptive recovery-independent error messages. The technique has been implemented in the compiler-writing system HLP (Helsinki Language Processor). Promising experimental results have been obtained by testing the technique with erroneous student-written ALGOL and Pascal programs. © 1983, ACM. All rights reserved.",error recovery; error reporting; LR parsing,
Code selection through object code optimization,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976688919&doi=10.1145%2f1780.1783&partnerID=40&md5=22eb3dea1e87c8cd7b3c534bd0de4c04,"This paper shows how thorough object code optimization has simplified a compiler and made it easy to retarget. The code generator forgoes case analysis and emits naive code that is improved by a retargetable object code optimizer. With this technique, cross-compilers have been built for seven machines, some in as few as three person days. These cross-compilers emit code comparable to hostspecific compilers. © 1984, ACM. All rights reserved.",Code generation; compilation; optimization; peephole optimization; portability,
Tentative steps toward a development method for interfering programs,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976735431&doi=10.1145%2f69575.69577&partnerID=40&md5=977bbee61813ce3b3f92e3e62fc7a220,"Development methods for (sequential) programs that run in isolation have been studied elsewhere. Programs that run in parallel can interfere with each other, either via shared storage or by sending messages. Extensions to earlier development methods are proposed for the rigorous development of interfering programs. In particular, extensions to the specification method based on postconditions that are predicates of two states and the development methods of operation decomposition and data refinement are proposed. © 1983, ACM. All rights reserved.",communicating sequential; guarantee-conditions; processes; Rely-conditions,
Synthesis of Communicating Processes from Temporal Logic Specifications,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976828744&doi=10.1145%2f357233.357237&partnerID=40&md5=e6ef3a56365ba5c8966adbf20d518026,"In this paper, Propositional Temporal Logic (PTL) is applied to the specification and synthesis of the synchronization part of communicating processes. To specify a process, a PTL formula that describes its sequence of communications is given. The synthesis is done by constructing a model of the given specifications using a tableau-like satisfiability algorithm for PTL. This model can then be interpreted as a program. © 1984, ACM. All rights reserved.",Concurrency; mutual exclusion; specification; synchronization,
User Recovery and Reversal in Interactive Systems,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976830385&doi=10.1145%2f357233.357234&partnerID=40&md5=14d3109e64cd9d17f27422fc6f44e899,"Interactive systems, such as editors and program development environments, should explicitly support facilities that permit a user to reverse the effects of past actions and to restore an object to a prior state. A model for interactive systems that allows such recovery facilities to be defined precisely and user and system responsibilities to be delineated is presented. Various techniques for implementing recovery are described. Application of a general recovery facility to support reverse execution is discussed. A program development system (called COPE} with extensive recovery facilities, including reverse execution, is described. © 1984, ACM. All rights reserved.",checkpoint; editor; Recovery; reverse execution; undo,
Grammar-Based Definition of Metaprogramming Systems,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976683239&doi=10.1145%2f357233.357235&partnerID=40&md5=c2a906535abfa4111881bc28c3292c03,"A metaprogramming system is a programming facility (subprogramming system or language) whose basic data objects include the programs and program fragments of some particular programming language, known as the target language of the system. Such systems are designed to facilitate the writing of metaprograms, that is, programs about programs. Metaprograms take as input programs and fragments in the target language, perform various operations on them, and possibly generate modified target-language programs as output. A grammar-based approach to the specification of the syntactic-manipulation component of a metaprogramming system is described. The method derives the specifications for a set of programmanipulating subprograms from an augmented BNF grammar for the target language. The method is applicable to any programming language and is illustrated in its particular application to Pascal. © 1984, ACM. All rights reserved.",Grammar-based processing; metaprogram; metaprogramming system; program improvement; program manipulation,
Comparison of Compacting Algorithms for Garbage Collection,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976679659&doi=10.1145%2f69575.357226&partnerID=40&md5=04856eba0506e879e9d83b70cdb90af5,"The relative efficiencies of four compactors of varisized cells are estimated by constructing their timeformulas. These are symbolic formulas expressing execution times as functions of the time to perform common, elementary operations such as assignment, addition, subscripting, and loop overhead. By binding the variables to numeric values corresponding to a specific machine one can estimate program execution times without resorting to empirical tests. The first of the compactors (Lisp 2) requires additional storage for pointer readjustment. The second (based on the work of Haddon and Waite) attempts to reduce these storage requirements at the expense of processing time. The last two (Morris' and Jonkers') are recently proposed compactors that require minimal additional storage and that update pointers by first threading them into linear lists. The paper provides unified descriptions of the algorithms and presents curves expressing the relative efficiencies of the compactors when run on a specific machine (PDP-10). It is straightforward to modify the given formulas to estimate compactors' efficiencies when run on other computers. © 1983, ACM. All rights reserved.",compaction; Garbage collection; pointer readjustment; storage management; time-formulas; varisized cells,
Tailored-List and Recombination-Delaying Buddy Systems,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976703091&doi=10.1145%2f357233.357239&partnerID=40&md5=a16a39e94fc4c8c8d9b712e90f1344e4,"Two improved variations of the binary buddy system for dynamic memory management, the tailoredlist buddy system (TLBS) and the recombination-delaying buddy system (RDBS), are introduced. In an attempt to save on execution time, these variations do not recombine free buddies every time recombination is possible. In the TLBS recombination is delayed in such a way as to tailor the available free-space lists to the request-size distribution. In the RDBS time is saved by recombining buddies only when larger blocks are unavailable during allocation. Comparative simulation experiments indicate that for not very heavy loads the TLBS is slightly faster than the RDBS, which, in turn, is significantly faster than the traditional system. Since no significant variation has been found among the memory utilizations of the three systems, the TLBS is preferable to the other systems provided that the load is not very heavy and the expected requestsize distribution is at hand. Otherwise, the RDBS is recommended. © 1984, ACM. All rights reserved.",binary buddy system; buddy system; dynamic memory management; Dynamic storage allocation; external fragmentation; recombination-delaying buddy system; simulation; storage fragmentation; tailored-list buddy system,
Termination of Probabilistic Concurrent Program,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976798378&doi=10.1145%2f2166.357214&partnerID=40&md5=f75df9ee032b6d2d4a3b6a8a27461af3,[No abstract available],,
Control Flow Aspects of Semantics-Directed Compiling,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976752178&doi=10.1145%2f69575.357227&partnerID=40&md5=50b8ff90313a491c994d482327d70c2e,"This paper is a demonstration of a semantics-directed compiler generator. We focus on the part of a compiler between syntax analysis and code generation. A language is specified by adding semantic rules in a functional notation to the syntax of the language. Starting with a small sublanguage of while statements, statement constructs of the C programming language are added in stages. Using a small ad hoc code generator, a compiler is automatically constructed from the semantics. The semantic description is analogous to a syntax-directed construction of a flow diagram for a program. By analogy with grammars and parser generators, minimal knowledge of the underlying theory is required. For the control flow aspects of languages, efficient compilers can quickly be generated. © 1983, ACM. All rights reserved.",Compiler generation; continuations; flow diagrams; mathematical semantics,
Correctness Proofs of Communicating Processes: Three Illustrative Examples From the Literature,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976670048&doi=10.1145%2f69575.2083&partnerID=40&md5=f42059392a76f33fdb14042e88cd0e74,"The proof method for networks of processes proposed by Misra and Chandy is demonstrated on three examples from the literature. It is shown that this method is easy to use, preserves process autonomy in the network proof, and conforms naturally to the hierarchical structure of the network. Two very large-scale integration algorithms and a sorting network are presented in Hoare's communicating sequential processes model, specified completely, and formally proved. © 1983, ACM. All rights reserved.",communicating sequential processes; CSP; Message-passing systems; program proofs; rebound sorting,
User Format Control in a LISP Prettyprinter,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976738802&doi=10.1145%2f69575.357225&partnerID=40&md5=46d519a77c697554fbd654f8383fcda9,"A LISP prettyprinter is presented that makes it easy for a user to control the format of the output produced. The printer can be used as a general mechanism for printing data structures as well as programs. It is divided into two parts: a set of formatting functions and an output routine. The user specifies how a particular type of object should be formatted by creating a formatting function for the type. When an object of that type is passed to it, the formatting function creates a sequence of directions that specify how the object should be printed if it can fit on one line and how it should be printed if it must be broken up across multiple lines. A simple template language makes it easy to specify these directions. Based on the line length available, the output routine decides what structures have to be broken up across multiple lines and produces the actual output following the directions created by the formatting functions. The paper concludes with a discussion of how the prettyprintingmethod presented could be applied to languages other than LISP. © 1983, ACM. All rights reserved.",Formatting; user interfaces,
Parallel Generation of Postfix and Tree Forms,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976829388&doi=10.1145%2f2166.357211&partnerID=40&md5=17ffdc3626ac5818849495a063dff609,[No abstract available],,
Postpass Code Optimization of Pipeline Constraints,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976829023&doi=10.1145%2f2166.357217&partnerID=40&md5=d14ffbd8e5df7ea3ba339bb450145362,[No abstract available],,
VLSI Layout as Programming,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976817166&doi=10.1145%2f2166.357216&partnerID=40&md5=e3ce7ee2b09dc62349d15fa42370e29b,[No abstract available],,
Corrigenda,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976703392&doi=10.1145%2f69575.357546&partnerID=40&md5=edf24362e9416fcd86f6004cff6c3db4,[No abstract available],,
Guest Editor's Introduction,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976839726&doi=10.1145%2f2166.357213&partnerID=40&md5=510937db663dd22332a4b0a784dfe314,[No abstract available],,
Parameterized Specifications: Parameter Passing and Implementation with Respect to Observability,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976821809&doi=10.1145%2f2166.357212&partnerID=40&md5=05f10106b41b0b61c78e5a8c1424c9e5,[No abstract available],,
Recursion As an Effective Step in Program Development,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913457082&doi=10.1145%2f357233.357236&partnerID=40&md5=a977a8ba5899eeb1c1436e5d3564b4c8,"A general translation rule from recursive procedures to iterative ones is augmented by also translating the correctness proof. The augmented translation rule is defined within the framework of Pascal programs, with the correctness proof expressed in the Hoare style. The translation is consistent with the stepwise development of Pascal programs. Moreover the translation can be done automatically provided that the assertions are expressed in a formal specification language. Given are a few simplification rules, whose applicability, after the translation, is easily detectable and strongly suggested by the translated assertions. It is shown that the particular cases of linear, tail, and simple recursion (which are known to be easily handled and simplified when expressed in a schematic functional notation) can be simplified automatically after the translation step without leaving the Pascal language. Two examples are provided to show that the given simplification rules can also effectively apply to more general recursive procedures. © 1984, ACM. All rights reserved.",Correctness; iteration; program development; program optimization; program transformations; proof translation,
The Type Theory of PL/CV3,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0011396464&doi=10.1145%2f357233.357238&partnerID=40&md5=e136a2367543c92a10a4224df569af38,"The programming logic PL/CV3 is based on the notion of a mathematical type. The core of the type theory, from which the full theory for program verification and specification can be derived, is presented. Whereas the full theory was designed to be usable, the core theory was selected to be analyzable. This presentation strives to be succinct, yet thorough. The last section consists of examples, but the approach here is not tutorial. © 1984, ACM. All rights reserved.",Automated logic; combinators; constructive logic; data type; foundations of mathematics; lambda calculus; program specification; program verification; semantics of programming languages; type theory,
The drinking philosophers problem,1984,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976705196&doi=10.1145%2f1780.1804&partnerID=40&md5=2676e14b833967850fbf4afc22fb0bc1,"The problem of resolving conflicts between processes in distributed systems is of practical importance. A conflict between a set of processes must be resolved in favor of some (usually one) process and against the others: a favored process must have some property that distinguishes it from others. To guarantee fairness, the distinguishing property must be such that the process selected for favorable treatment is not always the same. A distributed implementation of an acyclic precedence graph, in which the depth of a process (the longest chain of predecessors) is a distinguishing property, is presented. A simple conflict resolution rule coupled with the acyclic graph ensures fair resolution of all conflicts. To make the problem concrete, two paradigms are presented: the well-known distributed dining philosophers problem and a generalization of it, the distributed drinking philosophers problem. © 1984, ACM. All rights reserved.",Asymmetry; dining philosophers problem,
Incremental Context-Dependent Analysis for Language-Based Editors,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976827167&doi=10.1145%2f2166.357218&partnerID=40&md5=5cedeeedf2e5f913c9a3a00bca9f6aaf,[No abstract available],,
Concurrent Reading While Writing,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976657080&doi=10.1145%2f357195.357198&partnerID=40&md5=ae37dd3647365a79e22fe0c4bc049553,"The problem of asynchronous processes reading shared data while the data are being modified by another process is considered. This problem differs from the standard readers/writers problem in that concurrent reading while writing is allowed. The model used here strongly limits the use and size of the shared variables. If multiple copies of the shared data are allowed, then simple, efficient solutions are found. In general, solutions which are more time efficient because they avoid waiting are seen to require more copies of the shared data. The number of copies used by all algorithms is shown to be the best possible. The main solution demonstrates that any system of processes which uses large distributed variables can be strongly simulated by a system which uses only binary distributed variables. © 1983, ACM. All rights reserved.",,
Final Data Types and Their Specification,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976847852&doi=10.1145%2f357195.357202&partnerID=40&md5=66c1ac54ff0f31d2f16a6b10b3ca12bb,"data type specification is a description of the properties of a data abstraction for the benefit of its users and implementers. The data abstraction has realizations, all of which behave in a certain way. It is those properties implied by this behavior which we consider essential; properties specific to some realization are extraneous. The specification problem is to present all of the essential properties and no extraneous ones. We propose a specification method based upon the notion of “final data type.” A final data type is the smallest structure having a given behavior; every other structure having that behavior maps onto it homomorphically. This property makes the final data type specification a particularly good source of information about the abstraction it realizes, and eliminates “implementation bias” from the method. © 1983, ACM. All rights reserved.",,
Automatic Program Improvement: Variable Usage Transformations,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976845672&doi=10.1145%2f69624.357209&partnerID=40&md5=bfc3b3a7251a284eb01ff60a3bba46aa,"The design objective of the Leeds Transformation System is to transform existing programs, written in a variety of languages, into “tidier” programs. The total system was conceived of as having three phases: syntactic transformations, variable usage transformations, and synthesizing features. Because programmers vary greatly in what they consider to be a more acceptable form, we have aimed to make the system as data driven as possible. (That also enables us to deal with a variety of programming languages.) The paper reviews the first two phases, reports the second in some detail, and illustrates the use of the system on an ALGOL 60 program. Redundant assignments, redundant variables, and loop-invariant statements are discovered by means of a novel approach which represents variable usage within a program as a correspondence matrix. Potential enhancements of the system are also discussed. © 1983, ACM. All rights reserved.",correspondence matrix; flow-of-control graph; Variable usage,
Technical Correspondence: On LaLonde and des Rivieres’ “Handling Operator Precedence in Arithmetic Expressions with Tree Transformations”,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976796618&doi=10.1145%2f357195.357203&partnerID=40&md5=a28b16f50d912863492eae70a040ec74,[No abstract available],,
Eliminating Redundant Recursive Calls,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976760082&doi=10.1145%2f2166.2167&partnerID=40&md5=228edf3af3ff9092995b95c0149b9b35,[No abstract available],,
ACM Algorithms Policy,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976666614&doi=10.1145%2f2166.357223&partnerID=40&md5=9350616c120f3553b9171430ecd72551,[No abstract available],,
Generation of Compiler Symbol Processing Mechanisms from Specifications,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976745544&doi=10.1145%2f69624.69625&partnerID=40&md5=4b4b8dc83a9195dbe891b62e000d6305,[No abstract available],,
A Formal Framework for the Derivation of Machine-Specific Optimizers,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976709604&doi=10.1145%2f2166.357219&partnerID=40&md5=902f85d0ae6992efca399c23807d3361,[No abstract available],,
Access-Right Expressions,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0005030481&doi=10.1145%2f357195.357201&partnerID=40&md5=cd3c3fbf40324fc3efb92a6d58a09894,"The intended constraints on use of an instance of such a type can be expressed in two principal ways: as assertions on the domain of values input to each operator, and as constraints on the sequences in which the operators of the type can be called by a customer process. These constraints must be enforced in the environment in which an instance of the type is used. Nevertheless, they are very much a part of the type specification, for its definition is not complete, nor can the consistency of its representation be proved, without them. A notation is provided in which to express sequential constraints, which are here called accessright expressions. It is suggested that these expressions should be declared in a programming language that supports the definition of monitors or resource managers. Implications for the proof rules of monitors are discussed, and suggestions are made for a programming language implementation. © 1983, ACM. All rights reserved.",,
"Guardians and Actions: Linguistic Support for Robust, Distributed Programs",1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976650749&doi=10.1145%2f2166.357215&partnerID=40&md5=4be55538989b712cad26303d4fab95cb,[No abstract available],,
An Effective Implementation for the Generalized Input-Output Construct of CSP,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976737901&doi=10.1145%2f69624.357208&partnerID=40&md5=b1ca65aa42b752d1543ed132fe1a08a0,"Writing distributed algorithms in Hoare's CSP becomes more convenient if output statements are allowed in the guards of alternative and iterative commands. The major drawbacks of the previously published implementations of this construct are discussed. Criteria for an effective implementation are presented, and an algorithm that meets these criteria is constructed. © 1983, ACM. All rights reserved.",CSP; guarded commands; nondeterminism; output guards; Parallel programming; process communication,
A New Solution to Lamport's Concurrent Programming Problem Using Small Shared Variables,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976716976&doi=10.1145%2f357195.357199&partnerID=40&md5=18b7b3e9a2a823b7f99ee2a4765f037c,"A new solution to the concurrent programming control (mutual exclusion) problem that is immune to process failures and restarts is presented. The algorithm uses just four values of shared memory per process, which is within one value of the known lower bound. The algorithm is implemented using two binary variables that make it immune to read errors occurring during writes, that is, “flickering bits”. © 1983, ACM. All rights reserved.",,
Specifying Concurrent Program Modules,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976663837&doi=10.1145%2f69624.357207&partnerID=40&md5=126edb2c499e04d8f94cfd048ec589b5,[No abstract available],,
"Technical Correspondence: On Apt, Francez, and de Roever's “A Proof System for Communicating Sequential Processes”",1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976659682&doi=10.1145%2f2166.357222&partnerID=40&md5=ba904aa4b13738707ae4c64383947b39,[No abstract available],,
On the Construction of Submodule Specifications and Communication Protocols,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976840992&doi=10.1145%2f357195.357196&partnerID=40&md5=3c678d695e804e8ed16166eb7457dbfa,"The problem of elaborating the specification for the submodules of a system is considered. A new method for the construction of submodule specifications is described. If the system is to consist of n submodules and the system as well as (n - 1) submodules are specified, then the method described determines the specification of the additional nth submodule. A formula is given which defines the specification of the additional submodule in the general case where module specifications are given in terms of sets of possible execution sequences, and interaction occurs when several modules participate in the execution of an atomic interaction. For the restricted context of finite-state machines, a constructive algorithm for the evaluation of the formula is given. The use of this design method is demonstrated by examples, including a simple communication protocol involving error detection and retransmission. Possible applications in other areas, as well as remaining problems, are indicated. © 1983, ACM. All rights reserved.",,
A Distributed Algorithm for Minimum-Weight Spanning Trees,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976831429&doi=10.1145%2f357195.357200&partnerID=40&md5=6589af4ab88b928699d2460bdcb82f01,"A distributed algorithm is presented that constructs the minimum-weight spanning tree in a connected undirected graph with distinct edge weights. A processor exists at each node of the graph, knowing initially only the weights of the adjacent edges. The processors obey the same algorithm and exchange messages with neighbors until the tree is constructed. The total number of messages required for a graph of N nodes and E edges is at most 5N log2N + 2E, and a message contains at most one edge weight plus log28N bits. The algorithm can be initiated spontaneously at any node or at any subset of nodes. © 1983, ACM. All rights reserved.",,
Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processors,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976843516&doi=10.1145%2f69624.357206&partnerID=40&md5=2ab290b0dae215cc8727a6325b2bf947,"In this paper we implement several basic operating system primitives by using a “replace-add” operation, which can supersede the standard “test and set” and which appears to be a universal primitive for efficiently coordinating large numbers of independently acting sequential processors. We also present a hardware implementation of replace-add that permits multiple replace-adds to be processed nearly as efficiently as loads and stores. Moreover, the crucial special case of concurrent replace-adds updating the same variable is handled particularly well: If every processing element simultaneously addresses a replace-add at the same variable, all these requests are satisfied in the time required to process just one request. © 1983, ACM. All rights reserved.",network; Parallel processing; replace-add; synchronization; ultracomputer,
Experience with the SETL Optimizer,1983,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976673594&doi=10.1145%2f357195.357197&partnerID=40&md5=7b730d8a01c4916340c94ff2cd4d3066,"The structure of an existing optimizer for the very high-level, set theoretically oriented programming language SETL is described, and its capabilities are illustrated. The use of novel techniques (supported by state-of-the-art interprocedural program analysis methods) enables the optimizer to accomplish various sophisticated optimizations, the most significant of which are the automatic selection of data representations and the systematic elimination of superfluous copying operations. These techniques allow quite sophisticated data-structure choices to be made automatically. © 1983, ACM. All rights reserved.",,
Technical Correspondence: On Steensgaard-Madsen's “A Statement-Oriented Approach to Data Abstraction'’,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976808915&doi=10.1145%2f357153.357160&partnerID=40&md5=f9ddb18167ef5fcef974432ed7b0f782,[No abstract available],,
The Byzantine Generals Problem,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976699318&doi=10.1145%2f357172.357176&partnerID=40&md5=13a18f3e00e3df875eed4c015d105b4e,"Reliable computer systems must handle malfunctioning components that give conflicting information to different parts of the system. This situation can be expressed abstractly in terms of a group of generals of the Byzantine army camped with their troops around an enemy city. Communicating only by messenger, the generals must agree upon a common battle plan. However, one or more of them may be traitors who will try to confuse the others. The problem is to find an algorithm to ensure that the loyal generals will reach agreement. It is shown that, using only oral messages, this problem is solvable if and only if more than two-thirds of the generals are loyal; so a single traitor can confound two loyal generals. With unforgeable written messages, the problem is solvable for any number of generals and possible traitors. Applications of the solutions to reliable computer systems are then discussed. © 1982, ACM. All rights reserved.",Algorithms; Interactive consistency; Reliability,
ACM Algorithms Policy,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976824289&doi=10.1145%2f357172.357180&partnerID=40&md5=a7e5a1e5e8b0a35f9223ed4d6deaa8e7,[No abstract available],,
A Model for Implementing EUCLID Modules and Prototypes,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910350149&doi=10.1145%2f69622.357183&partnerID=40&md5=d9815eb46b30dc68cdf1050959e8c6ae,"The PASCAL-based programming language EUCLID was designed for use in implementing verifiable systems software. The design of EUCLID includes many novel extensions, including a module mechanism and a substantial generalization of the PASCAL type mechanism. This paper presents an implementation model for two of these extensions: modules and parameterized type definitions (prototypes). © 1982, ACM. All rights reserved.",Modules; packages; system implementation language,
An Introduction to S/SL: Syntax/Semantic Language,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976808763&doi=10.1145%2f357162.357164&partnerID=40&md5=4185d04a87f1ebceb58052f595fe7e9d,"S/SL (Syntax/Semantic Language) is a language that was developed for implementing compilers. A subset called SL (Syntax Language) has the same recognition power as do LR(k) parsers. Complete S/SL includes invocation of semantic operations implemented in another language such as PASCAL. S/SL implies a top-down programming methodology. First, a data-free algorithm is developed in S/SL. The algorithm invokes operations on “semantic mechanisms.” A semantic mechanism is an abstract object, specified, from the point of view of the S/SL, only by the effect of operations upon the object. Later, the mechanisms are implemented apart from the S/SL program. The separation of the algorithm from the data and the division of data into mechanisms reduce the effort needed to understand and maintain the resulting software. © 1982, ACM. All rights reserved.",,
A Weaker Precondition for Loops,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976692006&doi=10.1145%2f69622.357189&partnerID=40&md5=d8916b1100913cf555713981659a5d62,"In his book, A Discipline of Programming, Dijkstra presents the skeleton for a programming language and defines its semantics axiomatically using predicate transformers. HIS language involves only bounded nondeterminism. He shows that unbounded nondeterminism is incompatible with his axioms and his continuity principle, and he argues that this is no drawback because unboundedly nondeterministic machines cannot be built. This paper considers the question of unbounded nondeterminism. A new predicate transformer is derived to handle this. A proof is given that the new transformer corresponds to operational semantics, and an informal argument is given that unbounded nondeterminism can be a useful programming concept even in the absence of nondeterministic machines. © 1982, ACM. All rights reserved.",Ackermann's function; fair do loop; fair scheduling; nondeterminism; predicate transformer; total correctness; unbounded nondeterminism; Weakest precondition,
The Evaluation of Expressions in Icon,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722893&doi=10.1145%2f69622.357184&partnerID=40&md5=733cca567b22fc23dbceae259a1ee8f1,"Expressions in the Icon programming language may be conditional, possibly producing no result, or they may be generators, possibly producing a sequence of results. Generators, coupled with a goaldirected evaluation mechanism, provide a concise method for expressing many complex computations. This paper describes the evaluation of expressions in Icon and presents an Icon program that explicates the semantics of expression evaluation. This program also provides an executable “formalism” that can be used as a tool to design and test changes and additions to the language. © 1982, ACM. All rights reserved.",Generators,
Technical Correspondence: Steensgaard-Madsen's reply,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976682153&doi=10.1145%2f357153.357161&partnerID=40&md5=55ff7246e84bc8f3bf0e1b81b39bfb48,[No abstract available],,
Error Data Values in the Data-Flow Language VAL,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976784198&doi=10.1145%2f357162.357167&partnerID=40&md5=91d110f2e65925f1e3f8ace3308122e8,"The data-flow architecture is intended to support large scientific computations, and VAL is an algebraic, procedural language for use on a data-flow computer. VAL is apt for numerical computations but requires an error monitoring feature that can be used to diagnose and correct errors arising during program execution. Traditional monitoring methods (software traps and condition codes are inappropriate for VAL; instead, VAL includes a set of error data values and an algebra for their manipulation. The error data values and their algebra are described and assessed; the conclusion is that error values provide a clean way for a high-level language to handle numeric (and some other) errors. © 1982, ACM. All rights reserved.",,
Finite Differencing of Computable Expressions,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976843894&doi=10.1145%2f357172.357177&partnerID=40&md5=b5ce2b725626aef05ba84af82aec5580,[No abstract available],,
Deriving Target Code as a Representation of Continuation Semantics,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976841631&doi=10.1145%2f357172.357179&partnerID=40&md5=f1697b69c2e6e70bd55c363229d3bbdb,"Reynolds' technique for deriving interpreters is extended to derive compilers from continuation semantics. The technique starts by eliminating h-variables from the semantic equations through the introduction of special-purpose combinators. The semantics of a program phrase may be represented by a term built from these combinators. Then associative and distributive laws are used to simplify the terms. Last, a machine is built to interpret the simplified terms as the functions they represent. The combinators reappear as the instructions of this machine. The technique is illustrated with three examples. © 1982, ACM. All rights reserved.",combinators; Continuations,
A System for Assisting Program Transformation,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976857494&doi=10.1145%2f357153.357154&partnerID=40&md5=59ce7d0be9a8fd0f502a0bdc8a4dfd3f,"Program transformation has been advocated as a potentially appropriate methodology for program development. The ability to transform large programs is crucial to the practicality of such an approach. This paper describes research directed toward applying one particular transformation method to problems of increasing scale. The method adopted is that developed by Burstall and Darlington, and familiarity with their work is assumed. The problems which arise when attempting transformation of larger scale programs are discussed, and an approach to overcoming them is presented. Parts of the approach have been embodied in a machine-based system which assists a user in transforming his programs. The approach, and the use of this system, are illustrated by presenting portions of the transformation of a compiler for a “toy” language. © 1982, ACM. All rights reserved.",program development; program transformation,
Efficient Computation of LALR(1) Look-Ahead Sets,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976794555&doi=10.1145%2f69622.357187&partnerID=40&md5=e12a7f1dd48d57526754fb368496fe79,"Two relations that capture the essential structure of the problem of computing LALR(1) look-ahead sets are defined, and an efficient algorithm is presented to compute the sets in time linear in the size of the relations. In particular, for a PASCAL grammar, the algorithm performs fewer than 15 percent of the set unions performed by the popular compiler-compiler YACC. When a grammar is not LALR(1), the relations, represented explicitly, provide for printing useroriented error messages that specifically indicate how the look-ahead problem arose. In addition, certain loops in the digraphs induced by these relations indicate that the grammar is not LR(k) for any k. Finally, an oft-discovered and used but incorrect look-ahead set algorithm is similarly based on two other relations defined for the fwst time here. The formal presentation of this algorithm should help prevent its rediscovery. © 1982, ACM. All rights reserved.",Backus-Naur form; Context-free grammar; grammar debugging; LALR(1); LR(k); strongly connected component,
A Flexible Notation for Syntactic Definitions,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976681355&doi=10.1145%2f357153.357159&partnerID=40&md5=76291a073cc6b20210fe4590647ef6c7,"In view of the proliferation of notations for defining the syntax of programming languages, it has been suggested that a simple notation should be adopted as a standard. However, any notation adopted as a standard should also be as versatile as possible. For this reason, a notation is presented here which is both simple and versatile and which has additional benefits when specifying the static semantic rules of a language. © 1982, ACM. All rights reserved.",BNF,
Synchronization in Distributed Programs,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976650104&doi=10.1145%2f357162.357163&partnerID=40&md5=35df4b98a1fe7f6df59fdb11a98e551a,"A technique for solving synchronization problems in distributed programs is described. Use of this technique in environments in which processes may fail is discussed. The technique can be used to solve synchronization problems directly, to implement new synchronization mechanisms (which are presumably well suited for use in distributed programs), and to construct distributed versions of existing synchronization mechanisms. Use of the technique is illustrated with implementations of distributed semaphores and a conditional message-passing facility. © 1982, ACM. All rights reserved.",,
The VAL Language: Description and Analysis,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976731995&doi=10.1145%2f357153.357157&partnerID=40&md5=364553525922fd0fefbe2c7ce0b4dc12,"VAL is a high-level, function-based language designed for use on data flow computers. A data flow computer has many small processors organized to cooperate in the execution of a single computation. A computation is represented by its data flow graph; each operator in a graph is scheduled for execution on one of the processors after all of its operands' values are known. VAL promotes the identification of concurrency in algorithms and simplifies the mapping into data flow graphs. This paper presents a detailed introduction to VAL and analyzes its usefulness for programming in a highly concurrent environment. VAL provides implicit concurrency (operations that can execute simultaneously are evident without the need for any explicit language notation). The language uses function- and expression-based features that prohibit all side effects, which simplifies translation to graphs. The salient language features are described and illustrated through examples taken from a complete VAL program for adaptive quadrature. Analysis of the language shows that VAL meets the critical needs for a data flow environment. The language encourages programmers to think in terms of general concurrency, enhances readability (due to the absence of side effects), and possesses a structure amenable to verification techniques. However, VAL is still evolving. The language definition needs refining, and more support tools for programmer use need to be developed. Also, some new kinds of optimization problems should be addressed. © 1982, ACM. All rights reserved.",,
A One-Pass Algorithm for Overload Resolution in Ada,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976746690&doi=10.1145%2f69622.69623&partnerID=40&md5=20aa7b3a3889fd3d2ba45a1b0436e030,"A simple method is presented for detecting ambiguities and finding the correct interpretations of expressions in the programming language Ada. Unlike previously reported solutions to this problem, which require multiple passes over a tree structure, the method described here operates in one bottom-up pass, during which a directed acyclic graph is produced. The correctness of this approach is demonstrated by a brief formal argument. © 1982, ACM. All rights reserved.",intermediate code; Overloading; translators,
Proving Liveness Properties of Concurrent Programs,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976730945&doi=10.1145%2f357172.357178&partnerID=40&md5=282f816eeffdbc97d7800cad8c08be0c,"A liveness property asserts that program execution eventually reaches some desirable state. While termination has been studied extensively, many other liveness properties are important for concurrent programs. A formal proof method, based on temporal logic, for deriving liveness properties is presented. It allows a rigorous formulation of simple informal arguments. How to reason with temporal logic and how to use safety (invariance) properties in proving liveness is shown. The method is illustrated using, first, a simple programming language without synchronization primitives, then one with semaphores. However, it is applicable to any programming language. © 1982, ACM. All rights reserved.",fairness; liveness; multiprocessing; proof of correctness; synchronization; Temporal logic,
Some Observations Concerning Formal Differentiation of Set Theoretic Expressions,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976663092&doi=10.1145%2f357162.357166&partnerID=40&md5=c1f9f805b973c4838b4311d8333b5721,"A variety of matters related to formal differentiation are considered. First, an algebraic approach to formal differentiation of a class of set theoretic expressions is suggested. Then the application of formal differentiation to loop fusion is discussed. Finally, formal differentiation is applied to optimization of incremental construction of composite objects satisfying a given Predicate. The techniques developed are illustrated by transformational construction of a variety of algorithms. © 1982, ACM. All rights reserved.",,
An O(nlog n) Unidirectional Algorithm for the Circular Extrema Problem,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976762401&doi=10.1145%2f69622.357194&partnerID=40&md5=dba4707d7379fc47526c38e2ccf9766a,"Hirschberg and Sinclair recently published a solution to the circular extrema-finding (or election) problem which requires O (n log n) message passes in two directions around the ring. They conjecture that 12(n 2) message passes are required in the unidirectional case. This conjecture is shown to be false. The algorithms presented here are unidirectional, simpler than the Hirschberg and Sinclair solution, use fewer (in fact, optimal) distinct messages, have many fewer total message passes, and require less time. © 1982, ACM. All rights reserved.",Distributed algorithms; extrema finding; message passing,
Formal Specification of Graphic Data Types,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976821788&doi=10.1145%2f69622.357191&partnerID=40&md5=00a25910683b3929ac5a3654b009e2ef,"Formal specification techniques and data abstractions have seen little application to computer graphics. Many of the objects and operations unique to graphics programs can be handled conveniently by def'ming special graphic data types. Not only do graphic data types provide an attractive way to work with pictures, but they also allow specification techniques for data abstractions to be employed. Algebraic axioms, because of their definitional nature, are especially well suited to specifying the diversity of types useful in graphics applications. In this paper, definitions are given for some important concepts that appear in graphics programs. Based on these definitions, some illustrative graphic data types, called point, region, geometric function, graphic transformation, and tree-structured picture, are defined and specified algebraically. A simple graphics language for line drawings is created by embedding these new data types in the language PASCAL. Using the specifications, an outline of a correctness proof for a small programming example is presented. © 1982, ACM. All rights reserved.",Graphic data type,
Combining Algebraic and Algorithmic Reasoning: An Approach to the Schorr-Waite Algorithm,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976743907&doi=10.1145%2f357172.357175&partnerID=40&md5=bf2979155812747c896d6913b875cf3c,"The basic idea of the Schorr-Waite graph-marking algorithm can be precisely formulated, explained, and verified in a completely applicative (functional) programming style. Graphs are specified algebraically as objects of an abstract data type. When formulating recursive programs over such types, one can combine algebraic and algorithmic reasoning: An applicative depth-first-search algorithm is derived from a mathematical specification by applying properties of reflexive, transitive closures of relations. This program is then transformed in several steps into a fmal procedural version with the help of both algebraic properties of graphs and algorithmic properties reflected in the recursion structure of the program. © 1982, ACM. All rights reserved.",Algorithms; Languages; Verification,
Some Techniques for Recursion Removal from Recursive Functions,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976858007&doi=10.1145%2f357162.357171&partnerID=40&md5=9d2976d3c398d01e02dc65c9885ad786,"Three different techniques that can be used for recursion removal are described: generalization of the function definition, study of the computation traces of the function, and nonprocedural languages. Despite the existence of implemented versions of these techniques, they are easy to use “by hand” and should therefore be part of every programmer's knowledge. © 1982, ACM. All rights reserved.",,
A Value Transmission Method for Abstract Data Types,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976706598&doi=10.1145%2f69622.357182&partnerID=40&md5=02b5728baf9ef3ec2c9cbab96263ee2a,"Data types have proved to be a useful technique for structuring systems. In large systems it is sometimes useful to have different regions of the system use different representations for the abstract data values. A technique is described for communicating abstract values between such regions. The method was developed for use in constructing distributed systems, where the regions exist at different computers and the values are communicated over a network. The method defines a call-by-value semantics; it is also useful in nondistributed systems wherever call by value is the desired semantics. An important example of such a use is a repository, such as a file system, for storing longlived data. © 1982, ACM. All rights reserved.",call by value; long-term storage; Message communications,
Symbolic Debugging of Optimized Code,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976805568&doi=10.1145%2f357172.357173&partnerID=40&md5=7677a87db0cbfcdfb4c7646bece48a8a,"The long-standing conflict between code optimization and symbolic debugging is examined. The effects of local and global optimizations on the variables of a program are categorized, and models for representing the effect of optimizations are given. Algorithms use these models to determine the subset of variables whose values do not correspond to those in the original program. Restoring these variables to their correct values is investigated, and empirical results from the application of these algorithms to local optimization are also presented. © 1982, ACM. All rights reserved.",directed acyclic graphs; flow graphs; Symbolic debugging,
Data Type Specification: Parameterization and the Power of Specification Techniques,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976670254&doi=10.1145%2f69622.357192&partnerID=40&md5=3a2065aa7cd71d4aec82df6e5c2be572,"Our earlier work on abstract data types is extended by the answers to a number of questions on the power and limitations of algebraic specification techniques and by an algebraic treatment of parameterized data types like sets-of-( ) and stacks-of-(). The “hidden function” problem (the need to include operations in specifications which are wanted hidden from the user) is investigated; the relative power of conditional specifications and equational specifications is investigated; and it is shown that parameterized specifications must contain “side conditions” (e.g., that finite-sets-of-d requires an equality predicate on d). © 1982, ACM. All rights reserved.",Algebraic specification,
Programming with Equations,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722974&doi=10.1145%2f357153.357158&partnerID=40&md5=1a4acfe1c958bffea485640800a67729,"Equations provide a convenient notation for defining many computations, for example, for programming language interpreters. This paper illustrates the usefulness of equational programs, describes the problems involved in implementing equational programs, and investigates practical solutions to those problems. The goal of the study is a system to automatically transform a set of equations into an efficient program which exactly implements the logical meaning of the equations. This logical meaning may be defined in terms of the traditional mathematical interpretation of equations, without using advanced computing concepts. © 1982, ACM. All rights reserved.",equations; term-rewriting systems,
Inessential Error Entries and Their Use in LR Parser Optimization,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976759852&doi=10.1145%2f357162.357165&partnerID=40&md5=b00ab8ab4535a571ec04e0942388a586,"The use of “default reductions” in implementing LR parsers is considered in conjunction with the desire to decrease the number of states of the parser by making use of “don't-care” (also called “inessential” ) error entries. Default reductions are those which are performed independently of the lookahead string when other operations do not apply, and their use can lead to substantial savings in space and time. Don't-care error entries of an LR parser are those which are never consulted, and thus they can be arbitrarily replaced by nonerror entries in order to make a state compatible with another one. Determining don't-care error entries is most important in avoiding the growth of the size of the parser when eliminating reductions by single productions, that is, productions for which the right-hand side is a single symbol. The use of default reductions diminishes don't-care error entries. This effect is analyzed by giving a necessary and sufficient condition for an error entry to be don't-care when default reductions are used. As an application, elimination of reductions by single productions in conjunction with the use of default reductions is considered. © 1982, ACM. All rights reserved.",,
A Distributed Graph Algorithm: Knot Detection,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976728422&doi=10.1145%2f69622.357190&partnerID=40&md5=34b0297eb25a8eb337963310a0c2a822,"A knot in a directed graph is a useful concept in deadlock detection. A distributed algorithm for identifying a knot in a graph by using a network of processes is presented. The algorithm is based on the work of Dijkstra and Scholten. © 1982, ACM. All rights reserved.",Distributed algorithms; knot; message communication,
[formula omitted] for Semantics,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976829359&doi=10.1145%2f357162.357170&partnerID=40&md5=f19cff1a379ba082992a10416e164b82,"A constructive criticism of recent work in the semantics of programming languages is offered. The criticism is directed not so much at the techniques and results obtained as at the use to which they are put. The fact that denotational (or “mathematical”) semantics plays on the whole a passive (“descriptive”) role, whil e operational semantics plays on the whole an active (“prescriptive”) role, is seen as the basic problem. It is suggested that these roles be reversed. © 1982, ACM. All rights reserved.",,
Compact Storage of Binary Trees,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976754027&doi=10.1145%2f357172.357174&partnerID=40&md5=92e1de8ed8f7b5daa5c7c822c64e7752,"Statistical measurements of the behavior of LISP programs have shown a marked asymmetry in the distribution of their data structures (binary trees). On the basis of a statistical model for such a distribution, we evaluate the expected storage cost of a representation of binary trees based on the use of k-pointer cells instead of conventional two-pointer ones. We conclude that LISP trees would be more efficiently encoded using three-pointer nodes. © 1982, ACM. All rights reserved.",Compact encoding; list structure regularity; three-pointer cells; tree structure,
High-Level Language Implications of the Proposed IEEE Floating-Point Standard,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976817409&doi=10.1145%2f357162.357168&partnerID=40&md5=caf5997a610807538f1bf9d73ad3d4d6,"An IEEE Computer Society working group on floating-point arithmetic has recommended a standard for binary floating.point number formats, operations, and semantics. This paper, which has evolved in part during the deliberations of that committee, describes the significance to languages and, in particular, to FORTRAN and its Variants, of various novel features of the recommended standard. © 1982, ACM. All rights reserved.",,
A Structured APL System,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976654734&doi=10.1145%2f69622.357185&partnerID=40&md5=3156f6aa4fbe39b5c826ae30cf7ede0e,"A structured APL system introducing several interesting features is described. The APL group concept has been considerably extended to yield a new type of APL object called a segment. Segments constitute the basic building blocks used to manage memory and to build up the workspace and the user's library. The encapsulation capability provides a unified scheme for handling variables, functions, and other APL objects, including fries. A new structured user library is proposed. The dynamic call of objects during a terminal session links the user library to the workspace. New types of variables are described along with solutions to interesting problems based on them. © 1982, ACM. All rights reserved.",Workspace,
On the Development of the Algebra of Functional Programs,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976719059&doi=10.1145%2f69622.357193&partnerID=40&md5=6c0ab9cf7b4ac92f07bfe8a3608e7af2,"The development of the algebraic approach to reasoning about functional programs that was introduced by Backus in his Turing Award Lecture is furthered. Precise definitions for the foundations on which the algebra is based are given, and some new expansion theorems that broaden the class of functions for which this approach is applicable are proved. In particular, the class of “overruntolerant” forms, nonlinear forms that include some of the familiar divide-and-conquer program schemes, are defined; an expansion theorem for such forms is proved; and that theorem is used to show how to derive expansions for some programs deemed by nonlinear forms. © 1982, ACM. All rights reserved.",Transformations,
Transformational Derivation of a Garbage Collection Algorithm,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976772088&doi=10.1145%2f69622.357188&partnerID=40&md5=1270bf669033703b8539f94a64abc51d,"Transformational programming is a relatively new programming technique intended to derive complex algorithms automatically. Initially, a set of transformational rules is described, and an initial specification of the problem to be programmed is given. The specification is written in a high-level language in a fairly compact form possibly ignoring efficiency. A number of versions, called transformations, are created by successively applying the transformational rules starting with the initial specification. As an example of the application of this technique to a fairly complex case, a transformational derivation of a variant of a known efficient garbage collection and compaction algorithm from an initial very high-level specification is given. Currently, the techniques are still being developed, and therefore the transformations are derived manually. However, most of the transformations done are of a technical nature and could eventually be automated. © 1982, ACM. All rights reserved.",formal differentiation; garbage collection; loop fusion; strength reduction; Transformational programming; wide-spectrum languages,
An Efficient Unification Algorithm,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976745321&doi=10.1145%2f357162.357169&partnerID=40&md5=a7394fc6046768418f39a10862f2fa55,"The unification problem in f'mst-order predicate calculus is described in general terms as the solution of a system of equations, and a nondeterministic algorithm is given. A new unification algorithm, characterized by having the acyclicity test efficiently embedded into it, is derived from the nondeterministic one, and a PASCAL implementation is given. A comparison with other well-known unification algorithms shows that the algorithm described here performs well in all cases. © 1982, ACM. All rights reserved.",,
A Cost Model for the Internal Organization of B+-Tree Nodes,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976678579&doi=10.1145%2f357146.357152&partnerID=40&md5=e2d21f87e7181248a8fd98fea74d44c3,"Not only must an entire B+-tree support the operations of key insertion, deletion, and lookup, but the organization of keys within each tree node must support these same operations. Choice of the appropriate internal node organization for the keys involves typical space-time trade-offs. This paper presents a cost model for examining these trade-offs and illustrates it by analyzing four promising organizations: binary search, sequential search, square root search, and “partitioned pages.” Evaluation of the model for a set of typical parameters shows that binary search is the most economical if all keys are the same length, and square root search is preferable when the key length varies. One interesting result is that space overhead for organizations like linked lists exacts a much higher penalty during some stages of tree growth than during others. © 1981, ACM. All rights reserved.",B+-tree; binary search; data structures; database; disk; index; information retrieval; keys; pages; secondary storage; square root search; virtual memory,
An Automatic Technique for Selection of Data Representations in SETL Programs,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976758332&doi=10.1145%2f357133.357135&partnerID=40&md5=f7f1f043cd58c50dd7426dcb6aa9988d,[No abstract available],,
Locally Least-Cost Error Recovery in Earley's Algorithm,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976758737&doi=10.1145%2f357139.357145&partnerID=40&md5=afbb552b84bd6915a866d0253189b2f7,"While-least-cost~ error correction is fundamentally important to context-free language processing, it is inefficient w'Qhemdone globally. A locally least-cost repair method has been devised to model error recovery in conventional-~o-mpile]tsT. he principles of this recovery technique have inspired a practical LL(1) method and should be of value m ~ntmg-error~rJel~a~lr m other parsing algorithms.- At each point in the syntax analysis, a locally optimal repair of't~e-next-sy-mBffl is defined to be a string w such that w can be parsed without error and such that editing the symbol following w can be achieved at least cost, costs being defined by the Wagner-Fischer model of string-to-string correction. In this paper we describe how error recovery can be achieved in Earley's algorithm by simulating locally optimal repairs. The main result is to show that the complexity of Earley's algorithm is not affected by this process; that is, for any input string of length n, the work involved is O(n) if the given grammar is deterministic, O(n 2) if the grammar is unambiguous, and O(n 3) in the worst case. © 1981, ACM. All rights reserved.",complexity; error correction; error recovery; error repair; general context-free parsing,
Referencing and Retention in Block-Structured Coroutines,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976720510&doi=10.1145%2f357139.357143&partnerID=40&md5=f4ffffac865cc491a1a01524bb856b30,"The combination of coroutines with recursive procedures is characteristic of many modern higher level languages offering advanced control structures (e.g., SIMULA-67, SL5, or INTERLISP). We say a language has block-structured coroutines (BSCRs) when static nesting considerations govern the usage of this control combination. Starting with the BSCR control description work of Wang and Dahl, this paper pursues further the implications of static program structure on BSCR programs in a particular compilation-oriented setting. Disciplines on BSCR reference assignment and individual control actions are defined, offering enhanced implementability and program comprehensibility. Of particular interest is a scope-based discipline on “detach” operations, which avoids the formation of idle chain subheads, an implementationally undesirable condition. The retention requirements of BSCRs are analyzed under a range of possible remote accessibility conditions, and two deletion strategies are then defined, keyed to these requirements. The first uses a special form of scopesensitive reference counting, and the second does mark-sweep garbage collection, again exploiting static program structure. Space and time estimates for both methods are given, along with avenues for continuing research. © 1981, ACM. All rights reserved.",coroutines; deletion strategies; garbage collection; reference counting; remote accessing; static nesting,
Technical Correspondence: On Landwehr's “An Abstract Type for Statistics Collection”,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976779538&doi=10.1145%2f357133.357544&partnerID=40&md5=027a425e043e685406baa944052d60dd,[No abstract available],,
The Construction of Stack-Controlling LR Parsers for Regular Right Part Grammars,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976684340&doi=10.1145%2f357133.357138&partnerID=40&md5=f197d19187abc196b44e664f8d3e1c3f,[No abstract available],,
Synchronizing Resources,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976729196&doi=10.1145%2f357146.357149&partnerID=40&md5=27fd25d5c5a9a1176668aefa0e1591e7,"A new proposal for synchronization and communication in parallel programs is presented. The proposal synthesizes and extends aspects of procedures, coroutines, critical regions, messages, and monitors. It provides a single notation for parallel programming with or without shared variables and is suited for either shared or distributed memory architectures. The essential new concepts are operations, input statements, and resources. The proposal is illustrated by the solutions of a variety of parallel programming problems; its relation to other parallel programming proposals is also discussed. © 1981, ACM. All rights reserved.",databases; distributed processing; monitors; operating systems; parallel programming; process communication; processes; programming languages; synchronization,
Generators in Icon,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976759515&doi=10.1145%2f357133.357136&partnerID=40&md5=fe0cd0ed91c5db8a673a73d418e7562c,[No abstract available],,
"Data-Abstraction, Implementation, Specification, and Testing",1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976743225&doi=10.1145%2f357139.357140&partnerID=40&md5=f75df949f53caeb9068fb9f7814578a8,"A compiler-based system DAISTS that combines a data-abstraction implementation language (derived from the SIMULA class) with specification by algebraic axioms is described. The compiler, presented with two independent syntactic objects in the axioms and implementing code, compiles a “program” that consists of the former as test driver for the latter. Data points, in the form of expressions using the abstract functions and constant values, are fed to this program to determine if the implementation and axioms agree. Along the way, structural testing measures can be applied to both code and axioms to evaluate the test data. Although a successful test does not conclusively demonstrate the consistency of axioms and code, in practice the tests are seldom successful, revealing errors. The advantage over conventional programming systems is threefold. © 1981, ACM. All rights reserved.",abstract data type; program testing; specifications,
Ten Years of Hoare's Logic: A Survey—Part I,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976766710&doi=10.1145%2f357146.357150&partnerID=40&md5=eca3e95a03c0fc5a7d534d999f3f6393,"A survey of various results concerning Hoare's approach to proving partial and total correctness of programs is presented. Emphasis is placed on the soundness and completeness issues. Various proof systems for while programs, recursive procedures, local variable declarations, and procedures with parameters, together with the corresponding soundness, completeness, and incompleteness results, are discussed. © 1981, ACM. All rights reserved.",arithmetical interpretation; call-by-name; call-by-value; call-by-variable; completeness in the sense of Cook; dynamic scope; expressiveness; Hoare's logic; partial correctness; procedures as parameters; recursive procedures; soundness; static scope; subscripted variables; total correctness; variable declarations; while programs,
Termination Detection of Diffusing Computations in Communicating Sequential Processes,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0004667092&doi=10.1145%2f357153.357156&partnerID=40&md5=0a92c6c1641391a744334589d8787baa,"In this paper it is shown how the Dijkstra-Scholten scheme for termination detection in a diffusing computation can be adapted to detect termination or deadlock in a network of communicating sequential processes as defined by Hoare. © 1982, ACM. All rights reserved.",diffusing computation; distributed systems; networks of processes; termination detection,
Algorithm 568: PDS—A Portable Directory System,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976840179&doi=10.1145%2f357133.357137&partnerID=40&md5=c20982271b449d7bdced2e3ec41507af,[No abstract available],,
Nonsequentiality and Concrete Activity Phases in Discrete-Event Simulation Languages,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976765342&doi=10.1145%2f357139.357144&partnerID=40&md5=bb3597d4fe2e6eece9a2e52f47c874df,"The design of languages for programming complex discrete-event simulations, with a conventional global notion of simulation time, is considered. An example language is described in which the main objects dealt with are concrete manifestations of phases of activity conceptually underlying a simulation and in which programs have an extremely nonsequential mode of notional operation. A program in the language very directly specifies a certain type of formal simulation system which generates a unique maximal simulation history. This history is a sequence of time instants, each associated with the partially ordered set of events considered to occur at that instant. In contrast to the case of programs in existing discrete-event simulation languages, (1) the event orders achievable at instants can be partial and are not restricted in any way, and (2) phase objects are central and explicit in a program, being the main units describing overall structure, data, and control. Variants of the language could have uses other than simulation. © 1981, ACM. All rights reserved.",activity phases; concurrency; determinacy; discrete-event simulation; event scheduling; guarded commands; histories; nonsequentiality; parallel programs; simulation languages; simultaneous events; transition systems,
Specifying the Semantics of while Programs: A Tutorial and Critique of a Paper by Hoare and Lauer,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886766499&doi=10.1145%2f357146.357151&partnerID=40&md5=6a8eecf08ad9ebdbb0cf01577c7fac04,"We consider three kinds of mathematical objects which can be designated as the “meaning” or “semantics” of programs: binary relations between initial and final states, binary relations on predicates (partial-correctness semantics), and functionals from predicates to predicates (predicate transformers). We exhibit various formal specification mechanisms: induction on program syntax, axioms, and deductive systems. We show that each kind of semantics can be specified by several different mechanisms. As long as arbitrary predicates on states are permitted, each kind of semantics uniquely determines the others, with the sole exception of the weakest precondition semantics for nondeterministic programs. © 1981, ACM. All rights reserved.",partial correctness; semantics of programming languages; weakest precondition,
Process Communication Based on Input Specifications,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976690025&doi=10.1145%2f357139.357141&partnerID=40&md5=eb83f5edb8ab7970481a39c2be9f924a,"Input tools, originally introduced as a language model for interactive systems and based on high-level, input-driven objects, have been developed into a model for communicating parallel processes, called the input tool process model (ITP). In this model every process contains an input rule, comparable to the right-hand side of a production rule. This rule specifies in an expression the patterns and sources of input it exPects and where the input is to be handled. The reception of the input triggers action inside the too! process. As part of the action, messages may be sent to other processes, with destination specified to a varying degree of identification. A potential candidate for a message is any tool process with the correct type of message slot. Because sending tool processes do not have to specify completely the identity of receiving tool processes, and vice versa, ITP provides a fully dynamic communication model. Most communication aspects of other recently developed models are contained in this model. Synchronization of processes is accomplished implicitly by the input specification; explicit synchronizatiQn constructs such as monitors and guarded regions can therefore be easily simulated. The ITP constructs provide a general concept for interprocess communication. Its application areas range from interaction via process control to operating systems. From a programming point of view, the language constructs offered are not in any way dependent on whether processes run on single or multiple processors. © 1981, ACM. All rights reserved.",communicating processes; concurrency; data flow; input expressions; input tools; interactive systems; networks; operating systems; parallel processes; parallel programming; processes; real-time programming; synchronization,
Associons: A Program Notation with Tuples Instead of Variables,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976706308&doi=10.1145%2f357139.357142&partnerID=40&md5=735b431ad4930ea93d7a121eac99d8d6,"A program notation without variables is proposed. The state of a computation is recorded as a set of “associons.” Each associon is a tuple of names representing a relation between the entities with those names. The state of the computation can be changed by the creation of new associons representing new relations deducible from those already recorded. The building block prescribing such deductions is called the “closure statement.” The notation proposed is the result of our search for a basic statement the execution of which may employ more concurrency than is the case for the traditional assignment statement. Some possible extensions to the notation are discussed. © 1981, ACM. All rights reserved.",associative addressing; associons; closure statement; concurrency; content-retrievable tuples; data structures; programming languages,
Editing Data Structures,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976671049&doi=10.1145%2f357133.357134&partnerID=40&md5=b3b8b80e7938b0adf37efd3e39d572bc,[No abstract available],,
Technical Correspondence,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976674955&doi=10.1145%2f357146.357545&partnerID=40&md5=8601febe5213cb8c066043ad08c034a9,[No abstract available],,
Space-Efficient Storage Management in an Attribute Grammar Evaluator,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976773063&doi=10.1145%2f357146.357148&partnerID=40&md5=a653e98beb7185bf1c73b4aecd998988,"A space-efficient strategy for storing attributes during evaluation of an attribute grammar is presented. Attributes are classified as either one-pass or multipass. One-pass attributes are stored on a pushdown stack, and their storage is freed when no longer needed. Examination of extant grammars shows that a vast majority of attributes are indeed one-pass, and therefore the scheme presented can greatly reduce the storage requirements of an attribute grammar evaluator. Several approaches to storage management for multipass attributes are also presented. Data for several grammars are collected and used to show the effectiveness of the proposed storage management scheme. © 1981, ACM. All rights reserved.",attribute grammar; attribute storage management; compiler; semantic evaluation; space optimization; translator-writing system,
"The Programming Language Aspects of ThingLab, a Constraint-Oriented Simulation Laboratory",1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722628&doi=10.1145%2f357146.357147&partnerID=40&md5=58627b894f13eb2e5cc41bf097a471b2,"The programming language aspects of a graphic simulation laboratory named ThingLab are presented. The design and implementation of ThingLab are extensions to SmaUtalk. In ThingLab, constraints are used to specify the relations that must hold among the parts of the simulation. The system is object-oriented and employs inheritance and part-whole hierarchies to describe the structure of a simulation. An interactive, graphic user interface is provided that allows the user to view and edit a simulation. © 1981, ACM. All rights reserved.",constraint satisfaction; constraints; inheritance; object-oriented languages; part-whole hierarchies; Smalltalk; ThingLab,
Using Peephole Optimization on Intermediate Code,1982,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976650258&doi=10.1145%2f357153.357155&partnerID=40&md5=c77cb50a42ac7978751331088fa54f95,"Many portable compilers generate an intermediate code that is subsequently translated into the target machine's assembly language. In this paper a stack-machine-based intermediate code suitable for algebraic languages (e.g., PASCAL, C, FORTRAN) and most byte-addressed mini- and microcomputers is described. A table-driven peephole optimizer that improves this intermediate code is then discussed in detail and compared with other local optimization methods. Measurements show an improvement of about 15 percent, depending on the precise metric used. © 1982, ACM. All rights reserved.",abstract machine; intermediate code; peephole optimizer,
An Abstract Type for Statistics Collection in SIMULA,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976712331&doi=10.1145%2f357114.357118&partnerID=40&md5=18cf4fea19dcbd673ff31e655418f995,"Although the use of abstract types has been widely advocated as a specification and implementation technique, their use has often been associated with programming languages that are not widely available, and examples published to date are rarely taken from actual applications. SIMULA is a widely available language that supports the use of abstract types. The purposes of this paper are (1) to demonstrate the application of the concepts of data abstraction to a common problem; (2) to demonstrate the use of data abstraction in a widely available language; and (3) to provide a portable facility for statistics collection that may make the use of SIMULA more attractive. A discussion of the background of and requirements for an abstract type for statistics collection is presented, followed by a specification for the type using traces. A SIMULA implementation, with examples of its use, is given. Finally, implementation of the abstract type in other languages is discussed. © 1980, ACM. All rights reserved.",abstract types; data abstraction; programming; SIMULA; simulation; software; software design; software engineering; statistics collection,
Methods for Computing LALR(k) Lookahead,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976714519&doi=10.1145%2f357121.357126&partnerID=40&md5=3fb8ee89435edf8605060ccafdaf7441,[No abstract available],,
Applicability of Software Validation Techniques to Scientific Programs,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976723869&doi=10.1145%2f357103.357107&partnerID=40&md5=88ccebc2bd73b0e66146f32d64769a8f,"Error analysis involves the examination of a collection of programs whose errors are known. Each error is analyzed and validation techniques which would discover the error are identified. The errors that were present in version five of a package of Fortran scientific subroutines and then later corrected in version six were analyzed. An integrated collection of static and dynamic analysis methods would have discovered the errors in version five before its release. An integrated approach to validation and the effectiveness of individual methods are discussed. © 1980, ACM. All rights reserved.",dynamic analysis; empirical studies; errors; Fortran; functional testing; proofs of correctness; static analysis; structural testing; testing,Linguistics; Software engineering; Integrated approach; Scientific programs; Software validation; Static and dynamic analysis; Error analysis
Automatic Derivation of Code Generators from Machine Descriptions,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976772195&doi=10.1145%2f357094.357097&partnerID=40&md5=4f8d22082a9eefe68907b4b47bdde687,"Work with compiler compilers has dealt principally with automatic generation of parsers and lexical analyzers. Until recently, little work has been done on formalizing and generating the back end of a compiler, particularly an optimizing compiler. This paper describes formalizations of machines and code generators and describes a scheme for the automatic derivation of code generators from machine descriptions. It was possible to separate all machine dependence from the code generation algorithms for a wide range of typical architectures (IBM-360, PDP-11, PDP-10, Intel 8080) while retaining good code quality. Heuristic search methods from work in artificial intelligence were found to be both fast and general enough for use in generation of code generators with the machine representation proposed. A scheme is proposed to perform as much analysis as possible at code generator generation time, resulting in a fast pattern-matching code generator. The algorithms and representations were implemented to test their practicality in use. © 1980, ACM. All rights reserved.",,
A Multiprocessing Approach to Compile-Time Symbol Resolution,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976680011&doi=10.1145%2f357121.357123&partnerID=40&md5=0f32724ff45c5664d4badb2e2720d2f8,[No abstract available],,
Prettyprinting,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976800803&doi=10.1145%2f357114.357115&partnerID=40&md5=54966d2158e2789a3d3b5b7f72d78ac3,"An algorithm for prettyprinting is given. For an input stream of length n and an output device with linewidth m, the algorithm requires time O(n) and space O(m). The algorithm is described in terms of two parallel processes: the first scans the input stream to determine the space required to print logical blocks of tokens; the second uses this information to decide where to break lines of text; the two processes communicate by means of a buffer of size O(m). The algorithm does not wait for the entire stream to be input, but begins printing as soon as it has received a full line of input. The algorithm is easily implemented. © 1980, ACM. All rights reserved.",formating; paragraphing; prettyprinting; program manipulation; text editing,
Handling Operator Precedence in Arithmetic Expressions with Tree Transformations,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916456871&doi=10.1145%2f357121.357127&partnerID=40&md5=86623dc6f51f8950deeef91ec1257320,[No abstract available],,
An Alternative to the Use of Patterns in String Processing,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976771257&doi=10.1145%2f357094.357096&partnerID=40&md5=4a027721c40715cce4e24e7d002933d5,"SNOBOL4 is best known for its string processing facilities, which are based on patterns as data objects. Despite the demonstrated success of patterns, there are many shortcomings associated with their use. The concept of patterns in SNOBOL4 is examined and problem areas are discussed. An alternative method for high-level string processing is described. This method, implemented in the programming language Icon, employs generators, which are capable of producing alternative values. Generators, coupled with a goal-driven method of expression evaluation, provide the string processing facilities of SNOBOL4 without the disadvantages associated with patterns. Comparisons between SNOBOL4 and Icon are included and the broader implications of the new approach are discussed. © 1980, ACM. All rights reserved.",,
An Improved Context-Free Recognizer,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976683988&doi=10.1145%2f357103.357112&partnerID=40&md5=3b8f24badd461ad7aa6513345bf3e021,"A new algorithm for recognizing and parsing arbitrary context-free languages is presented, and several new results are given on the computational complexity of these problems. The new algorithm is of both practical and theoretical interest. It is conceptually simple and allows a variety of efficient implementations, which are worked out in detail. Two versions are given which run in faster than cubic time. Surprisingly close connections between the Cocke-Kasami-Younger and Earley algorithms are established which reveal that the two algorithms are “almost” identical. © 1980, ACM. All rights reserved.",context-free grammars; data structures; dynamic programming; parsing,Linguistics; Software engineering; Context-free; Efficient implementation; New results; Context free languages
A Proof System for Communicating Sequential Processes,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976742643&doi=10.1145%2f357103.357110&partnerID=40&md5=cd3c417bed948774cbb4ce2a00fb4bac,"An axiomatic proof system is presented for proving partial correctness and absence of deadlock (and failure) of communicating sequential processes. The key (meta) rule introduces cooperation between proofs, a new concept needed to deal with proofs about synchronization by message passing. CSP's new convention for distributed termination of loops is dealt with. Applications of the method involve correctness proofs for two algorithms, one for distributed partitioning of sets, the other for distributed computation of the greatest common divisor of n numbers. © 1980, ACM. All rights reserved.",absence of deadlock; blocking; communicating processes; concurrency; cooperating proofs; CSP; global invariant; Hoare-style proof rules; partial correctness,Message passing; Communicating sequential process; Correctness proofs; Distributed computations; Distributed Partitioning; Distributed termination; Greatest common divisors; Partial correctness; Proof system; Computer operating procedures
Synthesis of Resource Invariants for Concurrent Programs,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976765085&doi=10.1145%2f357103.357109&partnerID=40&md5=d7150ff615e6df168ec88620d7f5624e,"Owicki and Gries have developed a proof system for conditional critical regions. In their system, logically related variables accessed by more than one process are grouped together as resources, and processes are allowed access to a resource only in a critical region for that resource. Proofs of synchronization properties are constructed by devising predicates called resource invariants which describe relationships among the variables of a resource when no process is in a critical region for the resource. In constructing proofs using the system of Owicki and Gries, the programmer is required to supply the resource invariants. Methods are developed in this paper for automatically synthesizing resource invariants. Specifically, the resource invariants of a concurrent program are characterized as least fixpoints of a functional which can be obtained from the text of the program. By the use of this fixpoint characterization and a widening operator based on convex closure, good approximations may be obtained for the resource invariants of many concurrent programs. © 1980, ACM. All rights reserved.",concurrent program; conditional critical region; correctness proof; resource invariant,Software engineering; Concurrent program; Critical region; Fixpoints; Proof system; Related variables; Synchronization property; Widening operators; Linguistics
Ultracomputers,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976831114&doi=10.1145%2f357114.357116&partnerID=40&md5=384024d37fc965afd07ede5af2915505,"A class of parallel processors potentially involving thousands of individual processing elements is described. The architecture is based on the perfect shuffle connection and has two favorable characteristics: (1) Each processor communicates with a fixed number of other processors. (2) Important communication functions can be accomplished in time proportional to the logarithm of the number of processors. A number of basic algorithms for these “ultracomputers” are presented, and physical design considerations are discussed in a preliminary fashion. © 1980, ACM. All rights reserved.",parallel algorithms; parallel computation; parallelism,
A Statement-Oriented Approach to Data Abstraction,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976797324&doi=10.1145%2f357121.357122&partnerID=40&md5=4c071cc26b070911bf73a2379ca21b4e,[No abstract available],,
Output Guards and Nondeterminism in “Communicating Sequential Processes”,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976707205&doi=10.1145%2f357094.357101&partnerID=40&md5=80a55e0acb9754cabfc08817b45f8c1b,"In a recent paper C.A.R. Hoare outlined a language for concurrent programming. Guarded commands and nondeterminism are two features of the language. This paper points out two problems that arise in connection with these features and addresses one of them. © 1980, ACM. All rights reserved.",,
Compilation of Acyclic Smooth Programs for Parallel Execution,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976655812&doi=10.1145%2f357121.357124&partnerID=40&md5=edccae54d9757b4aaa1d5d99b44e68b5,[No abstract available],,
Corrigendum: “Distributed Termination”,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976733356&doi=10.1145%2f357103.357113&partnerID=40&md5=21fd229255a8f455618e391cb2baefeb,[No abstract available],,
The Activity of a Variable and Its Relation to Decision Trees,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976827910&doi=10.1145%2f357114.357120&partnerID=40&md5=a5018bd57cd0fcc98701e760f02c784d,"The construction of sequential testing procedures from functions of discrete arguments is a common problem in switching theory, software engineering, pattern recognition, and management. The concept of the activity of an argument is introduced, and a theorem is proved which relates it to the expected testing cost of the most general type of decision trees. This result is then extended to trees constructed from relations on finite sets and to decision procedures with cycles. These results are used, in turn, as the basis for a fast heuristic selection rule for constructing testing procedures. Finally, some bounds on the performance of the selection rule are developed. © 1980, ACM. All rights reserved.",activity; decision diagrams; decision tables; decision trees; expected testing cost; heuristic selection; identification procedure; pattern recognition; recursiveness; sequential testing procedure; software engineering; switching theory,
A Formal System for Reasoning about Programs Accessing a Relational Database,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976782766&doi=10.1145%2f357103.357111&partnerID=40&md5=7c11a2229639920581f1c2285ddd4934,"A formal system for proving properties of programs accessing a database is introduced. Proving that a program preserves consistency of the database is one of the possible applications of the system. The formal system is a variant of dynamic logic and incorporates a data definition language (DDL) for describing relational databases and a data manipulation language (DML) whose programs access data in a database. The DDL is a many-sorted first-order language that accounts for data aggregations. The DML features a many-sorted assignment in place of the usual data manipulation statements, in addition to the normal programming language constructs. © 1980, ACM. All rights reserved.",aggregation operators; consistency preservation; data definition languages; data manipulation languages; dynamic logic; formal systems; many-sorted first-order logic; program correctness; relational databases; serializability; synchronization; transactions,Application programs; Data aggregation; Data manipulations; Data-definition languages; Dynamic logic; First-order language; Formal systems; Reasoning about programs; Relational Database; Relational database systems
Deleting Irrelevant Tasks in an Expression-Oriented Multiprocessor System,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976818650&doi=10.1145%2f357121.357125&partnerID=40&md5=dee09f2c85e47fe7214d9b1cdd3faea0,[No abstract available],,
Ada exception handling: An axiomatic approach,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976802506&doi=10.1145%2f357094.357100&partnerID=40&md5=6959fd733780c0df6d522361b05271c3,"A method of documenting exception propagation and handling in Ada programs is proposed. Exception propagation declarations are introduced as a new component of Ada specifications, permitting documentation of those exceptions that can be propagated by a subprogram. Exception handlers are documented by entry assertions. Axioms and proof rules for Ada exceptions given. These rules are simple extensions of previous rules for Pascal and define an axiomatic semantics of Ada exceptions. As a result, Ada programs specified according to the method can be analyzed by formal proof techniques for consistency with their specifications, even if they employ exception propagation and handling to achieve required results (i.e., nonerror situations). Example verifications are given. © 1980, ACM. All rights reserved.",,
Managing Reentrant Structures Using Reference Counts,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976786293&doi=10.1145%2f357103.357104&partnerID=40&md5=5c9520fb868bc1ab6de1bf2a531fba31,"Automatic storage management requires that one identify storage unreachable by a user's program and return it to free status. One technique maintains a count of the references from user's programs to each cell, since a count of zero implies the storage is unreachable. Reentrant structures are self-referencing; hence no cell in them will have a count of zero, even though the entire structure is unreachable. A modification of standard reference counting can be used to manaage the deallocation of a large class of frequently used reentrant structures, including two-way and circularly linked lists. All the cells of a potentially reentrant structure are considered as part of a single group for deallocation purposes. Information associated with each cell specifies its group membership. Internal references (pointers from one cell of the group to another) are not reference counted. External references to any cell of this group are counted as references to the group as a whole. When the external reference count goes to zero, all the cells of the group can be deallocated. This paper describes several ways of specifying group membership, properties of each implementation, and properties of mutable and immutable group membership. © 1980, ACM. All rights reserved.",garbage collection; reference counting; storage management,Cytology; Storage management; De-allocation; Group memberships; Reference counting; Self-referencing; Two ways; User's programs; Cells
Design of a Machine-Independent Optimizing System for Emulator Development,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976787262&doi=10.1145%2f357094.357102&partnerID=40&md5=301b7b9ddc61e00747966562d057b89d,"Methods are described to translate a certain machine-independent intermediate language (IML) to efficient microprograms for a class of horizontal microprogrammable machines. The IML is compiled directly from a high-level microprogramming language used to implement a virtual instruction set processor as a microprogram. The primary objective of the IML-to-host machine interface design is to facilitate language portability. Transportability is accomplished by use of a field description model and a macro expansion table which describe the host machine to the translator system. Register allocation scheme and control flow analysis are employed to allocate the symbolic variables of the IML to the general-purpose registers of the host machine. A set of 5-tuple microoperations (function, input, output, field, phase) is obtained with the aid of the field description model. Then a compaction algorithm is used to detect the parallelism of microoperations and to generate suboptimal code for a horizontal microprogrammable machine. The study concludes with a description of the effects of the above methods upon the quality of microcode produced for a specific commercial computer. © 1980, ACM. All rights reserved.",,
Technical Correspondence: On Francez's “Distributed Termination'’,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976772547&doi=10.1145%2f357121.357131&partnerID=40&md5=b183760023fc90939320a7f39eb61c53,[No abstract available],,
On Parsing and Compiling Arithmetic Expressions on Vector Computers,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976850821&doi=10.1145%2f357094.357099&partnerID=40&md5=cfaa0cc2edb44d85a6e2272ab2f430ee,"The problem of parsing and compiling arithmetic expressions on vector computers is considered. Methods are developed which allow encodings of one or more arithmetic expressions to be transformed directly into encodings of their corresponding derivation trees. The algorithm which performs this transformation is compact, efficient, and able to make extensive use of concurrent vector operations. Routines which concurrently transverse encoded derivation trees in a top-down or bottom-up manner are presented. These routines can be used to structure efficient, compact, and highly concurrent algorithms which complete the process of compiling arithmetic expressions. © 1980, ACM. All rights reserved.",,
Chaining Span-Dependent Jump Instructions,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976778088&doi=10.1145%2f357103.357105&partnerID=40&md5=98ea95d73fda8ad150d7a77b5418435b,"The assembled length of a span-dependent jump instruction depends on the distance between the instruction and its target. Such instructions are found on many computers and typically have two forms, long and short. We consider the problem of minimizing object program length for such machines by chaining together jumps with the same target. Although the problem is NP-complete in its most general form, several mildly restricted forms of the problem exist that are of practical importance and have efficient solutions. © 1980, ACM. All rights reserved.",assembler; code generation; code optimization; compiler; computational complexit; long/short addressing; NP-completeness,Software engineering; NP Complete; Object program; Practical importance; Linguistics
Corrigendum: “The Design and Application of a Retargetable Peephole Optimizer'’,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976783230&doi=10.1145%2f357121.357129&partnerID=40&md5=979d88add2c9b463cfbecc938239eda8,[No abstract available],,
Specification of Abstract Data Types in Modula,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976735115&doi=10.1145%2f357114.357117&partnerID=40&md5=0c83f1c70b0d1c1952178cd6fdd65885,"The programming language MODULA is extended to permit the formal specification of the structure and functional capabilities of modules. This makes true hierarchical programming possible in MODULA by allowing programmers of higher level parts of a system to ignore completely the internal structure of lower level modules and to rely entirely on the specifications of the capabilities of these modules. An example is included to illustrate this technique. We show that our specification mechanisms are sufficiently powerful to support formal verification rules for modules that have disjoint representations for abstract objects. © 1980, ACM. All rights reserved.",abstract data types; hierarchical programming; MODULA; modularization; program verification; proof rules; software specification,
Derivation of Invariant Assertions During Program Development by Transformation,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976799819&doi=10.1145%2f357103.357108&partnerID=40&md5=509d3e8bd9888f359f78e43b132f54f5,"Two approaches to the development of efficient and correct iterative programs are contrasted: the construction of an iterative program and a proof of its correctness using invariant assertions of loops, and the construction and proof of a recursive program with a subsequent transformation into an iterative version by schematically applying suitable recursion removal rules. The connection between the approaches is demonstrated by augmenting such transformation rules by inductive assertions. It is argued that the latter approach to program development is superior since the correctness proof of a recursive program is easier in most cases. Considerable verification overhead can be avoided this way, in particular, some difficulties with the interaction of successive loops and their associated invariants. © 1980, ACM. All rights reserved.",assertions; invariants; iteration; program development; program transformations; recursion; recursion removal; specification; verification,Software engineering; Correctness proofs; Program development; Recursion removal; Recursive programs; Transformation rules; Linguistics
Corrigendum: “External Representations of Objects of User-Defined Type,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976669953&doi=10.1145%2f357121.357130&partnerID=40&md5=45d68952c6904ff54f98a7b3758b8afa,[No abstract available],,
External Representations of Objects of User-Defined Type,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976736690&doi=10.1145%2f357094.357095&partnerID=40&md5=c6126f5f67ae75692addbe744c35f1a3,"The portable programming language (PPL) is one of a number of recently designed programming languages that enable the user to define new types by giving their representations and operations in terms of those of previously available types. Such provisions for the construction of objects of user-defined type have been discussed elsewhere; this work concerns the related problem of the external representations of such objects, both on input-output media and as written constants within the program text. We introduce an enhancement to the PPL design allowing specification of the external representations of objects of user-defined type. This extension to the PPL design means that objects of user-defined type can be read, written, and used as constants exactly as if their representations had been selected by the writer of the PPL compiler. The implementation and use of the added facilities are also discussed. © 1980, ACM. All rights reserved.",data abstractions; data types; input-output; portability; programming languages; programming methodology; structured programming; types,
An Exercise in Program Explanation,1981,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976833201&doi=10.1145%2f357121.357128&partnerID=40&md5=3ba7b3433214d61d455dcdea26b6e6fa,[No abstract available],,
The Design and Application of a Retargetable Peephole Optimizer,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976748796&doi=10.1145%2f357094.357098&partnerID=40&md5=92fff826246cb82068ee49b52aadd14f,"Peephole optimizers improve object code by replacing certain sequences of instructions with better sequences. This paper describes PO, a peephole optimizer that uses a symbolic machine description to simulate pairs of adjacent instructions, replacing them, where possible, with an equivalent single instruction. As a result of this organization, PO is machine independent and can be described formally and concisely: when PO is finished, no instruction, and no pair of adjacent instructions, can be replaced with a cheaper single instruction that has the same effect. This thoroughness allows PO to relieve code generators of much case analysis; for example, they might produce only load/add-register sequences and rely on PO to, where possible, discard them in favor or add-memory, add-immediate, or increment instructions. Experiments indicate that naive code generators can give good code if used with PO. © 1980, ACM. All rights reserved.",,
Assignment and Procedure Call Proof Rules,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976809240&doi=10.1145%2f357114.357119&partnerID=40&md5=d5243d563e5c82a5c97622e0e8ca1d19,"The multiple assignment statement is defined in full generality—including assignment to subscripted variables and record fields—using the “axiomatic” approach of Hoare. Proof rules are developed for calls of procedures using global variables, var parameters, result parameters, and value parameters, using the idea of multiple assignment to provide understanding. An attempt is made to clarify some issues that have arisen concerning the use of rules of inference to aid in generating “verification conditions” in mechanical verifiers and the use of logical variables to denote initial values of program variables. © 1980, ACM. All rights reserved.",axiomatic semantics; formal semantics; multiple assignment; procedure call proof rules,
A Coroutine Approach to Parsing,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976810980&doi=10.1145%2f357103.357106&partnerID=40&md5=d6b8d95289c2c381d992bfda245d3871,"A method is presented for parsing syntactic constructs that are permitted to appear independently anywhere in a program. Some examples include comments, macros, and constructs for conditional compilation. Each such construct is defined by its own grammar and parsed by a separate coroutine. The coroutine model of parsing allows the program text to be parsed in one pass despite the syntactic inconsistencies among the program text and the additional constructs. The usefulness of the model is demonstrated by showing how a production language parsing method is extended to handle multiple syntax specifications. The implementation of conditional compilation by carrying along two parses in a coroutine manner is also given. The utility of the model is further demonstrated by showing its adaptation to a recursive descent parser. © 1980, ACM. All rights reserved.",compilers; conditional compilation; coroutines; extensible languages; macros; parsing; production language,Formal languages; Conditional compilations; Coroutine; One-pass; Parsing methods; Syntactics
On the Performance of Balanced Hashing Functions When the Keys Are Not Equiprobable,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976849864&doi=10.1145%2f357084.357089&partnerID=40&md5=5ca06e8f60aa629043abb3bd524b9255,"The cost (expected number of accesses per retrieval) of hashing functions is examined without the assumption that it is equally probable for all keys to be present in the table. It is shown that the obvious strategy—trying to balance the sums of probabilities of the keys mapped to any given address—may be suboptimal; however, the difference from the exactly optimal distribution cannot be large. © 1980, ACM. All rights reserved.",,
Use of a Nonprocedural Specification Language and Associated Program Generator in Software Development,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976863003&doi=10.1145%2f357073.357076&partnerID=40&md5=4fdd506b2574bb33b073d3939d8be610,"The Model II language and the associated program generator are used to explain and illustrate the use of very high level nonprocedural languages for computer programming. The effect of a very high level language is obtained in Model II through the elimination of procedural and control facilities that exist in high level programming languages such as PL/I or Cobol. In particular, the statements may be given in any order and there are no control constructs such as input/output, iterations, and memory allocation. The task of ordering the statements for execution and providing control statements is performed by the automatic program generator. The specification of a program is therefore much shorter (approximately one-fifth) than the equivalent high level procedural language program. Most important, a user need not regard the task of specifying a program as defining a process but rather as describing data and relations. This point of view greatly reduces the computer programming proficiency required of a user.The paper focuses on an example of the use of the language in business data processing, its advantages, and its novelty. It only briefly reviews the methodology incorporated in the existing program generator, a detailed description of which may be found in the references. © 1979, ACM. All rights reserved.",,
"Verification of Array, Record, and Pointer Operations in Pascal",1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976783546&doi=10.1145%2f357073.357078&partnerID=40&md5=470b2e324a9a0f71e82accb4c3fb40a1,"A practical method is presented for automating in a uniform way the verification of Pascal programs that operate on the standard Pascal data structures Array, Record, and Pointer. New assertion language primitives are introduced for describing computational effects of operations on these data structures. Axioms defining the semantics of the new primitives are given. Proof rules for standard Pascal operations on data structures are then defined using the extended assertion language. An axiomatic rule for the Pascal storage allocation operation, NEW, is also given. These rulers have been implemented in the Stanford Pascal program verifier. Examples illustrating the verification of programs which operate on list structures implemented with pointers and records are discussed. These include programs with side effects. © 1979, ACM. All rights reserved.",axiomatic semantics; data structures; formal semantics; Pascal; pointers; program verification; side effect; storage allocation,
A Language for Array and Vector Processors,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976791215&doi=10.1145%2f357073.357075&partnerID=40&md5=be07e421c28e8ea84699869ce37d191a,"The scientific community has consistently demanded from computing machines an increase in the number of instructions executed per second. The latest increase has been achieved by duplication of arithmetic units for an array processor and the pipelining of functional units for vector processors. The high level programming languages for such machines have not benefited from the advances which have been made in programming language design and implementation techniques.A high level language is described in this paper which is appropriate for both array and vector processors and is defined without reference to the hardware of either type of machine. The syntax enables the parallel nature of a problem to be expressed in a form which can be readily exploited by these machines. This is achieved by using the data declarations to indicate the maximum extent of parallel processing and then to manipulate this, or a lesser extent, in the course of program execution. It was found to be possible to modify many of the structured programming and data structuring concepts for this type of parallel environment and to maintain the benefits of compile time and run time checking. Several special constructs and operators are also defined.The language offers to the large scale scientific computing community many of the advances which have been made in software engineering techniques while it exploits the architectural advances which have been made. © 1979, ACM. All rights reserved.",array processing; parallel control; parallel data structures; vector processing,
Corrigendum: “A New Approach to Proving the Correctness of Multiprocess Programs”,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976786431&doi=10.1145%2f357084.357093&partnerID=40&md5=4e768ce0ce080a28321a6f7167fc84b7,[No abstract available],,
And/Or Programs: A New Approach to Structured Programming,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976724170&doi=10.1145%2f357084.357085&partnerID=40&md5=ecd61242c52177b988220b38f5d7a869,"A simple tree-like programming/specification language is presented. The central idea is the dividing of conventional programming constructs into the two classes of and and or subgoaling, the subgoal tree itself constituting the program. Programs written in the language can, in general, be both nondeterministic and parallel. The syntax and semantics of the language are defined, a method for verifying programs written in it is described, and the practical significance of programming in the language assessed. Finally, some directions for further research are indicated. © 1980, ACM. All rights reserved.","alternation, and/or program; program verification; structured programming; textual complexity",
Operators,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976848845&doi=10.1145%2f357073.357074&partnerID=40&md5=82ee960792f77d2adcc13717f42dd20b,"Although operators, which apply to functions to produce functions, prove very useful in mathematics, they are absent from most programming languages. This paper illustrates their simplicity and power in terms of the operators of APL, and examines related constructs in other programming languages. © 1979, ACM. All rights reserved.",APL; derived function; function composition; operator; operator syntax,
Noncanonical SLR(1) Grammars,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976725566&doi=10.1145%2f357073.357083&partnerID=40&md5=66f069e9db466a27ffae8a96b5df1dcf,"Two noncanonical extensions of the simple LR(1) (SLR(1)) method are presented, which reduce not only handles but also other phrases of sentential forms. A class of context-free grammars called leftmost SLR(1) (LSLR(1)) is defined by using lookahead symbols which appear in leftmost derivations. This class includes the SLR(1), reflected SMSP, and total precedence grammars as proper subclasses. The class of LSLR(1) languages properly includes the deterministic context-free languages, their reflections, and total precedence languages. By requiring that phrases which have been scanned be reduced as early as possible, a larger class of context-free grammars called noncanonical SLR(1) (NSLR(1)) is defined. The NSLR(1) languages can be recognized deterministically in linear time using a two-stack pushdown automaton. An NSLR(1) parser generator has been implemented. Empirical results show that efficient NSLR(1) parsers can be constructed for some non-LR grammars which generate nondeterministic languages. Applications of the NSLR(1) method to improve the parsing and translation of programming languages are discussed. © 1979, ACM. All rights reserved.",compilers; context-free grammars; deterministic context-free languages; grammars; LR(k ) grammars; noncanonical parsing; nondeterministic languages; parsers; SLR(k ); two-stack pushdown automata,
Is Sometimes Ever Better Than Always?,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976810999&doi=10.1145%2f357073.357080&partnerID=40&md5=15f0f0e6ae15d3bc5ad7b6c97924f3fe,"The “intermittent assertion” method for proving programs correct is explained and compared with the conventional method. Simple conventional proofs of iterative algorithms that compute recursively defined functions, including Ackermann's function, are given. © 1979, ACM. All rights reserved.",Ackermann function; axiomatic method; correctness of programs; intermittent assertion method; simulating recursion using iteration,
A Space Efficient Dynamic Allocation Algorithm for Queuing Messages,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976744003&doi=10.1145%2f357073.357082&partnerID=40&md5=26614ce5aeb052c0241800ee5126de15,"A simple dynamic allocation algorithm is described for queuing variable length messages in memory. The algorithm makes use of the ability of many operating system to increase and decrease available memory as required. Some results describing its efficiency are presented. © 1979, ACM. All rights reserved.",dynamic memory allocation; FIFO allocation; message queuing,
Comments on “Communicating Sequential Processes”,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976650872&doi=10.1145%2f357073.357077&partnerID=40&md5=90e534a33d4e0efcc118727f77da064d,"In his recent paper, “Communicating Sequential Processes” (Comm. ACM 21, 8 (Aug. 1978), 666-677), C.A.R. Hoare outlines a programming language notation for interprocess communication in which processes are synchronized by the messages they exchange. The notation carries with it certain implications for the synchronization protocols required in a message transfer. These are not at all obvious and are made explicit here. An alternative convention is suggested in which communication and synchronization are partially uncoupled from one another. © 1979, ACM. All rights reserved.",communication; concurrency; interprocess; message-passing; synchronization,
A Deductive Approach to Program Synthesis,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976781844&doi=10.1145%2f357084.357090&partnerID=40&md5=901bca44dedaecc45a6a50b43ba4d6c1,"Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework. © 1980, ACM. All rights reserved.",mathematical induction; program synthesis; program transformation; resolution; theorem proving,
Uniform Random Generation of Balanced Parenthesis Strings,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976812307&doi=10.1145%2f357084.357091&partnerID=40&md5=87bf156b82a379f13dc97f082ceac38f,"The empirical testing of error repair schemes for skeletons of source programs in a block-structured language leads to the problem of generating balanced parenthesis strings in a uniform random manner. An efficient generator which works from left to right must compute the correct probability for the next symbol at each stage of the generation. The associated enumeration problem may be solved by adopting a geometric interpretation usually associated with random walk problems. This solution leads immediately to an O(n) algorithm for the generator. © 1980, ACM. All rights reserved.",balanced parenthesis strings; block structure; enumeration problems; error recovery; error repair; geometric interpretation; program skeletons; reflection principle; uniform random generation,
Compact Encodings of List Structure,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976804090&doi=10.1145%2f357073.357081&partnerID=40&md5=74aabd8c80df66c7f36f678d9b240aed,"List structures provide a general mechanism for representing easily changed structured data, but can introduce inefficiencies in the use of space when fields of uniform size are used to contain pointers to data and to link the structure. Empirically determined regularity can be exploited to provide more space-efficient encodings without losing the flexibility inherent in list structures. The basic scheme is to provide compact pointer fields big enough to accommodate most values that occur in them and to provide “escape” mechanisms for exceptional cases. Several examples of encoding designs are presented and evaluated, including two designs currently used in Lisp machines. Alternative escape mechanisms are described, and various questions of cost and implementation are discussed. In order to extrapolate our results to larger systems than those measured, we propose a model for the generation of list pointers and we test the model against data from two programs. We show that according to our model, list structures with compact cdr fields will, as address space grows, continue to be compacted well with a fixed-width small field. Our conclusion is that with a microcodable processor, about a factor of two gain in space efficiency for list structure can be had for little or no cost in processing time. © 1979, ACM. All rights reserved.",compact encoding; linearization; Lisp; Lisp machine; list structure; list structure regularity,
Simplification by Cooperating Decision Procedures,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976700950&doi=10.1145%2f357073.357079&partnerID=40&md5=e0700206d5289b6072307f132e905839,"A method for combining decision procedures for several theories into a single decision procedure for their combination is described, and a simplifier based on this method is discussed. The simplifier finds a normal form for any expression formed from individual variables, the usual Boolean connectives, the equality predicate =, the conditional function if-then-else, the integers, the arithmetic functions and predicates +, -, and ≤, the Lisp functions and predicates car, cdr, cons, and atom, the functions store and select for storing into and selecting from arrays, and uninterpreted function symbols. If the expression is a theorem it is simplified to the constant true, so the simplifier can be used as a decision procedure for the quantifier-free theory containing these functions and predicates. The simplifier is currently used in the Stanford Pascal Verifier. © 1979, ACM. All rights reserved.",decidability; program manipulation; program verification; simplification; theorem proving,
An Axiomatic Approach to Information Flow in Programs,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976840591&doi=10.1145%2f357084.357088&partnerID=40&md5=12b65af9be9d8fa8f0bd3ecdc85ce111,"A new approach to information flow in sequential and parallel programs is presented. Flow proof rules that capture the information flow semantics of a variety of statements are given and used to construct program flow proofs. The method is illustrated by examples. The applications of flow proofs to certifying information flow policies and to solving the confinement problem are considered. It is also shown that flow rules and correctness rules can be combined to form an even more powerful proof system. © 1980, ACM. All rights reserved.",axiomatic logic; information flow; information security; parallel programs; proof rules; security certification,
Distributed Termination,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976809509&doi=10.1145%2f357084.357087&partnerID=40&md5=ede17af0b7a5e635676da7ad075a3f9f,"Discussed is a distributed system based on communication among disjoint processes, where each process is capable of achieving a post-condition of its local space in such a way that the conjunction of local post-conditions implies a global post-condition of the whole system. The system is then augmented with extra control communication in order to achieve distributed termination, without adding new channels of communication. The algorithm is applied to a problem of constructing a sorted partition. © 1980, ACM. All rights reserved.",communicatio; concurrent programs; disjoint memories; distributed processes; distributed termination; nput-output,
Global Context Recovery: A New Strategy for Syntactic Error Recovery by Table-Drive Parsers,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-9544253223&doi=10.1145%2f357084.357086&partnerID=40&md5=599080344a43faef07fbc92b5e58a64b,"Described is a method for syntactic error recovery that is compatible with deterministic parsing methods and that is able to recover from many errors more quickly than do other schemes because it performs global context recovery. The method relies on fiducial symbols, which are typically reserved key words of a language, to provide mileposts for error recovery. The method has been applied to LL(1) parsers, for which a detailed algorithm is given, and informally proved correct. The algorithm will always recover and return control to the parser if the text being analyzed satisfies only minimal requirements: that it contains one or more occurrences of fiducial symbols following the point at which an error is detected. Tables needed for error recovery have been automatically generated, along with parsing tables, by a parser constructor for the LL(1) grammars. A theoretical characterization of fiducial symbols is given, and the utility of this characterization in practice is discussed. It has been applied to a grammar for the programming language Pascal to aid in selection of a set of fiducial symbols. The error recovery scheme has been tested on a set of student-written Pascal program texts and is compared with other error recovery strategies. © 1980, ACM. All rights reserved.",error recovery; fiducial symbol; parsing; Pascal; syntax errors,
A Note on Median Split Trees,1980,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976749494&doi=10.1145%2f357084.357092&partnerID=40&md5=b17801f7c1d4c7881c90e3b53a19db3a,"The median split tree is an elegant technique for searching static sets of keys when the frequency of access is highly skewed. This paper generalizes the median split search technique, relates it to sequential search and binary search, discusses the choice of an optimum search strategy for a given set of keys, and poses several related optimization problems. © 1980, ACM. All rights reserved.",balanced trees; binary search; median split search; sequential search; tree search,
A New Approach to Proving the Correctness of Multiprocess Programs,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002908596&doi=10.1145%2f357062.357068&partnerID=40&md5=90fba5a1371201d9e6f148b78a7e5e83,"A new, nonassertional approach to proving multiprocess program correctness is described by proving the correctness of a new algorithm to solve the mutual exclusion problem. The algorithm is an improved version of the bakery algorithm. It is specified and proved correct without being decomposed into indivisible, atomic operations. This allows two different implementations for a conventional, nondistributed system. Moreover, the approach provides a sufficiently general specification of the algorithm to allow nontrivial implementations for a distributed system as well. © 1979, ACM. All rights reserved.",concurrent processing; multiprocessing; mutual exclusion; program correctness,
A Deterministic Attribute Grammar Evaluator Based on Dynamic Scheduling,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976719756&doi=10.1145%2f357062.357072&partnerID=40&md5=f73980711df8e7a99b6ae2a8128626e0,"The problem of semantic evaluation in a compiler-generating system can be addressed by specifying language semantics in an attribute grammar [19], a context-free grammar augmented with “attributes” for the nonterminals and “semantic functions” to compute the attributes. A deterministic method for evaluating all attributes in a “semantic” parse tree is derived and shown to have time and space complexities which are essentially linear in the size of the tree. In a prepass through the parse tree, the method determines an evaluation sequence for the attributes; thus it is somewhat analogous to dynamic programming. The constructor-evaluator system described should be suitable for inclusion in a general translator-writing system. for inclusion in a general translator-writing system. © 1979, ACM. All rights reserved.",attribute grammar; compiler; formal semantics; programming language; semantic evaluation; translator writing system,
Backtracking in a Generalized Control Setting,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976722839&doi=10.1145%2f357062.357063&partnerID=40&md5=d4b1827866194b817f093b54fa09cfe8,"Backtracking is a powerful conceptual and practical programming language control structure. However, its application in general has been limited to global control over recursive programs. In this paper we explore the coherence and utility of applying backtracking in a more general control setting, namely, block-structured coroutines. The following criteria are proposed for such a control combination to be judged successful: (i) retention of each control form's individual semantics; (ii) coherent semantics for each legal application of the combination; (iii) nonpreeminence of either control form, and (iv) facilitation of genuinely novel programming effects. The attainability of these criteria is assessed, with the aid of an informal language design and three illustrative applications: (i) a dual tree walk program using coroutine-managed backtracking subsystems; (ii) a context-free language intersection tester using bilevel hierarchical backtracking, and (iii) an optimizing computer job scheduler using backtracking in a simulation language context. Full programs are given for each example, phrased in a Pascal extension offering both coroutines and backtracking (expressed through nondeterministic control). © 1979, ACM. All rights reserved.",backtracking; control structures; coroutines; nondeterministic programming; Pascal; simulation,
The Compilation of Loop Induction Expressions,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040860720&doi=10.1145%2f357062.357065&partnerID=40&md5=94142955cf56e78df403dd6c0e47ee0b,"In an optimizing compiler, it is often desirable to compile subscript expressions such as Abase-2 + I*2 so that the value of the expression is available in a register and is simply incremented whenever I is incremented, thus avoiding the multiplication inside the loop. This change is effected by a standard optimization called strength reduction. Program loops often contain several such expressions stemming perhaps from references to operands A(I), A(I+1), B(I), and C(K,J,I,L). Under what circumstances can we do better than keeping four addresses in four separate registers or temporaries? A general technique is presented which minimizes the number of registers needed to hold such values, while simultaneously minimizing the amount of computation inside the loop. In the above collection, it is possible to use as few as two registers for the four I-dependent values. © 1979, ACM. All rights reserved.",code generation; common subexpressions; computer architectur; optimizing compilers; register allocation,
Morris's Garbage Compaction Algorithm Restores Reference Counts,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976803424&doi=10.1145%2f357062.357070&partnerID=40&md5=9b475ec724d879827366d4a155ebe318,"The two-pass compaction algorithm of F.L. Morris, which follows upon the mark phase in a garbage collector, may be modified to recover reference counts for a hybrid storage management system. By counting the executions of two loops in that algorithm where upward and downward references, respectively, are forwarded to the relocation address of one node, we can initialize a count of active references and then update it but once. The reference count may share space with the mark bit in each node, but it may not share the additional space required in each pointer by Morris's algorithm, space which remains unused outside the garbage collector. © 1979, ACM. All rights reserved.",garbage collection; reference counting; storage management,
A Fast Algorithm for Finding Dominators in a Flowgraph,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976651458&doi=10.1145%2f357062.357071&partnerID=40&md5=a3caa6ac1cd79f5634641fa3ad0d11f1,"A fast algorithm for finding dominators in a flowgraph is presented. The algorithm uses depth-first search and an efficient method of computing functions defined on paths in trees. A simple implementation of the algorithm runs in O(m log n) time, where m is the number of edges and n is the number of vertices in the problem graph. A more sophisticated implementation runs in O(mα(m, n)) time, where α(m, n) is a functional inverse of Ackermann's function.Both versions of the algorithm were implemented in Algol W, a Stanford University version of Algol, and tested on an IBM 370/168. The programs were compared with an implementation by Purdom and Moore of a straightforward O(mn)-time algorithm, and with a bit vector algorithm described by Aho and Ullman. The fast algorithm beat the straightforward algorithm and the bit vector algorithm on all but the smallest graphs tested. © 1979, ACM. All rights reserved.",depth-first search; dominators; global flow analysis; graph algorithm; path compression,
Code Generation and Storage Allocation for Machines With Span-Dependent Instructions,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976792627&doi=10.1145%2f357062.357067&partnerID=40&md5=bef1796599e6ee6ab1ac4ed386144094,"Many machine languages have two instruction formats, one of which allows addressing of “nearby” operands with “short” (e.g. one word) instructions, while “faraway” operands require “long” format (e.g. two words). Because the distance between an instruction and its operand depends upon the formats of the intervening instructions, the formats of different instructions may be interdependent.An efficient technique is discussed which optimally assigns formats to instructions in a given program and is practical in space as well as time. The more sophisticated problem of arranging operands within programs is discussed. Unfortunately, it is unlikely that an efficient algorithm can guarantee even a good approximation for this problem, since it is shown that r-approximation is NP-complete.Finally, implications of these problems for hardware and software design are considered. © 1979, ACM. All rights reserved.",assembler; code-generation; compiler; computational complexity; NP-completeness; optimization; short/long addresses; span-dependent instructions; storage-allocation; variable-length addressing,
Incremental Parsing,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-0007435814&doi=10.1145%2f357062.357066&partnerID=40&md5=cb95b884a7a9841f851d2d70311f9d74,"An incremental parser is a device which is able to perform syntax analysis in an incremental way, avoiding complete reparsing of a program after each modification. The incremental parser presented extends the conventional LR parsing algorithm and its performance is compared with that of a conventional parser. Suggestions for an implementation and possible extensions to other parsing methods are also discussed. © 1979, ACM. All rights reserved.",,
"Programming by Refinement, as Exemplified by the SETL Representation Sublanguage",1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976702755&doi=10.1145%2f357062.357064&partnerID=40&md5=46efbf21b9cc05625920404b74b28431,"“Pure” SETL is a language of very high level allowing algorithms to be programmed rapidly and succintly. SETL's representation sublanguage adds a system of declarations which allow the user of the language to control the data structures that will be used to implement an algorithm which has already been written in pure SETL, so as to improve its efficiency. Ideally no rewriting of the algorithm should be necessary. The facilities provided by the representation sublanguage and the run-time data structures that it can generate are described; based on this a heuristic which uses some of the methods of global program analysis and which should be capable of selecting an acceptably efficient representation automatically is given. © 1979, ACM. All rights reserved.",automatic data structure choice; high level languages; optimization; set-theoretic languages; stepwise refinement,
A Hierarchical Approach to Formal Semantics With Application to the Definition of PL/CS,1979,ACM Transactions on Programming Languages and Systems (TOPLAS),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909551519&doi=10.1145%2f357062.357069&partnerID=40&md5=d4b57b703a374924c5f05269f2c4968c,"We describe a means of presenting hierarchically organized formal definitions of programming languages using the denotational approach of D. Scott and C. Strachey. As an example of our approach, we give the semantics of PL/CS, an instructional variant of PL/I. We also discuss the implications of this approach to language design, pointing out some cases where the wrong choices may cause the hierarchy to collapse into chaotic rubble. © 1979, ACM. All rights reserved.",denotational semantics; PL/C; PL/CS; PL/I; programming language semantics; recursive functions,
