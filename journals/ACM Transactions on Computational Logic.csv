Title,Year,Source title,Link,Abstract,Author Keywords,Index Keywords
May-happen-in-parallel analysis for actor-based concurrency,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954104826&doi=10.1145%2f2824255&partnerID=40&md5=519f32a97d8514867af01150634cb8e9,"This article presents a may-happen-in-parallel (MHP) analysis for languages with actor-based concurrency. In this concurrency model, actors are the concurrency units such that, when a method is invoked on an actor a2 from a task executing on actor a1, statements of the current task in a1 may run in parallel with those of the (asynchronous) call on a2, and with those of transitively invoked methods. The goal of the MHP analysis is to identify pairs of statements in the program that may run in parallel in any execution. Our MHP analysis is formalized as a method-level (local) analysis whose information can be modularly composed to obtain application-level (global) information. The information yielded by the MHP analysis is essential to infer more complex properties of actor-based concurrent programs, for example, data race detection, deadlock freeness, termination, and resource consumption analyses can greatly benefit from the MHP relations to increase their accuracy. We report on MayPar, a prototypical implementation of an MHP static analyzer for a distributed asynchronous language. Copyright © 2015 ACM.",Actors; Analysis; Concurrency; May-happen-in-parallel,Logic programming; Actors; Analysis; Concurrency; Concurrency modeling; Data race detection; May happen in parallels; Prototypical implementation; Resource consumption; Computational linguistics
Belief merging by examples,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954310978&doi=10.1145%2f2818645&partnerID=40&md5=e4c4eefaf7bbc7bfa6da46723c50b3b0,"A common assumption in belief revision is that the reliability of the information sources is either given, derived from temporal information, or the same for all. This article does not describe a new semantics for integration but studies the problem of obtaining the reliability of the sources given the result of a previous merging. As an example, corrections performed manually on the result of merging some databases may indicate that the relative reliability of their sources is different from what was previously assumed, helping subsequent data mergings. Copyright © 2015 ACM.",Belief merging; Reliability estimation,Reliability; Semantics; Belief revision; Information sources; Reliability estimation; Temporal information; Merging
Effective interpolation and preservation in guarded logics,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954226795&doi=10.1145%2f2814570&partnerID=40&md5=7ad659a223e171c219debd55d1eb99ee,"Desirable properties of a logic include decidability, and a model theory that inherits properties of first-order logic, such as interpolation and preservation theorems. It is known that the Guarded Fragment (GF) of firstorder logic is decidable and satisfies some preservation properties from first-order model theory; however, it fails to have Craig interpolation. The Guarded Negation Fragment (GNF), a recently defined extension, is known to be decidable and to have Craig interpolation. Here we give the first results on effective interpolation for extensions of GF. We provide an interpolation procedure for GNF whose complexity matches the doubly exponential upper bound for satisfiability of GNF. We show that the same construction gives not only Craig interpolation, but Lyndon interpolation and relativized interpolation, which can be used to provide effective proofs of some preservation theorems. We provide upper bounds on the size of GNF interpolants for both GNF and GF input, and complement this with matching lower bounds. © 2015 ACM.",Guarded fragment; Guarded negation fragment; Mosaic method,Computability and decidability; Computer circuits; Formal logic; Reconfigurable hardware; Craig interpolation; First order logic; First-order models; Guarded fragment; Guarded negation fragment; Mosaic methods; Preservation theorems; Satisfiability; Interpolation
Differential Game Logic,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954157600&doi=10.1145%2f2817824&partnerID=40&md5=ee8c8e25d5fba325a7f1c5717ff39d47,"Differential game logic (dGL) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic dGL can be used to study the existence of winning strategies for such hybrid games, i.e., ways of resolving the player's choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e., from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic dGL, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, dGL is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.",Axiomatization; Expressiveness; Game logic; Hybrid games,Computation theory; Computer games; Game theory; Hybrid systems; Reconfigurable hardware; Axiomatization; Differential games; Expressiveness; Game logic; Hybrid games; Sound and complete; System Dynamics; Winning strategy; Computer circuits
An assertional proof of the stability and correctness of Natural Mergesort,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954312216&doi=10.1145%2f2814571&partnerID=40&md5=2c704d8e591ba9b96af35eb155be0079,"We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny. We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof. Copyright © 2015 ACM.",Dafny; Formal methods; Naturalmergesort; Software engineering; Sorting; Stability; Theorem proving; Verification,Algorithms; Convergence of numerical methods; Formal verification; Software engineering; Sorting; Theorem proving; Verification; A-stable; Automatic verification; Dafny; Naturalmergesort; Pre/post conditions; Program proof; Sorting algorithm; State of the art; Formal methods
Model checking existential logic on partially ordered sets,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948988989&doi=10.1145%2f2814937&partnerID=40&md5=8f2306c476a25650f40b1c754aa457fc,"We study the problem of checking whether an existential sentence (i.e., a first-order sentence in prefix form built using existential quantifiers and all Boolean connectives) is true in a finite partially ordered set (a poset). A poset is a reflexive, antisymmetric, and transitive digraph. The problem encompasses the fundamental embedding problem of finding an isomorphic copy of a poset as an induced substructure of another poset. Model checking existential logic is already NP-hard on a fixed poset; thus, we investigate structural properties of posets yielding conditions for fixed-parameter tractability when the problem is parameterized by the sentence. We identify width as a central structural property (the width of a poset is the maximum size of a subset of pairwise incomparable elements); our main algorithmic result is that model checking existential logic on classes of finite posets of bounded width is fixed-parameter tractable. We observe a similar phenomenon in classical complexity, in which we prove that the isomorphism problem is polynomialtime tractable on classes of posets of bounded width; this settles an open problem in order theory. We surround our main algorithmic result with complexity results on less restricted, natural neighboring classes of finite posets, establishing its tightness in this sense.We also relate our work with (and demonstrate its independence of) fundamental fixed-parameter tractability results for model checking on digraphs of bounded degree and bounded clique-width. © 2015 ACM.",model checking; parameterized complexity; Partially ordered sets; width,Computational complexity; Directed graphs; Graph theory; Parallel processing systems; Polynomials; Set theory; Structural properties; Existential quantifiers; Existential sentences; First order sentences; Fixed-parameter tractability; Isomorphism problems; Parameterized complexity; Partially ordered set; width; Model checking
Dynamic reasoning systems,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948435772&doi=10.1145%2f2798727&partnerID=40&md5=84d9f4b83a77df49439ae5b8a66451b8,"A dynamic reasoning system (DRS) is an adaptation of a conventional formal logical system that explicitly portrays reasoning as a temporal activity, with each extralogical input to the system and each inference rule application being viewed as occurring at a distinct timestep. Every DRS incorporates some well-defined logic together with a controller that serves to guide the reasoning process in response to user inputs. Logics are generic, whereas controllers are application specific. Every controller does, nonetheless, provide an algorithm for nonmonotonic belief revision. The general notion of a DRS comprises a framework within which one can formulate the logic and algorithms for a given application and prove that the algorithms are correct, that is, that they serve to (1) derive all salient information and (2) preserve the consistency of the belief set. This article illustrates the idea with ordinary first-order predicate calculus, suitably modified for the present purpose, and two examples. The latter example revisits some classic nonmonotonic reasoning puzzles (Opus the Penguin, Nixon Diamond) and shows how these can be resolved in the context of a DRS, using an expanded version of first-order logic that incorporates typed predicate symbols. All concepts are rigorously defined and effectively computable, thereby providing the foundation for a future software implementation. © 2015 ACM.",Belief revision; Dynamic reasoning; Nonmonotonic reasoning,Algorithms; Calculations; Controllers; Application specific; Belief revision; Dynamic reasoning; First order logic; First order predicate calculus; Non-monotonic reasoning; Reasoning process; Software implementation; Formal logic
Lax theory morphisms,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946848813&doi=10.1145%2f2818644&partnerID=40&md5=8ea12e62b22ac0e7ceccf1440013d881,"When relating formal languages, e.g., in logic or type theory, it is often important to establish representation theorems. These interpret one language in terms of another in a way that preserves semantic properties such as provability or typing. Metalanguages for stating representation theorems can be divided into two groups: First, computational languages are very expressive (usually Turing-complete), but verifying the representation theorems is very difficult (often prohibitively so); second, declarative languages are restricted to certain classes of representation theorems (often based on theory morphisms), for which correctness is decidable. Neither is satisfactory, and this article contributes to the investigation of the trade-off between these two methods. Concretely, we introduce lax theory morphisms, which combine some of the advantages of each: they are substantially more expressive than conventional theory morphisms, but they share many of the invariants that make theory morphisms easy to work with. Specifically, we introduce lax morphisms between theories of a dependently typed logical framework, but our approach and results carry over to most declarative metalanguages. We demonstrate the usefulness of lax theorymorphisms by stating and verifying a type erasure translation from typed to untyped first-order logic. The translation is stated as a single lax theory morphism, and the invariants of the framework guarantee its correctness. This is the first time such a complex translation has be verified in a declarative framework. © 2015 ACM.",Dependent type theory; Logical framework; Logical relation; Representation theorem; Theory morphism; Translation,Computational linguistics; Economic and social effects; Formal languages; Formal logic; Semantics; Translation (languages); Dependent type theory; Logical frameworks; Logical relations; Morphisms; Representation theorem; Computation theory
Optimal tableau method for constructive satisfiability testing and model synthesis in the alternating-time temporal logic ATL+,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946838725&doi=10.1145%2f2811261&partnerID=40&md5=e6ae71ae8287559ec6ae5e1bf197c98b,"We develop a sound, complete, and practically implementable tableau-based decision method for constructive satisfiability testing and model synthesis for the fragment ATL+ of the full alternating-time temporal logic ATL∗. The method extends in an essential way a previously developed tableau-based decision method for ATL and works in 2EXPTIME, which is the optimal worst-case complexity of the satisfiability problem for ATL+. We also discuss how suitable parameterizations and syntactic restrictions on the class of input ATL+ formulas can reduce the complexity of the satisfiability problem. © 2015 ACM.",Alternating-time temporal logics; ATL+; Decision procedure; Model synthesis; Satisfiability; Tableaux,Software agents; Synthesis (chemical); Temporal logic; Alternating time temporal logic; ATL; Decision procedure; Model synthesis; Satisfiability; Tableaux; Formal logic
Backdoors to normality for disjunctive logic programs,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946820138&doi=10.1145%2f2818646&partnerID=40&md5=c54fd07a38254ec3d51edc29eb794874,"The main reasoning problems for disjunctive logic programs are complete for the second level of the polynomial hierarchy and hence considered harder than the same problems for normal (i.e., disjunction-free) programs, which are on the first level. We propose a new exact method for solving the disjunctive problems which exploits the small distance of a disjunctive programs from being normal. The distance is measured in terms of the size of a smallest ""backdoor to normality,"" which is the smallest number of atoms whose deletion makes the program normal. Our method consists of three phases. In the first phase, a smallest backdoor is computed. We show that this can be done using an efficient algorithm for computing a smallest vertex cover of a graph. In the second phase, the backdoor is used to transform the logic program into a quantified Boolean formula (QBF) where the number of universally quantified variables equals the size of the backdoor and where the total size of the quantified Boolean formula is quasilinear in the size of the given logic program. The quasilinearity is achieved by means of a characterization of the least model of a Horn program in terms of level numberings. In a third phase, the universal variables are eliminated using universal expansion yielding a propositional formula. The blowup in the last phase is confined to a factor that is exponential in the size of the backdoor but linear in the size of the quantified Boolean formula. By checking the satisfiability of the resulting formula with a SAT solver (or by checking the satisfiability of the quantified Boolean formula by a QBF-SAT solver), we can decide the ASP reasoning problems on the input program. In consequence, we have a transformation from ASP problems to propositional satisfiability where the combinatorial explosion, which is expected when transforming a problem from the second level of the polynomial hierarchy to the first level, is confined to a function of the distance to normality of the input program. In terms of parameterized complexity, the transformation is fixed-parameter tractable. We complement this result by showing that (under plausible complexity-theoretic assumptions) such a fixed-parameter tractable transformation is not possible if we consider the distance to tightness instead of distance to normality. © 2015 ACM.",Answer set programming; Backdoors; Parameterized complexity; Propositional satisfiability; Quantified Boolean formulas,Algorithms; Atoms; Boolean functions; Computer programming; Embedded systems; Formal logic; Logic programming; Model checking; Problem solving; Answer set programming; Backdoors; Parameterized complexity; Propositional satisfiability; Quantified Boolean formulas; Boolean algebra
From security protocols to pushdown automata,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942811995&doi=10.1145%2f2811262&partnerID=40&md5=07fec9427b6da25d86f24808e1b779ba,"Formal methods have been very successful in analyzing security protocols for reachability properties such as secrecy or authentication. In contrast, there are very few results for equivalence-based properties, crucial for studying, for example, privacy-like properties such as anonymity or vote secrecy. We study the problem of checking equivalence of security protocols for an unbounded number of sessions. Since replication leads very quickly to undecidability (even in the simple case of secrecy), we focus on a limited fragment of protocols (standard primitives but pairs, one variable per protocol's rules) for which the secrecy preservation problem is known to be decidable. Surprisingly, this fragment turns out to be undecidable for equivalence. Then, restricting our attention to deterministic protocols, we propose the first decidability result for checking equivalence of protocols for an unbounded number of sessions. This result is obtained through a characterization of equivalence of protocols in terms of equality of languages of (generalized, real-time) deterministic pushdown automata. We further show that checking for equivalence of protocols is actually equivalent to checking for equivalence of generalized, real-time deterministic pushdown automata. Very recently, the algorithm for checking for equivalence of deterministic pushdown automata has been implemented. We have implemented our translation from protocols to pushdown automata, yielding the first tool that decides equivalence of (some class of) protocols, for an unbounded number of sessions. As an application, we have analyzed some protocols of the literature including a simplified version of the basic access control (BAC) protocol used in biometric passports. © 2015 ACM.",Formal proofs; Security protocols; Trace equivalence; Verification,Access control; Automata theory; Computability and decidability; Formal methods; Network security; Robots; Verification; Biometric passport; Deterministic protocols; Deterministic pushdown automata; Formal proofs; Push-down automata; Security protocols; Trace equivalence; Undecidability; Equivalence classes
On the decidability of elementary modal logics,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942776030&doi=10.1145%2f2817825&partnerID=40&md5=67d9548d75366cf40017029ea628196f,"We consider the satisfiability problem for modal logic over first-order definable classes of frames.We confirm the conjecture from Hemaspaandra and Schnoor [2008] that modal logic is decidable over classes definable by universal Horn formulae. We provide a full classification of Horn formulae with respect to the complexity of the corresponding satisfiability problem. It turns out, that except for the trivial case of inconsistent formulae, local satisfiability is eitherNP-complete or PSPACE-complete, and global satisfiability is NP-complete, PSPACE-complete, or ExpTime-complete. We also show that the finite satisfiability problem for modal logic over Horn definable classes of frames is decidable. On the negative side, we show undecidability of two related problems. First, we exhibit a simple universal three-variable formula defining the class of frames over which modal logic is undecidable. Second, we consider the satisfiability problem of bimodal logic over Horn definable classes of frames, and also present a formula leading to undecidability. © 2015 ACM.",Computational complexity; Elementary logics; Modal logic,Computability and decidability; Computational complexity; Elementary logics; Finite satisfiability; Modal logic; Negative sides; PSPACE-complete; Satisfiability; Satisfiability problems; Undecidability; Computer circuits
Ramsey-based inclusion checking for visibly pushdown automata,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941564826&doi=10.1145%2f2774221&partnerID=40&md5=445c9a337bf812500dfd6f4ba239e379,"Checking whether one formal language is included in another is important inmany verification tasks. In this article, we provide solutions for checking the inclusion of languages given by visibly pushdown automata over both finite and infinite words. Visibly pushdown automata are a richer automaton model than the classical finite-state automata, which allows one, for example, to reason about the nesting of procedure calls in the executions of recursive imperative programs. The presented solutions do not rely on explicit automaton constructions for determinization and complementation. Instead, they are more direct and generalize the so-called Ramsey-based inclusion-checking algorithms, which apply to classical finite-state automata and proved to be effective there to visibly pushdown automata.We also experimentally evaluate these algorithms, demonstrating the virtues of avoiding explicit determinization and complementation constructions. © 2015 ACM.",Automata over finite and infinite words; Decision problems; Nested words; Verification; Visibly pushdown languages,Automata theory; Formal languages; Verification; Complementation constructions; Decision problems; Imperative programs; Infinite word; Nested words; Verification task; Visibly pushdown automaton; Visibly pushdown languages; Robots
From small space to small width in resolution,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941557324&doi=10.1145%2f2746339&partnerID=40&md5=bcdc77e56e9a21a4d1ddfa714bc0379f,"In 2003, Atserias and Dalmau resolved a major open question about the resolution proof system by establishing that the space complexity of a Conjunctive Normal Form (CNF) formula is always an upper bound on the width needed to refute the formula. Their proof is beautiful but uses a nonconstructive argument based on Ehrenfeucht-Fraïssé games. We give an alternative, more explicit, proof that works by simple syntactic manipulations of resolution refutations. As a by-product, we develop a ""black-box"" technique for proving space lower bounds via a ""static"" complexitymeasure that works against any resolution refutation-previous techniques have been inherently adaptive. We conclude by showing that the related question for polynomial calculus (i.e., whether space is an upper bound on degree) seems unlikely to be resolvable by similarmethods. © 2015 ACM.",degree; PCR; Polynomial calculus; Polynomial calculus resolution; Proof complexity; Resolution; Space; Width,Optical resolving power; Polynomials; degree; Polynomial calculus; Proof complexity; Space; Width; Calculations
Abstraction in fixpoint logic,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941562591&doi=10.1145%2f2740964&partnerID=40&md5=822b68cd125a6d4f104f5944892434b9,"We present a theory of abstraction for the framework of parameterised Boolean equation systems, a firstorder fixpoint logic. Parameterised Boolean equation systems can be used to solve a variety of problems in verification. We study the capabilities of the abstraction theory by comparing it to an abstraction theory for Generalised Kripke modal Transition Systems (GTSs). We show that for model checking the modal ì-calculus, our abstractions can be exponentially more succinct than GTSs and our theory is as complete as the GTS framework for abstraction. Furthermore, we investigate the completeness of our theory irrespective of the encoded decision problem. We illustrate the potential of our theory through case studies using the first-order modal ì-calculus and a real-time extension thereof, conducted using a prototype implementation of a new syntactic transformation for parameterised Boolean equation systems. © 2015 ACM.",Parameterised Boolean equation systems; Simulation,Abstracting; Calculations; Computer aided software engineering; Computer circuits; Decision theory; Model checking; Parameterization; Real time systems; Boolean equation system; Case-studies; Decision problems; Modal Transition Systems; Prototype implementations; Real-time extension; Simulation; Syntactic transformations; Boolean algebra
DL-lite ontology revision based on an alternative semantic characterization,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941554748&doi=10.1145%2f2786759&partnerID=40&md5=5a6213f7b616a16152df4673103c924a,"Ontology engineering and maintenance require (semi-)automated ontology change operations. Intensive research has been conducted on TBox and ABox changes in description logics (DLs), and various change operators have been proposed in the literature. Existing operators largely fall into two categories: syntaxbased and model-based.While each approach has its advantages and disadvantages, an important topic that has rarely been explored is how to achieve a balance between syntax-based and model-based approaches. Also, most existing operators are specially designed for either TBox change or ABox change, and cannot handle the general ontology revision task-given a DL knowledge base (KB, a pair consisting of a TBox and an ABox), how to revise it by a set of TBox and ABox axioms (i.e., a new DL KB). In this article, we introduce an alternative structure for DL-Lite, called a featured interpretation, and show that featured models provide a finite and tight characterization to the classical semantics of DL-Lite. A key issue for defining a change operator is the so-called expressibility, that is, whether a set of models (or featured models here) is axiomatizable in DLs. It is indeed much easier to obtain expressibility results for featured models than for classical DL models. As a result, the new semantics determined by featured models provides a method for defining and studying various changes of DL-Lite KBs that involve both TBoxes and ABoxes. To demonstrate the usefulness of the new semantic characterization in ontology change, we define two revision operators for DL-Lite KBs using featured models and study their properties. In particular, we show that our two operators both satisfy AGMpostulates.We show that the complexity of our revisions is 2-complete, that is, on the same level as major revision operators in propositional logic, which further justifies the feasibility of our revision approach for DL-Lite. Also, we develop algorithms for these DL-Lite revisions. © 2015 ACM.",Description logics; DL-Lite; Ontology change; Revision,Data description; Formal languages; Formal logic; Knowledge based systems; Semantics; Alternative structure; Description logic; Dl-lite; Model based approach; Ontology changes; Ontology engineering; Revision; Semantic characterizations; Ontology
Concurrent dynamic Algebra,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941570011&doi=10.1145%2f2785967&partnerID=40&md5=d89156b78dba0f36a03fc317cbdff176,"We reconstruct Peleg's concurrent dynamic logic in the context of modal Kleene algebras. We explore the algebraic structure of its multirelational semantics and develop an axiomatization of concurrent dynamic algebras from that basis. In this context, sequential composition is not associative. It interacts with parallel composition through a weak distributivity law. The modal operators of concurrent dynamic algebra are obtained from abstract axioms for domain and antidomain operators; the Kleene star is modelled as a least fixpoint. Algebraic variants of Peleg's axioms are shown to be derivable in these algebras, and their soundness is proved relative to the multirelational model. Additional results include iteration principles for the Kleene star and a refutation of variants of Segerberg's axiom in the multirelational setting. The most important results have been verified formally with Isabelle/HOL. © 2015 ACM.",Dynamic logic; Modal algebra; Multirelations,Computer circuits; Semantics; Stars; Algebraic structures; Axiomatization; Dynamic logic; Kleene algebras; Modal operators; Multirelations; Parallel composition; Sequential compositions; Algebra
Errata: Randomisation in Automata on Infinite Trees (ACM Transactions on Computational Logic (2015) 16:4 (36)),2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946031178&doi=10.1145%2f2824254&partnerID=40&md5=0a4413701f93594fda382ee8e93282cb,[No abstract available],,
Łukasiewicz games: A logic-based approach to quantitative strategic interactions,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946020984&doi=10.1145%2f2783436&partnerID=40&md5=371b8cf8f30bb6040213b0388378a033,"Boolean games provide a simple, compact, and theoretically attractive abstract model for studying multiagent interactions in settings where players will act strategically in an attempt to achieve individual goals. A standard critique of Boolean games, however, is that the strictly dichotomous nature of the preference relations induced by Boolean goals inevitably trivialises the nature of such strategic interactions: a player is assumed to be indifferent between all outcomes that satisfy her goal, and indifferent between all outcomes that do not satisfy her goal. While various proposals have been made to overcome this limitation, many of these proposals require the inclusion of nonlogical structures into games to capture nondichotomous preferences. In this article, we introduce Łukasiewicz games, which overcome this limitation by allowing goals to be specified using Łukasiewicz logics. By expressing goals as formulae of Łukasiewicz logics, we can express a much richer class of utility functions for players than is possible using classical Boolean logic: we can express every continuous piecewise linear polynomial function with rational coefficients over [0, 1]n as well as their finite-valued restrictions over {0, 1/k,...,(k - 1)/k, 1}n. We thus obtain a representation of nondichotomous preference structures within a purely logical framework. After introducing the formal framework of Łukasiewicz games, we present a number of detailed worked examples to illustrate the framework, and then investigate some of their theoretical properties. In particular, we present a logical characterisation of the existence of Nash equilibria in finite and infinite Łukasiewicz games. We conclude by briefly discussing issues of computational complexity. ï¿½ 2015 ACM 1529-3785/2015/09-ART33 $15.00.",Games; Knowledge representation; Logic; Multiagent systems; Łukasiewicz logics,Abstracting; Knowledge representation; Multi agent systems; Piecewise linear techniques; Rational functions; Class of utility functions; Games; Logic; Multi-agent interaction; Piecewise linear polynomials; Preference structures; Rational coefficients; Strategic interactions; Boolean functions
Logic of intuitionistic interactive proofs (formal theory of perfect knowledge transfer),2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946048105&doi=10.1145%2f2811263&partnerID=40&md5=2ff4bd51aa6cd3f937d3ff00cd36faaf,"We produce a decidable super-intuitionistic normal modal logic of internalised intuitionistic (and thus disjunctive and monotonic) interactive proofs (LIiP) from an existing classical counterpart of classical monotonic non-disjunctive interactive proofs (LiP). Intuitionistic interactive proofs effect a durable epistemic impact in the possibly adversarial communication medium CM (which is imagined as a distinguished agent) and only in that, that consists in the permanent induction of the perfect and thus disjunctive knowledge of their proof goal by means of CM's knowledge of the proof: If CM knew my proof then CM would persistently and also disjunctively know that my proof goal is true. So intuitionistic interactive proofs effect a lasting transfer of disjunctive propositional knowledge (disjunctively knowable facts) in the communication medium of multiagent distributed systems via the transmission of certain individual knowledge (knowable intuitionistic proofs). Our (necessarily) CM-centred notion of proof is also a disjunctive explicit refinement of KD45-belief, and yields also such a refinement of standard S5-knowledge. Monotonicity but not communality is a commonality of LiP, LIiP, and their internalised notions of proof. As a side-effect, we offer a short internalised proof of the Disjunction Property of Intuitionistic Logic (originally proved by Godel). © 2015 ACM 1529-3785/2015/09-ART35 $15.00.",Agents as proof-checkers; Communication networks; Constructive kripkesemantics; Disjunctive explicit doxastic and epistemic logic; Interactive and oracle computation; Interpreted communication; Intuitionistic modal logic; Multiagent distributed systems,Distributed computer systems; Distributed database systems; Formal logic; Knowledge management; Multi agent systems; Telecommunication networks; Distributed systems; Epistemic logic; Intuitionistic modal logic; Kripke-semantics; Proof checkers; Computer circuits
Computational complexity via finite types,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933047674&doi=10.1145%2f2764906&partnerID=40&md5=a6a61391c03c3ec31af0de38eeab0258,"We address computational complexity writing polymorphic functions between finite types (i.e., types with a finite number of canonical elements), expressing costs in terms of the cardinality of these types. This allows us to rediscover, in a more syntactical setting, the known result that the different levels in the hierarchy of higher-order primitive recursive functions (Gödel system T), when interpreted over finite structures, precisely capture basic complexity classes: functions of rank 1 characterize LOGSPACE, rank 2 PTIME, rank 3 PSPACE, rank 4 EXPTIME=DTIME(2poly), and so on. © 2015 ACM.",Complexity classes; Finite types; Higher-order primitive recursion; Memoization; System T,Recursive functions; Complexity class; Finite types; Memoization; Recursions; System T; Computational complexity
Undecidable propositional bimodal logics and one-variable first-order linear temporal logics with counting,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937828243&doi=10.1145%2f2757285&partnerID=40&md5=b0f38939985baeac180b7e3eccd24d47,"First-order temporal logics are notorious for their bad computational behavior. It is known that even the two-variable monadic fragment is highly undecidable over various linear timelines, and over branching time even one-variable fragments might be undecidable. However, there have been several attempts at finding well-behaved fragments of first-order temporal logics and related temporal description logics, mostly either by restricting the available quantifier patterns or by considering sub-Boolean languages. Here we analyze seemingly ""mild"" extensions of decidable one-variable fragments with counting capabilities, interpreted in models with constant, decreasing, and expanding first-order domains. We show that over most classes of linear orders, these logics are (sometimes highly) undecidable, even without constant and function symbols, and with the sole temporal operator ""eventually."" We establish connections with bimodal logics over 2D product structures having linear and ""difference"" (inequality) component relations and prove our results in this bimodal setting. We show a general result saying that satisfiability over many classes of bimodal models with commuting ""unbounded"" linear and difference relations is undecidable. As a byproduct, we also obtain new examples of finitely axiomatizable but Kripke incomplete bimodal logics. Our results generalize similar lower bounds on bimodal logics over products of two linear relations, and our proof methods are quite different from the known proofs of these results. Unlike previous proofs that first ""diagonally encode"" an infinite grid and then use reductions of tiling or Turing machine problems, here we make direct use of the grid-like structure of product frames and obtain lower-complexity bounds by reductions of counter (Minsky) machine problems. Representing counter machine runs apparently requires less control over neighboring grid points than tilings or Turing machine runs, and so this technique is possibly more versatile, even if one component of the underlying product structures is ""close to"" being the universal relation. © 2015 ACM.",Bimodal logic; First-order linear temporal logic; Satisfiability problem,Data description; Machinery; Specification languages; Temporal logic; Turing machines; Bimodal logic; Component relations; First-order temporal logic; Linear temporal logic; Product structure; Satisfiability problems; Temporal operators; Variable fragment; Formal logic
On the complexity of probabilistic abstract argumentation frameworks,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933051359&doi=10.1145%2f2749463&partnerID=40&md5=22d58b9ebd22f0d34dca822759210fdf,"Probabilistic abstract argumentation combines Dung's abstract argumentation framework with probability theory in order to model uncertainty in argumentation. In this setting, we address the fundamental problem of computing the probability that a set of arguments is an extension according to a given semantics.We focus on the most popular semantics (i.e., admissible, stable, complete, grounded, preferred, ideal-set, ideal, stage, and semistable) and show the following dichotomy result: computing the probability that a set of arguments is an extension is either FP or FP#P-complete depending on the semantics adopted. Our polynomial-time results are particularly interesting, as they hold for some semantics for which no polynomial-time technique was known so far. © 2015 ACM.",Argumentation theory; Computational complexity; Probabilistic reasoning; Uncertainty,Computational complexity; Polynomial approximation; Probability; Semantics; Uncertainty analysis; Abstract argumentation; Argumentation theory; Dichotomy results; Model uncertainties; Polynomial-time; Probabilistic reasoning; Probability theory; Uncertainty; Problem solving
A sat approach to clique-width,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932644414&doi=10.1145%2f2736696&partnerID=40&md5=70411ecbbc5c3cf3234eb19d38d39658,"Clique-width is a graph invariant that has been widely studied in combinatorics and computational logic. Computing the clique-width of a graph is an intricate problem, because the exact clique-width is not known even for very small graphs. We present a new method for computing clique-width via an encoding to propositional satisfiability (SAT), which is then evaluated by a SAT solver. Our encoding is based on a reformulation of clique-width in terms of partitions that utilizes an efficient encoding of cardinality constraints. Our SAT-based method is the first to discover the exact clique-width of various small graphs, including famous named graphs from the literature as well as random graphs of various density. With our method, we determined the smallest graphs that require a small predescribed clique-width. We further show how our method can be modified to compute the linear clique-width of graphs, a variant of clique-width that has recently received considerable attention. In an appendix, we provide certificates for tight upper bounds for the clique-width and linear clique-width of famous named graphs. © 2015 ACM.",Cardinality constraint; Clique-width; K-expression; Linear clique-width; SAT encoding; SAT solver; Satisfiability,Computation theory; Encoding (symbols); Formal logic; Graphic methods; Logic programming; Model checking; Cardinality constraints; Clique-width; Computational logic; Efficient encoding; Propositional satisfiability; SAT solvers; Satisfiability; Various densities; Graph theory
"Nonelementary complexities for branching VASS, MELL, and extensions",2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932609684&doi=10.1145%2f2733375&partnerID=40&md5=17ecbb5d4d6c54700e107ef5565a45cc,"We study the complexity of reachability problems on branching extensions of vector addition systems, which allows us to derive new non-elementary complexity bounds for fragments and variants of propositional linear logic. We show that provability in the multiplicative exponential fragment is TOWER-hard already in the affine case- and hence non-elementary. We match this lower bound for the full propositional affine linear logic, proving its TOWER-completeness. We also show that provability in propositional contractive linear logic is ACKERMANN-complete.",,Petri nets; Vectors; Complexity bounds; Linear logic; Lower bounds; Reachability problem; Vector addition systems; Linear algebra
Efficiently deciding μ-calculus with converse over finite trees,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927517004&doi=10.1145%2f2724712&partnerID=40&md5=8ec88df9f81eb0b39ad0af286856acfc,"We present a sound and complete satisfiability-testing algorithm and its effective implementation for an alternation-free modal ì-calculus with converse, where formulas are cycle-free and are interpreted over finite ordered trees. The time complexity of the satisfiability-testing algorithm is 2O(n) in terms of formula size n. The algorithm is implemented using symbolic techniques (BDD). We present crucial implementation techniques and heuristics that we used to make the algorithm as fast as possible in practice. Our implementation is available online and can be used to solve logical formulas of significant size and practical value. We illustrate this in the setting of XML trees. © 2015 ACM.",Implementation; Modal logic; Satisfiability,Algorithms; Problem Solving; Algorithms; Calculations; Forestry; Formal logic; Temporal logic; XML; Implementation; Implementation techniques; Logical formulas; Modal logic; Satisfiability; Satisfiability testing; Sound and complete; Symbolic techniques; Trees (mathematics)
The local universes model: An overlooked coherence construction for dependent type theories,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937852654&doi=10.1145%2f2754931&partnerID=40&md5=a6c368682f38a92fe13e6b97e296cc97,"We present a new coherence theorem for comprehension categories, providing strict models of dependent type theory with all standard constructors, including dependent products, dependent sums, identity types, and other inductive types. Precisely, we take as input a ""weak model"": a comprehension category, equipped with structure corresponding to the desired logical constructions.We assume throughout that the base category is close to locally Cartesian closed: specifically, that products and certain exponentials exist. Beyond this, we require only that the logical structure should be weakly stable - a pure existence statement, not involving any specific choice of structure, weaker than standard categorical Beck-Chevalley conditions, and holding in the now standard homotopy-theoretic models of type theory. Given such a comprehension category, we construct an equivalent split one whose logical structure is strictly stable under reindexing. This yields an interpretation of type theory with the chosen constructors. The model is adapted from Voevodsky's use of universes for coherence, and at the level of fibrations is a classical construction of Giraud. It may be viewed in terms of local universes or delayed substitutions. © 2015 ACM.",Categorical semantics; Coherence theorems; Comprehension categories; Dependent type theory,Semantics; Categorical semantics; Comprehension categories; Dependent type theory; Exponentials; Inductive-type; Logical structure; Strictly stable; Theoretic model; Formal languages
On the variable hierarchy of first-order spectra,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927551306&doi=10.1145%2f2733376&partnerID=40&md5=b06999bd0303257ff3d6f8b0752b1bb5,"The spectrum of a first-order logic sentence is the set of natural numbers that are cardinalities of its finite models. In this article, we study the hierarchy of first-order spectra based on the number of variables. It has been conjectured that it collapses to three variables. We show the opposite: it forms an infinite hierarchy. However, despite the fact that more variables can express more spectra, we show that to establish whether the class of first-order spectra is closed under complement, it is sufficient to consider sentences using only three variables and binary relations.",Bounded number of variables; First-order spectra; Nondeterministic exponential time,Logic programming; Binary relation; Bounded number of variables; Cardinalities; Exponential time; Finite model; First order; First order logic; Natural number; Formal logic
Higher homotopies in a hierarchy of univalent universes,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927560011&doi=10.1145%2f2729979&partnerID=40&md5=c83ea7be704ce10faab6f4548ef76dcc,"For Martin-Löf type theory with a hierarchy U0 : U1 : U2 : . . . of univalent universes, we show that Un is not an n-type. Our construction also solves the problem of finding a type that strictly has some high truncation level without using higher inductive types. In particular, Un is such a type if we restrict it to n-types. We have fully formalized and verified our results within the dependently typed language and proof assistant Agda. © 2015 ACM.",Homotopy type theory; Loop spaces; Truncation levels; Univalent universes,Logic programming; Homotopies; Homotopy types; Inductive-type; Loop space; Proof assistant; Truncation levels; Type theory; Univalent universes; Formal languages
Reasoning about substructures and games,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937857761&doi=10.1145%2f2757286&partnerID=40&md5=9a76ff1d05c92dce0e82a8efbf344ccc,"Many decision problems in formal verification and design can be suitably formulated in game-theoretic terms. This is the case for the model checking of open and closed systems and both controller and reactive synthesis. Interpreted in this context, these problems require one to find a strategy (i.e., a plan) to force the system to fulfill some desired goal, no matter what the opponent (e.g., the environment) does. A strategy essentially constrains the possible behaviors of the system to those that are compatible with the decisions dictated by the plan itself. Therefore, finding a strategy to meet some goal basically reduces to identifying a portion of the model of interest (i.e., one of its substructures) that satisfies that goal. In this view, the ability to reason about substructures becomes a crucial aspect for several fundamental problems. In this article, we present and study a new branching-time temporal logic, called Substructure Temporal Logic (STL∗ for short), whose distinctive feature is to allow for quantifying over the possible substructure of a given structure. The logic is obtained by adding four new temporal-like operators to CTL∗, whose interpretation is given relative to the partial order induced by a suitable substructure relation. STL∗ turns out to be very expressive and allows one to capture in a very natural way many well-known problems, such as module checking, reactive synthesis, and reasoning about games in a wide sense. A formal account of the model-theoretic properties of the new logic and results about (un)decidability and complexity of related decision problems are also provided. ©2015 ACM.",Quantification on substructures; Reasoning about games; Temporal logics,Computer circuits; Decision theory; Game theory; Model checking; Branching time; Closed systems; Decision problems; Game-theoretic; Model-theoretic; Quantification on substructures; Reactive synthesis; Reasoning about games; Temporal logic
Bounds for the quantifier depth in finite-variable logics: Alternation hierarchy,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929177984&doi=10.1145%2f2732409&partnerID=40&md5=d33420b785473868bbd1c0e74b8fe5cf,"Given two structures G and H distinguishable in FO (first-order logic with k variables), let A(G, H) denote the minimum alternation depth of a FO formula distinguishing G from H. Let A (n) be the maximum value of A (G, H) over n-element structures. We prove the strictness of the quantifier alternation hierarchy of FO in a strong quantitative form, namely A (n) > n/8-2, which is tight up to a constant factor. For each k > 2, it holds that A (n) > logk+1n - 2 even over colored trees, which is also tight up to a constant factor if k > 3. For k > 3, the last lower bound holds also over uncolored trees, whereas the alternation hierarchy of FO collapses even over all uncolored graphs. We also show examples of colored graphs G and H on n vertices that can be distinguished in FO much more succinctly if the alternation number is increased just by one: Whereas in Ei it is possible to distinguish G from H with bounded quantifier depth, in πi this requires quantifier depth Ω(n2). The quadratic lower bound is best possible here because, if G and H can be distinguished in FOk with i quantifier alternations, this can be done with quantifier depth n2k-2 + 1 and the same number of alternations. © 2015 ACM.",Alternation hierarchy; Finite-variable logic,Logic; Structures; Forestry; Formal logic; Trees (mathematics); Alternation hierarchies; Constant factors; Finite variable logic; First order logic; Lower bounds; Quantifier-alternation hierarchy; Computer circuits
On the power of substitution in the calculus of structures,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929165748&doi=10.1145%2f2701424&partnerID=40&md5=7eb101c33739cc289b762d8c25e58828,"There are two contributions in this article. First, we give a direct proof of the known fact that Frege systems with substitution can be p-simulated by the calculus of structures (CoS) extended with the substitution rule. This is done without referring to the p-equivalence of extended Frege systems and Frege systems with substitution. Second, we then show that the cut-free CoS with substitution is p-equivalent to the cut-free CoS with extension. © 2015 ACM.",Calculus of structures; Classical logic; Deep inference; Extension; Frege systems; Proof complexity; Substitution,Cobalt compounds; Substitution reactions; Calculus of structures; Classical logic; Deep inference; Extension; Proof complexity; Calculations
Why is it hard to obtain a dichotomy for consistent query answering?,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926385089&doi=10.1145%2f2670537&partnerID=40&md5=a15287cc5f3e6d92b37d3329428488e3,"A database may for various reasons become inconsistent with respect to a given set of integrity constraints. In the late 1990s, the formal approach of consistent query answering was proposed in order to query such databases. Since then, a lot of efforts have been spent to classify the complexity of consistent query answering under various classes of constraints. It is known that for the most common constraints and queries, the problem is in CONP and might be CONP-hard, yet several relevant tractable classes have been identified. Additionally, the results that emerged suggested that given a set of key constraints and a conjunctive query, the problem of consistent query answering is either in PTIME or is CONP-complete. However, despite all the work, as of today this dichotomy remains a conjecture. The main contribution of this article is to explain why it appears so difficult to obtain a dichotomy result in the setting of consistent query answering. Namely, we prove that such a dichotomy with respect to common classes of constraints and queries is harder to achieve than a dichotomy for the constraint satisfaction problem, which is a famous open problem since the 1990s. © 2015 ACM.",Consistent query answering; Constraint satisfaction problem; Dichotomy; Inconsistent databases,Database systems; Query processing; Classification (of information); Problem oriented languages; Query languages; Conjunctive queries; Consistent query answering; Dichotomy; Dichotomy results; Formal approach; Inconsistent database; Integrity constraints; Tractable class; Constraint and logic languages; Database management; Theory; Constraint satisfaction problems
Layer systems for proving confluence,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925689142&doi=10.1145%2f2710017&partnerID=40&md5=88101118c25e631d114f22f18328b796,"We introduce layer systems for proving generalizations of the modularity of confluence for first-order rewrite systems. Layer systems specify how terms can be divided into layers. We establish structural conditions on those systems that imply confluence. Our abstract framework covers known results like modularity, many-sorted persistence, layer-preservation, and currying. We present a counterexample to an extension of persistence to order-sorted rewriting and derive new sufficient conditions for the extension to hold. All our proofs are constructive. © 2015 ACM.",Confluence; Modularity; Persistence; Term rewriting,Abstract framework; Confluence; First order; Modularity; Persistence; Rewrite systems; Structural condition; Term rewriting; Logic programming
Normal higher-order termination,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925657549&doi=10.1145%2f2699913&partnerID=40&md5=900bcf03dff61c6530bdbd73f7c5d129,"We extend the termination proof methods based on reduction orderings to higher-order rewriting systems based on higher-order pattern matching. We accommodate, on the one hand, a weakly polymorphic, algebraic extension of Church's simply typed λ-calculus and, on the other hand, any use of eta, as a reduction, as an expansion, or as an equation. The user's rules may be of any type in this type system, either a base, functional, or weakly polymorphic type. © 2015 ACM.",Higher-order orderings; Higher-order patterns; Higher-order rewriting; Typed lambda calculus,Computational mechanics; Differentiation (calculus); Pattern matching; Higher-order; Higher-order rewriting; Polymorphic types; Simply typed lambda calculus; Termination proof; Type systems; Typed lambda calculus; Calculations
An evaluation-driven decision procedure for G3i,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926387810&doi=10.1145%2f2660770&partnerID=40&md5=a72a054a156b8cd7046be00fdfa4e950,"It is well known that G3i, the sequent calculus for intuitionistic propositional logic where weakening and contraction are absorbed into the rules, is not terminating. Indeed, due to the contraction in the rule for left implication, the naïve goal-oriented proof-search strategy, consisting in applying the rules of the calculus bottom up until possible, can generate branches of infinite length. The usual solution to this problem is to support the proof-search procedure with a loop checking mechanism that prevents the generation of infinite branches by storing and analyzing some information regarding the branch under development. In this article, we propose a new technique based on evaluation functions. An evaluation function is a lightweight computational mechanism that, analyzing only the current goal of the proof search, allows one to drive the application of rules to guarantee termination and to avoid useless backtracking. We describe an evaluation-driven proof-search procedure that given a sequent σ returns either a G3i-derivation of σ or a countermodel for σ. We prove that such a procedure is terminating and correct, and that the depth of the G3i-trees generated during proof search is quadratic in the size of σ. Finally, we discuss the overhead time introduced by evaluation functions in the proof-search procedure. © 2015 ACM.",Intuitionistic propositional logic; Proof-search procedures; Sequent calculi,Biomineralization; Calculations; Computation theory; Differentiation (calculus); Function evaluation; Bottom up; Decision procedure; Evaluation function; Goal-oriented; Intuitionistic propositional logic; Proof search; Sequent calculus; Formal logic
The complexity of decomposing modal and first-order theories,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926392387&doi=10.1145%2f2699918&partnerID=40&md5=e588b6e45393ee8f359eb66897647dd8,"We study the satisfiability problem of the logic K2 = K × K-the two-dimensional variant of unimodal logic, where models are restricted to asynchronous products of two Kripke frames. Gabbay and Shehtman proved in 1998 that this problem is decidable in a tower of exponentials. So far, the best-known lower bound is NEXP-hardness shown by Marx and Mikula's in 2001. Our first main result closes this complexity gap. We show that satisfiability in K2 is nonelementary. More precisely, we prove that it is k-NEXP-complete, where k is the switching depth (the minimal modal rank among the two dimensions) of the input formula, hereby solving a conjecture of Marx and Mikula's. Using our lower-bound technique also allows us to derive nonelementary lower bounds for the two-dimensional modal logics K4 × K and S52 × K, for which only elementary lower bounds were previously known. Moreover, we apply our technique to prove nonelementary lower bounds for the sizes of Feferman-Vaught decompositions with respect to product for any decomposable logic that is at least as expressive as unimodal K, generalizing a recent result by the first author and Lin. For the three-variable fragment FO3 of first-order logic, we obtain the following two immediate corollaries: the size of Feferman-Vaught decompositions with respect to disjoint sum are inherently nonelementary, and equivalent formulas in Gaifman normal form are inherently nonelementary. Our second main result consists in providing effective elementary (more precisely, doubly exponential) upper bounds for the two-variable fragment FO2 of first-order logic both for Feferman-Vaught decompositions and for equivalent formulas in Gaifman normal form. © 2015 ACM.",Feferman-Vaught decomposition; Gaifman's theorem; Modal logic; Two-dimensional modal logic,Decomposition; First order logic; First order theories; Gaifman's theorem; Lower bound techniques; Modal logic; Satisfiability; Satisfiability problems; Variable fragment; Formal logic
Minimizing deterministic lattice automata,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926298094&doi=10.1145%2f2631915&partnerID=40&md5=d0533491f83364a2e3ea1c4aee4991f6,"Traditional automata accept or reject their input and are therefore Boolean. In contrast, weighted automata map each word to a value from a semiring over a large domain. The special case of lattice automata, in which the semiring is a finite lattice, has interesting theoretical properties as well as applications in formal methods. A minimal deterministic automaton captures the combinatorial nature and complexity of a formal language. Deterministic automata are used in runtime monitoring, pattern recognition, and modeling systems. Thus, the minimization problem for deterministic automata is of great interest, both theoretically and in practice. For deterministic traditional automata on finite words, a minimization algorithm, based on the Myhill-Nerode right congruence on the set of words, generates in polynomial time a canonical minimal deterministic automaton. A polynomial algorithm is known also for deterministic weighted automata over the tropical semiring. For general deterministic weighted automata, the problem of minimization is open. In this article, we study minimization of deterministic lattice automata. We show that it is impossible to define a right congruence in the context of lattices, and that no canonical minimal automaton exists. Consequently, the minimization problem is much more complicated, and we prove that it is NP-complete. As good news, we show that while right congruence fails already for finite lattices that are fully ordered, for this setting we are able to combine a finite number of right congruences and generate a minimal deterministic automaton in polynomial time. © 2015 ACM.",Deterministic finite automata; Lattice automata and languages; Minimization,Computational linguistics; Formal languages; Formal methods; Optimization; Pattern recognition; Polynomial approximation; Polynomials; Deterministic automata; Deterministic finite automata; Minimization algorithms; Minimization problems; Polynomial algorithm; Runtime Monitoring; Tropical semiring; Weighted automata; Pattern recognition systems
Two-variable separation logic and its inner circle,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929174800&doi=10.1145%2f2724711&partnerID=40&md5=26455974d6c41467ebb45dac6878cd45,"Separation logic is a well-known assertion language for Hoare-style proof systems. We show that first-order separation logic with a unique record field restricted to two quantified variables and no program variables is undecidable. This is among the smallest fragments of separation logic known to be undecidable, and this contrasts with the decidability of two-variable first-order logic. We also investigate its restriction by dropping the magic wand connective, known to be decidable with nonelementary complexity, and we show that the satisfiability problem with only two quantified variables is not yet elementary recursive. Furthermore, we establish insightful and concrete relationships between two-variable separation logic and propositional interval temporal logic (PITL), data logics, and modal logics, providing an inner circle of closely related logics. © 2015 ACM.",Complexity; Data logic; Decidability; Interval temporal logic; Modal logic; Separation logic; Two-variable logics,Computability and decidability; Separation; Temporal logic; Complexity; Data logic; Interval temporal logic; Modal logic; Separation logic; Two-variable logics; Computer circuits
"A confluent rewriting system having no computable, one-step, normalizing strategy",2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923480198&doi=10.1145%2f2699917&partnerID=40&md5=beb2b50ee6a53abad0c52f1a35731c33,"A full and finitely generated Church-Rosser term rewriting system is presented that has no computable onestep, normalizing strategy; the system is both left- and right-linear. The result provides a negative answer to a question posed by Kennaway in 1989: Number 10 on the List of Open Problems in Rewriting. © 2015 ACM.",Church-Rosser property; Computability; Normalization; Reduction strategy; Rewriting,Logic programming; Church-Rosser property; Computability; Normalization; Reduction strategy; Rewriting; Computer science
Optimization modulo theories with linear rational costs,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923512333&doi=10.1145%2f2699915&partnerID=40&md5=ad9e085328f08560de5c6054aa4a1e15,"In the contexts of automated reasoning (AR) and formal verification (FV), important decision problems are effectively encoded into Satisfiability Modulo Theories (SMT). In the last decade, efficient SMT solvers have been developed for several theories of practical interest (e.g., linear arithmetic, arrays, and bit vectors). Surprisingly, little work has been done to extend SMT to deal with optimization problems; in particular, we are not aware of any previous work on SMT solvers able to produce solutions that minimize cost functions over arithmetical variables. This is unfortunate, since some problems of interest require this functionality. In the work described in this article we start filling this gap.We present and discuss two general procedures for leveraging SMT to handle the minimization of linear rational cost functions, combining SMT with standard minimization techniques. We have implemented the procedures within the MathSAT SMT solver. Due to the absence of competitors in the AR, FV, and SMT domains, we have experimentally evaluated our implementation against state-of-the-art tools for the domain of Linear Generalized Disjunctive Programming (LGDP), which is closest in spirit to our domain, on sets of problems that have been previously proposed as benchmarks for the latter tools. The results show that our tool is very competitive with, and often outperforms, these tools on these problems, clearly demonstrating the potential of the approach. © 2015 ACM.",Automated reasoning; Optimization; Satisfiability modulo theories,Cost functions; Formal logic; Optimization; Automated reasoning; Decision problems; Generalized disjunctive programming; Linear arithmetic; Minimization techniques; Optimization problems; Satisfiability modulo Theories; State of the art; Rational functions
Probabilistic event calculus for event recognition,2015,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923517534&doi=10.1145%2f2699916&partnerID=40&md5=362ed819692de4e1c73c71bf38005236,"Symbolic event recognition systems have been successfully applied to a variety of application domains, extracting useful information in the form of events, allowing experts or other systems to monitor and respond when significant events are recognised. In a typical event recognition application, however, these systems often have to deal with a significant amount of uncertainty. In this article, we address the issue of uncertainty in logic-based event recognition by extending the Event Calculus with probabilistic reasoning. Markov logic networks are a natural candidate for our logic-based formalism. However, the temporal semantics of the Event Calculus introduce a number of challenges for the proposed model. We show how and under what assumptions we can overcome these problems. Additionally,we study how probabilistic modelling changes the behaviour of the formalism, affecting its key property-the inertia of fluents. Furthermore, we demonstrate the advantages of the probabilistic Event Calculus through examples and experiments in the domain of activity recognition, using a publicly available dataset for video surveillance. © 2015 ACM.",Events; Machine learning; Probabilistic inference; Uncertainty,Computer circuits; Learning systems; Logic programming; Probabilistic logics; Security systems; Semantics; Activity recognition; Events; Logic based formalism; Markov logic networks; Probabilistic inference; Probabilistic modelling; Probabilistic reasoning; Uncertainty; Calculations
A conceptual framework for secrecy-preserving reasoning in knowledge bases,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920933451&doi=10.1145%2f2637477&partnerID=40&md5=b1b28848a9b4d004b33bfb3a451f3bf0,"In many applications, Knowledge Bases (KBs) contain confidential or private information (secrets). The KB should be able to use this secret information in its reasoning process but in answering user queries care must be exercised so that secrets are not revealed to unauthorized users.We consider this problem under the OpenWorld Assumption (OWA) in a setting with multiple querying agents M1,.,Mm that can pose queries against the KB κ and selectively share answers that they receive from κ with one or more other querying agents. We assume that for each Mi, the KB has a prespecified set of secrets Si that need to be protected from Mi. Communication between querying agents is modeled by a communication graph, a directed graph with self-loops. We introduce a general framework and propose an approach to secrecy-preserving query answering based on sound and complete proof systems. The idea is to hide the truthful answer from a querying agent Mi by feigning ignorance without lying (i.e., to provide the answer 'Unknown' to a query q if it needs to be protected. Under the OWA, a querying agent cannot distinguish between the case that q is being protected (for reasons of secrecy) and the case that it cannot be inferred from κ. In the pre-query stage we compute a set of envelopes E1,., Em (restricted to a finite subset of the set of formulae that are entailed by κ) so that Si ⊆ Ei, and a query α posed by agent Mi can be answered truthfully whenever α ∉ Ei and ¬α ∉ Ei. After the pre-query stage, the envelope is updated as needed. We illustrate this approach with two simple cases: the Propositional Horn KBs and the Description Logic AL KBs. © 2014 ACM.",Multiagents; Secrecy-preserving reasoning,Data description; Directed graphs; Communication graphs; Conceptual frameworks; Knowledge basis (KBs); Multi agent; Private information; Secrecy-preserving reasoning; Secret information; Sound and complete; Query processing
Parameterized weighted containment,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920872816&doi=10.1145%2f2665076&partnerID=40&md5=8d86ed6ff28db969766fd142361486d3,"Partially specified systems and specifications are used in formal methods such as stepwise design and query checking. Existing methods consider a setting in which systems and their correctness are Boolean. In recent years, there has been growing interest and need for quantitative formal methods, where systems may be weighted and specifications may be multivalued.Weighted automata, which map input words to a numerical value, play a key role in quantitative reasoning. Technically, every transition in a weighted automaton A has a cost, and the value A assigns to a finite word w is the sum of the costs on the transitions traversed along the most expensive accepting run of A on w. We study parameterized weighted containment: given three weighted automata A, B, and C, with B being partial, the goal is to find an assignment to the missing costs in B so that we end up with B′ for which A ≤ B′ ≤ C, where ≤ is the weighted counterpart of containment. We also consider a one-sided version of the problem, where only A or only C is given in addition to B, and the goal is to find a minimal assignment with which A ≤ B′ or, respectively, a maximal one with which B′ ≤ C. We argue that both problems are useful in stepwise design of weighted systems as well as approximated minimization of weighted automata. We show that when the automata are deterministic, we can solve the problems in polynomial time. Our solution is based on the observation that the set of legal assignments to κ missing costs forms a κ-dimensional polytope. The technical challenge is to find an assignment in polynomial time even though the polytope is defined by means of exponentially many inequalities.We do so by developing a divide-and-conquer algorithm based on a separation oracle for polytopes. For nondeterministic automata, the weighted setting is much more complex, and in fact even nonparameterized containment is undecidable. We are able to show positive results for variants of the problems, where containment is replaced by simulation. © 2014 ACM.",Ellipsoid method; Partially specified systems; Quantitative verification; Weighted automata,Automata theory; Costs; Formal methods; Formal specification; Numerical methods; Polynomial approximation; Specifications; Divide-and-conquer algorithm; Ellipsoid method; Nondeterministic automata; Numerical values; Quantitative reasoning; Quantitative verification; Technical challenges; Weighted automata; Problem solving
Taming paraconsistent (and other) logics: An algorithmic approach,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920920896&doi=10.1145%2f2661636&partnerID=40&md5=da07905173e6c155026dfdb0231e52ed,"We develop a fully algorithmic approach to ""taming"" logics expressed Hilbert style, that is, reformulating them in terms of analytic sequent calculi and useful semantics. Our approach applies to Hilbert calculi extending the positive fragment of propositional classical logic with axioms of a certain general form that contain new unary connectives. Our work encompasses various results already obtained for specific logics. It can be applied to new logics, as well as to known logics for which an analytic calculus or a useful semantics has so far not been available. A Prolog implementation of the method is described. © 2014 ACM.",Nonclassical logics; Nondeterministic matrices; Paraconsistent logics; Proof theory; Sequent calculus,Algorithms; Biomineralization; Differentiation (calculus); Pathology; PROLOG (programming language); Semantics; A-prolog; Algorithmic approach; Classical logic; Hilbert; Non-classical logic; Paraconsistent logic; Proof theory; Sequent calculus; Calculations
Decidability of approximate skolem problem and applications to logical verification of dynamical properties of markov chains,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920930189&doi=10.1145%2f2666772&partnerID=40&md5=4ca51df7681be12e5f6e99b6b50f50c5,"When studying probabilistic dynamical systems, temporal logic has typically been used to analyze path properties. Recently, there has been some interest in analyzing the dynamical evolution of state probabilities of these systems. In this article, we show that verifying linear temporal properties concerning the state evolution induced by a Markov chain is equivalent to the decidability of the Skolem problem-a longstanding open problem in Number Theory. However, from a practical point of view, usually it is enough to check properties up to some acceptable error bound ε. We show that an approximate version of the Skolem problem is decidable, and that it can be applied to verify, up to arbitrarily small ε, linear temporal properties of the state evolution induced by a Markov chain. © 2014 ACM.",Markov chains; Skolem problem; Temporal logic,Chains; Computability and decidability; Dynamical systems; Number theory; Probabilistic logics; Temporal logic; Dynamical evolution; Dynamical properties; Error bound; Path properties; Skolem problem; State evolutions; State probability; Temporal property; Markov processes
Reasoning about strategies: On the model-checking problem,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914173732&doi=10.1145%2f2631917&partnerID=40&md5=cbaa20108c276be1ca48382e13caa14c,"In open systems verification, to formally check for reliability, one needs an appropriate formalism to model the interaction between agents and express the correctness of the system no matter how the environment behaves. An important contribution in this context is given by modal logics for strategic ability, in the setting of multiagent games, such as ATL, ATL ∗, and the like. Recently, Chatterjee, Henzinger, and Piterman introduced Strategy Logic, which we denote here by CHP-SL, with the aim of getting a powerful framework for reasoning explicitly about strategies. CHP-SL is obtained by using first-order quantifications over strategies and has been investigated in the very specific setting of two-agents turned-based games, where a nonelementary model-checking algorithm has been provided. While CHP-SL is a very expressive logic, we claim that it does not fully capture the strategic aspects of multiagent systems. In this article, we introduce and study a more general strategy logic, denoted SL, for reasoning about strategies in multiagent concurrent games. As a key aspect, strategies in SL are not intrinsically glued to a specific agent, but an explicit binding operator allows an agent to bind to a strategy variable. This allows agents to share strategies or reuse one previously adopted. We prove that SL strictly includes CHP-SL, while maintaining a decidable model-checking problem. In particular, the algorithm we propose is computationally not harder than the best one known for CHP-SL. Moreover, we prove that such a problem for SL is NONELEMENTARY. This negative result has spurred us to investigate syntactic fragments of SL, strictly subsuming ATL ∗, with the hope of obtaining an elementary model-checking problem. Among others, we introduce and study the sublogics SL[NG], SL[BG], and SL[1G]. They encompass formulas in a special prenex normal form having, respectively, nested temporal goals, Boolean combinations of goals, and, a single goal at a time. Intuitively, for a goal, we mean a sequence of bindings, one for each agent, followed by an LTL formula. We prove that the model-checking problem for SL[1G] is 2EXPTIME-COMPLETE, thus not harder than the one for ATL ∗. In contrast, SL[NG] turns out to be NONELEMENTARY-HARD, strengthening the corresponding result for SL. Regarding SL[BG], we show that it includes CHP-SL and its model-checking is decidable with a 2EXPTIME lower-bound. It is worth enlightening that to achieve the positive results about SL[1G], we introduce a fundamental property of the semantics of this logic, called behavioral, which allows to strongly simplify the reasoning about strategies. Indeed, in a non behavioral logic such as SL[BG] and the subsuming ones, to satisfy a formula, one has to take into account that a move of an agent, at a given moment of a play, may depend on the moves taken by any agent in another counterfactual play. © 2014 ACM.",Behavioral strategies; Model checking; Strategy logic,
Fuzzy time in linear temporal logic,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907589022&doi=10.1145%2f2629606&partnerID=40&md5=51f6bbc52fc61ec97a27bf65ab7ac6c7,"In the past years, the adoption of adaptive systems has increased in many fields of computer science, such as databases and software engineering. These systems are able to automatically react to events by collecting information from the external environment and generating new events. However, the collection of data is often hampered by uncertainty and vagueness. The decision-makingmechanism used to produce a reaction is also imprecise and cannot be evaluated in a crisp way, as it depends on vague temporal constraints expressed by humans. Logic has been extensively used as an abstraction to express vagueness in the satisfaction of system properties, as well as to enrich existing modeling formalisms. However, existing attempts to fuzzify the temporalmodalities still have some limitations. Existing fuzzy temporal languages are generally obtained from classical temporal logic by replacing classical connectives or propositions with their fuzzy counterparts. Hence, these languages do not allow us to represent temporal properties, such as ""almost always"" and ""soon,"" in which the notion of time is inherently fuzzy. To overcome these limitations, we propose a temporal framework, fuzzy-time temporal logic (FTL), to express vagueness on time. This framework formally defines a set of fuzzy temporal modalities that can be customized by choosing a specific semantics for the connectives. The semantics of the language is sound, and the introduced modalities respect a set of mutual relations. We also prove that under the assumption that all events are crisp, FTL reduces to linear temporal logic (LTL). Moreover, for some of the possible fuzzy interpretations of the connectives, we identify adequate sets of temporal operators, from which it is possible to derive all of the other ones. © 2014 ACM.",Fuzzy temporal logic; Vague requirements,Adaptive systems; Computer circuits; Decision making; Semantics; Software engineering; External environments; Fuzzy interpretations; Linear temporal logic; Modeling formalisms; Specific semantics; Temporal constraints; Temporal modalities; Vague requirements; Temporal logic
The ordering principle in a fragment of approximate counting,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911460986&doi=10.1145%2f2629555&partnerID=40&md5=be7c1c0330ddd972c568fdb005701952,"The ordering principle states that every finite linear order has a least element. We show that, in the relativized setting, the surjective weak pigeonhole principle for polynomial time functions does not prove a Herbrandized version of the ordering principle over T12. This answers an open question raised in Buss et al. [2012] and completes their program to compare the strength of Jeřábek's bounded arithmetic theory for approximate counting with weakened versions of it. © 2014 ACM 1529-3785/2014/11-ART29 $15.00.",Bounded arithmetic; Computational complexity; Polynomial local search; Propositional proof complexity,Computational complexity; Computer science; Logic programming; Approximate counting; Bounded arithmetic; Linear order; Local search; Pigeonhole principle; Polynomial time functions; Propositional proof complexity; Surjective; Polynomial approximation
Logical characterizations of behavioral relations on transition systems of probability distributions,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907577668&doi=10.1145%2f2641566&partnerID=40&md5=582a1d8390a96a1b28dcd93f9192964f,"Probabilistic nondeterministic processes are commonly modeled as probabilistic LTSs (PLTSs). A number of logical characterizations of the main behavioral relations on PLTSs have been studied. In particular, Parma and Segala [2007] and Hermanns et al. [2011] define a probabilistic Hennessy-Milner logic interpreted over probability distributions, whose corresponding logical equivalence/preorder when restricted to Dirac distributions coincides with standard bisimulation/simulation between the states of a PLTS. This result is here extended by studying the full logical equivalence/preorder between (possibly non-Dirac) distributions in terms of a notion of bisimulation/simulation defined on an LTS whose states are distributions (dLTS). We show that the well-known spectrum of behavioral relations on nonprobabilistic LTSs as well as their corresponding logical characterizations in terms of Hennessy-Milner logic scales to the probabilistic setting when considering dLTSs. © 2014 ACM.",Bisimulation; Hennessy-Milner logic; Probabilistic labeled transition systems; Simulation,Computer circuits; Bisimulations; Dirac distribution; Hennessy-Milner Logics; Labeled transition systems; Logical characterization; Logical equivalence; Non-deterministic process; Simulation; Probability distributions
A sound and complete proof technique for linearizability of concurrent data structures,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907578190&doi=10.1145%2f2629496&partnerID=40&md5=fb127149a654c27d8b88d93ce9fd9c47,"Efficient implementations of data structures such as queues, stacks or hash-tables allow for concurrent access by many processes at the same time. To increase concurrency, these algorithms often completely dispose with locking, or only lock small parts of the structure. Linearizability is the standard correctness criterion for such a scenario-where a concurrent object is linearizable if all of its operations appear to take effect instantaneously some time between their invocation and return. The potential concurrent access to the shared data structure tremendously increases the complexity of the verification problem, and thus current proof techniques for showing linearizability are all tailored to specific types of data structures. In previous work, we have shown how simulation-based proof conditions for linearizability can be used to verify a number of subtle concurrent algorithms. In this article, we now show that conditions based on backward simulation can be used to show linearizability of every linearizable algorithm, that is, we show that our proof technique is both sound and complete. We exemplify our approach by a linearizability proof of a concurrent queue, introduced in Herlihy and Wing's landmark paper on linearizability. Except for their manual proof, none of the numerous other approaches have successfully treated this queue. © 2014 ACM.",Concurrent access; KIV; Linearizability; Nonatomic refinement; Refinement; Theorem proving; Z,Data Sharing; Data structures; Locks (fasteners); Queueing theory; Theorem proving; Concurrent access; Concurrent data structures; Efficient implementation; Linearizability; Non-atomic refinement; Refinement; Shared data structure; Verification problems; Concurrency control
"A general theory of barbs, contexts, and labels",2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907578350&doi=10.1145%2f2631916&partnerID=40&md5=5638070e4a35b5b7a51be66e4a53baf8,"Barbed bisimilarity is a widely used behavioral equivalence for interactive systems: given a set of predicates (denoted ""barbs"" and representing basic observations on states) and a set of contexts (representing the possible execution environments), two systems are deemed to be equivalent if they verify the same barbs whenever inserted inside any of the chosen contexts. Despite its flexibility and expressiveness, this definition of equivalence is unsatisfactory because often the quantification is over an infinite set of contexts, thus making barbed bisimilarity very hard to be verified. Should a labeled operational semantics be available, more efficient observational equivalences might be adopted. To this end, a series of techniques has been proposed to derive labeled transition systems (LTSs) from unlabeled ones, the main example being Leifer and Milner's theory of reactive systems. The underlying intuition is that labels should be the ""minimal"" contexts that allow for a reduction step to be performed. However, minimality is difficult to asses, whereas the set of ""intuitively"" correct labels is often easily devised by the ingenuity of the researcher. This article introduces a framework that characterizes (weak) barbed bisimilarity via LTSs whose labels are (not necessarily minimal) contexts. Differently from previous proposals, our theory does not depend on the way the labeled transitions are built but instead relies on a simple set-theoretical presentation for identifying those properties such an LTS should verify to (1) capture the barbed bisimilarities of the underlying system and (2) ensure that such bisimilarities are congruences. Furthermore, we adopt suitable proof techniques to make feasible the verification of such properties. To provide a test-bed for our formalism, we instantiate it by addressing the semantics of the Mobile Ambients calculus, recasting its barbed bisimilarities via label-based behavioral equivalences. © 2014 ACM.",Barbed bisimilarity; Contexts-as-labels paradigm; Interactive systems,Bioinformatics; Semantics; Behavioral equivalence; Bisimilarity; Contexts-as-labels paradigm; Execution environments; Interactive system; Labeled transition systems; Observational equivalences; Operational semantics; Calculations
Terminating evaluation of logic programs with finite three-valued models,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905261374&doi=10.1145%2f2629337&partnerID=40&md5=02ddfc9f98236d077c47ceffb2970a32,"As evaluation methods for logic programs have become more sophisticated, the classes of programs for which termination can be guaranteed have expanded. From the perspective of ar set programs that include function symbols, recent work has identified classes for which grounding routines can terminate either on the entire program [Calimeri et al. 2008] or on suitable queries [Baselice et al. 2009]. From the perspective of tabling, it has long been known that a tabling technique called subgoal abstraction provides good termination properties for definite programs [Tamaki and Sato 1986] and this result was recently extended to stratified programs via the class of bounded term-size programs [Riguzzi and Swift 2013]. In this article, we provide a formal definition of tabling with subgoal abstraction resulting in the SLGSA algorithm. Moreover, we discuss a declarative characterization of the queries and programs for which SLGSA terminates. We call this class strongly bounded term-size programs and show its equivalence to programs with finite well-founded models. For normal programs, strongly bounded term-size programs strictly includes the finitely ground programs of Calimeri et al. [2008]. SLGSA has an asymptotic complexity on strongly bounded term-size programs equal to the best known and produces a residual program that can be sent to an answer set programming system. Finally, we describe the implementation of subgoal abstraction within the SLG-WAM of XSB and provide performance results. © 2014 ACM.",Tabled logic programming; Termination,Abstracting; Aluminum; Computer circuits; Computer programming; Equivalence classes; Formal logic; Answer set programming; Asymptotic complexity; Evaluation methods; Formal definition; Termination; Termination property; Three-valued models; Well-founded models; Logic programming
Temporal specifications with accumulative values,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907578614&doi=10.1145%2f2629686&partnerID=40&md5=1eb03236cd60ade6fb8c28f22e0558de,"Recently, there has been an effort to add quantitative objectives to formal verification and synthesis. We introduce and investigate the extension of temporal logics with quantitative atomic assertions. At the heart of quantitative objectives lies the accumulation of values along a computation. It is often the accumulated sum, as with energy objectives, or the accumulated average, as with mean-payoff objectives. We investigate the extension of temporal logics with the prefix-accumulation assertions Sum(v) ≥ c and Avg(v) ≥ c, where v is a numeric (or Boolean) variable of the system, c is a constant rational number, and Sum(v) and Avg(v) denote the accumulated sum and average of the values of v from the beginning of the computation up to the current point in time. We also allow the path-accumulation assertions LimInfAvg(v) ≥ c and LimSupAvg(v) ≥ c, referring to the average value along an entire infinite computation. We study the border of decidability for such quantitative extensions of various temporal logics. In particular, we show that extending the fragment of CTL that has only the EX, EF, AX, and AG temporal modalities with both prefix-accumulation assertions, or extending LTL with both path-accumulation assertions, results in temporal logics whose model-checking problem is decidable. Moreover, the prefix-accumulation assertions may be generalized with ""controlled accumulation,"" allowing, for example, to specify constraints on the average waiting time between a request and a grant. On the negative side, we show that this branching-time logic is, in a sense, the maximal logic with one or both of the prefix-accumulation assertions that permits a decidable model-checking procedure. Extending a temporal logic that has the EG or EU modalities, such as CTL or LTL, makes the problem undecidable. © 2014 ACM.",Accumulation; Formal verification; Model checking; Nondeterminism; Specification; Temporal logic,Computability and decidability; Computer circuits; Formal verification; Model checking; Specifications; Accumulation; Average waiting-time; Model checking problem; Non-determinism; Quantitative objectives; Rational numbers; Temporal modalities; Temporal specification; Temporal logic
Inference of field-sensitive reachability and cyclicity,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907571027&doi=10.1145%2f2629478&partnerID=40&md5=5660e8b879a5f95527873d543898eadb,"In heap-based languages, knowing that a variable x points to an acyclic data structure is useful for analyzing termination. This information guarantees that the depth of the data structure to which x points is greater than the depth of the structure pointed to by x. fld, and allows bounding the number of iterations of a loop that traverses the data structure on fld. In general, proving termination needs acyclicity, unless program-specific or nonautomated reasoning is performed. However, recent work could prove that certain loops terminate even without inferring acyclicity, because they traverse data structures ""acyclically."" Consider a double-linked list: if it is possible to demonstrate that every cycle involves both the ""next"" and the ""prev"" field, then a traversal on ""next"" terminates since no cycle will be traversed completely. This article develops a static analysis inferring field-sensitive reachability and cyclicity information, which is more general than existing approaches. Propositional formulæ are computed, which describe which fields may or may not be traversed by paths in the heap. Consider a tree with edges ""left"" and ""right"" to the left and right subtrees, and ""parent"" to the parent node: termination of a loop traversing leaf-up cannot be guaranteed by state-of-the-art analyses. Instead, propositional formulæ computed by this analysis indicate that cycles must traverse ""parent"" and at least one between ""left"" and ""right"": termination is guaranteed, as no cycle is traversed completely. This work defines the necessary abstract domains and builds an abstract semantics on them. A prototypical implementation provides the expected result on relevant examples. © 2014 ACM.",Abstract interpretation; Cyclicity analysis; Data structures; Heap manipulation; Pointer analysis; Shape analysis; Static analysis; Termination analysis,Abstracting; Semantics; Static analysis; Abstract interpretations; Cyclicity; Heap manipulation; Pointer analysis; Shape analysis; Termination analysis; Data structures
Identifying efficient abductive hypotheses using multicriteria dominance relation,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907584723&doi=10.1145%2f2629669&partnerID=40&md5=8f3840f8fe7b5e89f9cf7d94678b9542,"In this article, results of the automation of an abductive procedure are reported. This work is a continuation of our earlier research [Komosinski et al. 2012], where a general scheme of the procedure has been proposed. Here, a more advanced system developed to generate and evaluate abductive hypotheses is introduced. Abductive hypotheses have been generated by the implementation of the synthetic tableau method. Prior to the evaluation, the set of hypotheses has undergone several reduction phases. To assess usefulness of abductive hypotheses in the reduced set, several criteria have been employed. The evaluation of efficiency of the hypotheses has been provided by the multicriteria dominance relation. To comprehend the abductive procedure and the evaluation process more extensively, analyses have been conducted on a number of artificially generated abductive problems. © 2014 ACM.",Abduction; Dominance relation; Multicriteria; Optimization; Synthetic tableau method,Logic programming; Optimization; Abduction; Advanced systems; Dominance relation; Multi-criteria; Reduction phasis; Tableau method; Computer science
Refining the process rewrite systems hierarchy via ground tree rewrite systems,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907571099&doi=10.1145%2f2629679&partnerID=40&md5=69d7ef6a4c48c05275ce9fbbde1a3feb,"In his seminal paper, Mayr introduced the well-known process rewrite systems (PRS) hierarchy, which contains many well-studied classes of infinite-state systems including pushdown systems (PDS), Petri nets, and PA-processes. A separate development in the term rewriting community introduced the notion of ground tree rewrite systems (GTRS), which is a model that strictly extends PDS while still enjoying desirable decidable properties. There have been striking similarities between the verification problems that have been shown decidable (and undecidable) over GTRS and over models in the PRS hierarchy such as PA and PAD processes. It is open to what extent PRS and GTRS are connected in terms of their expressive power. In this article, we pinpoint the exact connection between GTRS and models in the PRS hierarchy in terms of their expressive power with respect to strong, weak, and branching bisimulation. Among others, this connection allows us to give new insights into the decidability results for subclasses of PRS, such as simpler proofs of known decidability results of verifications problems on PAD. © 2014 ACM.",Ground terms; Hierarchy; Rewrite systems; Trees,Computability and decidability; Petri nets; Branching bisimulation; Ground terms; Hierarchy; Infinite state systems; Process rewrite systems; Rewrite systems; Trees; Verification problems; Forestry
Complexity classifications for logic-based argumentation,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907578385&doi=10.1145%2f2629421&partnerID=40&md5=587f420213df37f0fd4c7f0c75ea655d,"We consider logic-based argumentation in which an argument is a pair (φ, α), where the support φ is a minimal consistent set of formulae taken from a given knowledge base (usually denoted by δ) that entails the claim ? (a formula). We study the complexity of three central problems in argumentation: the existence of a support φ ⊆ δ, the verification of a support, and the relevance problem (given ψ, is there a support φ such that ψ ∈φ?). When arguments are given in the full language of propositional logic, these problems are computationally costly tasks: the verification problem is DP-complete; the others are σ p2-complete. We study these problems in Schaefer's famous framework where the considered propositional formulae are in generalized conjunctive normal form. This means that formulae are conjunctions of constraints built upon a fixed finite set of Boolean relations Γ (the constraint language). We show that according to the properties of this language Γ, deciding whether there exists a support for a claim in a given knowledge base is either polynomial, NP-complete, coNP-complete, or σ p2-complete. We present a dichotomous classification, P or DPcomplete, for the verification problem and a trichotomous classification for the relevance problem into either polynomial, NP-complete, or σ p2-complete. These last two classifications are obtained by means of algebraic tools. © 2014 ACM.",Computational complexity; Generalized satisfiability; Logic-based argumentation; Schaefer,Computational complexity; Formal logic; Knowledge based systems; Boolean relations; Conjunctive normal forms; Constraint language; Logic-based argumentations; Propositional logic; Satisfiability; Schaefer; Verification problems; Computer circuits
Randomization in automata on infinite trees,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907571731&doi=10.1145%2f2629336&partnerID=40&md5=3ad39f98b6998f1eadbc76cb15b650a2,"We study finite automata running over infinite binary trees. A run of such an automaton over an input tree is a tree labeled by control states of the automaton: the labeling is built in a top-down fashion and should be consistent with the transitions of the automaton. A branch in a run is accepting if the ω-word obtained by reading the states along the branch satisfies some acceptance condition (typically an ω-regular condition such as a Büchi or a parity condition). Finally, a tree is accepted by the automaton if there exists a run over this tree in which every branch is accepting. In this article, we consider two relaxations of this definition, introducing a qualitative aspect. First, we relax the notion of accepting run by allowing a negligible set (in the sense of measure theory) of nonaccepting branches. In this qualitative setting, a tree is accepted by the automaton if there exists a run over this tree in which almost every branch is accepting. This leads to a new class of tree languages, qualitative tree languages. This class enjoys many good properties: closure under union and intersection (but not under complement), and emptiness is decidable in polynomial time. A dual class, positive tree languages, is defined by requiring that an accepting run contains a non-negligeable set of branches. The second relaxation is to replace the existential quantification (a tree is accepted if there exists some accepting run over the input tree) with a probabilistic quantification (a tree is accepted if almost every run over the input tree is accepting). For the run, we may use either classical acceptance or qualitative acceptance. In particular, for the latter, we exhibit a tight connection with partial observation Markov decision processes. Moreover, if we additionally restrict operation to the Büchi condition, we show that it leads to a class of probabilistic automata on infinite trees enjoying a decidable emptiness problem. To our knowledge, this is the first positive result for a class of probabilistic automaton over infinite trees. © 2014 ACM.",(; Finite automata on infinite trees; Measure theory; Partial observation) Markov decision processes; Probabilistic automata,Computability and decidability; Decision theory; Finite automata; Markov processes; Polynomial approximation; Probabilistic logics; Robots; Acceptance conditions; Existential quantifications; Infinite trees; Markov Decision Processes; Measure theory; Probabilistic automata; Probabilistic quantification; Qualitative aspects; Binary trees
Structural focalization,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907587442&doi=10.1145%2f2629678&partnerID=40&md5=8b1c9c7d8f7f1d0408732da485e5905c,"Focusing, introduced by Jean-Marc Andreoli in the context of classical linear logic [Andreoli 1992], defines a normal form for sequent calculus derivations that cuts down on the number of possible derivations by eagerly applying invertible rules and grouping sequences of non-invertible rules. A focused sequent calculus is defined relative to some nonfocused sequent calculus; focalization is the property that every nonfocused derivation can be transformed into a focused derivation. In this article, we present a focused sequent calculus for propositional intuitionistic logic and prove the focalization property relative to a standard presentation of propositional intuitionistic logic. Compared to existing approaches, the proof is quite concise, depending only on the internal soundness and completeness of the focused logic. In turn, both of these properties can be established (and mechanically verified) by structural induction in the style of Pfenning's structural cut elimination without the need for any tedious and repetitious invertibility lemmas. The proof of cut admissibility for the focused system, which establishes internal soundness, is not particularly novel. The proof of identity expansion, which establishes internal completeness, is a major contribution of this work. © 2014 ACM.",Cut admissibility; Focusing; Identity expansion; Intuitionstic logic; Normalization; Polarized logic; Proof search; Proof terms,Calculations; Differentiation (calculus); Expansion; Focusing; Formal logic; Cut admissibility; Intuitionstic logic; Normalization; Polarized logic; Proof search; Proof terms; Computer circuits
A certified reduction strategy for homological image processing,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907581196&doi=10.1145%2f2630789&partnerID=40&md5=21b22fb8cc6160e4fe2475771c642525,"The analysis of digital images using homological procedures is an outstanding topic in the area of Computational Algebraic Topology. In this article, we describe a certified reduction strategy to deal with digital images, but one preserving their homological properties. We stress both the advantages of our approach (mainly, the formalization of the mathematics allowing us to verify the correctness of algorithms) and some limitations (related to the performance of the running systems inside proof assistants). The drawbacks are overcome using techniques that provide an integration of computation and deduction. Our driving application is a problem in bioinformatics, where the accuracy and reliability of computations are specially requested. © 2014 ACM.",Biomedical images; Computational algebraic topology; Coq; Formalization of mathematics; Homology; SSReflect,Algebra; Image processing; Theorem proving; Biomedical images; Computational algebraic topology; Digital image; Homology; Proof assistant; Reduction strategy; Running systems; Ssreflect; Topology
A cookbook for temporal conceptual data modelling with description logics,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907587294&doi=10.1145%2f2629565&partnerID=40&md5=42bfdee39c615fb62c02001dfb912f32,"We design temporal description logics (TDLs) suitable for reasoning about temporal conceptual data models and investigate their computational complexity. Our formalisms are based on DL-Lite logics with three types of concept inclusions (ranging from atomic concept inclusions and disjointness to the full Booleans), as well as cardinality constraints and role inclusions. The logics are interpreted over the Cartesian products of object domains and the flow of time (Z,>), satisfying the constant domain assumption. Concept and role inclusions of the TBox hold at all moments of time (globally), and data assertions of the ABox hold at specified moments of time. To express temporal constraints of conceptual data models, the languages are equipped with flexible and rigid roles, standard future and past temporal operators on concepts, and operators ""always"" and ""sometime"" on roles. The most expressive of our TDLs (which can capture lifespan cardinalities and either qualitative or quantitative evolution constraints) turns out to be undecidable. However, by omitting some of the temporal operators on concepts/roles or by restricting the form of concept inclusions, we construct logics whose complexity ranges between NLOGSPACE and PSPACE. These positive results are obtained by reduction to various clausal fragments of propositional temporal logic, which opens a way to employ propositional or first-order temporal provers for reasoning about temporal data models. © 2014 ACM.",Description logic; Temporal conceptual data model,Computer circuits; Formal languages; Cardinality constraints; Cartesian Products; Conceptual data modeling; Conceptual data models; Description logic; Temporal constraints; Temporal data models; Temporal operators; Data description
Model-checking linear-time properties of quantum systems,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907587265&doi=10.1145%2f2629680&partnerID=40&md5=a7083097f2060da6a47d550d481ae008,"We define a formal framework for reasoning about linear-time properties of quantum systems in which quantum automata are employed in the modeling of systems and certain (closed) subspaces of state Hilbert spaces are used as the atomic propositions about the behavior of systems. We provide an algorithm for verifying invariants of quantum automata. Then, an automata-based model-checking technique is generalized for the verification of safety properties recognizable by reversible automata and ω?properties recognizable by reversible Büchi automata. © 2014 ACM.",Invariants; Liveness; Model-checking; Persistence properties; Quantum automata; Quantum engineering systems; Safety,Accident prevention; Automata theory; Quantum optics; Quantum theory; Safety engineering; Invariants; Liveness; Persistence properties; Quantum automata; Quantum engineering; Model checking
Super-solutions: Succinctly representing solutions in abductive annotated probabilistic temporal logic,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907582543&doi=10.1145%2f2627354&partnerID=40&md5=814ec85d6f22d95208102726440a03c5,"Annotated Probabilistic Temporal (APT) logic programs are a form of logic programs that allow users to state (or systems to automatically learn) rules of the form ""formula G becomes true δt time units after formula F became true with ℓ to u% probability."" In this article, we deal with abductive reasoning in APT logic: given an APT logic program Pi;, a set of formulas H that can be ""added"" to Π, and a (temporal) goal g, is there a subset S of H such that Pi; ? S is consistent and entails the goal g? In general, there are many different solutions to the problem and some of them can be highly repetitive, differing only in some unimportant temporal aspects. We propose a compact representation called super-solutions that succinctly represent sets of such solutions. Super-solutions are compact, but lossless representations of sets of such solutions. We study the complexity of existence of basic, super-, and maximal super-solutions as well as check if a set is a solution/super-solution/maximal super-solution. We then leverage a geometric characterization of the problem to suggest a set of pruning strategies and interesting properties that can be leveraged to make the search of basic and super-solutions more efficient. We propose correct sequential algorithms to find solutions and super-solutions. In addition, we develop parallel algorithms to find basic and super-solutions. © 2014 ACM.",Abductive reasoning; Imprecise Probabilities; Probabilistic and temporal reasoning,Computer circuits; Geometry; Logic programming; Abductive reasoning; Compact representation; Geometric characterization; Imprecise probabilities; Probabilistic temporal logic; Pruning strategy; Sequential algorithm; Temporal reasoning; Probabilistic logics
LoCo-A logic for configuration problems,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907578845&doi=10.1145%2f2629454&partnerID=40&md5=9e0dc6cc06039e6e657d30f8d9427a83,"In this work, we present LoCo, a fragment of classical first-order logic carefully tailored for expressing technical product configuration problems. The core feature of LoCo is that the number of components used in configurations does not have to be finitely bounded explicitly, but instead is bounded implicitly through the axioms. Computing configurations is equivalent to the task ofmodel finding.We present the language, related algorithms, and complexity results as well as a prototypical implementation via answer set programming. © 2014 ACM.",Model-based reasoning; Technical product configuration,Computational complexity; Formal logic; Logic programming; Answer set programming; Complexity results; First order logic; Model-based Reasoning; Number of components; Prototypical implementation; Related algorithms; Technical products; Computer circuits
Using tableau to decide description logics with full role negation and identity,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897727730&doi=10.1145%2f2559947&partnerID=40&md5=7b718b86e01bab161e3675edf55c8989,"This article presents a tableau approach for deciding expressive description logics with full role negation and role identity. We consider the description logic ALBOid, which is ALC extended with the Boolean role operators, inverse of roles, the identity role, and includes full support for individuals and singleton concepts. ALBOid is expressively equivalent to the two-variable fragment of first-order logic with equality and subsumes Boolean modal logic. In this article, we define a sound, complete, and terminating tableau calculus for ALBOid that provides the basis for decision procedures for this logic and all its sublogics. An important novelty of our approach is the use of a generic unrestricted blocking mechanism. Unrestricted blocking is based on equality reasoning and a conceptually simple rule, which performs case distinctions over the identity of individuals. The blocking mechanism ties the proof of termination of tableau derivations to the finite model property of ALBOid. © 2014 ACM.",Blocking; Boolean modal logic; Completeness; Complexity; Decidability; Description logic; Identity role; Role negation; Tableau-based reasoning,Case based reasoning; Computability and decidability; Formal languages; Blocking; Completeness; Complexity; Description logic; Identity role; Modal logic; Role negation; Tableau-based reasoning; Data description
A PSPACE-Complete first-order fragment of computability logic,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897678425&doi=10.1145%2f2559949&partnerID=40&md5=5c01ea663d735674da14f69325fe93c3,"In a recently launched research program for developing logic as a formal theory of (interactive) computability, several very interesting logics have been introduced and axiomatized. These fragments of the larger Computability Logic aim not only to describe what can be computed, but also provide a mechanism for extracting computational algorithms from proofs. Among the most expressive and fundamental of these is CL4, known to be (constructively) sound and complete with respect to the underlying computational semantics. Furthermore, the ?, ?-free fragment of CL4 was shown to be decidable in polynomial space. The present work extends this result and proves that this fragment is, in fact, PSPACE-complete. © 2014 ACM.",Computability logic; Computational complexity; Game semantics; Interactive computation,Computational complexity; Computer science; Logic programming; Computability logic; Computational algorithm; Computational semantics; Game semantics; Interactive computation; Polynomial space; Research programs; Sound and complete; Semantics
On the complexity of existential positive queries,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897722741&doi=10.1145%2f2559946&partnerID=40&md5=17cc7c616bc4273fa0bb5e6b11ebb763,"We systematically investigate the complexity of model checking the existential positive fragment of first-order logic. In particular, for a set of existential positive sentences, we consider model checking where the sentence is restricted to fall into the set; a natural question is then to classify which sentence sets are tractable and which are intractable. With respect to fixed-parameter tractability, we give a general theorem that reduces this classification question to the corresponding question for primitive positive logic, for a variety of representations of structures. This general theorem allows us to deduce that an existential positive sentence set having bounded arity is fixed-parameter tractable if and only if each sentence is equivalent to one in bounded-variable logic.We then use the lens of classical complexity to study these fixed-parameter tractable sentence sets. We show that such a set can be NP-complete, and consider the length needed by a translation from sentences in such a set to bounded-variable logic; we prove superpolynomial lower bounds on this length using the theory of compilability, obtaining an interesting type of formula size lower bound. Overall, the tools, concepts, and results of this article set the stage for the future consideration of the complexity of model checking on more expressive logics. © 2014 ACM.",Compilation; First-order logic; Fixed-parameter tractability; Model checking,Computer science; Logic programming; Classification questions; Compilability; Compilation; First order logic; Fixed-parameter tractability; Formula size lower bounds; Lower bounds; NP Complete; Model checking
Improved witnessing and local improvement principles for second-order bounded arithmetic,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897744097&doi=10.1145%2f2559950&partnerID=40&md5=f4582c2f60ca3c5515ad7ddeeb23c8f6,"This article concerns the second-order systems U12 and V1 2 of bounded arithmetic, which have proof-theoretic strengths corresponding to polynomial-space and exponential-time computation. We formulate improved witnessing theorems for these two theories by using S12 as a base theory for proving the correctness of the polynomial-space or exponential-time witnessing functions. We develop the theory of nondeterministic polynomial-space computation, including Savitch's theorem, in U12 . Kolodziejczyk et al. [2011] have introduced local improvement properties to characterize the provably total NP functions of these second-order theories. We show that the strengths of their local improvement principles over U12 and V1 2 depend primarily on the topology of the underlying graph, not the number of rounds in the local improvement games. The theory U12 proves the local improvement principle for linear graphs even without restricting to logarithmically many rounds. The local improvement principle for grid graphs with only logarithmically-many rounds is complete for the provably total NP search problems of V1 2. Related results are obtained for local improvement principles with one improvement round and for local improvement over rectangular grids. © 2014 ACM.",Bounded arithmetic; Local improvement; NP search problems; Polynomial space; Provably total functions; Witnessing,Polynomials; Bounded arithmetic; Local improvement; Polynomial space; Search problem; Witnessing; Topology
Degree lower bounds of tower-type for approximating formulas with parity quantifiers,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897693906&doi=10.1145%2f2559948&partnerID=40&md5=54eea0ed12e2decd601f134db6dba30f,"Kolaitis and Kopparty have shown that for any first-order formula with parity quantifiers over the language of graphs, there is a family of multivariate polynomials of constant-degree that agree with the formula on all but a 2-(n)-fraction of the graphs with n vertices. The proof bounds the degree of the polynomials by a tower of exponentials whose height is the nesting depth of parity quantifiers in the formula. We show that this tower-type dependence is necessary. We build a family of formulas of depth q whose approximating polynomials must have degree bounded from below by a tower of exponentials of height proportional to q. Our proof has two main parts. First, we adapt and extend the results by Kolaitis and Kopparty that describe the joint distribution of the parities of the numbers of copies of small subgraphs in a random graph to the setting of graphs of growing size. Second, we analyze a variant of Karp's graph canonical labeling algorithm and exploit its massive parallelism to get a formula of low depth that defines an almost canonical pre-order on a random graph. © 2014 ACM.",Canonical labeling algorithm; Convergence laws; Gowers uniformity norm; Logic; Parity quantifiers; Random graphs,Algorithms; Towers; Convergence laws; Gowers uniformity norm; Labeling algorithms; Logic; Parity quantifiers; Random graphs; Graph theory
A resolution calculus for the branching-time temporal logic CTL,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897679985&doi=10.1145%2f2529993&partnerID=40&md5=b6aa3273e3b1f466006a7bba406932ad,"The branching-time temporal logic CTL is useful for specifying systems that change over time and involve quantification over possible futures. Here we present a resolution calculus for CTL that involves the translation of formulae to a normal form and the application of a number of resolution rules.We use indices in the normal form to represent particular paths and the application of the resolution rules is restricted dependent on an ordering and selection function to reduce the search space. We show that the translation preserves satisfiability, the calculus is sound, complete, and terminating, and consider the complexity of the calculus. © 2014 ACM.",Automated theorem proving; Resolution; Temporal logic,Optical resolving power; Temporal logic; Theorem proving; Automated theorem proving; Normal form; Satisfiability; Search spaces; Selection function; Calculations
Quantifier-Free interpolation in combinations of equality interpolating theories,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897731579&doi=10.1145%2f2490253&partnerID=40&md5=540c9451180a54cfb8376ab043cba819,"The use of interpolants in verification is gaining more and more importance. Since theories used in applications are usually obtained as (disjoint) combinations of simpler theories, it is important to modularly reuse interpolation algorithms for the component theories. We show that a sufficient and necessary condition to do this for quantifier-free interpolation is that the component theories have the strong (sub-)amalgamation property. Then, we provide an equivalent syntactic characterization and show that such characterization covers most theories commonly employed in verification. Finally, we design a combined quantifier-free interpolation algorithm capable of handling both convex and nonconvex theories; this algorithm subsumes and extends most existing work on combined interpolation. © 2014 ACM.",Combined interpolation; Craig interpolation theorem; Satisfiability modulo theories; Strong amalgamability,Algorithms; Metals; Component theories; Craig interpolation; Interpolants; Interpolation algorithms; Satisfiability modulo Theories; Strong amalgamability; Sufficient and necessary condition; Syntactic characterization; Interpolation
Algebra-Coalgebra duality in brzozowski's minimization algorithm,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897690061&doi=10.1145%2f2490818&partnerID=40&md5=c455cf65b71363ffc8dd38671fc4dcda,"We give a new presentation of Brzozowski's algorithm to minimize finite automata using elementary facts from universal algebra and coalgebra and building on earlier work by Arbib and Manes on a categorical presentation of Kalman duality between reachability and observability. This leads to a simple proof of its correctness and opens the door to further generalizations. Notably, we derive algorithms to obtain minimal language equivalent automata from Moore nondeterministic and weighted automata. © 2014 ACM.",Algebra; Automata; Coalgebra; Duality,Algebra; Algorithms; Automata; Brzozowski's minimization algorithms; Coalgebras; Duality; Minimal languages; Reachability; Universal algebra; Weighted automata; Automata theory
Non-Finite axiomatizability of dynamic topological logic,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897728641&doi=10.1145%2f2489334&partnerID=40&md5=aad347e5ca32050a8b4d140951faa63a,"Dynamic topological logic (DTL) is a polymodal logic designed for reasoning about dynamic topological systems. These are pairs (X, f ), where X is a topological space and f : X ? X is continuous. DTL uses a language L which combines the topological S4 modality ( with temporal operators from linear temporal logic. Recently, we gave a sound and complete axiomatization DTL for an extension of the logic to the language L, where ) is allowed to act on finite sets of formulas and is interpreted as a tangled closure operator. No complete axiomatization is known in the language L, although one proof system, which we shall call KM, was conjectured to be complete by Kremer and Mints. In this article, we show that given any language L' such that L L' L, the set of valid formulas of L' is not finitely axiomatizable. It follows, in particular, that KM is incomplete. © 2014 ACM.",Dynamical systems; Spatial reasoning; Temporal logic; Theory complexity,Dynamical systems; Temporal logic; Complete axiomatizations; Dynamic topological logic; Linear temporal logic; Spatial reasoning; Temporal operators; Theory complexity; Topological spaces; Topological systems; Topology
Extending two-variable logic on data trees with order on data values and its automata,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897706379&doi=10.1145%2f2559945&partnerID=40&md5=1855e6f093b0af0f32c9e1490a84ca43,"Data trees are trees in which each node, besides carrying a label from a finite alphabet, also carries a data value from an infinite domain. They have been used as an abstraction model for reasoning tasks on XML and verification. However, most existing approaches consider the case where only equality test can be performed on the data values. In this article we study data trees in which the data values come from a linearly ordered domain, and in addition to equality test, we can test whether the data value in a node is greater than the one in another node. We introduce an automata model for them which we call ordered-data tree automata (ODTA), provide its logical characterisation, and prove that its non-emptiness problem is decidable in 3-NEXPTIME. We also show that the two-variable logic on unranked data trees, studied by Bojanczyk et al. [2009], corresponds precisely to a special subclass of this automata model. Then we define a slightly weaker version of ODTA, which we call weak ODTA, and provide its logical characterisation. The complexity of the non-emptiness problem drops to NP. However, a number of existing formalisms and models studied in the literature can be captured already by weak ODTA. We also show that the definition of ODTA can be easily modified, to the case where the data values come from a tree-like partially ordered domain, such as strings. © 2014 ACM.",Data trees; Finite-state automata; Ordered data values; Two-variable logic,Algorithms; Data Bases; Mathematical Models; Problem Solving; Automata theory; Forestry; Abstraction model; Automata models; Data tree; Finite alphabet; Finite-state automata; Infinite domains; Ordered data; Two-variable logic; Trees (mathematics)
Pebble weighted automata and weighted logics,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900304093&doi=10.1145%2f2579819&partnerID=40&md5=1e75d7723ec1993a20fd7fe184a43dde,"We introduce new classes of weighted automata on words. Equipped with pebbles, they go beyond the class of recognizable formal power series: they capture weighted first-order logic enriched with a quantitative version of transitive closure. In contrast to previous work, this calculus allows for unrestricted use of existential and universal quantifications over positions of the input word. We actually consider both two-way and one-way pebble weighted automata. The latter class constrains the head of the automaton to walk left-to-right, resetting it each time a pebble is dropped. Such automata have already been considered in the Boolean setting, in the context of data words. Our main result states that two-way pebble weighted automata, oneway pebble weighted automata, and our weighted logic are expressively equivalent. We also give new logical characterizations of standard recognizable series. © 2014 ACM.",Formal power series; Pebble automata; Quantitative properties; Weighted automata; Weighted logics,Computer science; Logic programming; Formal power series; Pebble automata; Quantitative properties; Weighted automata; Weighted logics; Automata theory
"Safety and liveness, weakness and strength, and the underlying topological relations",2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900309533&doi=10.1145%2f2532440&partnerID=40&md5=fbe2add81362a60e276be4a56ffde63f,"We present a characterization that shows what it means for a formula to be a weak or strong version of another formula. We show that the weak version of a formula is not the same as Alpern and Schneider's safety component, but can be achieved by taking the closure in the Cantor topology over an augmented alphabet in which every formula is satisfiable. The resulting characterization allows us to show that the set of semantically weak formulas is exactly the set of nonpathological safety formulas. Furthermore, we use the characterization to show that the original versions of the IEEE standard temporal logics PSL and SVA are broken, and we show that the source of the problem lies in the semantics of the SERE intersection and fusion operators. Finally, we use the topological characterization to show the internal consistency of the alternative semantics adopted by the latest version of the PSL standard. © 2014 ACM.",Liveness; PSL; Regular expressions; Safety; SVA; Temporal logic; Topology,Accident prevention; Characterization; IEEE Standards; Semantics; Temporal logic; Alternative Semantics; Cantor topology; Fusion operator; Internal consistency; Liveness; Regular expressions; Safety component; Topological relations; Topology
Formalizing negotiations using logic programming,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900323202&doi=10.1145%2f2526270&partnerID=40&md5=5a37979117367afc7a4b52442e0933e1,"The article introduces a logical framework for negotiation among dishonest agents. The framework relies on the use of abductive logic programming as a knowledge representation language for agents to deal with incomplete information and preferences. The article shows how intentionally false or inaccurate information of agents can be encoded in the agents' knowledge bases. Such disinformation can be effectively used in the process of negotiation to have desired outcomes by agents. The negotiation processes are formulated under the answer set semantics of abductive logic programming, and they enable the exploration of various strategies that agents can employ in their negotiation. A preliminary implementation has been developed using the ASP-Prolog platform. © 2014 ACM.",Abductive logic programming; Answer set programming; Dishonesty; Negotiation; Negotiation agent,Knowledge representation; Semantics; Abductive logic programming; Answer set programming; Dishonesty; Negotiation; Negotiation agents; Logic programming
Parity games and propositional proofs,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900319915&doi=10.1145%2f2579822&partnerID=40&md5=747afdeea4d68aaee93f689d59e29b96,"A propositional proof system is weakly automatizable if there is a polynomial time algorithm that separates satisfiable formulas from formulas that have a short refutation in the system, with respect to a given length bound. We show that if the resolution proof system is weakly automatizable, then parity games can be decided in polynomial time. We give simple proofs that the same holds for depth-1 propositional calculus (where resolution has depth 0) with respect to mean payoff and simple stochastic games. We define a new type of combinatorial game and prove that resolution is weakly automatizable if and only if one can separate, by a set decidable in polynomial time, the games in which the first player has a positional winning strategy from the games in which the second player has a positional winning strategy. Our main technique is to show that a suitable weak bounded arithmetic theory proves that both players in a game cannot simultaneously have a winning strategy, and then to translate this proof into propositional form. © 2014 ACM.",Bounded arithmetic; Mean payoff games; Parity games; Resolution; Simple stochastic sames; Weak automatizability,Optical resolving power; Polynomial approximation; Automatizability; Bounded arithmetic; Mean payoff games; Parity games; Simple stochastic; Game theory
Symbolic bisimulation for quantum processes,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900334442&doi=10.1145%2f2579818&partnerID=40&md5=e2762f870e348843678760082869ef9c,"With the previous notions of bisimulation presented in the literature, to check if two quantum processes are bisimilar, we have to instantiate their free quantum variables with arbitrary quantum states, and verify the bisimilarity of the resulting configurations. This makes checking bisimilarity infeasible from an algorithmic point of view, because quantum states constitute a continuum. In this article, we introduce a symbolic operational semantics for quantum processes directly at the quantum operation level, which allows us to describe the bisimulation between quantum processes without resorting to quantum states. We show that the symbolic bisimulation defined here is equivalent to the open bisimulation for quantum processes in previous work, when strong bisimulations are considered. An algorithm for checking symbolic ground bisimilarity is presented. We also give a modal characterisation for quantum bisimilarity based on an extension of Hennessy-Milner logic to quantum processes. © 2014 ACM.",Open bisimulation; Quantum processes; Symbolic bisimulation,Algorithms; Fault tolerance; Arbitrary quantum state; Bisimulations; Hennessy-Milner Logics; Operational semantics; Quantum operations; Quantum process; Symbolic bisimulation; Two-quantum process; Quantum theory
Partial-observation stochastic games: How to win when belief fails,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900338044&doi=10.1145%2f2579821&partnerID=40&md5=27950a2653972048d3dcfda2f7cf2889,"In two-player finite-state stochastic games of partial observation on graphs, in every state of the graph, the players simultaneously choose an action, and their joint actions determine a probability distribution over the successor states. The game is played for infinitely many rounds and thus the players construct an infinite path in the graph. We consider reachability objectives where the first player tries to ensure a target state to be visited almost-surely (i.e., with probability 1) or positively (i.e., with positive probability), no matter the strategy of the second player. We classify such games according to the information and to the power of randomization available to the players. On the basis of information, the game can be one-sided with either (a) player 1, or (b) player 2 having partial observation (and the other player has perfect observation), or two-sided with (c) both players having partial observation. On the basis of randomization, (a) the players may not be allowed to use randomization (pure strategies), or (b) they may choose a probability distribution over actions but the actual random choice is external and not visible to the player (actions invisible), or (c) they may use full randomization. Our main results for pure strategies are as follows: (1) For one-sided games with player 2 having perfect observation we show that (in contrast to full randomized strategies) belief-based (subset-construction based) strategies are not sufficient, and we present an exponential upper bound on memory both for almost-sure and positive winning strategies; we show that the problem of deciding the existence of almost-sure and positive winning strategies for player 1 is EXPTIME-complete and present symbolic algorithms that avoid the explicit exponential construction. (2) For one-sided games with player 1 having perfect observation we show that nonelementarymemory is both necessary and sufficient for both almost-sure and positive winning strategies. (3) We show that for the general (two-sided) case finite-memory strategies are sufficient for both positive and almost-sure winning, and at least nonelementary memory is required. We establish the equivalence of the almost-sure winning problems for pure strategies and for randomized strategies with actions invisible. Our equivalence result exhibit serious flaws in previous results of the literature: we show a nonelementary memory lower bound for almost-sure winning whereas an exponential upper bound was previously claimed. © 2014 ACM.",Memory bounds; Partial-observation games; Positive and almost-sure winning; Reachability and Büchi objectives; Stochastic games; Strategy complexity,Game theory; Probability distributions; Memory bounds; Partial-observation games; Positive and almost-sure winning; Reachability; Stochastic game; Strategy complexity; Random processes
Preferred first-order answer set programs,2014,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900307323&doi=10.1145%2f2579817&partnerID=40&md5=59b289471a1a8e9c9527616f7d413a17,"In this article, we consider the issue of how first-order answer set programs can be extended for handling preference reasoning. To this end, we propose a progression-based preference semantics for first-order answer set programs while explicit preference relations are presented. We study essential properties of the proposed preferred answer set semantics. To understand the expressiveness of preferred first-order answer set programming, we further specify a second-order logic representation which precisely characterizes the progression-based preference semantics. 2014 Copyright held by the Owner/Author.",Answer set programming; First-order nonmonotonic reasoning; Preference; Second-order logic,Logic programming; Semantics; Answer set programming; Answer set semantics; First-order; Non-monotonic reasoning; Preference; Preference reasoning; Preference relation; Second-order logic; Knowledge representation
Constraint satisfaction tractability from semi-Lattice operations on infinite sets,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890699533&doi=10.1145%2f2528933&partnerID=40&md5=7ab6ddbce7a5e9cc0109e601ed442cd7,"A famous result by Jeavons, Cohen, and Gyssens shows that every Constraint Satisfaction Problem (CSP) where the constraints are preserved by a semi-lattice operation can be solved in polynomial time. This is one of the basic facts for the so-called universal algebraic approach to a systematic theory of tractability and hardness in finite domain constraint satisfaction. Not surprisingly, the theorem of Jeavons et al. fails for arbitrary infinite domain CSPs. Many CSPs of practical interest, though, and in particular those CSPs that are motivated by qualitative reasoning calculi from artificial intelligence, can be formulated with constraint languages that are rather well-behaved from amodel-theoretic point of view. In particular, the automorphism group of these constraint languages tends to be large in the sense that the number of orbits of n-subsets of the automorphism group is bounded by some function in n. In this article we present a generalization of the theorem by Jeavons et al. to infinite domain CSPs where the number of orbits of n-subsets grows subexponentially in n, and prove that preservation under a semilattice operation for such CSPs implies polynomial-time tractability. Unlike the result of Jeavons et al., this includes CSPs that cannot be solved by Datalog. ©2013 ACM 1529-3785/2013/11-ART33 $15.00.",ω-categoricity; Computational complexity; Constraint satisfaction problems; Semi-lattice operations,Artificial intelligence; Biomineralization; Computational complexity; Constraint theory; Polynomial approximation; Algebraic approaches; Categoricity; Constraint Satisfaction; Finite domain constraints; Qualitative reasoning; Semi-lattice operations; Semilattice operation; Systematic theories; Constraint satisfaction problems
Least upper bounds on the size of confluence and church-Rosser diagrams in term rewriting and λ-Calculus,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890357288&doi=10.1145%2f2528934&partnerID=40&md5=f13a88c0f32aab5b0eebd0812c1a2a9b,"We study confluence and the Church-Rosser property in term rewriting and λ-calculus with explicit bounds on term sizes and reduction lengths. Given a system R, we are interested in the lengths of the reductions in the smallest valleys t →* s′ *← t′ expressed as a function: -for confluence a function vsR(m, n) where the valleys are for peaks t *← s →* t′ with s of size at most m and the reductions of maximum length n, and -for the Church-Rosser property a function cvsR(m, n) where the valleys are for conversions t ↔* t′ with t and t′ of size at most mand the conversion of maximum length n. For confluent Term Rewriting Systems (TRSs), we prove that vsR is a total computable function, and for linear such systems that cvsR is a total computable function. Conversely, we show that every total computable function is the lower bound on the functions vsR(m, n) and cvsR(m, n) for some TRS R: In particular, we show that for every total computable function φ : N -→ N there is a TRS R with a single term s such that vsR(|s|, n) ≥ φ(n) and cvsR(n, n) ≥ φ(n) for all n. For orthogonal TRSs R we prove that there is a constant k such that: (a) vsR(m, n) is bounded from above by a function exponential in k and (b) cvsR(m, n) is bounded from above by a function in the fourth level of the Grzegorczyk hierarchy. Similarly, for λ-calculus, we show that vsR(m, n) is bounded from above by a function in the fourth level of the Grzegorczyk hierarchy. ©2013 ACM 1529-3785/2013/11-ART33 $15.00.",Church-Rosser property; Confluence; Lambda calculus; Term rewriting; Upper bounds,Calculations; Computational mechanics; Differentiation (calculus); Exponential functions; Landforms; Religious buildings; Church-Rosser property; Confluence; Lambda calculus; Term rewriting; Upper Bound; Orthogonal functions
Three syntactic theories for combinatory graph reduction,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890581503&doi=10.1145%2f2528932&partnerID=40&md5=28b87b23d14df69abf07bf7fe6796b3c,"We present a purely syntactic theory of graph reduction for the canonical combinators S, K, and I, where graph vertices are represented with evaluation contexts and let expressions. We express this first syntactic theory as a storeless reduction semantics of combinatory terms. We then factor out the introduction of let expressions to denote as many graph vertices as possible upfront instead of on demand. The factored terms can be interpreted as term graphs in the sense of Barendregt et al. We express this second syntactic theory, which we prove equivalent to the first, as a storeless reduction semantics of combinatory term graphs. We then recast let bindings as bindings in a global store, thus shifting, in Strachey's words, from denotable entities to storable entities. The store-based terms can still be interpreted as term graphs. We express this third syntactic theory, which we prove equivalent to the second, as a store-based reduction semantics of combinatory term graphs. We then refocus this store-based reduction semantics into a store-based abstract machine. The architecture of this store-based abstract machine coincides with that of Turner's original reduction machine. The three syntactic theories presented here therefore properly account for combinatory graph reduction As We Know It. These three syntactic theories scale to handling the Y combinator. This article therefore illustrates the scientific consensus of theoreticians and implementors about graph reduction: it is the same combinatory elephant. ©2013 ACM 1529-3785/2013/11-ART33 $15.00.",Abstract machines; Continuation-Passing style (CPS); Continuations; CPS transformation; Defunctionalization; Evaluation contexts; Reduction contexts; Reduction semantics; Reduction-based normalization; Reduction-free normalization; Refocusing; Refunctionalization,Abstracting; Graphic methods; Semantics; Syntactics; Abstract machines; Continuation-passing style; Continuations; CPS transformation; Defunctionalizations; Evaluation contexts; Reduction semantics; Reduction-based normalization; Reduction-free normalization; Refocusing; Refunctionalization; Graph theory
Enumeration of monadic second-order queries on trees,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890338687&doi=10.1145%2f2528928&partnerID=40&md5=15b32a22eed484da508da4a19e6f6039,"We consider the enumeration problem of Monadic Second-Order (MSO) queries with first-order free variables over trees. In Bagan [2006] it was shown that this problem is in CONSTANT-DELAYlin. An enumeration problem belongs to CONSTANT-DELAYlin if for an input structure of size n it can be solved by: -an O(n) precomputation phase building an index structure, -followed by a phase enumerating the answers with no repetition and a constant delay between two consecutive outputs. © 2013 ACM 1529-3785/2013/11-ART25 $15.00.",Bounded tree-width; Enumeration; Logic; Monadic second-order,Algorithms; Forestry; Problem Solving; Computer science; Constant delays; Enumeration; Enumeration problems; Index structure; Logic; Pre-computation; Second orders; Tree-width; Forestry
Verification of linear duration properties over continuous-Time markov chains,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890394093&doi=10.1145%2f2528935&partnerID=40&md5=998532784c298d7502d820721a617ceb,"Stochastic modelling and algorithmic verification techniques have been proved useful in analysing and detecting unusual trends in performance and energy usage of systems such as power management controllers and wireless sensor devices.Many important properties are dependent on the cumulated time that the device spends in certain states, possibly intermittently. We study the problem of verifying continuous-time Markov Chains (CTMCs) against Linear Duration Properties (LDP), that is, properties stated as conjunctions of linear constraints over the total duration of time spent in states that satisfy a given property. We identify two classes of LDP properties, Eventuality Duration Properties (EDP) and Invariance Duration Properties (IDP), respectively referring to the reachability of a set of goal states, within a time bound; and the continuous satisfaction of a duration property over an execution path. The central question that we address is how to compute the probability of the set of infinite timed paths of the CTMC that satisfy a given LDP. We present algorithms to approximate these probabilities up to a given precision, stating their complexity and error bounds. The algorithms mainly employ an adaptation of uniformisation and the computation of volumes of multidimensional integrals under systems of linear constraints, together with different mechanisms to bound the errors. ©2013 ACM 1529-3785/2013/11-ART33 $15.00.",Continuous-time Markov chains; Linear duration properties; Markovian reward models; Model checking,Error analysis; Markov processes; Model checking; Algorithmic verification; Continuous time Markov chain; Different mechanisms; Linear constraints; Linear duration; Markovian; Multidimensional integral; Power managements; Algorithms
Logical relations for a logical framework,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890379779&doi=10.1145%2f2536740.2536741&partnerID=40&md5=479b365a55cd33c827af19812455d79e,"Logical relations are a central concept used to study various higher-order type theories and occur frequently in the proofs of a wide variety of meta-theorems. Besides extending the logical relation principle to more general languages, an important research question has been how to represent and thus verify logical relation arguments in logical frameworks. We formulate a theory of logical relations for Dependent Type Theory (DTT) with β η-equality which guarantees that any valid logical relation satisfies the Basic Lemma. Our definition is syntactic and reflective in the sense that a relation at a type is represented as a DTT type family but also permits expressing certain semantic definitions. We use the Edinburgh Logical Framework (LF) incarnation of DTT and implement our notion of logical relations in the type-checker Twelf. This enables us to formalize and mechanically decide the validity of logical relation arguments. Furthermore, our implementation includes a module system so that logical relations can be built modularly. We validate our approach by formalizing and verifying several syntactic and semantic meta-theorems in Twelf. Moreover, we show how object languages encoded in DTT can inherit a notion of logical relation from the logical framework. ©2013 ACM 1529-3785/2013/11- ART33 $15.00.",Dependent type theory; LF; Logical framework; Logical relation; Module system; Parametricity; Twelf,Semantics; Syntactics; Dependent type theory; LF; Logical frameworks; Logical relations; Module systems; Parametricity; Twelf; Formal languages
Logical foundations for more expressive declarative temporal logic programming languages,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890338108&doi=10.1145%2f2528931&partnerID=40&md5=3bf80038156ab6bd4865deabd49b74ff,"In this article, we present a declarative propositional temporal logic programming language called TeDiLog that is a combination of the temporal and disjunctive paradigms in logic programming. TeDiLog is, syntactically, a sublanguage of the well-known Propositional Linear-time Temporal Logic (PLTL). TeDiLog allows both eventualities and always-formulas to occur in clause heads and also in clause bodies. To the best of our knowledge, TeDiLog is the first declarative temporal logic programming language that achieves this high degree of expressiveness. We establish the logical foundations of our proposal by formally defining operational and logical semantics for TeDiLog and by proving their equivalence. The operational semantics of TeDiLog relies on a restriction of the invariant-free temporal resolution procedure for PLTL that was introduced by Gaintzarain et al. in [2013].We define a fixpoint semantics that captures the reverse (bottom-up) operational mechanism and prove its equivalence with the logical semantics. We also provide illustrative examples and comparison with other proposals. ©2013 ACM 1529-3785/2013/11-ART33 $15.00.",Disjunctive logic programming; Invariant-free clausal temporal resolution; Linear-time temporal logic; Operational and logical semantics; Refutation procedure; Temporal logic programming,Computer programming languages; Semantics; Temporal logic; Disjunctive logic programming; Linear time temporal logic; Logical semantics; Refutation procedure; Temporal resolution; Logic programming
Computing persistent homology within coq/ssreflect,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890420418&doi=10.1145%2f2528929&partnerID=40&md5=d9f303cc088d463803f75ed32b967c14,"Persistent homology is one of the most active branches of computational algebraic topology with applications in several contexts such as optical character recognition or analysis of point cloud data. In this article, we report on the formal development of certified programs to compute persistent Betti numbers, an instrumental tool of persistent homology, using the COQ proof assistant together with the SSREFLECT extension. To this aim it has been necessary to formalize the underlying mathematical theory of these algorithms. This is another example showing that interactive theorem provers have reached a point where they are mature enough to tackle the formalization of nontrivial mathematical theories. © 2013 ACM 1529-3785/2013/11-ART25 $15.00.",Computational algebraic topology; COQ; Formalization of mathematics; Persistent homology; SSREFLECT,Optical character recognition; Theorem proving; Computational algebraic topology; COQ; Coq proof assistant; Instrumental tools; Interactive theorem prover; Mathematical theory; Persistent homology; Ssreflect; Mathematical techniques
A unified semantic framework for fully structural propositional sequent systems,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890337944&doi=10.1145%2f2528930&partnerID=40&md5=637120090ca2f7f3b417560f25459ed0,"We identify a large family of fully structural propositional sequent systems, which we call basic systems. We present a general uniform method for providing (potentially, nondeterministic) strongly sound and complete Kripke-style semantics, which is applicable for every system of this family. In addition, this method can also be applied when: (i) some formulas are not allowed to appear in derivations, (ii) some formulas are not allowed to serve as cut formulas, and (iii) some instances of the identity axiom are not allowed to be used. This naturally leads to new semantic characterizations of analyticity (global subformula property), cut admissibility and axiom expansion in basic systems. We provide a large variety of examples showing that many soundness and completeness theorems for different sequent systems, as well as analyticity, cut admissibility, and axiom expansion results, easily follow using the general method of this article. © 2013 ACM 1529-3785/2013/11-ART27 $15.00.",Analyticity; Axiom expansion; Cut admissibility; Kripke semantics; Logic; Nondeterministic semantics; Proof theory; Semantic characterization; Sequent calculi,Differentiation (calculus); Signal theory; Analyticity; Cut admissibility; Kripke semantics; Logic; Proof theory; Semantic characterizations; Sequent calculus; Semantics
"Algebra, proof theory and applications for an intuitionistic logic of propositions, actions and adjoint modal operators",2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886377175&doi=10.1145%2f2536740.2536742&partnerID=40&md5=5e58505eff9a29f865e2e5dd3244bcd7,"We develop a cut-free nested sequent calculus as basis for a proof search procedure for an intuitionistic modal logic of actions and propositions. The actions act on propositions via a dynamic modality (the weakest precondition of program logics), whose left adjoint we refer to as ""update"" (the strongest postcondition). The logic has agent-indexed adjoint pairs of epistemic modalities: the left adjoints encode agents' uncertainties and the right adjoints encode their beliefs. The rules for the ""update"" modality encode learning as a result of discarding uncertainty. We prove admissibility of Cut, and hence the soundness and completeness of the logic with respect to an algebraic semantics. We interpret the logic on epistemic scenarios that consist of honest and dishonest communication actions, add assumption rules to encode them, and prove that the calculus with the assumption rules still has the admissibility results. We apply the calculus to encode (and allow reasoning about) the classic epistemic puzzles of dirty children (a.k.a. ""muddy children"") and drinking logicians and some versions with dishonesty or noise; we also give an application where the actions are movements of a robot rather than announcements. © 2013 ACM 1529-3785/2013/11-ART34 $15.00.",Adjoint modalities; Algebra; Cut admissibility; Decision procedures; Epistemic scenarios; Logics for multi-agent systems; Proof theory,Algebra; Calculations; Decision theory; Differentiation (calculus); Formal logic; Multi agent systems; Adjoints; Cut admissibility; Decision procedure; Epistemic scenarios; Proof theory; Encoding (symbols)
Propositional update operators based on formula/literal dependence,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883642241&doi=10.1145%2f2499937.2499945&partnerID=40&md5=e95f52156d1f8e15e7e8e1ebe53b712b,"We present and study a general family of belief update operators in a propositional setting. Its operators are based on formula/literal dependence, which is more fine-grained than the notion of formula/variable dependence that was proposed in the literature: formula/variable dependence is a particular case of formula/ literal dependence. Our update operators are defined according to the ""forget-then-conjoin"" scheme: updating a belief base by an input formula consists in first forgetting in the base every literal on which the input formula has a negative influence, and then conjoining the resulting base with the input formula. The operators of our family differ by the underlying notion of formula/literal dependence, which may be defined syntactically or semantically, and which may or may not exploit further information like known persistent literals and pre-set dependencies. We argue that this allows to handle the frame problem and the ramification problem in a more appropriate way. We evaluate the update operators of our family w.r.t. two important dimensions: the logical dimension, by checking the status of the Katsuno-Mendelzon postulates for update, and the computational dimension, by identifying the complexity of a number of decision problems (including model checking, consistency and inference), both in the general case and in some restricted cases, as well as by studying compactability issues. It follows that several operators of our family are interesting alternatives to previous belief update operators. © 2013 ACM.",Computational complexity; Knowledge representation; Update,Knowledge representation; Model checking; Compactability; Decision problems; Frame problems; Literals; Ramification problems; Update; Update operators; Computational complexity
Does treewidth help in modal satisfiability?,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883627131&doi=10.1145%2f2499937.2499939&partnerID=40&md5=257833d0f30650bde5c7dcb23217e8ad,"Many tractable algorithms for solving the Constraint Satisfaction Problem (CSP) have been developed using the notion of the treewidth of some graph derived from the input CSP instance. In particular, the incidence graph of the CSP instance is one such graph. We introduce the notion of an incidence graph for modal logic formulas in a certain normal form. We investigate the parameterized complexity of modal satisfiability with the modal depth of the formula and the treewidth of the incidence graph as parameters. For various combinations of Euclidean, reflexive, symmetric, and transitive models, we show either that modal satisfiability is Fixed Parameter Tractable (FPT), or that it is W[1]-hard. In particular, modal satisfiability in general models is FPT, while it is W[1]-hard in transitive models. As might be expected, modal satisfiability in transitive and Euclidean models is FPT. © 2013 ACM.",Parameterized complexity; Satisfiability; Treewidth,Computer science; General model; Incidence graphs; Modal logic; Parameterized complexity; Satisfiability; Tractable algorithms; Transitive models; Tree-width; Formal logic
Graph reachability and pebble automata over infinite alphabets,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883625199&doi=10.1145%2f2499937.2499940&partnerID=40&md5=a5d5cdbe8cd1b302475804b086b45255,"Let D denote an infinite alphabet - a set that consists of infinitely many symbols. A word w = a0b0a1b1 ... anbn of even length over D can be viewed as a directed graph Gw whose vertices are the symbols that appear in w, and the edges are (a0, b 0), (a1, b1), . . , (an, b n). For a positive integer m, define a language Rm such that a word w = a0b0 ...anbn ε Rm if and only if there is a path in the graph Gw of length ≤ m from the vertex a0 to the vertex bn. We establish the following hierarchy theorem for pebble automata over infinite alphabet. For every positive integer k, (i) there exists a k-pebble automaton that accepts the language R2k+1; (ii) there is no k-pebble automaton that accepts the language R2k+1-2. Using this fact, we establish the following main results in this article: (a) a strict hierarchy of the pebble automata languages based on the number of pebbles; (b) the separation of monadic second order logic from the pebble automata languages; (c) the separation of one-way deterministic register automata languages from pebble automata languages. © 2013 ACM.",Graph reachability; Infinite alphabets; Pebble automata,C (programming language); Graph theory; Graph G; Infinite alphabets; Monadic second-order logic; Pebble automata; Positive integers; Reachability; Automata theory
Extensional higher-order logic programming,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883632550&doi=10.1145%2f2499937.2499942&partnerID=40&md5=e6f426b3ee2d9169e07c9013896ce41f,"We propose a purely extensional semantics for higher-order logic programming. In this semantics program predicates denote sets of ordered tuples, and two predicates are equal iff they are equal as sets. Moreover, every program has a unique minimum Herbrand model which is the greatest lower bound of all Herbrand models of the program and the least fixed-point of an immediate consequence operator. We also propose an SLD-resolution proof system which is proven sound and complete with respect to the minimum Herbrand model semantics. In other words, we provide a purely extensional theoretical framework for higher-order logic programming which generalizes the familiar theory of classical (first-order) logic programming. © 2013 ACM.",Algebraic lattices; Denotational semantics; Extensionality; Higher-order logic programming,Semantics; Algebraic lattices; Denotational semantics; Extensionality; Herbrand model; Higher-order logic programming; SLD-resolution; Sound and complete; Theoretical framework; Logic programming
Constraint propagation for first-order logic and inductive definitions,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883637964&doi=10.1145%2f2499937.2499938&partnerID=40&md5=c90e4beb5192c2372855c58973a7e163,"In Constraint Programming, constraint propagation is a basic component of constraint satisfaction solvers. Here we study constraint propagation as a basic form of inference in the context of first-order logic (FO) and extensions with inductive definitions (FO(ID)) and aggregates (FO(AGG)). In a first, semantic approach, a theory of propagators and constraint propagation is developed for theories in the context of three-valued interpretations. We present an algorithm with polynomial-time data complexity. We show that constraint propagation in this manner can be represented by a datalog program. In a second, symbolic approach, the semantic algorithm is lifted to a constraint propagation algorithm in symbolic structures, symbolic representations of classes of structures. The third part of the article is an overview of existing and potential applications of constraint propagation for model generation, grounding, interactive search problems, approximate methods for ISO problems, and approximate query answering in incomplete databases. © 2013 ACM.",Aggregates; Constraint propagation; First-order logic; Inductive definitions,Aggregates; Algorithms; Computer programming; Formal logic; Semantics; Approximate query answering; Constraint programming; Constraint propagation; Constraint propagation algorithms; Constraint Satisfaction; First order logic; Inductive definitions; Symbolic representation; Constraint theory
Common knowledge in email exchanges,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883641987&doi=10.1145%2f2499937.2499944&partnerID=40&md5=f2d49ea710c6f31e672e59b94dfea1dd,"We consider a framework in which a group of agents communicates by means of emails, with the possibility of replies, forwards and blind carbon copies (BCC). We study the epistemic consequences of such email exchanges by introducing an appropriate epistemic language and semantics. This allows us to find out what agents learn from the emails they receive and to determine when a group of agents acquires common knowledge of the fact that an email was sent. We also show that in our framework from the epistemic point of view the BCC feature of emails cannot be simulated using messages without BCC recipients. © 2013 ACM.",Common knowledge; Communication; Eemail; Epistemic logic,Communication; Semantics; Blind carbon copies; Common knowledge; Eemail; Epistemic logic; Electronic mail
Parameterized complexity of DPLL search procedures,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879381038&doi=10.1145%2f2499937.2499941&partnerID=40&md5=24c53212ecd4a9aa748c6ea309ef4a8f,"We study the performance of DPLL algorithms on parameterized problems. In particular, we investigate how difficult it is to decide whether small solutions exist for satisfiability and other combinatorial problems. For this purpose we develop a Prover-Delayer game that models the running time of DPLL procedures and we establish an information-theoretic method to obtain lower bounds to the running time of parameterized DPLL procedures. We illustrate this technique by showing lower bounds to the parameterized pigeonhole principle and to the ordering principle. As our main application we study the DPLL procedure for the problem of deciding whether a graph has a small clique. We show that proving the absence of a k-clique requires n(k) steps for a nontrivial distribution of graphs close to the critical threshold. For the restricted case of tree-like Parameterized Resolution, this result answers a question asked by Beyersdorff et al. [2012] of understanding the Resolution complexity of this family of formulas. © 2013 ACM.",Parameterized complexity; Proof complexity; Prover-delayer games; Resolution,Computer science; Optical resolving power; Combinatorial problem; Information-theoretic methods; Parameterized complexity; Parameterized problems; Pigeonhole principle; Proof complexity; Prover-Delayer games; Resolution complexity; Parameterization
On the inference of resource usage upper and lower bounds,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883620006&doi=10.1145%2f2499937.2499943&partnerID=40&md5=3b267818d8228d056e218feb0eddf876,"Cost analysis aims at determining the amount of resources required to run a program in terms of its input data sizes. The most challenging step is to infer the cost of executing the loops in the program. This requires bounding the number of iterations of each loop and finding tight bounds for the cost of each of its iterations. This article presents a novel approach to infer upper and lower bounds from cost relations. These relations are an extended form of standard recurrence equations that can be nondeterministic, contain inexact size constraints and have multiple arguments that increase and/or decrease. We propose novel techniques to automatically transform cost relations into worst-case and best-case deterministic one-argument recurrence relations. The solution of each recursive relation provides a precise upper-bound and lower-bound for executing a corresponding loop in the program. Importantly, since the approach is developed at the level of the cost equations, our techniques are programming language independent. © 2013 ACM.",Lower bounds; Static cost analysis; Upper bounds,Cost accounting; Java programming language; Cost analysis; Lower bounds; Novel techniques; Number of iterations; Recurrence equation; Recurrence relations; Upper and lower bounds; Upper Bound; Costs
First-order logic on higher-order nested pushdown trees,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881444906&doi=10.1145%2f2480759.2480760&partnerID=40&md5=d43a97466d35845ed99feda38289cd63,"We introduce a new hierarchy of higher-order nested pushdown trees generalising Alur et al.'s concept of nested pushdown trees. Nested pushdown trees are useful representations of control flows in the verification of programs with recursive calls of first-order functions. Higher-order nested pushdown trees are expansions of unfoldings of graphs generated by higher-order pushdown systems. Moreover, the class of nested pushdown trees of level n is uniformly first-order interpretable in the class of collapsible pushdown graphs of level n + 1. The relationship between the class of higher-order pushdown graphs and the class of collapsible higher-order pushdown graphs is not very well understood. We hope that the further study of the nested pushdown tree hierarchy leads to a better understanding of these two hierarchies. In this article, we are concerned with the first-order model checking problem on higher-order nested pushdown trees. We show that the first-order model checking on the first two levels of this hierarchy is decidable. Moreover, we obtain an alternating 2-EXPTIME algorithm for the class of nested pushdown trees of level 1. The proof technique involves a pseudo-local analysis of strategies in the Ehrenfeucht-Fraïssé games on two identical copies of a nested pushdown tree. Ordinary locality arguments in the spirit of Gaifman's lemma do not apply here because nested pushdown trees tend to have small diameters. We introduce the notion of relevant ancestors which provide a sufficient description of the FOk-type of each element in a higher-order nested pushdown tree. The local analysis of these ancestors allows us to prove the existence of restricted winning strategies in the Ehrenfeucht- Fraïssé game. These strategies are then used to create a first-order model checking algorithm. © 2013 ACM.",Decidability; Ehrenfeucht- Fraïssé game; First-oder model checking; First-order logic; FO; Higher-order pushdown graph; Higher-order pushdown system; Nested pushdown tree; Pumping lemma,Algorithms; Computation; Decision Making; Forestry; Fuzzy Logic; Algorithms; Computability and decidability; Forestry; Graphic methods; Model checking; Recursive functions; First order logic; FO; Pumping lemma; Pushdown; Pushdown graphs; Pushdown systems; Trees (mathematics)
Using generalized annotated programs to solve social network diffusion optimization problems,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881461006&doi=10.1145%2f2480759.2480762&partnerID=40&md5=5ccd0cd963fbb509703f60867e73f77b,"There has been extensive work in many different fields on how phenomena of interest (e.g., diseases, innovation, product adoption) ""diffuse"" through a social network. As social networks increasingly become a fabric of society, there is a need to make ""optimal"" decisions with respect to an observed model of diffusion. For example, in epidemiology, officials want to find a set of k individuals in a social network which, if treated, would minimize spread of a disease. In marketing, campaign managers try to identify a set of k customers that, if given a free sample, would generate maximal ""buzz"" about the product. In this article, we first show that the well-known Generalized Annotated Program (GAP) paradigm can be used to express many existing diffusion models. We then define a class of problems called Social Network Diffusion Optimization Problems (SNDOPs). SNDOPs have four parts: (i) a diffusion model expressed as a GAP, (ii) an objective function we want to optimize with respect to a given diffusion model, (iii) an integer k > 0 describing resources (e.g., medication) that can be placed at nodes, (iv) a logical condition VC that governs which nodes can have a resource (e.g., only children above the age of 5 can be treated with a given medication). We study the computational complexity of SNDOPs and show both NP-completeness results as well as results on complexity of approximation. We then develop an exact and a heuristic algorithm to solve a large class of SNDOPproblems and show that our GREEDY-SNDOP algorithm achieves the best possible approximation ratio that a polynomial algorithm can achieve (unless P = NP). We conclude with a prototype experimental implementation to solve SNDOPs that looks at a real-world Wikipedia dataset consisting of over 103,000 edges. © 2013 ACM.",Approximation algorithms; Generalized annotated programs; Social network,Approximation algorithms; Diffusion; Heuristic algorithms; Optimization; Polynomial approximation; Social networking (online); Annotated program; Approximation ratios; Network diffusions; Np-completeness; Objective functions; Optimization problems; Polynomial algorithm; Product adoption; Integer programming
A model-theoretic approach to belief change in answer set programming,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881452241&doi=10.1145%2f2480759.2480766&partnerID=40&md5=b5fdc85d745e4760ac505b9a02e4981a,"We address the problem of belief change in (nonmonotonic) logic programming under answer set semantics. Our formal techniques are analogous to those of distance-based belief revision in propositional logic. In particular, we build upon the model theory of logic programs furnished by SE interpretations, where an SE interpretation is a model of a logic program in the same way that a classical interpretation is a model of a propositional formula. Hence we extend techniques from the area of belief revision based on distance between models to belief change in logic programs. We first consider belief revision: for logic programs P and Q, the goal is to determine a program R that corresponds to the revision of P by Q, denoted P * Q. We investigate several operators, including (logic program) expansion and two revision operators based on the distance between the SE models of logic programs. It proves to be the case that expansion is an interesting operator in its own right, unlike in classical belief revision where it is relatively uninteresting. Expansion and revision are shown to satisfy a suite of interesting properties; in particular, our revision operators satisfy all or nearly all of the AGM postulates for revision. We next consider approaches for merging a set of logic programs, P1, ..., Pn. Again, our formal techniques are based on notions of relative distance between the SE models of the logic programs. Two approaches are examined. The first informally selects for each program Pi those models of Pi that vary the least from models of the other programs. The second approach informally selects those models of a program P0 that are closest to the models of programs P1, ..., Pn. In this case, P0 can be thought of as a set of database integrity constraints. We examine these operators with regards to how they satisfy relevant postulate sets. Last, we present encodings for computing the revision as well as the merging of logic programs within the same logic programming framework. This gives rise to a direct implementation of our approach in terms of off-the-shelf answer set solvers. These encodings also reflect the fact that our change operators do not increase the complexity of the base formalism. © 2013 ACM.",Answer set programming; Belief merging; Belief revision; Program encodings; Strong equivalence,Encoding (symbols); Expansion; Formal logic; Merging; Semantics; Answer set programming; Answer set semantics; Belief revision; Database integrity constraints; Encodings; Programming framework; Propositional formulas; Strong equivalence; Logic programming
Topological logics with connectedness over euclidean spaces,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881392932&doi=10.1145%2f2480759.2480765&partnerID=40&md5=a5c09066a35faf6c7d49d3cc060e566b,"We consider the quantifier-free languages, ℬc and ℬco, obtained by augmenting the signature of Boolean algebras with a unary predicate representing, respectively, the property of being connected, and the property of having a connected interior. These languages are interpreted over the regular closed sets of ℝn (n ≥ 2) and, additionally, over the regular closed semilinear sets of ℝn. The resulting logics are examples of formalisms that have recently been proposed in the Artificial Intelligence literature under the rubric Qualitative Spatial Reasoning. We prove that the satisfiability problem for ℬc is undecidable over the regular closed semilinear sets in all dimensions greater than 1, and that the satisfiability problem for ℬc and ℬco is undecidable over both the regular closed sets and the regular closed semilinear sets in the Euclidean plane. However, we also prove that the satisfiability problem for ℬco is NP-complete over the regular closed sets in all dimensions greater than 2, while the corresponding problem for the regular closed semilinear sets is EXPTIME-complete. Our results show, in particular, that spatial reasoning is much harder over Euclidean spaces than over arbitrary topological spaces. © 2013 ACM.",Connectedness; Euclidean spaces; Qualitative spatial reasoning; Topology,Artificial intelligence; Boolean algebra; Formal logic; Geometry; Topology; Connectedness; Euclidean planes; Euclidean spaces; Qualitative spatial reasoning; Satisfiability problems; Spatial reasoning; Topological logic; Topological spaces; C (programming language)
Tableau calculi for logic programs under answer set semantics,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881472070&doi=10.1145%2f2480759.2480767&partnerID=40&md5=6528cad00cdd7cc1832928697cf95d92,"We introduce formal proof systems based on tableau methods for analyzing computations in Answer Set Programming (ASP). Our approach furnishes fine-grained instruments for characterizing operations as well as strategies of ASP solvers. The granularity is detailed enough to capture a variety of propagation and choice methods of algorithms usedfor ASP solving, also incorporating SAT-based and conflict-driven learning approaches to some extent. This provides us with a uniform setting for identifying and comparing fundamental properties of ASP solving approaches. In particular, we investigate their proof complexities and show that the run-times of best-case computations can vary exponentially between different existing ASP solvers. Apart from providing a framework for comparing ASP solving approaches, our characterizations also contribute to their understanding by pinning down the constitutive atomic operations. Furthermore, our framework is flexible enough to integrate new inference patterns, and so to study their relation to existing ones. To this end, we generalize our approach and provide an extensible basis aiming at a modular incorporation of additional language constructs. This is exemplified by augmenting our basic tableau methods with cardinality constraints and disjunctions. © 2013 ACM.",Answer set programming; Proof complexity; Tableau calculi,Algorithms; Biomineralization; Pathology; Semantics; Answer set programming; Answer set semantics; Cardinality constraints; Fundamental properties; Inference patterns; Language constructs; Proof complexity; Tableau calculi; Logic programming
Instantiation schemes for nested theories,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881468219&doi=10.1145%2f2480759.2480763&partnerID=40&md5=216bb980c41554e54ecfa7f36077568c,"This article investigates under which conditions instantiation-based proof procedures can be combined in a nested way, in order to mechanically construct new instantiation procedures for richer theories. Interesting applications in the field of verification are emphasized, particularly for handling extensions of the theory of arrays. © 2013 ACM.",Combination of theories; Instantiation-based proof procedures; Satisfiability modulo theories,Combination of theories; Proof procedures; Satisfiability modulo Theories; Computer science
Fair synthesis for asynchronous distributed systems,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881410824&doi=10.1145%2f2480759.2480761&partnerID=40&md5=f2bc2dd067830814fd5ffe101df56a6b,"We study the synthesis problem in an asynchronous distributed setting: a finite set of processes interact locally with an uncontrollable environment and communicate with each other by sending signals - actions controlled by a sender process and that are immediately received by the target process. The fair synthesis problem is to come up with a local strategy for each process such that the resulting fair behaviors of the system meet a given specification. We consider external specifications satisfying some natural closure properties related to the architecture. We present this new setting for studying the fair synthesis problem for distributed systems, and give decidability results for the subclass of networks where communications happen through a strongly connected graph. We claim that this framework for distributed synthesis is natural, convenient and avoids most of the usual sources of undecidability for the synthesis problem. Hence, it may open the way to a decidable theory of distributed synthesis. © 2013 ACM.",Church's problem; Distributed systems; Semicommutations; Synthesis,Computability and decidability; Specifications; Synthesis (chemical); Asynchronous distributed system; Closure property; Decidable theory; Distributed systems; Local strategies; Semi-commutations; Strongly connected; Synthesis problems; Automata theory
Parallel abductive query answering in probabilistic logic programs,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881464124&doi=10.1145%2f2480759.2480764&partnerID=40&md5=3c49eef705c34afe604780a7b9c77d62,"Action-probabilistic logic programs (ap-programs) are a class of probabilistic logic programs that have been extensively used during the last few years for modeling behaviors of entities. Rules in ap-programs have the form ""If the environment in which entity E operates satisfies certain conditions, then the probability that E will take some action A is between L and U"". Given an ap-program, we are interested in trying to change the environment, subject to some constraints, so that the probability that entity E takes some action (or combination of actions) is maximized. This is called the Basic Abductive Query Answering Problem (BAQA). We first formally define and study the complexity of BAQA, and then go on to provide an exact (exponential time) algorithm to solve it, followed by more efficient algorithms for specific subclasses of the problem. We also develop appropriate heuristics to solve BAQA efficiently. The second problem, called the Cost-based Query Answering (CBQA) problem checks to see if there is some way of achieving a desired action (or set of actions) with a probability exceeding a threshold, given certain costs. We first formally define and study an exact (intractable) approach to CBQA, and then go on to propose a more efficient algorithm for a specific subclass of ap-programs that builds on the results for the basic version of this problem. We also develop the first algorithms for parallel evaluation of CBQA. We conclude with an extensive report on experimental evaluations performed over prototype implementations of the algorithms developed for both BAQA and CBQA, showing that our parallel algorithms work well in practice. © 2013 ACM.",Imprecise probabilities; Probabilistic reasoning,Logic programming; Probabilistic logics; Probability; Experimental evaluation; Imprecise probabilities; Modeling behavior; Parallel evaluation; Probabilistic logic programs; Probabilistic reasoning; Prototype implementations; Query-answering problems; Algorithms
Query-driven procedures for Hybrid MKNF knowledge bases,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881424703&doi=10.1145%2f2480759.2480768&partnerID=40&md5=f9dc81bc3d417bd9f7d3b67c7891cc84,"Hybrid MKNF knowledge bases are one of the most prominent tightly integrated combinations of openworld ontology languages with closed-world (nonmonotonic) rule paradigms. Based on the logic of minimal knowledge and negation as failure (MKNF), the definition of Hybrid MKNF is parametric on the description logic (DL) underlying the ontology language, in the sense that nonmonotonic rules can extend any decidable DL language. Two related semantics have been defined for Hybrid MKNF: one that is based on the Stable Model Semantics for logic programs and one on the Well-Founded Semantics (WFS). Under WFS, the definition of Hybrid MKNF relies on a bottom-up computation that has polynomial data complexity whenever the DL language is tractable. Here we define a general query-driven procedure for Hybrid MKNF that is sound with respect to the stable model-based semantics, and sound and complete with respect to its WFS variant. This procedure is able to answer a slightly restricted form of conjunctive queries, and is based on tabled rule evaluation extended with an external oracle that captures reasoning within the ontology. Such an (abstract) oracle receives as input a query along with knowledge already derived, and replies with a (possibly empty) set of atoms, defined in the rules, whose truth would suffice to prove the initial query. With appropriate assumptions on the complexity of the abstract oracle, the general procedure maintains the data complexity of the WFS for Hybrid MKNF knowledge bases. To illustrate this approach, we provide a concrete oracle for εℒ+, a fragment of the lightweight DL εℒ++. Such an oracle has practical use, as εℒ++ is the language underlying OWL 2 EL, which is part of the W3C recommendations for the Semantic Web, and is tractable for reasoning tasks such as subsumption. We show that query-driven Hybrid MKNF preserves polynomial data complexity when using the εℒ+ oracle and WFS. © 2013 ACM.",Description logics; Hybrid knowledge bases; Ontologies; Rules; Tabling; Tractable fragments; Well-founded semantics,Computability and decidability; Data description; Formal languages; Logic programming; Description logic; Hybrid knowledge; Rules; Tabling; Tractable fragments; Well founded semantics; Ontology
Computing loops with at most one external support rule,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876216036&doi=10.1145%2f2422085.2422088&partnerID=40&md5=a8141534abfed9fef1816a3cc9a63709,"A consequence of a logic program under answer set semantics is one that is true for all answer sets. This article considers using loop formulas to compute some of these consequences in order to increase the efficiency of answer set solvers. Since computing loop formulas are in general intractable, we consider only loops with either no external support or at most one external support, as their loop formulas are either unit or binary clauses. We show that for disjunctive logic programs, loop formulas of loops with no external support can be computed in polynomial time, and that an iterative procedure using unit propagation on these formulas and the program completion computes the well-founded models in the case of normal logic programs and the least fixed point of a simplification operator used by DLV for disjunctive logic programs. For loops with at most one external support, their loop formulas can be computed in polynomial time for normal logic programs, but are NP-hard for disjunctive programs. So for normal logic programs, we have a procedure similar to the iterative one for loops without any external support, but for disjunctive logic programs, we present a polynomial approximation algorithm. All these algorithms have been implemented, and our experiments show that for certain logic programs, the consequences computed by our algorithms can significantly speed up current ASP solvers cmodels, clasp, and DLV. © 2013 ACM 1529-3785/2013/02-ART3 $15.00.",Answer set semantics; Answer set solvers; Disjunctive logic programs; Loop formulas; Normal logic programs; Well-founded semantics,Approximation algorithms; Iterative methods; Polynomial approximation; Semantics; Answer set; Answer set semantics; Disjunctive logic programs; Logic programs; Loop formulas; Well founded semantics; Logic programming
Complexities of horn description logics,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876256506&doi=10.1145%2f2422085.2422087&partnerID=40&md5=7ed47f2e499b0d23e6f5534be956e298,"Description logics (DLs) have become a prominent paradigm for representing knowledge in a variety of application areas, partly due to their ability to achieve a favourable balance between expressivity of the logic and performance of reasoning. Horn description logics are obtained, roughly speaking, by disallowing all forms of disjunctions. They have attracted attention since their (worst-case) data complexities are in general lower than those of their non-Horn counterparts, which makes them attractive for reasoning with large sets of instance data (ABoxes). It is therefore natural to ask whether Horn DLs also provide advantages for schema (TBox) reasoning, that is, whether they also feature lower combined complexities. This article settles this question for a variety of Horn DLs. An example of a tractable Horn logic is the DL underlying the ontology language OWL RL, which we characterize as the Horn fragment of the description logic SROIQ without existential quantifiers. If existential quantifiers are allowed, however, many Horn DLs become intractable. We find that Horn-ALC already has the same worst-case complexity as ALC, that is, ExpTime, but we also identify various DLs for which reasoning is PSPACE-complete. As a side effect, we derive simplified syntactic definitions of Horn DLs for which we exploit suitable normal form transformations. © 2013 ACM 1529-3785/2013/02-ART2 $15.00.",Computational complexity; Description logics; Horn logic,Computational complexity; Formal languages; Application area; Combined complexity; Description logic; Existential quantifiers; Horn logic; Ontology language OWL; PSPACE-complete; Worst-case complexity; Data description
Nondeterministic phase semantics and the undecidability of Boolean BI,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876252429&doi=10.1145%2f2422085.2422091&partnerID=40&md5=7e85b1af4c552de3157d662cbeb8a553,"We solve the open problem of the decidability of Boolean BI logic (BBI), which can be considered the core of separation and spatial logics. For this, we define a complete phase semantics suitable for BBI and characterize it as trivial phase semantics. We deduce an embedding between trivial phase semantics for intuitionistic linear logic (ILL) and Kripke semantics for BBI. We single out the elementary fragment of ILL, which is both undecidable and complete for trivial phase semantics. Thus, we obtain the undecidability of BBI. © 2013 ACM 1529-3785/2013/02-ART6 $15.00.",Boolean BI; Decidability; Linear logic; Minsky machines encoding,Computability and decidability; Linear algebra; Intuitionistic linear logic; Kripke semantics; Linear logic; Phase semantics; Spatial logic; Undecidability; Semantics
Sound and complete axiomatizations of coalgebraic language equivalence,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876218890&doi=10.1145%2f2422085.2422092&partnerID=40&md5=0b3df6b53ed94d2aec9fef9a5b6f1c3e,"Coalgebras provide a uniform framework for studying dynamical systems, including several types of automata. In this article, we make use of the coalgebraic view on systems to investigate, in a uniform way, under which conditions calculi that are sound and complete with respect to behavioral equivalence can be extended to a coarser coalgebraic language equivalence, which arises from a generalized powerset construction that determinizes coalgebras. We show that soundness and completeness are established by proving that expressions modulo axioms of a calculus form the rational fixpoint of the given type functor. Our main result is that the rational fixpoint of the functor FT, where T is a monad describing the branching of the systems (e.g., non-determinism, weights, probability, etc.), has as a quotient the rational fixpoint of the deter-minized type functor F, a lifting of F to the category of T-algebras. We apply our framework to the concrete example of weighted automata, for which we present a new sound and complete calculus for weighted language equivalence. As a special case, we obtain nondeterministic automata in which we recover Rabinovich's sound and complete calculus for language equivalence. © 2013 ACM 1529-3785/2013/02-ART7 $15.00.",Coalgebra; Language; Regular expressions; Trace; Weighted automata,Biomineralization; Calculations; Computer programming languages; Dynamical systems; Equivalence classes; Pattern matching; Coalgebras; Language; Regular expressions; Trace; Weighted automata; Automata theory
Proof nets for Herbrand's theorem,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876204142&doi=10.1145%2f2422085.2422090&partnerID=40&md5=49506c7759b4af65e6408ecb637fcadc,"This article explores Herbrand's theorem as the source of a natural notion of abstract proof object for classical logic, embodying the ""essence"" of a sequent calculus proof. We see how to view a calculus of abstract Herbrand proofs (Herbrand nets) as an analytic proof system with syntactic cut-elimination. Herbrand nets can also be seen as a natural generalization of Miller's expansion tree proofs to a setting including cut. We demonstrate sequentialization of Herbrand nets into a sequent calculus LKH; each net corresponds to an equivalence class of LKH proofs under natural proof transformations. A surprising property of our cut-reduction algorithm is that it is non-confluent despite not supporting the usual examples of non-confluent reduction in classical logic. © 2013 ACM 1529-3785/2013/02- ART5 $15.00.",Classical logic; Cut elimination; Herbrand's theorem; Proof nets,Abstracting; Differentiation (calculus); Equivalence classes; Classical logic; Cut elimination; Herbrand's theorem; Natural generalization; Natural proofs; Proof net; Proof system; Sequent calculus; Number theory
Linear-logic based analysis of constraint handling rules with disjunction,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876241079&doi=10.1145%2f2422085.2422086&partnerID=40&md5=6f17e8f0ecd2d67334df48fbd6864726,"Constraint Handling Rules (CHR) is a declarative rule-based programming language that has cut out its niche over the course of the last 20 years. It generalizes concurrent constraint logic programming to multiple heads, thus closing the gap to multiset transformation systems. Its popular extension CHR with Disjunction (CHR∨) is a multiparadigm declarative programming language that allows embedding of Horn programs with SLD resolution. We analyze the assets and the limitations of the classical declarative semantics of CHR∨ and highlight its natural relationship with linear-logic. We furthermore develop two linear-logic semantics for CHR∨ that differ in the reasoning domain for which they are instrumental.We show their idempotence and their soundness and completeness with respect to the operational semantics. We show how to apply the linear-logic semantics to decide program properties and to reason about operational equivalence of CHR∨ programs. © 2013 ACM.",Constraint handling rules; Linear logic,Logic programming; Semantics; Concurrent constraint; Constraint Handling Rules; Declarative programming language; Declarative semantics; Linear logic; Multiset transformation; Rule-based programming; Soundness and completeness; Computer programming languages
Yapa: A generic tool for computing intruder knowledge,2013,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876221649&doi=10.1145%2f2422085.2422089&partnerID=40&md5=fbd3cfd0db6528fbba4fed4f8eed4d17,"Reasoning about the knowledge of an attacker is a necessary step in many formal analyses of security protocols. In the framework of the applied pi-calculus, as in similar languages based on equational logics, knowledge is typically expressed by two relations: deducibility and static equivalence. Several decision procedures have been proposed for these relations under a variety of equational theories. However, each theory has its particular algorithm, and none has been implemented so far. We provide a generic procedure for deducibility and static equivalence that takes as input any convergent rewrite system. We show that our algorithm covers most of the existing decision procedures for convergent theories. We also provide an efficient implementation and compare it briefly with the tools ProVerif and KiSs. © 2013 ACM 1529-3785/2013/02-ART4 $15.00.",Deduction; Formal proofs; Security protocols; Static equivalence; Verification,Verification; Decision procedure; Deduction; Efficient implementation; Formal proofs; Generic procedures; Particular algorithms; Security protocols; Static equivalence; Computer science
"Translating to Co-B üchi made tight, unified, and useful",2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870165737&doi=10.1145%2f2362355.2362357&partnerID=40&md5=24faa59e2c95d7d34c99a8ffeae002b6,"We solve the longstanding open problems of the blow-up involved in the translations, when possible, of a nondeterministic Büchi word automaton (NBW) to a nondeterministic co-Büchi word automaton (NCW) and to a deterministic co-Büchi word automaton (DCW). For the NBW to NCW translation, the currently known upper bound is 2o(nlog n) and the lower bound is 1.5n. We improve the upper bound to n2n and describe a matching lower bound of 2ω(n). For the NBW to DCW translation, the currently known upper bound is 2o(nlog n). We improve it to 2 o(n), which is asymptotically tight. Both of our upper-bound constructions are based on a simple subset construction, do not involve intermediate automata with richer acceptance conditions, and can be implemented symbolically. We continue and solve the open problems of translating nondeterministic Streett, Rabin, Muller, and parity word automata to NCW and to DCW. Going via an intermediate NBW is not optimal and we describe direct, simple, and asymptotically tight constructions, involving a 2o(n) blow-up. The constructions are variants of the subset construction, providing a unified approach for translating all common classes of automata to NCW and DCW. Beyond the theoretical importance of the results, we point to numerous applications of the new constructions. In particular, they imply a simple subset-construction based translation, when possible, of LTL to deterministic Büchi word automata. © 2012 ACM.",Büchi automata; Co-büchi automata; Formal verification; Model checking; Nondeterminism,Model checking; Acceptance conditions; Blow-up; Formal verifications; Lower bounds; New constructions; Non-determinism; Unified approach; Upper Bound; Upper-bound construction; Word automata; Automata theory
Maps in multiple belief change,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870213619&doi=10.1145%2f2362355.2362358&partnerID=40&md5=de84d3326b4c18a2848de03b979ad20e,"Multiple Belief Change extends the classical AGM framework for Belief Revision introduced by Alchourron, Gardenfors, and Makinson in the early '80s. The extended framework includes epistemic input represented as a (possibly infinite) set of sentences, as opposed to a single sentence assumed in the original framework. The transition from single to multiple epistemic input worked out well for the operation of belief revision. The AGM postulates and the system-of-spheres model were adequately generalized and so was the representation result connecting the two. In the case of belief contraction however, the transition was not as smooth. The generalized postulates for contraction, which were shown to correspond precisely to the generalized partial meet model, failed to match up to the generalized epistemic entrenchment model. The mismatch was fixed with the addition of an extra postulate, called the limit postulate, that relates contraction by multiple epistemic input to a series of contractions by single epistemic input. The new postulate however creates problems on other fronts. First, the limit postulate needs to be mapped into appropriate constraints in the partial meet model. Second, via the Levi and Harper Identities, the new postulate translates into an extra postulate for multiple revision, which in turn needs to be characterized in terms of systems of spheres. Both these open problems are addressed in this article. In addition, the limit postulate is compared with a similar condition in the literature, called (K*F), and is shown to be strictly weaker than it. An interesting aspect of our results is that they reveal a profound connection between rationality in multiple belief change and the notion of an elementary set of possible worlds (closely related to the notion of an elementary class of models from classical logic). © 2012 ACM.",Belief; Knowledge representation; Revision,Computer science; Alchourron; Belief; Belief change; Belief contraction; Belief revision; Classical logic; Possible worlds; Revision; Knowledge representation
A generalized QSQR evaluation method for horn knowledge bases,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870227911&doi=10.1145%2f2362355.2362360&partnerID=40&md5=64eeddb305548d07e11cc0765dde813f,"We generalize the QSQR evaluation method to give the first set-oriented depth-first evaluation method for Horn knowledge bases. The resulting procedure closely simulates SLD-resolution (to take advantages of the goal-directed approach) and highly exploits set-at-a-time tabling. Our generalized QSQR evaluation procedure is sound and complete. It does not use adornments and annotations. To deal with function symbols, our procedure uses iterative deepening search, which iteratively increases term-depth bound for atoms and substitutions occurring in the computation. When the term-depth bound is fixed, our evaluation procedure runs in polynomial time in the size of extensional relations. © 2012 ACM.",Horn knowledge bases; QSQR evaluation method,Polynomial approximation; Depth first; Function symbols; Iterative deepening; Knowledge basis; Polynomial-time; QSQR evaluation method; SLD-resolution; Iterative methods
Hierarchies in dependence logic,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870230642&doi=10.1145%2f2362355.2362359&partnerID=40&md5=636a6cf757743d6d5aa2fedaf047a15d,"We study fragments D(k∀) and D(k-dep) of dependence logic defined either by restricting the number k of universal quantifiers or the width of dependence atoms in formulas. We find the sublogics of existential second-order logic corresponding to these fragments of dependence logic. We also show that, for any fixed signature, the fragments D(k∀) give rise to an infinite hierarchy with respect to expressive power. On the other hand, for the fragments D(k-dep), a hierarchy theorem is otained only in the case the signature is also allowed to vary. For any fixed signature, this question is open and is related to the so-called Spectrum Arity Hierarchy Conjecture. © 2012 ACM.",Dependence logic; Descriptive complexity; Expressibility hierarchies; Team,Dependence logic; Descriptive complexity; Expressibility; Expressive power; Second-order logic; Sublogics; Team; Universal quantifiers; Computer science
Epistemic strategies and games on concurrent processes,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870195931&doi=10.1145%2f2362355.2362356&partnerID=40&md5=8f70dfcb56e83d0018a8770678a79f13,"We develop a game semantics for process algebra with two interacting agents. The purpose of our semantics is to make manifest the role of knowledge and information flow in the interactions between agents and to control the information available to interacting agents. We define games and strategies on process algebras, so that two agents interacting according to their strategies determine the execution of the process, replacing the traditional scheduler. We show that different restrictions on strategies represent different amounts of information being available to a scheduler. We also show that a certain class of strategies corresponds to the syntactic schedulers of Chatzikokolakis and Palamidessi, which were developed to overcome problems with traditional schedulers modelling interaction. The restrictions on these strategies have an explicit epistemic flavour. © 2012 ACM.",Concurrency; Epistemic logic; Game semantics; Probability; Process algebra; Schedulers,Algebra; Probabilistic logics; Probability; Semantics; Concurrency; Epistemic logic; Game semantics; Process algebras; Schedulers; Scheduling
Fuzzy equilibrium logic: Declarative problem solving in continuous domains,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870193384&doi=10.1145%2f2362355.2362361&partnerID=40&md5=2973e7df5bb256268cce38e5e01d73c5,"In this article, we introduce fuzzy equilibrium logic as a generalization of both Pearce equilibrium logic and fuzzy answer set programming. The resulting framework combines the capability of equilibrium logic to declaratively specify search problems, with the capability of fuzzy logics to model continuous domains. We show that our fuzzy equilibrium logic is a proper generalization of both Pearce equilibrium logic and fuzzy answer set programming, and we locate the computational complexity of the main reasoning tasks at the second level of the polynomial hierarchy. We then provide a reduction from the problem of finding fuzzy equilibrium logic models to the problem of solving a particular bilevel mixed integer program (biMIP), allowing us to implement reasoners by reusing existing work from the operations research community. To illustrate the usefulness of our framework from a theoretical perspective, we show that a well-known characterization of strong equivalence in Pearce equilibrium logic generalizes to our setting, yielding a practical method to verify whether two fuzzy answer set programs are strongly equivalent. Finally, to illustrate its application potential, we show how fuzzy equilibrium logic can be used to find strong Nash equilibria, even when players have a continuum of strategies at their disposal. As a second application example, we show how to find abductive explanations from Łukasiewicz logic theories. © 2012 ACM.",Answer set programming; Equilibrium logic; Fuzzy logics; Lukasiewicz logic,Fuzzy logic; Integer programming; Knowledge representation; Logic programming; Operations research; Answer set; Answer set programming; Application examples; Bilevel; Continuous domain; Equilibrium logic; Logic theory; Lukasiewicz logic; Mixed-integer programs; Nash equilibria; Polynomial hierarchies; Practical method; Reasoning tasks; Search problem; Second level; Problem solving
Algorithmic analysis of array-accessing programs,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865985736&doi=10.1145%2f2287718.2287727&partnerID=40&md5=4dd3747ea418bef5027c36f17d0cb457,"For programs whose data variables range over Boolean or finite domains, program verification is decidable, and this forms the basis of recent tools for software model checking. In this article, we consider algorithmic verification of programs that use Boolean variables, and in addition, access a single read-only array whose length is potentially unbounded, and whose elements range over an unbounded data domain. We show that the reachability problem, while undecidable in general, is (1) PSPACE-complete for programs in which the array-accessing for-loops are not nested, (2) decidable for a restricted class of programs with doubly nested loops. The second result establishes connections to automata and logics defining languages over data words. © 2012 ACM 1529-3785/2012/08-ART27.",Algorithmic software verification; Arrays; Automata,Automata theory; Model checking; Algorithmic analysis; Algorithmic verification; Arrays; Automata; Boolean variables; Data domains; Data variables; Finite domains; Nested Loops; Program Verification; Reachability problem; Software model checking; Software verification; Algorithms
Deductive inference for the interiors and exteriors of horn theories,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865962102&doi=10.1145%2f2287718.2287723&partnerID=40&md5=63036d756abd7ffdfe371224dcfb5efc,"In this article, we investigate deductive inference for interiors and exteriors of Horn knowledge bases, where interiors and exteriors were introduced by Makino and Ibaraki [1996] to study stability properties of knowledge bases. We present a linear time algorithm for deduction for interiors and show that deduction is coNP-complete for exteriors. Under model-based representation, we show that the deduction problem for interiors is NP-complete while the one for exteriors is coNP-complete. As for Horn envelopes of exteriors, we show that it is linearly solvable under model-based representation, while it is coNP-complete under formula-based representation. We also discuss polynomially solvable cases for all the intractable problems. © 2012 ACM 1529-3785/2012/08-ART23.",Characteristic set; Deduction; Horn theory; Interior/exterior function; Model-based reasoning; NP-hardness; Propositional logic; Tractability,Stability; Characteristic set; Deduction; Horn theory; Model-based Reasoning; NP-hardness; Propositional logic; Tractability; Formal logic
Calculus of cooperation and game-based reasoning about protocol privacy,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865988432&doi=10.1145%2f2287718.2287722&partnerID=40&md5=c384c9e20f3e8dbddcf12481c72fdca2,"The article introduces a new formal system, the calculus of cooperation, for reasoning about coalitions of players in a certain class of games. The calculus is an extension of the propositional intuitionistic logic that adds a coalition parameter to intuitionistic implication. The system is shown to be sound and complete with respect to a game semantics. One intended application of the calculus of cooperation is the verification of privacy properties in multiparty computation protocols. The article argues that such properties can be established by providing a set of strategies for a non-zero-sum, perfect information game based on the protocol. It concludes with several examples of such verifications formalized in the calculus of cooperation. © 2012 ACM 1529-3785/2012/08-ART22.",Formal Verification; Games; Intuitionistic logic; Multiparty computation; Privacy,Computation theory; Data privacy; Semantics; Formal systems; Formal verifications; Game semantics; Games; Information game; Intuitionistic logic; Multi-party computation protocols; Multiparty computation; Calculations
Well-structured program equivalence is highly undecidable,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865973209&doi=10.1145%2f2287718.2287726&partnerID=40&md5=2c9da1fdb520940b2ce5250b0a159c75,"We show that strict deterministic propositional dynamic logic with intersection is highly undecidable, solving a problem in the Stanford Encyclopedia of Philosophy. In fact we show something quite a bit stronger. We introduce the construction of program equivalence, which returns the value T precisely when two given programs are equivalent on halting computations. We show that virtually any variant of propositional dynamic logic has a Π1/1-hard validity problem if it can express even just the equivalence of well-structured programs with the empty program skip.We also show, in these cases, that the set of propositional statements valid over finite models is not recursively enumerable, so there is not even an axiomatization for finitely valid propositions. © 2012 ACM 1529-3785/2012/08-ART26.",Deterministic propositional dynamic logic; Fixset; Intersection; PDL; Program equivalence; Undecidability,Intersections; Fixset; PDL; Program equivalence; Propositional dynamic logic; Undecidability; Computer science
LTL over description logic axioms,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865969115&doi=10.1145%2f2287718.2287721&partnerID=40&md5=36372f0b5fae258232cc16304032f1e9,"Most of the research on temporalized Description Logics (DLs) has concentrated on the case where temporal operators can be applied to concepts, and sometimes additionally to TBox axioms and ABox assertions. The aim of this article is to study temporalized DLs where temporal operators on TBox axioms and ABox assertions are available, but temporal operators on concepts are not. While the main application of existing temporalized DLs is the representation of conceptual models that explicitly incorporate temporal aspects, the family of DLs studied in this article addresses applications that focus on the temporal evolution of data and of ontologies. Our results show that disallowing temporal operators on concepts can significantly decrease the complexity of reasoning. In particular, reasoning with rigid roles (whose interpretation does not change over time) is typically undecidable without such a syntactic restriction, whereas our logics are decidable in elementary time even in the presence of rigid roles. We analyze the effects on computational complexity of dropping rigid roles, dropping rigid concepts, replacing temporal TBoxes with global ones, and restricting the set of available temporal operators. In this way, we obtain a novel family of temporalized DLs whose complexity ranges from 2-EXPTIME-complete via NEXPTIME-complete to EXPTIME-complete. © 2012 ACM 1529-3785/2012/08-ART21.",Complexity; Description logics; Knowledge representation; Temporal Extensions,Formal languages; Knowledge representation; Complexity; Conceptual model; Description logic; Temporal aspects; Temporal evolution; Temporal extensions; Temporal operators; Data description
Permissive-nominal logic: First-order logic over nominal terms and sets,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865962498&doi=10.1145%2f2287718.2287720&partnerID=40&md5=4540aab7e244fe2894ebe5e3785c9b9e,"Permissive-Nominal Logic (PNL) is an extension of first-order predicate logic in which term-formers can bind names in their arguments. This allows for direct axiomatizations with binders, such as of the λ-binder of the lambda-calculus or the ∀-binder of first-order logic. It also allows us to finitely axiomatize arithmetic, and similarly to axiomatize ""nominal"" datatypes-with-binding. Just like first- and higher-order logic, equality reasoning is not necessary to α-rename. This gives PNL much of the expressive power of higher-order logic, but models and derivations of PNL are first-order in character, and the logic seems to strike a good balance between expressivity and simplicity. © 2012 ACM 1529-3785/2012/08-ART20.",Languages; Theory,Differentiation (calculus); Formal logic; Query languages; Expressive power; First order logic; First-order; Higher order logic; Lambda-calculus; Nominal terms; Predicate logic; Theory; Binders
Graded computation tree logic,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865998050&doi=10.1145%2f2287718.2287725&partnerID=40&md5=979a9e445100638bd3bdafdca82188ea,"In modal logics, graded (world) modalities have been deeply investigated as a useful framework for generalizing standard existential and universal modalities in such a way that they can express statements about a given number of immediately accessible worlds. These modalities have been recently investigated with respect to the μCALCULUS, which have provided succinctness, without affecting the satisfiability of the extended logic, that is, it remains solvable in EXPTIME. A natural question that arises is how logics that allow reasoning about paths could be affected by considering graded path modalities. In this article, we investigate this question in the case of the branching-time temporal logic CTL (GCTL, for short). We prove that, although GCTL is more expressive than CTL, the satisfiability problem for GCTL remains solvable in EXPTIME, even in the case that the graded numbers are coded in binary. This result is obtained by exploiting an automata-theoretic approach, which involves a model of alternating automata with satellites. The satisfiability result turns out to be even more interesting as we show that GCTL is at least exponentially more succinct than graded μCALCULUS. © 2012 ACM 1529-3785/2012/08-ART25.",Branching temporal logics; Gradedmodalities; Satisfiability; Specification,Automata theory; Calculations; Specifications; Alternating automata; Automata-theoretic approach; Computation tree logic; Extended logic; Gradedmodalities; Modal logic; Satisfiability; Satisfiability problems; Temporal logic
The dynamic complexity of formal languages,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865985406&doi=10.1145%2f2287718.2287719&partnerID=40&md5=02aa15d93d84426d9fcf76ad22538e7b,"The article investigates the power of the dynamic complexity classes DYNFO, DYNQF, and DYNPROP over string languages. The latter two classes contain problems that can be maintained using quantifier-free first-order updates, with and without auxiliary functions, respectively. It is shown that the languages maintainable in DYNPROP are exactly the regular languages, even when allowing arbitrary precomputation. This enables lower bounds for DYNPROP and separates DYNPROP from DYNQF and DYNFO. Further, it is shown that any context-free language can be maintained in DYNFO and a number of specific context-free languages, for example all Dyck-languages, are maintainable in DYNQF. Furthermore, the dynamic complexity of regular tree languages is investigated and some results concerning arbitrary structures are obtained: There exist first-order definable properties which are not maintainable in DYNPROP. On the other hand, any existential first-order property can be maintained in DYNQF when allowing precomputation. © 2012 ACM 1529-3785/2012/08-ART19.",Languages; Theory,Computer science; Query languages; Arbitrary structures; Auxiliary functions; Dynamic complexity; First-order; Lower bounds; Pre-computation; Regular tree languages; String languages; Theory; Context free languages
Arithmetic complexity via effective names for random sequences,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865972220&doi=10.1145%2f2287718.2287724&partnerID=40&md5=a21237c97b5d974b70c2d2ce136912ec,"We investigate enumerability properties for classes of sets which permit recursive, lexicographically increasing approximations, or left-r.e. sets. In addition to pinpointing the complexity of left-r.e. Martin-Löf, computably, Schnorr, and Kurtz random sets, weakly 1-generics and their complementary classes, we find that there exist characterizations of the third and fourth levels of the arithmetic hierarchy purely in terms of these notions. More generally, there exists an equivalence between arithmetic complexity and existence of numberings for classes of left-r.e. sets with shift-persistent elements. While some classes (such as Martin- Löf randoms and Kurtz nonrandoms) have left-r.e. numberings, there is no canonical, or acceptable, left-r.e. numbering for any class of left-r.e. randoms. Finally, we note some fundamental differences between left-r.e. numberings for sets and reals. © 2012 ACM 1529-3785/2012/08-ART24.",Arithmetical hierarchy; Computable randomness; Schnorr randomness,Random processes; Arithmetic complexity; Arithmetic hierarchy; Arithmetical hierarchy; Computable randomness; Random sequence; Random set; Schnorr randomness; Equivalence classes
Nominal unification from a higher-order perspective,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860313909&doi=10.1145%2f2159531.2159532&partnerID=40&md5=bd4bf07583e89ec4a1bcd12d0c68c0ce,"Nominal logic is an extension of first-order logic with equality, name-binding, renaming via name-swapping and freshness of names. Contrarily to lambda-terms, in nominal terms, bindable names, called atoms, and instantiable variables are considered as distinct entities. Moreover, atoms are capturable by instantiations, breaking a fundamental principle of the lambda-calculus. Despite these differences, nominal unification can be seen from a higher-order perspective. From this view, we show that nominal unification can be quadratically reduced to a particular fragment of higher-order unification problems: higher-order pattern unification. We also prove that the translation preserves most generality of unifiers. © 2012 ACM 1529-3785/2012/04-ART10 $10.00.",Higher-order pattern unification; Lambda-calculus; Nominal unification,Computer science; First-order logic with equality; Fundamental principles; Higher order; Higher-order unification; Lambda terms; Lambda-calculus; Name-binding; Nominal logic; Nominal terms; Nominal unification; Pattern unification; Differentiation (calculus)
Complexity of data dependence problems for program schemas with concurrency,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860305831&doi=10.1145%2f2159531.2159537&partnerID=40&md5=af73189da53f6503eda607520d45c37a,"The problem of deciding whether one point in a program is data dependent upon another is fundamental to program analysis and has been widely studied. In this article we consider this problem at the abstraction level of program schemas in which computations occur in the Herbrand domain of terms and predicate symbols, which represent arbitrary predicate functions, are allowed. Given a vertex ℓ in the flowchart of a schema S having only equality (variable copying) assignments, and variables v, w, we show that it is PSPACE-hard to decide whether there exists an execution of a program defined by S in which v holds the initial value of w at at least one occurrence of ℓ on the path of execution, with membership in PSPACE holding provided there is a constant upper bound on the arity of any predicate in S. We also consider the 'dual' problem in which v is required to hold the initial value of w at every occurrence of ℓ, for which the analogous results hold. Additionally, the former problem for programs with nondeterministic branching (in effect, free schemas) in which assignments with functions are allowed is proved to be polynomial-time decidable provided a constant upper bound is placed upon the number of occurrences of the concurrency operator in the schemas being considered. This result is promising since many concurrent systems have a relatively small number of threads (concurrent processes), especially when compared with the number of statements they have. © 2012 ACM 1529-3785/2012/04-ART15 $10.00.",Data dependence; Free schemas; Herbrand domain; Program analysis; Program schemas,Abstraction level; Concurrency operators; Concurrent process; Concurrent systems; Data dependence; Data dependent; Herbrand domain; Initial values; Number of threads; Polynomial-time; Predicate functions; Program analysis; Schemas; Upper Bound; Computer science
An implicit characterization of PSPACE,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860267299&doi=10.1145%2f2159531.2159540&partnerID=40&md5=26e289a68965b207ebd849822a1d3885,"We present a type system for an extension of lambda calculus with a conditional construction, named STAB, that characterizes the PSPACE class. This system is obtained by extending STA, a type assignment for lambda-calculus inspired by Lafont's Soft Linear Logic and characterizing the PTIME class. We extend STA by means of a ground type and terms for Booleans and conditional. The key issue in the design of the type system is to manage the contexts in the rule for conditional in an additive way. Thanks to this rule, we are able to program polynomial time Alternating Turing Machines. From the well-known result APTIME = PSPACE, it follows that STA B is complete for PSPACE. Conversely, inspired by the simulation of Alternating Turing machines by means of Deterministic Turing machine, we introduce a call-by-name evaluation machine with two memory devices in order to evaluate programs in polynomial space. As far as we know, this is the first characterization of PSPACE that is based on lambda calculus and light logics. © 2012 ACM 1529-3785/2012/04-ART18 $10.00.",Implicit computational complexity; Linear Logic; Operational semantics; Polynomial space; Type assignment,Computational mechanics; Computer programming languages; Differentiation (calculus); Polynomial approximation; Turing machines; Implicit computational complexity; Linear logic; Operational semantics; Polynomial space; Type assignment; Machinery
Interactive realizers: A new approach to program extraction from nonconstructive proofs,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860306895&doi=10.1145%2f2159531.2159533&partnerID=40&md5=512f6c4868418cb6d0ffcf4fd6ee91f2,"We propose a realizability interpretation of a system for quantier free arithmetic which is equivalent to the fragment of classical arithmetic without nested quantifiers, called here EM 1-arithmetic. We interpret classical proofs as interactive learning strategies, namely as processes going through several stages of knowledge and learning by interacting with the ""nature,"" represented by the standard interpretation of closed atomic formulas, and with each other. We obtain in this way a program extraction method by proof interpretation, which is faithful with respect to proofs, in the sense that it is compositional and that it does not need any translation. © 2012 ACM 1529-3785/2012/04-ART11 $10.00.",Constructive interpretations of classical logic; Learning in the limit; Realizability,Computer science; Classical logic; Interactive learning; Learning in the limit; Program extraction; Realizability; Standard interpretation; Program translators
Simplification rules for Intuitionistic propositional tableaux,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860285935&doi=10.1145%2f2159531.2159536&partnerID=40&md5=099a6ea794f87eee0c3fdd18dbc9687c,"The implementation of a logic requires, besides the definition of a calculus and a decision procedure, the development of techniques to reduce the search space. In this article we introduce some simplification rules for Intuitionistic propositional logic that try to replace a formula with an equi-satisfiable ""simpler"" one with the aim to reduce the search space. Our results are proved via semantical techniques based on Kripke models. We also provide an empirical evaluation of their impact on implementations. © 2012 ACM 1529-3785/2012/04-ART14 $10.00.",Decision procedures; Intuitionistic logic; Simplification rules; Tableau calculi,Biomineralization; Decision procedure; Empirical evaluations; Intuitionistic logic; Kripke model; Propositional logic; Search spaces; Simplification rules; Tableau calculi; Formal logic
On the relative strength of pebbling and resolution,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860287678&doi=10.1145%2f2159531.2159538&partnerID=40&md5=fe6e9edb21d7692d4e5032e21839d597,"The last decade has seen a revival of interest in pebble games in the context of proof complexity. Pebbling has proven to be a useful tool for studying resolution-based proof systems when comparing the strength of different subsystems, showing bounds on proof space, and establishing size-space trade-offs. The typical approach has been to encode the pebble game played on a graph as a CNF formula and then argue that proofs of this formula must inherit (various aspects of) the pebbling properties of the underlying graph. Unfortunately, the reductions used here are not tight. To simulate resolution proofs by pebblings, the full strength of nondeterministic black-white pebbling is needed, whereas resolution is only known to be able to simulate deterministic black pebbling. To obtain strong results, one therefore needs to find specific graph families which either have essentially the same properties for black and black-white pebbling (not at all true in general) or which admit simulations of black-white pebblings in resolution. This article contributes to both these approaches. First, we design a restricted form of black-white pebbling that can be simulated in resolution and show that there are graph families for which such restricted pebblings can be asymptotically better than black pebblings. This proves that, perhaps somewhat unexpectedly, resolution can strictly beat black-only pebbling, and in particular that the space lower bounds on pebbling formulas in Ben-Sasson and Nordström [2008] are tight. Second, we present a versatile parametrized graph family with essentially the same properties for black and black-white pebbling, which gives sharp simultaneous trade-offs for black and black-white pebbling for various parameter settings. Both of our contributions have been instrumental in obtaining the time-space trade-off results for resolution-based proof systems in Ben-Sasson and Nordström [2011]. © 2012 ACM 1529-3785/2012/04-ART16 $10.00.",Pebble games; Pebbling formula; Proof complexity; Resolution; Space; Trade-off,Computer science; Optical resolving power; Pebble game; Pebbling formula; Proof complexity; Space; Trade-off; Economic and social effects
Annotated Probabilistic Temporal logic: Approximate fixpoint implementation,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860278712&doi=10.1145%2f2159531.2159535&partnerID=40&md5=7d2066983df50e4d8ff7be4c3b893577,"Annotated Probabilistic Temporal (APT) logic programs support building applications where we wish to reason about statements of the form ""Formula G becomes true with a probability in the range [L, U] within (or in exactly) At time units after formula F became true."" In this paper, we present a sound, but incomplete fixpoint operator that can be used to check consistency and entailment in APT logic programs. We present the first implementation of APT-logic programs and evaluate both its compute time and convergence on a suite of 23 ground APT-logic programs that were automatically learned from two real-world data sets. In both cases, the APT-logic programs contained up to 1,000 ground rules. In one data set, entailment problems were solved on average in under 0.1 seconds per ground rule, while in the other, it took up to 1.3 seconds per ground rule. Consistency was also checked in a reasonable amount of time. When discussing entailment of APT-logic formulas, convergence of the fixpoint operator refers to (U - L) being below a certain threshold. We show that on virtually all of the 23 automatically generated APT-logic programs, convergence was quick-often in just 2-3 iterations of the fixpoint operator. Thus, our implementation is a practical first step towards checking consistency and entailment in temporal probabilistic logics without independence or Markovian assumptions. © 2012 ACM 1529-3785/2012/04-ART13 $10.00.",Frequency functions; Imprecise probabilities; Probabilistic and temporal reasoning; Threads,Logic programming; Probability density function; Temporal logic; Virtual reality; Automatically generated; Building applications; Data sets; Fixpoints; Imprecise probabilities; Logic programs; Markovian; Probabilistic temporal logic; Real world data; Temporal reasoning; Threads; Time units; Probabilistic logics
Model checking of recursive probabilistic systems,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860308014&doi=10.1145%2f2159531.2159534&partnerID=40&md5=adf8ee5d5786a9c27150bec3fb3b8e2e,"Recursive Markov Chains (RMCs) are a natural abstract model of procedural probabilistic programs and related systems involving recursion and probability. They succinctly define a class of denumerable Markov chains that generalize several other stochastic models, and they are equivalent in a precise sense to probabilistic Pushdown Systems. In this article, we study the problem of model checking an RMC against an ω-regular specification, given in terms of a Büchi automaton or a Linear Temporal Logic (LTL) formula. Namely, given an RMC A and a property, we wish to know the probability that an execution of A satisfies the property. We establish a number of strong upper bounds, as well as lower bounds, both for qualitative problems (is the probability = 1, or = 0?), and for quantitative problems (is the probability ≥ p?, or, approximate the probability to within a desired precision). The complexity upper bounds we obtain for automata and LTL properties are similar, although the algorithms are different. We present algorithms for the qualitative model checking problem that run in polynomial space in the size |A| of the RMC and exponential time in the size of the property (the automaton or the LTL formula). For several classes of RMCs, including single-exit RMCs (a class that encompasses some well-studied stochastic models, for instance, stochastic context-free grammars) the algorithm runs in polynomial time in |A|. For the quantitative model checking problem, we present algorithms that run in polynomial space in the RMC and exponential space in the property. For the class of linearly recursive RMCs we can compute the exact probability in time polynomial in the RMC and exponential in the property. For deterministic automata specifications, all our complexities in the specification come down by one exponential. For lower bounds, we show that the qualitative model checking problem, even for a fixed RMC, is already EXPTIME-complete. On the other hand, even for simple reachability analysis, we know from our prior work that our PSPACE upper bounds in A can not be improved substantially without a breakthrough on a well-known open problem in the complexity of numerical computation. © 2012 ACM 1529-3785/2012/04-ART12 $10.00.",Büchi automata; Markov Chains; Model checking; Probabilistic systems; Pushdown Systems; Recursive systems; Stochastic context-free grammars; Temporal Logic,Algorithms; Automata theory; Context free grammars; Equivalence classes; Markov processes; Polynomial approximation; Probability; Specifications; Temporal logic; Abstract models; Deterministic automata; Exponential time; Linear temporal logic; Lower bounds; LTL formulae; LTL property; Numerical computations; Open problems; Polynomial space; Polynomial-time; Probabilistic programs; Probabilistic pushdown systems; Probabilistic systems; Pushdown systems; Qualitative model; Quantitative model checking; Reachability analysis; Recursions; Recursive markov chains; Related systems; Stochastic context free grammar; Time polynomials; Upper Bound; Model checking
The complexity of reasoning for fragments of autoepistemic logic,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860305809&doi=10.1145%2f2159531.2159539&partnerID=40&md5=e4164dcbac775fbf43362453b824dd8e,"Autoepistemic logic extends propositional logic by the modal operator L. A formula φ that is preceded by an L is said to be ""believed."" The logic was introduced by Moore in 1985 for modeling an ideally rational agent's behavior and reasoning about his own beliefs. In this article we analyze all Boolean fragments of autoepistemic logic with respect to the computational complexity of the three most common decision problems expansion existence, brave reasoning and cautious reasoning. As a second contribution we classify the computational complexity of checking that a given set of formulae characterizes a stable expansion and that of counting the number of stable expansions of a given knowledge base. We improve the best known Δ 2 p-upper bound on the former problem to completeness for the second level of the Boolean hierarchy. To the best of our knowledge, this is the first paper analyzing counting problem for autoepistemic logic. © 2012 ACM 1529-3785/2012/04-ART17 $10.00.",Autoepistemic logic; Complexity; Nonmonotonic reasoning; Post's lattice,Computational complexity; Expansion; Knowledge based systems; Autoepistemic logic; Complexity; Counting problems; Decision problems; Knowledge base; Modal operators; Non-monotonic reasoning; Post's lattice; Propositional logic; Rational agents; Second level; Upper Bound; Formal logic
Decidability of downward XPath,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870166592&doi=10.1145%2f2362355.2362362&partnerID=40&md5=c8e4d9daae9676986654e11b2fa50d82,"We investigate the satisfiability problem for downward-XPath, the fragment of XPath that includes the child and descendant axes, and tests for (in)equality of attributes' values. We prove that this problem is decidable, EXPTIME-complete. These bounds also hold when path expressions allow closure under the Kleene star operator. To obtain these results, we introduce a Downward Data automata model (DD automata) over trees with data, which has a decidable emptiness problem. Satisfiability of downward-XPath can be reduced to the emptiness problem of DD automata and hence its decidability follows. Although downward-XPath does not include any horizontal axis, DD automata are more expressive and can perform some horizontal tests. Thus, we show that the satisfiability remains in EXPTIME even in the presence of the regular constraints expressible by DD automata. However, the same problem in the presence of any regular constraint is known to have a nonprimitive recursive complexity. Finally, we give the exact complexity of the satisfiability problem for several fragments of downward-XPath. © 2012 ACM.",Data tree; Data values; DD automata; Downward data automata; Emptiness; Extensible language; Infinite alphabet; Satisfiability; XML; XPath,Data; Forestry; Mathematics; Trees; Automata theory; Computability and decidability; Forestry; Robots; XML; Data tree; Data values; DD automata; Downward data automata; Emptiness; Extensible languages; Infinite alphabet; Satisfiability; XPath; Trees (mathematics)
Robust vacuity for branching temporal logic,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857186724&doi=10.1145%2f2071368.2071369&partnerID=40&md5=514542973494abbb7e8af63eb9dfea1b,"There is a growing interest in techniques for detecting whether a logic specification is satisfied too easily, or vacuously. For example, the specification ""every request is eventually followed by an acknowledgment"" is satisfied vacuously by a system that never generates any requests. Vacuous satisfaction misleads users of model-checking into thinking that a system is correct. It is a serious problem in practice. There are several existing definitions of vacuity. Originally, Beer et al. [1997] formalized vacuity as in-sensitivity to syntactic perturbation (syntactic vacuity). This formulation captures the intuition of ""vacuity"" when applied to a single occurrence of a subformula. Armoni et al. argued that vacuity must be robust; not affected by semantically invariant changes, such as extending a model with additional atomic propositions. They show that syntactic vacuity is not robust for subformulas of linear temporal logic, and propose an alternative definition; trace vacuity. In this article, we continue this line of research. We show that trace vacuity is not robust for branching time logic. We further refine the notion of vacuity so that it applies uniformly to linear and branching time logic and does not suffer from the common pitfalls of prior definitions. Our new definition, bisimulation vacuity, is a proper and nontrivial extension of both syntactic and trace vacuity. We discuss the complexity of detecting bisimulation vacuity, and identify several practically-relevant subsets of CTL * for which vacuity detection problem is reducible to model-checking. We believe that in most practical applications, bisimulation vacuity provides both the desired theoretical properties and is tractable computationally. © 2012 ACM.",Verification,Model checking; Specifications; Temporal logic; Verification; Atomic propositions; Bisimulations; Branching time; Linear temporal logic; Logic specifications; Subformulas; Vacuity detection; Syntactics
Least and greatest fixed points in linear logic,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857165896&doi=10.1145%2f2071368.2071370&partnerID=40&md5=0ed14a29e232c3ea8fdc77e55d579a27,"The first-order theory of MALL (multiplicative, additive linear logic) over only equalities is a well-structured but weak logic since it cannot capture unbounded (infinite) behavior. Instead of accounting for unbounded behavior via the addition of the exponentials (! and ?), we add least and greatest fixed point operators. The resulting logic, which we call μMALL, satisfies two fundamental proof theoretic properties: we establish weak normalization for it, and we design a focused proof system that we prove complete with respect to the initial system. That second result provides a strong normal form for cut-free proof structures that can be used, for example, to help automate proof search. We show how these foundations can be applied to intuitionistic logic. © 2012 ACM.",Design; Theory; Verification,Design; Verification; Exponentials; First-order theories; Greatest fixed points; Intuitionistic logic; Linear logic; Normal form; Proof search; Proof system; Theory; Computer science
Topological and simplicial models of identity types,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857170576&doi=10.1145%2f2071368.2071371&partnerID=40&md5=58d82e02590789d73a0037c9c82b61ea,"In this paper we construct new categorical models for the identity types of Martin-Löf type theory, in the categories Top of topological spaces and SSet of simplicial sets. We do so building on earlier work of Awodey and Warren [2009], which has suggested that a suitable environment for the interpretation of identity types should be a category equipped with a weak factorization system in the sense of Bousfield-Quillen. It turns out that this is not quite enough for a sound model, due to some subtle coherence issues concerned with stability under substitution; and so our first task is to introduce a slightly richer structure, which we call a homotopy-theoretic model of identity types, and to prove that this is sufficient for a sound interpretation. Now, although both Top and SSet are categories endowed with a weak factorization system - and indeed, an entire Quillen model structure - exhibiting the additional structure required for a homotopy-theoretic model is quite hard to do. However, the categories we are interested in share a number of common features, and abstracting these leads us to introduce the notion of a path object category. This is a relatively simple axiomatic framework, which is nonetheless sufficiently strong to allow the construction of homotopy-theoretic models. Now by exhibiting suitable path object structures on Top and SSet, we endow those categories with the structure of a homotopy-theoretic model and, in this way, obtain the desired topological and simplicial models of identity types. © 2012 ACM.",Theory,Computer science; Additional structures; Axiomatic framework; Categorical model; Common features; Object categories; Object structure; Theory; Topological spaces; Type theory; Weak factorization system; Topology
The complexity of positive first-order logic without equality,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857172803&doi=10.1145%2f2071368.2071373&partnerID=40&md5=eee68435b255c8e5f0a87d057acbeb89,"We study the complexity of evaluating positive equality-free sentences of first-order (FO) logic over a fixed, finite structure B. This may be seen as a natural generalisation of the nonuniform quantified constraint satisfaction problem QCSP(B). We introduce surjective hyper-endomorphisms and use them in proving a Galois connection that characterizes definability in positive equality-free FO. Through an algebraic method, we derive a complete complexity classification for our problems as B ranges over structures of size at most three. Specifically, each problem either is in L, is NP-complete, is co-NP-complete, or is Pspace-complete. © 2012 ACM.",Languages; Theory,Algebra; Query languages; Algebraic method; Definability; Finite structures; First-order logic; Galois connection; Generalisation; NP Complete; Quantified constraint satisfaction problems; Surjective; Theory; Computational complexity
On the expressive power of multiple heads in CHR,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857151069&doi=10.1145%2f2071368.2071374&partnerID=40&md5=c518a35833d6a9128e8c67a5f12ec174,"Constraint Handling Rules (CHR) is a committed-choice declarative language that has been originally designed for writing constraint solvers and is nowadays a general purpose language. CHR programs consist of multiheaded guarded rules which allow to rewrite constraints into simpler ones until a solved form is reached. Many empirical evidences suggest that multiple heads augment the expressive power of the language, however no formal result in this direction has been proved, so far. In the first part of this article we analyze the Turing completeness of CHR with respect to the underlying constraint theory. We prove that if the constraint theory is powerful enough then restricting to single head rules does not affect the Turing completeness of the language. On the other hand, differently from the case of the multiheaded language, the single head CHR language is not Turing powerful when the underlying signature (for the constraint theory) does not contain function symbols. In the second part we prove that, no matter which constraint theory is considered, under some reasonable assumptions it is not possible to encode the CHR language (with multi-headed rules) into a single headed language while preserving the semantics of the programs. We also show that, under some stronger assumptions, considering an increasing number of atoms in the head of a rule augments the expressive power of the language. © 2012 ACM.",Languages; Theory,Atoms; Query languages; Semantics; Constraint Handling Rules; Declarative Languages; Expressive power; Function symbols; General purpose languages; Theory; Turing completeness; Writing constraint; Formal logic
Reachability problems in piecewise FIFO systems,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857151739&doi=10.1145%2f2071368.2071375&partnerID=40&md5=99a3794dee580c9eca9a7a18c0367ca1,"Systems consisting of several finite components that communicate via unbounded perfect FIFO channels (i.e., FIFO systems) arise naturally in modeling distributed systems. Despite well-known difficulties in analyzing such systems, they are of significant interest as they can describe a wide range of communication protocols. In this article, we study the problem of computing the set of reachable states of a FIFO system composed of piecewise components. This problem is closely related to calculating the set of all possible channel contents, that is, the limit language, for each control location. We present an algorithm for calculating the limit language of a system with a single communication channel. For multichannel systems, we show that the limit language is piecewise if the initial language is piecewise. Our construction is not effective in general; however, we provide algorithms for calculating the limit language of a restricted class of multichannel systems in which messages are not passed around in cycles through different channels. We show that the worst case complexity of our algorithms for single-channel and important subclasses of multichannel systems is exponential in the size of the initial content of the channels. © 2012 ACM.",Verification,Computer science; Verification; Distributed systems; FIFO channels; Limit languages; Multichannel system; Piece-wise; Reachability problem; Single-channel; Worst-case complexity; Algorithms
The complexity of proving the discrete jordan curve theorem,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857170873&doi=10.1145%2f2071368.2071377&partnerID=40&md5=c569f100f676f54ca29ca33c32eda937,"The Jordan curve theorem (JCT) states that a simple closed curve divides the plane into exactly two connected regions. We formalize and prove the theorem in the context of grid graphs, under different input settings, in theories of bounded arithmetic that correspond to small complexity classes. The theory V 0(2) (corresponding to AC 0(2)) proves that any set of edges that form disjoint cycles divides the grid into at least two regions. The theory V 0 (corresponding to AC 0) proves that any sequence of edges that form a simple closed curve divides the grid into exactly two regions. As a consequence, the Hex tautologies and the st-connectivity tautologies have polynomial size AC 0(2)-Frege-proofs, which improves results of Buss which only apply to the stronger proof system TC 0-Frege. © 2012 ACM.",Theory,Computer science; Bounded arithmetic; Closed curve; Complexity class; Connected region; Disjoint cycle; Grid graphs; Jordan curve theorem; Polynomial size; Proof system; Theory; Computational complexity
Structural analysis of boolean equation systems,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857175244&doi=10.1145%2f2071368.2071376&partnerID=40&md5=dd392b31ee2d0ba86477f7b8560a895b,"We analyze the problem of solving Boolean equation systems through the use of structure graphs. The latter are obtained through an elegant set of Plotkin-style deduction rules. Our main contribution is that we show that equation systems with bisimilar structure graphs have the same solution. We show that our work conservatively extends earlier work, conducted by Keiren and Willemse, in which dependency graphs were used to analyze a subclass of Boolean equation systems, viz., equation systems in standard recursive form. We illustrate our approach by a small example, demonstrating the effect of simplifying an equation system through minimization of its structure graph. © 2012 ACM.",Theory; Verification,Verification; Boolean equation system; Deduction rule; Dependency graphs; Equation systems; Recursive forms; Theory; Computer science
Succinctness of the complement and intersection of regular expressions,2012,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857186021&doi=10.1145%2f2071368.2071372&partnerID=40&md5=7e3a62a1c0a28c67d2b66950e9c9a3eb,"We study the succinctness of the complement and intersection of regular expressions. In particular, we sho that when constructing a regular expression defining the complement of a given regular expression, a doubl exponential size increase cannot be avoided. Similarly, when constructing a regular expression defining th intersection of a fixed and an arbitrary number of regular expressions, an exponential and double exponen tial size increase, respectively, cannot be avoided. All mentioned lower bounds improve the existing ones b one exponential and are tight in the sense that the target expression can be constructed in the correspond ing time class, that is, exponential or double exponential time. As a by-product, we generalize a theore by Ehrenfeucht and Zeiger stating that there is a class of DFAs which are exponentially more succinct tha regular expressions, to a fixed alphabet. When the given regular expressions are one-unambiguous, as fo instance required by the XML Schema specification, the complement can be computed in polynomial tim whereas the bounds concerning intersection continue to hold. For the subclass of single-occurrence regula expressions, we prove a tight exponential lower bound for intersection. © 2012 ACM.",Languages; Theory,Computer science; Query languages; Arbitrary number; Exponential time; Lower bounds; Regular expressions; Theory; XML schemas; Titanium compounds
Unification and matching on compressed terms,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051938966&doi=10.1145%2f1970398.1970402&partnerID=40&md5=0f33f250ef7a97c21f84359db6526a35,"Term unification plays an important role in many areas of computer science, especially in those related to logic. The universal mechanism of grammar-based compression for terms, in particular the so-called singleton tree grammars (STGAs), have recently drawn considerable attention. Using STGs, terms of exponential size and height can be represented in linear space. Furthermore, the term representation by directed acyclic graphs (dags) can be efficiently simulated. The present article is the result of an investigation on term unification and matching when the terms given as input are represented using different compression mechanisms for terms such as dags and singleton tree grammars. We describe a polynomial time algorithm for context matching with dags, when the number of different context variables is fixed for the problem. For the same problem, NP-completeness is obtained when the terms are represented using the more general formalism of singleton tree grammars. For first-order unification and matching polynomial time algorithms are presented, each of them improving previous results for those problems. © 2011 ACM.",Context matching; Singleton tree grammars; Term unification,Algorithms; Data compression; Polynomial approximation; Compression mechanism; Context matching; Directed acyclic graphs; First-order; Grammar-based compression; Linear spaces; Matching polynomial; Np-completeness; Polynomial-time algorithms; Singleton tree grammars; Term representation; Term unification; Tree grammars; Plant extracts
A system of interaction and structure IV: The exponentials and decomposition,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051942494&doi=10.1145%2f1970398.1970399&partnerID=40&md5=9436b383fa6362316df8bfaade5d537f,"We study a system, called NEL, which is themixed commutative/noncommutative linear logic BV augmented with linear logic's exponentials. Equivalently, NEL is MELL augmented with the noncommutative self-dual connective seq. In this article,we show a basic compositionality property ofNEL,which we call decomposition. This result leads to a cut-elimination theorem, which is proved in the next article of this series. To control the induction measure for the theorem, we rely on a novel technique that extracts from NEL proofs the structure of exponentials, into what we call !-?-Flow-Graphs. © 2011 ACM.",!-?-flow-graphs; Calculus of structures; Cut elimination; Decomposition; Deep inference; Linear logic; Noncommutativity,Calculus of structures; Cut elimination; Deep inference; Flow-graphs; Linear logic; Noncommutativity; Theorem proving
Complexity of conservative constraint satisfaction problems,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051943600&doi=10.1145%2f1970398.1970400&partnerID=40&md5=8cd13fa6cc46719fc71894e11d157629,"In a constraint satisfaction problem (CSP), the aim is to find an assignment of values to a given set of variables, subject to specified constraints. The CSP is known to be NP-complete in general. However, certain restrictions on the form of the allowed constraints can lead to problems solvable in polynomial time. Such restrictions are usually imposed by specifying a constraint language, that is, a set of relations that are allowed to be used as constraints. A principal research direction aims to distinguish those constraint languages that give rise to tractable CSPs from those that do not. We achieve this goal for the important version of the CSP, in which the set of values for each individual variable can be restricted arbitrarily. Restrictions of this type can be studied by considering those constraint languages which contain all possible unary constraints; we call such languages conservative. We completely characterize conservative constraint languages that give rise to polynomial time solvable CSP classes. In particular, this result allows us to obtain a complete description of those (directed) graphs H for which the List H-Coloring problem is solvable in polynomial time. The result, the solving algorithm, and the proofs heavily use the algebraic approach to CSP developed in Jeavons et al. [1997], Jeavons [1998], Bulatov et al. [2005], and Bulatov and Jeavons [2001b, 2003]. © 2011 ACM.",Complexity; Constraint satisfaction problem; Dichotomy theorem; Homomorphism problem,Algebraic approaches; Complexity; Constraint language; Constraint satisfaction problem; Constraint Satisfaction Problems; Dichotomy theorem; Homomorphism problem; NP Complete; Polynomial-time; Research directions; Solving algorithm; Polynomial approximation
Logics for information systems and their dynamic extensions,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051949780&doi=10.1145%2f1970398.1970405&partnerID=40&md5=854df7ab30b6a9939fd8658044135b98,"The article proposes logics for information systems, which provide information about a set of objects regarding a set of attributes. Both ""complete"" and ""incomplete"" information systems are dealt with. The language of these logics contains modal operators, and constants corresponding to attributes and attribute values. Sound and complete deductive systems for these logics are presented, and the problem of decidability is addressed. Furthermore, notions of information and information update are defined, and dynamic extensions of the above logics are presented to accommodate these notions. A set of reduction axioms enables us to obtain a complete axiomatization of the dynamic logics. © 2011 ACM.",Approximation space; Dynamic epistemic logic; Information system; Modal logic; Rough set,Computability and decidability; Approximation spaces; Attribute values; Complete axiomatizations; Deductive systems; Dynamic epistemic logic; Dynamic extension; Dynamic logic; Information updates; Modal logic; Modal operators; Rough set; Information systems
Qualitative concurrent parity games,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051943408&doi=10.1145%2f1970398.1970404&partnerID=40&md5=b630c45a08781fd1928041ff26f8ad8f,"We consider two-player games played on a finite state space for an infinite number of rounds. The games are concurrent: in each round, the two players (player 1 and player 2) choose their moves independently and simultaneously; the current state and the two moves determine the successor state. We consider ω-regular winning conditions specified as parity objectives. Both players are allowed to use randomization when choosing their moves. We study the computation of the limit-winning set of states, consisting of the states where the sup-inf value of the game for player 1 is 1: in other words, a state is limit-winning if player 1 can ensure a probability of winning arbitrarily close to 1.We show that the limit-winning set can be computed in Ο(n 2d+2) time, where n is the size of the game structure and 2d is the number of priorities (or colors). The membership problem of whether a state belongs to the limit-winning set can be decided in NP ∩ coNP. While this complexity is the same as for the simpler class of turn-based parity games, where in each state only one of the two players has a choice of moves, our algorithms are considerably more involved than those for turn-based games. This is because concurrent games do not satisfy two of the most fundamental properties of turn-based parity games. First, in concurrent games limit-winning strategies require randomization; and second, they require infinite memory. © 2011 ACM.",ω-regular objectives; Concurrent games; Games on graphs; Parity objectives; Temporal logics,Concurrent games; Concurrent parity games; Finite state spaces; Fundamental properties; Games on graphs; Infinite memory; Infinite numbers; Membership problem; Parity games; Parity objectives; Two-player games; Winning conditions
Two-variable logic on data words,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051933837&doi=10.1145%2f1970398.1970403&partnerID=40&md5=84097a7e6a44af51e9cb88822d838bd2,"In a data word each position carries a label from a finite alphabet and a data value from some infinite domain. This model has been already considered in the realm of semistructured data, timed automata, and extended temporal logics. This article shows that satisfiability for the two-variable fragment FO 2(∼,<,+1) of first-order logic with data equality test ∼ is decidable over finite and infinite data words. Here +1 and < are the usual successor and order predicates, respectively. The satisfiability problem is shown to be at least as hard as reachability in Petri nets. Several extensions of the logic are considered; some remain decidable while some are undecidable. © 2011 ACM.",Data words; First-order logic; One equivalence relation; Petri net reachability; Two variables,Petri nets; Temporal logic; Data values; Data words; Equivalence relations; Finite alphabet; First-order logic; Infinite domains; Reachability; Satisfiability; Satisfiability problems; Semi structured data; Timed Automata; Two variables; Computability and decidability
Proposition algebra,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956110838&doi=10.1145%2f1929954.1929958&partnerID=40&md5=20e009e20ec4fba23a748c023ec864a3,"Sequential propositional logic deviates from conventional propositional logic by taking into account that during the sequential evaluation of a propositional statement, atomic propositions may yield different Boolean values at repeated occurrences. We introduce ""free valuations"" to capture this dynamics of a propositional statement's environment. The resulting logic is phrased as an equationally specified algebra rather than in the form of proof rules, and is named ""proposition algebra."" It is strictly more general than Boolean algebra to the extent that the classical connectives fail to be expressively complete in the sequential case. The four axioms for free valuation congruence are then combined with other axioms in order define a few more valuation congruences that gradually identify more propositional statements, up to static valuation congruence (which is the setting of conventional propositional logic). Proposition algebra is developed in a fashion similar to the process algebra ACP and the program algebra PGA, via an algebraic specification which has a meaningful initial algebra for which a range of coarser congruences are considered important as well. In addition, infinite objects (i.e., propositional statements, processes and programs respectively) are dealt with by means of an inverse limit construction which allows the transfer of knowledge concerning finite objects to facts about infinite ones while reducing all facts about infinite objects to an infinity of facts about finite ones in return. © 2011 ACM.",Conditional composition; Propositional statement; Reactive valuation; Satisfiability; Sequential connective; Short-circuit evaluation; Side effect,Formal logic; Conditional composition; Propositional statement; Reactive valuation; Satisfiability; Sequential connective; Short-circuit evaluation; Side effect; Boolean algebra
Embedding nonground logic programs into autoepistemic logic for knowledge-base combination,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956085890&doi=10.1145%2f1929954.1929957&partnerID=40&md5=670e35541246bffa4fad4b81c3a6b93a,"In the context of the Semantic Web, several approaches for combining ontologies, given in terms of theories of classical first-order logic and rule bases, have been proposed. They either cast rules into classical logic or limit the interaction between rules and ontologies. Autoepistemic logic (AEL) is an attractive formalism which allows overcoming these limitations by serving as a uniform host language to embed ontologies and nonmonotonic logic programs into it. For the latter, so far only the propositional setting has been considered. In this article, we present three embeddings of normal and three embeddings of disjunctive nonground logic programs under the stable model semantics into first-order AEL. While all embeddings correspond with respect to objective ground atoms, differences arise when considering nonatomic formulas and combinations with first-order theories. We compare the embeddings with respect to stable expansions and autoepistemic consequences, considering the embeddings by themselves, as well as combinations with classical theories. Our results reveal differences and correspondences of the embeddings, and provide useful guidance in the choice of a particular embedding for knowledge combination. © 2011 ACM.",First-order autoepistemic logic; Knowledge combination; Ontologies; Rules; Stable model semantics,Formal logic; Logic programming; Semantic Web; Semantics; User interfaces; Classical logic; Classical theory; Embeddings; First order logic; First-order; First-order theories; Knowledge base; Knowledge combination; Logic programs; Nonmonotonic logic programs; Rule basis; Rules; Stable model semantics; Ontology
Modal abstractions of concurrent behavior,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956111351&doi=10.1145%2f1929954.1929955&partnerID=40&md5=8ee812e3c6652a9213bc0059bbe47a43,"We present an effective algorithm for the automatic construction of finite modal transition systems as abstractions of potentially infinite concurrent processes. Modal transition systems are recognized as valuable abstractions for model checking because they allow for the validation as well as refutation of safety and liveness properties. However, the algorithmic construction of finite abstractions from potentially infinite concurrent processes is a missing link that prevents their more widespread usage for model checking of concurrent systems. Our algorithm is a worklist algorithm using concepts from abstract interpretation and operating upon mappings from sets to intervals in order to express simultaneous over- and underapprox-imations of the multisets of process actions available in a particular state. We obtain a finite abstraction that is 3-valued in both states and transitions and that supports the definition of a 3-valued modal logic for validating as well as refuting properties of systems. The construction is illustrated on a few examples, including the Ingemarsson-Tang-Wong key agreement protocol. © 2011 ACM.",3-valued logic; Abstract interpretation; Abstraction; CCS; Concurrency; Labeled transition systems; Modal transition systems; Monotone frameworks; Over- and underapproximations; Process calculi; Static analysis; Temporal logic,Algorithms; Model checking; Temporal logic; 3-valued logic; Abstract interpretation; Abstraction; CCS; Concurrency; Labeled transition systems; Modal transition systems; Monotone frameworks; Over- and underapproximations; Process calculi; Abstracting
Alternating automata on data trees and XPath satisfiability,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956113932&doi=10.1145%2f1929954.1929956&partnerID=40&md5=420a07ad7200137d42996e5d68b3f3d3,"A data tree is an unranked ordered tree whose every node is labeled by a letter from a finite alphabet and an element (""datum"") from an infinite set, where the latter can only be compared for equality. The article considers alternating automata on data trees that can move downward and rightward, and have one register for storing data. The main results are that nonemptiness over finite data trees is decidable but not primitive recursive, and that nonemptiness of safety automata is decidable but not elementary. The proofs use nondeterministic tree automata with faulty counters. Allowing upward moves, leftward moves, or two registers, each causes undecidability. As corollaries, decidability is obtained for two data-sensitive fragments of the XPath query language. © 2011 ACM.",Algorithms; Verification,Automata theory; Computability and decidability; Plant extracts; Query languages; Alternating automata; Data tree; Finite alphabet; Ordered tree; Satisfiability; Tree automata; Undecidability; Trees (mathematics)
A calculus of multiary sequent terms,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956067809&doi=10.1145%2f1929954.1929959&partnerID=40&md5=cdef83303e35954ff06363e829f0e30b,"Multiary sequent terms were originally introduced as a tool for proving termination of permutative conversions in cut-free sequent calculus. This work develops the language of multiary sequent terms into a term calculus for the computational (Curry-Howard) interpretation of a fragment of sequent calculus with cuts and cut-elimination rules. The system, called generalized multiary λ-calculus, isarich extensionofthe lambda;-calculus where the computational content of the sequent calculus format is explained through an enlarged form of the application constructor. Such constructor exhibits the features of multiarity (the ability to form lists of arguments) and generality (the ability to prescribe a kind of continuation). The system integrates in a modular way the multiary lambda;-calculus and an isomorphic copy of the lambda;-calculus with generalized application, A J (in particular, natural deduction is captured internally up to isomorphism). In addition, the system: (i) comes with permutative conversion rules, whose role is to eliminate the new features of application; (ii) is equipped with reduction rules - either the μ-rule, typical of the multiary setting, or rules for cut-elimination, which enlarge the ordinary β-rule. This article establishes the metatheory of the system, with emphasis on the role of the μ-rule, and including a study of the interaction of reduction and permutative conversions. © 2011 ACM.",Curry-Howard isomorphism; Generalized application; Intuitionistic sequent calculus; Lambda-calculus; Multiary application; Permutative conversions,Differentiation (calculus); Formal logic; Set theory; Curry-Howard isomorphism; Generalized application; Intuitionistic sequent calculus; Lambda-calculus; Multiary application; Permutative conversions; Calculations
"The tractability of model checking for LTL: The good, the bad, and the ugly fragments",2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551675107&doi=10.1145%2f1877714.1877719&partnerID=40&md5=c26cf78ef6d549adbf3d18ba24cfdcf3,"In a seminal paper from 1985, Sistla and Clarke showed that the model-checking problem for Linear Temporal Logic (LTL) is either NP-complete or PSPACE-complete, depending on the set of temporal operators used. If in contrast, the set of propositional operators is restricted, the complexity may decrease. This article systematically studies the model-checking problem for LTL formulae over restricted sets of propositional and temporal operators. For almost all combinations of temporal and propositional operators, we determine whether the model-checking problem is tractable (in P) or intractable (NP-hard). We then focus on the tractable cases, showing that they all are NL-complete or even logspace solvable. This leads to a surprising gap in complexity between tractable and intractable cases. It is worth noting that our analysis covers an infinite set of problems, since there are infinitely many sets of propositional operators.© 2011 ACM.",Computational complexity; Linear Temporal Logic; Model checking; Post's lattice,Computational complexity; Temporal logic; Linear Temporal Logic; Logspace; LTL formulae; Model checking problem; NP Complete; NP-hard; Post's lattice; Temporal operators; Model checking
Monadic second order logic on graphs with local cardinality constraints,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551670282&doi=10.1145%2f1877714.1877718&partnerID=40&md5=23bf048613e2b6ec1c11f940fe3a8f26,"We introduce the class of MSO-LCC problems, which are problems of the following form. Given a graph G and for each vertex ν of G a set α(ν) of non-negative integers. Is there a set S of vertices or edges of G such that, (1) S satisfies a fixed property expressible in monadic second order logic, and (2) for each vertex ν of G the number of vertices/edges in S adjacent/incident with v belongs to the set α(ν)? We demonstrate that several hard combinatorial problems such as Lovász's General Factor Problem can be naturally formulated as MSO-LCC problems. Our main result is the polynomial-time tractability of MSO-LCC problems for graphs of bounded treewidth. We obtain this result by means of a tree-automata approach. By way of contrast we show that a more general class of MSO-LCC problems, where cardinality constraints are applied to second-order variables that are arbitrarily quantified, does not admit polynomial-time tractability for graphs of bounded treewidth unless P = NP.© 2011 ACM.",Cardinality constraint; MSO model checking; NP-hardness; Treewidth; W[1]-hardness,Automata theory; Hardness; Cardinality constraints; MSO model checking; NP-hardness; Treewidth; W[1]-hardness; Model checking
Logic programs with propositional connectives and aggregates,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051953475&doi=10.1145%2f1970398.1970401&partnerID=40&md5=47519d06bc15ffdab2bd350cd6df2da6,"Answer set programming (ASP) is a logic programming paradigm that can be used to solve complex combinatorial search problems. Aggregates are an ASP construct that plays an important role in many applications. Defining a satisfactory semantics of aggregates turned out to be a difficult problem, and in this article we propose a new approach, based on an analogy between aggregates and propositional connectives. First we extend the definition of an answer set/stable model to cover arbitrary propositional theories; then we define aggregates on top of them both as primitive constructs and as abbreviations for formulas. Our definition of an aggregate combines expressiveness and simplicity, and it inherits many theorems about programs with nested expressions, such as theorems about strong equivalence and splitting. © 2011 ACM.",Aggregates; Answer sets; Logic programming; Stable models,Aggregates; Computer circuits; Semantics; Answer set; Answer set programming; Combinatorial search; Logic programs; Nested expressions; New approaches; Propositional theories; Stable model; Logic programming
Safety alternating automata on data words,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551680264&doi=10.1145%2f1877714.1877716&partnerID=40&md5=8a2291f572b30cd4905984f54d0e0cad,"A data word is a sequence of pairs of a letter from a finite alphabet and an element from an infinite set, where the latter can only be compared for equality. Safety one-way alternating automata with one register on infinite data words are considered, their nonemptiness is shown to be EXPSPACE-complete, and their inclusion decidable but not primitive recursive. The same complexity bounds are obtained for satisfiability and refinement, respectively, for the safety fragment of linear temporal logic with freeze quantification. Dropping the safety restriction, adding past temporal operators, or adding one more register, each causes undecidability.© 2011 ACM.",,Automata theory; Computability and decidability; Alternating automata; Complexity bounds; Finite alphabet; Linear temporal logic; Satisfiability; Temporal operators; Undecidability; Temporal logic
MWeb: A principled framework for modular Web rule bases and its semantics,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551675260&doi=10.1145%2f1877714.1877723&partnerID=40&md5=bcaef267a297241efb529a56ad4570ac,"We present a principled framework for modular Web rule bases, called MWeb. According to this framework, each predicate defined in a rule base is characterized by its defining reasoning mode, scope, and exporting rule base list. Each predicate used in a rule base is characterized by its requesting reasoning mode and importing rule base list. For legal MWeb modular rule bases S, the MWebAS and MWebWFS semantics of each rule base s ε S with respect to S are defined model-theoretically. These semantics extend the answer set semantics (AS) and the well-founded semantics with explicit negation (WFSX) on ELPs, respectively, keeping all of their semantical and computational characteristics. Our framework supports: (1) local semantics and different points of view, (2) local closed-world and open-world assumptions, (3) scoped negation-as-failure, (4) restricted propagation of local inconsistencies, and (5) monotonicity of reasoning, for fully shared predicates.© 2011 ACM.",Local closed-world and open-world assumptions; Local semantics; Modular Web rule bases; Scoped negation-as-failure,Semantics; Answer set semantics; Local closed-world and open-world assumptions; Local semantics; Modular Web rule bases; Monotonicity; Negation-as-failure; Rule base; Rule basis; Scoped negation-as-failure; Well-founded semantics with explicit negation; Semantic Web
Logic of infons: The propositional case,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551665938&doi=10.1145%2f1877714.1877715&partnerID=40&md5=620b04d7a0c89281de0aeecfcc902d11,"Infons are statements viewed as containers of information (rather then representations of truth values). The logic of infons turns out to be a conservative extension of logic known as constructive or intuitionistic. Distributed Knowledge Authorization Language uses additional unary connectives ""p said"" and ""p implied"" where p ranges over principals. Here we investigate infon logic and a narrow but useful primal fragment of it. In both cases, we develop model theory and analyze the derivability problem: Does the given query follow from the given hypotheses? Our more involved technical results are on primal infon logic. We construct an algorithm for the multiple derivability problem: Which of the given queries follow from the given hypotheses? Given a bound on the quotation depth of the hypotheses, the algorithm runs in linear time. We quickly discuss the significance of this result for access control.© 2011 ACM.",Access control; Complexity; Derivation problem; Infon; Infon logic; Intuitionistic logic; Linear time; Logic,Algorithms; Query processing; Security systems; Complexity; Derivation problem; Infon; Infon logic; Intuitionistic logic; Linear time; Logic; Access control
Persistent queries in the behavioral theory of algorithms,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551662383&doi=10.1145%2f1877714.1877722&partnerID=40&md5=3685e2a7bcb7d56c676c78ea2ab2583c,"We propose an extension of the behavioral theory of interactive sequential algorithms to deal with the following situation. A query is issued during a certain step, but the step ends before any reply is received. Later, a reply arrives, and later yet the algorithm makes use of this reply. By a persistent query, we mean a query for which a late reply might be used. Our proposal involves issuing, along with a persistent query, a location where a late reply is to be stored. After presenting our proposal in general terms, we discuss the modifications that it requires in the existing axiomatics of interactive sequential algorithms and in the existing syntax and semantics of abstract state machines. To make that discussion self-contained, we include a summary of this material before the modifications. Fortunately, only rather minor modifications are needed.© 2011 ACM.",Abstract state machines; Interactive algorithms; Sequential algorithms; Small-step algorithms; Step-for-step simulation,Abstracting; Contour followers; Semantics; Sequential machines; Sequential switching; Abstract state machines; Interactive algorithms; Sequential algorithms; Small-step algorithms; Step-for-step simulation; Algorithms
Annotated probabilistic temporal logic,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551655427&doi=10.1145%2f1877714.1877720&partnerID=40&md5=6450cf013be90ac8cdf1cb73aff340de,"The semantics of most logics of time and probability is given via a probability distribution over threads, where a thread is a structure specifying what will be true at different points in time (in the future). When assessing the probabilities of statements such as ""Event a will occur within 5 units of time of event b,"" there are many different semantics possible, even when assessing the truth of this statement within a single thread. We introduce the syntax of annotated probabilistic temporal (APT) logic programs and axiomatically introduce the key notion of a frequency function (for the first time) to capture different types of intrathread reasoning, and then provide a semantics for intrathread and interthread reasoning in APT logic programs parameterized by such frequency functions. We develop a comprehensive set of complexity results for consistency checking and entailment in APT logic programs, together with sound and complete algorithms to check consistency and entailment. The basic algorithms use linear programming, but we then show how to substantially and correctly reduce the sizes of these linear programs to yield better computational properties. We describe a real world application we are developing using APT logic programs.© 2011 ACM.",Frequency functions; Imprecise probabilities; Probabilistic and temporal reasoning; Threads,Algorithms; Cantilever beams; Linear programming; Logic programming; Probability distributions; Semantics; Temporal logic; Complexity results; Computational properties; Consistency checking; Event-B; Frequency functions; Imprecise probabilities; Linear programs; Logic programs; Parameterized; Probabilistic and temporal reasoning; Probabilistic temporal logic; Real-world application; Threads; Probabilistic logics
Mechanizing the metatheory of LF,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551665507&doi=10.1145%2f1877714.1877721&partnerID=40&md5=aa2159c051323436f763e67873581431,"LF is a dependent type theory in which many other formal systems can be conveniently embedded. However, correct use of LF relies on nontrivial metatheoretic developments such as proofs of correctness of decision procedures for LF's judgments. Although detailed informal proofs of these properties have been published, they have not been formally verified in a theorem prover. We have formalized these properties within Isabelle/HOL using the Nominal Datatype Package, closely following a recent article by Harper and Pfenning. In the process, we identified and resolved a gap in one of the proofs and a small number of minor lacunae in others. We also formally derive a version of the type checking algorithm from which Isabelle/HOL can generate executable code. Besides its intrinsic interest, our formalization provides a foundation for studying the adequacy of LF encodings, the correctness of Twelf-style metatheoretic reasoning, and the metatheory of extensions to LF.© 2011 ACM.",Logical frameworks; Nominal isabelle; Theorem provers,Embedded systems; Data type; Decision procedure; Dependent type theory; Encodings; Executable codes; Formal systems; Informal proofs; Isabelle/HOl; Logical frameworks; Meta-theory; Nominal isabelle; Theorem provers; Typechecking; Open systems
Well-founded semantics for description logic programs in the Semantic Web,2011,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551655153&doi=10.1145%2f1877714.1877717&partnerID=40&md5=3ea178af95f362da9d2e18dce91ecfe4,"The realization of the Semantic Web vision, in which computational logic has a prominent role, has stimulated a lot of research on combining rules and ontologies, which are formulated in different formalisms. In particular, combining logic programming with the Web Ontology Language (OWL), which is a standard based on description logics, emerged as an important issue for linking the Rules and Ontology Layers of the Semantic Web. Nonmonotonic description logic programs (dl-programs) were introduced for such a combination, in which a pair (L, P) of a description logic knowledge base L and a set of rules P with negation as failure is given a model-based semantics that generalizes the answer set semantics of logic programs. In this article, we reconsider dl-programs and present a well-founded semantics for them as an analog for the other main semantics of logic programs. It generalizes the canonical definition of the well-founded semantics based on unfounded sets, and, as we show, lifts many of the well-known properties from ordinary logic programs to dl-programs. Among these properties, our semantics amounts to a partial model approximating the answer set semantics, which yields for positive and stratified dl-programs, a total model coinciding with the answer set semantics; it has polynomial data complexity provided the access to the description logic knowledge base is polynomial; under suitable restrictions, it has lower complexity and even first-order rewritability is achievable. The results add to previous evidence that dl-programs are a versatile and robust combination approach, which moreover is implementable using legacy engines.© 2011 ACM.",Answer set semantics; Description logic programs; Description logics; Normal logic programs; Semantic Web; Well-founded semantic,Computation theory; Data description; Knowledge based systems; Logic programming; Ontology; Semantics; Answer set semantics; Description logic programs; Description logics; Normal logic programs; Well-founded semantic; Semantic Web
Unicast and multicast QoS routing with soft-constraint logic programming,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649378353&doi=10.1145%2f1838552.1838557&partnerID=40&md5=ebb8ed86087bfe03015b36b45402aff2,"We present a formal model to represent and solve the unicast/multicast routing problem in networks with quality-of-service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g., bandwidth). The second step consists in writing this graph as a program in soft-constraint logic programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay < 40 ms), thus finding a solution to QoS routing problems. C-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved. The article highlights the expressivity of SCLP. © 2010 ACM.",Constraint logic programming (CLP); Constraints; Preferences; Quality of Service (QoS); Routing; Soft constraints,Computer software selection and evaluation; Logic programming; Multicasting; Network routing; Quality control; Quality of service; Constraint logic programming; Constraints; Preferences; Quality of Service (QoS); Routing; Soft constraint; Computer programming languages
Efficient generation of craig interpolants in satisfiability modulo theories,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649370899&doi=10.1145%2f1838552.1838559&partnerID=40&md5=f85a2feedbaab8fb66397066ad7f08fd,"The problem of computing Craig interpolants has recently received a lot of interest. In this article, we address the problem of efficient generation of interpolants for some important fragments of first-order logic, which are amenable for effective decision procedures, called satisfiability modulo theory (SMT) solvers. We make the following contributions. First, we provide interpolation procedures for several basic theories of interest: the theories of linear arithmetic over the rationals, difference logic over rationals and integers, and UTVPI over rationals and integers. Second, we define a novel approach to interpolate combinations of theories that applies to the delayed theory combination approach. Efficiency is ensured by the fact that the proposed interpolation algorithms extend state-of-the-art algorithms for satisfiability modulo theories. Our experimental evaluation shows that the MathSAT SMT solver can produce interpolants with minor overhead in search, and much more efficiently than other competitor solvers. © 2010 ACM.",Craig interpolation; Decision procedures; SMT,Decision theory; Formal logic; Basic theory; Craig interpolants; Craig interpolation; Decision procedure; Experimental evaluation; First order logic; Interpolants; Interpolation algorithms; Linear arithmetic; Satisfiability modulo Theories; SMT; State-of-the-art algorithms; Interpolation
On (Omega-)regular model checking,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649360116&doi=10.1145%2f1838552.1838554&partnerID=40&md5=0d4da899d613abc15a533e7f19ddcd3d,"Checking infinite-state systems is frequently done by encoding infinite sets of states as regular languages. Computing such a regular representation of, say, the set of reachable states of a system requires acceleration techniques that can finitely compute the effect of an unbounded number of transitions. Among the acceleration techniques that have been proposed, one finds both specific and generic techniques. Specific techniques exploit the particular type of system being analyzed, for example, a system manipulating queues or integers, whereas generic techniques only assume that the transition relation is represented by a finite-state transducer, which has to be iterated. In this article, we investigate the possibility of using generic techniques in cases where only specific techniques have been exploited so far. Finding that existing generic techniques are often not applicable in cases easily handled by specific techniques, we have developed a new approach to iterating transducers. This new approach builds on earlier work, but exploits a number of new conceptual and algorithmic ideas, often induced with the help of experiments, that give it a broad scope, as well as good performances. © 2010 ACM.",(Omega-)regular model checking; Extrapolation; Implementation; Infinite-state system; Transducers,Extrapolation; Transducers; Acceleration technique; Algorithmic ideas; Finite state transducers; Implementation; Infinite state systems; New approaches; Regular languages; Regular model checking; Regular representations; Transition relations; Model checking
Optimality of Size-Degree Tradeoffs for Polynomial Calculus,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025403889&doi=10.1145%2f1838552.1838556&partnerID=40&md5=f1e593d94bacef542b093d41b2da6ed5,"There are methods to turn short refutations in polynomial calculus (PC) and polynomial calculus with resolution (PCR) into refutations of low degree. Bonet and Galesi [1999, 2003] asked if such size-degree tradeoffs for PC [Clegg et al. 1996; Impagliazzo et al. 1999] and PCR [Alekhnovich et al. 2004] are optimal. We answer this question by showing a polynomial encoding of the graph ordering principle on m variables which requires PC and PCR refutations of degree [formulae omitted]. Tradeoff optimality follows from our result and from the short refutations of the graph ordering principle in Bonet and Galesi [1999, 2001]. We then introduce the algebraic proof system PCRkwhich combines together polynomial calculus and k-DNF resolution (RESk). We show a size hierarchy theorem for PCRk: PCRkis exponentially separated from PCRk+1. This follows from the previous degree lower bound and from techniques developed for RESk. Finally we show that random formulas in conjunctive normal form (3-CNF) are hard to refute in PCRk. © 2010, ACM. All rights reserved.",Algebraic proofs; computational complexity; polynomial calculus; proof complexity; Theory,
A counterexample-guided abstraction-refinement framework for markov decision processes,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049377674&doi=10.1145%2f1838552.1838553&partnerID=40&md5=1eac24d540423e47e4e582ffe01117ef,"The main challenge in using abstractions effectively is to construct a suitable abstraction for the system being verified. One approach that tries to address this problem is that of counterexample guided abstraction refinement (CEGAR), wherein one starts with a coarse abstraction of the system, and progressively refines it, based on invalid counterexamples seen in prior model checking runs, until either an abstraction proves the correctness of the system or a valid counterexample is generated. While CEGAR has been successfully used in verifying nonprob- abilistic systems automatically, CEGAR has only recently been investigated in the context of probabilistic systems. The main issues that need to be tackled in order to extend the approach to probabilistic systems is a suitable notion of ""counterexample"", algorithms to generate counterexamples, check their validity, and then automatically refine an abstraction based on an invalid counterexample. In this article, we address these issues, and present a CEGAR framework for Markov decision processes. © 2010 ACM.",Abstraction; Counterexamples; Markov decision processes; Model checking; Refinement,Markov processes; Model checking; Refining; Abstraction; Abstraction-refinement; Counterexample-guided abstraction refinement; Counterexamples; Markov Decision Processes; Probabilistic systems; Refinement; Abstracting
An inclusion theorem for defeasible logics,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449234487&doi=10.1145%2f1838552.1838558&partnerID=40&md5=5cb7e8d0c3a5a3d8feb975949d9b077a,"Defeasible reasoning is a computationally simple nonmonotonic reasoning approach that has attracted significant theoretical and practical attention. It comprises a family of logics that capture different intuitions, among them ambiguity propagation versus ambiguity blocking, and the adoption or rejection of team defeat. This article provides a compact presentation of the defeasible logic variants, and derives an inclusion theorem which shows that different notions of provability in defeasible logic form a chain of levels of proof. © 2010 ACM.",Ambiguity blocking; Ambiguity propagation; Defeasible logic; Defeasible logic variants; Team defeat,Ambiguity blocking; Ambiguity propagation; Defeasible logic; Defeasible reasoning; Non-monotonic reasoning; Team defeat; Theorem proving
A theory of sampling for continuous-time metric temporal logic,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649381164&doi=10.1145%2f1838552.1838560&partnerID=40&md5=24ae4c9ce05d9b052dc66a43f32dd88d,"This article revisits the classical notion of sampling in the setting of real-time temporal logics for the modeling and analysis of systems. The relationship between the satisfiability of metric temporal logic (MTL) formulas over continuous-time models and over discrete-time models is studied. It is shown to what extent discrete-time sequences obtained by sampling continuous-time signals capture the semantics of MTL formulas over the two time domains. The main results apply to ""flat"" formulas that do not nest temporal operators and can be applied to the problem of reducing the verification problem for MTL over continuous-time models to the same problem over discrete time, resulting in an automated partial practically efficient discretization technique. © 2010 ACM.",Hybrid systems; Metric temporal logic; Real-time,Continuous time systems; Electric grounding; Embedded systems; Hybrid computers; Hybrid systems; Linearization; Real time systems; Time domain analysis; Continuous time; Continuous time models; Continuous-time signal; Discrete time; Discrete-time model; Discrete-time sequences; Discretizations; Metric temporal logic; Modeling and analysis; Real-time; Satisfiability; Temporal operators; Time domain; Verification problems; Temporal logic
Monadic datalog over finite structures of bounded treewidth,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649341098&doi=10.1145%2f1838552.1838555&partnerID=40&md5=51f17e768d89fc01f33522425d9146a4,"Bounded treewidth and monadic second-order (MSO) logic have proved to be key concepts in establishing fixed-parameter tractability results. Indeed, by Courcelle's Theorem we know that any property of finite structures, which is expressible by an MSO sentence, can be decided in linear time (data complexity) if the structures have bounded treewidth. In principle, Courcelle's Theorem can be applied directly to construct concrete algorithms by transforming the MSO evaluation problem into a tree language recognition problem. The latter can then be solved via a finite tree automaton (FTA). However, this approach has turned out to be problematical, since even relatively simple MSO formulae may lead to a ""state explosion"" of the FTA. In this work we propose monadic datalog (i.e., datalog where all intentional predicate symbols are unary) as an alternative method to tackle this class of fixed-parameter tractable problems. We show that if some property of finite structures is expressible in MSO then this property can also be expressed by means of a monadic datalog program over the decomposed structure:wemeanby this that the original structure is augmented with new elements and new relations that encode one of its tree decompositions. In the first place, we thus compare the expressive power of two query languages. However, we also show that the resulting fragment of datalog can be evaluated in linear time (both with respect to the program size and with respect to the data size). Hence, our transformation of an MSO query into a monadic datalog program yields an alternative proof of Courcelle's Theorem. In order to actually construct efficient algorithms for problems whose tractability is due to Courcelle's Theorem, we propose to use a fragment of full (i.e., not necessarily monadic) datalog which allows for a succinct representation of the corresponding monadic datalog programs and for an efficient execution. This new approach is put to work by devising datalog programs for the 3-Colorability problem of graphs and for the PRIMALITY problem of relational schemas (i.e., testing if some attribute in a relational schema is part of a key). We also report on experimental results with a prototype implementation. © 2010 ACM.",Datalog; Fixed-parameter tractability; Monadic second-order logic; Tree decomposition; Treewidth,Graph theory; Theorem proving; Datalog; Fixed-parameter tractability; Monadic second-order logic; Tree decomposition; Tree-width; Query languages
Optimality of size-degree tradeoffs for polynomial calculus,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649352528&doi=10.1145%2f1838552&partnerID=40&md5=9df4dd60347971c766924f321345803b,"There are methods to turn short refutations in polynomial calculus (PC)and polynomial calculus with resolution (Pcr) into refutations of low degree. Bonet and Galesi [1999, 2003] asked if such size-degree tradeoffs for Pc [Clegg et al. 1996; Impagliazzo et al. 1999] and Pcr [Alekhnovich et al. 2004] are optimal. We answer this question by showing a polynomial encoding of the graph ordering principle on m variables which requires Pc and Pcr refutations of degree Ω(√m). Tradeoff optimality follows from our result and from the short refutations of the graph ordering principle in Bonet and Galesi [1999, 2001]. We then introduce the algebraic proof system PcRk which combines together polynomial calculus and k-DNF resolution (RESk). We show a size hierarchy theorem for PCRk:PCRk is exponentially separated from PCRk+1. This follows from the previous degree lower bound and from techniques developed for RESk. Finally we show that random formulas in conjunctive normal form (3-CNF) are hard to refute in PcRk. © 2010 ACM.",Algebraic proofs; Computational complexity; Polynomial calculus; Proof complexity,Boolean functions; Calculations; Polynomials; Algebraic proofs; Conjunctive normal forms; Low degree; Lower bounds; Optimality; Polynomial calculus; Proof complexity; Proof system; Random formulas; Computational complexity
ACM Transactions on Computational Logic: CSL 2008 special issue,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954978479&doi=10.1145%2f1805950.1805951&partnerID=40&md5=80f21aaabc36f2d412792cb60f8cd934,[No abstract available],,
Superposition for fixed domains,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954970352&doi=10.1145%2f1805950.1805957&partnerID=40&md5=96909454f06f36032ef5c9d431b89bbd,"Superposition is an established decision procedure for a variety of first-order logic theories represented by sets of clauses. A satisfiable theory, saturated by superposition, implicitly defines a minimal term-generated model for the theory. Proving universal properties with respect to a saturated theory directly leads to a modification of the minimal model's term-generated domain, as new Skolem functions are introduced. For many applications, this is not desired. Therefore, we propose the first superposition calculus that can explicitly represent existentially quantified variables and can thus compute with respect to a given domain. This calculus is sound and refutationally complete in the limit for a first-order fixed domain semantics. For saturated Horn theories and classes of positive formulas, we can even employ the calculus to prove properties of the minimal model itself, going beyond the scope of known superposition-based approaches. © 2010 ACM.",Automated theorem proving; Fixed domain semantics; Inductionless induction; Minimal model semantics; Proof by consistency; Superposition,Formal logic; Semantics; Automated theorem proving; Domain semantics; Inductionless induction; Minimal model semantics; Proof by consistency; Superposition; Calculations
On isomorphisms of intersection types,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955007657&doi=10.1145%2f1805950.1805955&partnerID=40&md5=9a2c69c2f7067723886eb32e9b5eff36,"The study of type isomorphisms for different λ-calculi started over twenty years ago, and a very wide body of knowledge has been established, both in terms of results and in terms of techniques. A notable missing piece of the puzzle was the characterization of type isomorphisms in the presence of intersection types. While, at first thought, this may seem to be a simple exercise, it turns out that not only finding the right characterization is not simple, but that the very notion of isomorphism in intersection types is an unexpectedly original element in the previously known landscape, breaking most of the known properties of isomorphisms of the typed λ-calculus. In particular, isomorphism is not a congruence and types that are equal in the standard models of intersection types may be nonisomorphic. © 2010 ACM.",Intersection types; Lambda calculus; Type isomorphism,Biomineralization; Calculations; Differentiation (calculus); Body of knowledge; Intersection types; Lambda calculus; Lambda-calculi; Non-isomorphic; The standard model; Type isomorphism; Typed lambda calculus; Set theory
Nonuniform Boolean constraint satisfaction problems with cardinality constraint,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954977646&doi=10.1145%2f1805950.1805954&partnerID=40&md5=3eda2251130549ab51c525ff68889d70,"We study the computational complexity of Boolean constraint satisfaction problems with cardinality constraint. A Galois connection between clones and coclones has received a lot of attention in the context of complexity considerations for constraint satisfaction problems. This connection does not seem to help when considering constraint satisfaction problems that support in addition a cardinality constraint. We prove that a similar Galois connection, involving a weaker closure operator and partial polymorphisms, can be applied to such problems. Thus, we establish dichotomies for the decision as well as for the counting problems in Schaefer's framework. © 2010 ACM.",Computational complexity; Constraint satisfaction,Computational complexity; Boolean constraint; Cardinality constraints; Closure operators; Constraint Satisfaction; Counting problems; Galois connection; Partial polymorphisms; Constraint satisfaction problems
Erratum: What Causes a System to Satisfy a Specification? (ACM Trans. Comput. Logic (2010) 11:4 (2)),2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954978958&doi=10.1145%2f1805950.1805959&partnerID=40&md5=3dd0f332632b6fdbd871b292878cdb61,[No abstract available],,
A tight Karp-Lipton collapse result in bounded arithmetic,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954989152&doi=10.1145%2f1805950.1805952&partnerID=40&md5=337c8780740c314437803a9a075f2b7b,"Cook and Krajíček have recently obtained the following Karp-Lipton collapse result in bounded arithmetic: if the theory PV proves NP ⊆ P/poly, then the polynomial hierarchy collapses to the Boolean hierarchy, and this collapse is provable in PV. Here we show the converse implication, thus answering an open question posed by Cook and Krajíček. We obtain this result by formalizing in PV a hard/easy argument of Buhrman et al. [2003]. In addition, we continue the investigation of propositional proof systems using advice, initiated by Cook and Krajíček. In particular, we obtain several optimality results for proof systems using advice. We further show that these optimal systems are equivalent to natural extensions of Frege systems. © 2010 ACM.",Advice; Bounded arithmetic; Extended frege; Karp-Lipton theorem; Optimal propositional proof systems,Computer science; Logic programming; Advice; Bounded arithmetic; Extended frege; Karp-Lipton theorem; Propositional proof systems; Formal logic
Quantitative languages,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954986172&doi=10.1145%2f1805950.1805953&partnerID=40&md5=ba757707e10455de524a39dd2f5ed02d,"Quantitative generalizations of classical languages, which assign to each word a real number instead of a Boolean value, have applications in modeling resource-constrained computation. We use weighted automata (finite automata with transition weights) to define several natural classes of quantitative languages over finite and infinite words; in particular, the real value of an infinite run is computed as the maximum, limsup, liminf, limit average, or discounted sum of the transition weights. We define the classical decision problems of automata theory (emptiness, universality, language inclusion, and language equivalence) in the quantitative setting and study their computational complexity. As the decidability of the language-inclusion problem remains open for some classes of weighted automata, we introduce a notion of quantitative simulation that is decidable and implies language inclusion. We also give a complete characterization of the expressive power of the various classes of weighted automata. In particular, we show that most classes of weighted automata cannot be determinized. © 2010 ACM.",Expressiveness; Model checking; Quantitative verification; Weighted automata,Computability and decidability; Computer simulation languages; Decision theory; Equivalence classes; Model checking; Robots; Classical decision problems; Classical language; Expressiveness; Language inclusion problems; Quantitative simulation; Quantitative verification; Transition weight; Weighted automata; Modeling languages
Typing streams in the Λμ-calculus,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954993480&doi=10.1145%2f1805950.1805958&partnerID=40&md5=ac143918b6ac845e21e45a8932e92ab0,"Λμ-calculus is a Bohm-complete extension of Parigot's λμ-calculus closely related with delimited control in functional programming. In this article, we investigate the meta-theory of untyped Λμ-calculus by proving confluence of the calculus and characterizing the basic observables for the Separation theorem, canonical normal forms. Then, we define Λs, a new type system for Λμ-calculus that contains a special type construction for streams, and prove that strong normalization and type preservation hold. Thanks to the new typing discipline of Λs, new computational behaviors can be observed, which were forbidden in previous type systems for λμ-calculi. Those new typed computational behaviors witness the stream interpretation of Λμ-calculus. © 2010 ACM.",Böhm theorem; Classical λ-calculus; Confluence; Delimited control; Streams; Type system; λμ-calculus,Biomineralization; Computation theory; Differentiation (calculus); Functional programming; Basic observables; Confluence; Lambda-mu calculus; Meta-theory; Separation theorem; Streams; Strong normalization; Type systems; Calculations
Pure pointer programs with iteration,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954988862&doi=10.1145%2f1805950.1805956&partnerID=40&md5=c8a3f4c1cb17365ca49d551a1bd5c3d4,"Many LOGSPACE algorithms are naturally described as programs that operate on a structured input (e.g., a graph), that store in memory only a constant number of pointers (e.g., to graph nodes) and that do not use pointer arithmetic. Such ""pure pointer algorithms"" thus are a useful abstraction for studying the nature of LOGSPACE-computation. In this article, we introduce a formal class PURPLE of pure pointer programs and study them on locally ordered graphs. Existing classes of pointer algorithms, such as Jumping Automata on Graphs (JAGs) or Deterministic Transitive Closure (DTC) logic, often exclude simple programs. PURPLE subsumes these classes and allows for a natural representation of many graph algorithms that access the input graph using a constant number of pure pointers. It does so by providing a primitive for iterating an algorithm over all nodes of the input graph in an unspecified order. Since pointers are given as an abstract data type rather than as binary digits we expect that logarithmic-size worktapes cannot be encoded using pointers as is done, for example, in totally ordered DTC-logic. We show that this is indeed the case by proving that the property ""the number of nodes is a power of two,"" which is in LOGSPACE, is not representable in PURPLE. © 2010 ACM.",Deterministic transitive closure logic; Iteration in unspecified order; Logarithmic space; Pebble automation; Pointer program,Abstract data types; Abstracting; Computation theory; Computer circuits; Graph structures; Graph theory; Iterative methods; Binary digits; Iteration in unspecified order; Log-space algorithms; Logarithmic space; Natural representation; Pointer arithmetic; Pointer programs; Transitive closure; Graph algorithms
Complexity of propositional proofs under a promise,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952800429&doi=10.1145%2f1740582.1740586&partnerID=40&md5=e50ff8ee9345ef2f619431fea94652f7,"We studywithin the framework of propositional proof complexitythe problem of certifying unsatisfiability of CNF formulas under the promise that any satisfiable formula has many satisfying assignments, where many stands for an explicitly specified function in the number of variables n. To this end, we develop propositional proof systems under different measures of promises (i.e., different ) as extensions of resolution. This is done by augmenting resolution with axioms that, roughly, can eliminate sets of truth assignments defined by Boolean circuits. We then investigate the complexity of such systems, obtaining an exponential separation in the average case between resolution under different size promises: (1) Resolution has polynomial-size refutations for all unsatisfiable 3CNF formulas when the promise is 2n, for any constant 0<<1. (2) There are no subexponential size resolution refutations for random 3CNF formulas, when the promise is 2Δ n, for any constant 0<Δ<1 (and the number of clauses is O(n3/2-), for 0<<1/2). Goods Satisfactory or Money Refunded The Eaton Promise © 2010 ACM.",Promise problems; Propositional proof complexity; Random 3CNF; Resolution,Average case; Boolean circuit; CNF formulas; Different sizes; Promise problems; Propositional proof complexity; Propositional proof systems; Resolution refutation; Satisfying assignments; Truth assignment; Size separation
On the completeness of compositional reasoning methods,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952840711&doi=10.1145%2f1740582.1740584&partnerID=40&md5=e93a33283422a7b4eedf6f9aeedbc8e2,"Hardware systems and reactive software systems can be described as the composition of several concurrently active processes. Automated reasoning based on model checking algorithms can substantially increase confidence in the overall reliability of a system. Direct methods for model checking a concurrent composition, however, usually suffer from the explosion in the number of program states that arises from concurrency. Reasoning compositionally about individual processes helps mitigate this problem. A number of rules have been proposed for compositional reasoning, typically based on an assume-guarantee reasoning paradigm. Reasoning with these rules can be delicate, as some are syntactically circular in nature, in that assumptions and guarantees are mutually dependent. This is known to be a source of unsoundness. In this article, we investigate rules for compositional reasoning from the viewpoint of completeness. We show that several rules are incomplete: that is, there are properties whose validity cannot be established using (only) these rules. We derive a new, circular, reasoning rule and show it to be sound and complete. We show that the auxiliary assertions needed for completeness need be defined only on the interface of the component processes. We also show that the two main paradigms of circular and noncircular reasoning are closely related, in that a proof of one type can be transformed in a straightforward manner to one of the other type. These results give some insight into the applicability of compositional reasoning methods. © 2010 ACM.",Assume-guarantee reasoning; Automated reasoning; Compositional reasoning; Concurrent systems; Syntactically circular reasoning,Automation; Model checking; Problem solving; Active process; Assume-guarantee reasoning; Automated reasoning; Compositional reasoning; Concurrent composition; Concurrent systems; Direct method; Hardware system; Model checking algorithm; Non-circular; Program state; Reactive software; Reasoning rules; Automata theory
A fast algorithm and datalog inexpressibility for temporal reasoning,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952859059&doi=10.1145%2f1740582.1740583&partnerID=40&md5=f37ede9327e4bd1fd3c6c6bc22d8fc02,"We introduce a new tractable temporal constraint language, which strictly contains the Ord-Horn language of Bürkert and Nebel and the class of AND/OR precedence constraints. The algorithm we present for this language decides whether a given set of constraints is consistent in time that is quadratic in the input size. We also prove that (unlike Ord-Horn) the constraint satisfaction problem of this language cannot be solved by Datalog or by establishing local consistency. © 2010 ACM.",Algorithms; Computational complexity; Constraint satisfaction; Datalog; Ord-Horn; Precedence constraints; Temporal reasoning,Algorithms; Automata theory; Linguistics; Constraint Satisfaction Problems; Datalog; Fast algorithms; Input size; Local consistency; Ord-Horn; Precedence constraints; Temporal constraints; Temporal reasoning; Computational complexity
On the distributivity of LTL specifications,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952817122&doi=10.1145%2f1740582.1740588&partnerID=40&md5=983093aa24c418d8e88c15116d5329fa,"In this article, we investigate LTL specifications where γ [φ ψ] is equivalent to γ [φ] γ [ψ] independent of φ and ψ. Formulas φ with this property are called distributive queries because they naturally arise in Chan's seminal approach to temporal logic query solving [Chan 2000]. As recognizing distributive LTL queries is PSPACE-complete, we consider distributive fragments of LTL defined by templates as in Buccafurri et al. [2001]. Our main result is a syntactic characterization of distributive LTL queries in terms of LTL templates: we construct a context-free template grammar LTLQx which guarantees that all specifications obtained from LTLQx are distributive, and all templates not obtained from LTLQx have simple nondistributive instantiations. © 2010 ACM.",Constraint satisfaction; Distributivity; LTL; Query solving; Strongest solution; Syntactic characterization; Template characterization; Unique solution,Syntactics; Temporal logic; Constraint satisfaction; Context-free; Distributivity; Query solving; Syntactic characterization; Specifications
Lower bounds for bounded depth Frege proofs via Pudlák-Buss games,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952846685&doi=10.1145%2f1740582.1740587&partnerID=40&md5=21ae5deb277253164055aa3f28533cd6,"We present a simple proof of the bounded-depth Frege proof lower bounds of Pitassi et al. [1993] and Krajíček et al. [1995] for the pigeonhole principle. Our method uses the interpretation of proofs as two player games given by Pudlák and Buss. Our lower bound is conceptually simpler than previous ones, and relies on tools and intuition that are well known in the context of computational complexity. This makes the lower bound of Pitassi et al. [1993] and Krajíček et al. [1995] accessible to the general computational complexity audience.We hope this new view will open new directions for research in proof complexity. © 2010 ACM.",Frege proofs; Lower bounds; Pigeonhole principle; Proof complexity,Frege proofs; Lower bounds; New directions; Pigeonhole principle; Proof complexity; Two-player games; Computational complexity
Deciding strategy properties of contract-signing protocols,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952849941&doi=10.1145%2f1740582.1740585&partnerID=40&md5=e60f8e454320bde6ea58edd8418b6e5d,"Research on the automatic analysis of cryptographic protocols has so far concentrated on reachability properties, such as secrecy and authentication. In this article, we prove that certain game-theoretic security properties, including balance for contract-signing protocols, can be decided in a Dolev-Yao style model with a bounded number of sessions. The decision algorithm that we develop is based on standard constraint-solving procedures, which, in the past, have successfully been employed in tools for reachability properties. Our result thus paves the way for extending these tools to deal with game-theoretic security properties. © 2010 ACM.",Automatic security analysis; Contract signing; Decidability,Computability and decidability; Cryptography; Network protocols; Security systems; Automatic analysis; Contract signing; Contract-signing protocols; Cryptographic protocols; Decision algorithms; Dolev-Yao style model; Game-theoretic security properties; Reachability; Security analysis; Standard constraints; Network security
Deciding security properties for cryptographic protocols. Application to key cycles,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249100283&doi=10.1145%2f1656242.1656244&partnerID=40&md5=74af8e4a445ac474d0565f0cf09ab5cd,"There is a large amount of work dedicated to the formal verification of security protocols. In this article, we revisit and extend the NP-complete decision procedure for a bounded number of sessions. We use a, now standard, deducibility constraint formalism for modeling security protocols. Our first contribution is to give a simple set of constraint simplification rules, that allows to reduce any deducibility constraint to a set of solved forms, representing all solutions (within the bound on sessions). As a consequence, we prove that deciding the existence of key cycles is NP-complete for a bounded number of sessions. The problem of key-cycles has been put forward by recent works relating computational and symbolic models. The so-called soundness of the symbolic model requires indeed that no key cycle (e.g., enc(k, k)) ever occurs in the execution of the protocol. Otherwise, stronger security assumptions (such as KDM-security) are required. We show that our decision procedure can also be applied to prove again the decidability of authentication-like properties and the decidability of a significant fragment of protocols with timestamps. © 2010 ACM.",Formal proofs; Security protocols; Symbolic constraints; Verification,Communication channels (information theory); Computability and decidability; Cryptography; Network protocols; Cryptographic protocols; Decision procedure; Formal proofs; Formal Verification of Security; NP Complete; Security properties; Security protocols; Simplification rules; Symbolic model; Time stamps; Network security
Annotated RDF,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249086336&doi=10.1145%2f1656242.1656245&partnerID=40&md5=37796b17a52cf1f98e1800937f5cb4de,"Real-world use of RDF requires the ability to transparently represent and explain metadata associated with RDF triples. For example, when RDF triples are extracted automatically by information extraction programs, there is a need to represent where the triples came from, what their temporal validity is, and how certain we are that the triple is correct. Today, there is no theoretically clean and practically scalable mechanism that spans these different needs - reification is the only solution propose to date, and its implementations have been ugly. In this paper, we present Annotated RDF (or aRDF for short) in which RDF triples are annotated by members of a partially ordered set (with bottom element) that can be selected in any way desired by the user. We present a formal declarative semantics (model theory) for annotated RDF and develop algorithms to check consistency of aRDF theories and to answer queries to aRDF theories. We show that annotated RDF supports users who need to think about the uncertainty, temporal aspects, and provenance of the RDF triples in an RDF database. We develop a prototype aRDF implementation and show that our algorithms work efficiently even on real world data sets containing over 10 million triples. © 2010 ACM.",Annotated RDF; Query processing; View maintenance,Metadata; Query processing; Set theory; Declarative semantics; Information Extraction; Model theory; Partially ordered set; RDF database; RDF query processing; Real world data; Real-world; Temporal aspects; View maintenance; Maintenance
Undecidability and intractability results concerning datalog programs and their persistency numbers,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249097004&doi=10.1145%2f1656242.1656247&partnerID=40&md5=109c1db53236b28618c9971c682a7b0c,"The relation between Datalog programs and homomorphism problems, and, between Datalog programs and bounded treewidth structures has been recognized for some time and given much attention recently. Additionally, the essential role of persistent variables (in program expansions) for solving several relevant problems has also started to be observed. In Afrati et al. [2005] the general notion of program persistencies was refined into four notions (two syntactical ones and two semantical ones) and the interrelationship between these four persistency numbers was studied. In the present article (1) we prove undecidability results concerning the semantical notions of persistency number-modulo equivalence, of persistency number and of characteristic integer, (2) we exhibit new classes of programs for which boundedness is undecidable and (3) we prove intractabiltity results concerning the syntactical notions of weak persistency number and of weak characteristic integer. © 2010 ACM.",Bounded treewidth hypergraphs; Boundedness; Datalog; Intractability; Persistency numbers; Persistent variables; Undecidability,Equivalence classes; Bounded treewidth; Boundedness; Datalog; Hyper graph; Persistency numbers; Persistent variables; Undecidability; Graph theory
Proof search specifications of bisimulation and modal logics for the π-calculus,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249110996&doi=10.1145%2f1656242.1656248&partnerID=40&md5=d7ba59e95bb8821c481d27f5c360fa7c,"We specify the operational semantics and bisimulation relations for the finite π-calculus within a logic that contains the ∇ quantifier for encoding generic judgments and definitions for encoding fixed points. Since we restrict to the finite case, the ability of the logic to unfold fixed points allows this logic to be complete for both the inductive nature of operational semantics and the coinductive nature of bisimulation. The ∇ quantifier helps with the delicate issues surrounding the scope of variables within π-calculus expressions and their executions (proofs). We illustrate several merits of the logical specifications permitted by this logic: they are natural and declarative; they contain no side-conditions concerning names of variables while maintaining a completely formal treatment of such variables; differences between late and open bisimulation relations arise from familar logic distinctions; the interplay between the three quantifiers (∀, and ∇) and their scopes can explain the differences between early and late bisimulation and between various modal operators based on bound input and output actions; and proof search involving the application of inference rules, unification, and backtracking can provide complete proof systems for one-step transitions, bisimulation, and satisfaction in modal logic. We also illustrate how one can encode the π-calculus with replications, in an extended logic with induction and co-induction. © 2010 ACM.",Bisimulation; Generic judgments; Higher-order abstract syntax; Modal logics; Proof search; λ-tree syntax; π-calculus; ∇ quantifier,Calculations; Computer programming languages; Encoding (symbols); Formal logic; Semantics; Signal encoding; Specifications; Syntactics; Bisimulations; Generic judgments; Higher-order abstract syntax; Modal logic; Proof search; Computer circuits
FDNC: Decidable nonmonotonic disjunctive logic programs with function symbols,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249092810&doi=10.1145%2f1656242.1656249&partnerID=40&md5=ed621124cd08a461e4800edfd5ead324,"We present the class FDNC of logic programs that allows for function symbols (F), disjunction (D), nonmonotonic negation under the answer set semantics (N), and constraints (C), while still retaining the decidability of the standard reasoning tasks. Thanks to these features, FDNC programs are a powerful formalism for rule-based modeling of applications with potentially infinite processes and objects, and which allows also for common-sense reasoning in this context. This is evidenced, for instance, by tasks in reasoning about actions and planning: brave and open queries over FDNC programs capture the well-known problems of plan existence and secure (conformant) plan existence, respectively, in transition-based actions domains. As for reasoning from FDNC programs, we show that consistency checking and brave/cautious reasoning tasks are ExpTime-complete in general, but have lower complexity under syntactic restrictions that give rise to a family of program classes. Furthermore, we also determine the complexity of open queries (i.e., with answer variables), for which deciding non-empty answers is shown to be ExpSpace -complete under cautious entailment. Furthermore, we present algorithms for all reasoning tasks that are worst-case optimal. The majority of them resorts to a finite representation of the stable models of an FDNC program that employs maximal founded sets of knots, which are labeled trees of depth at most 1 from which each stable model can be reconstructed. Due to this property, reasoning over FDNC programs can in many cases be reduced to reasoning from knots. Once the knot-representation for a program is derived (which can be done off-line), several reasoning tasks are not more expensive than in the function-free case, and some are even feasible in polynomial time. This knowledge compilation technique paves the way to potentially more efficient online reasoning methods not only for FDNC, but also for other formalisms. © 2010 ACM.",Answer set programming; Computational complexity; Description logics; Function symbols; Knowledge compilation; Nonmonotonic logic programs; Reasoning about actions,Computational complexity; Computational efficiency; Data description; Logic programming; Polynomial approximation; XML; Answer set programming; Description logic; Function symbols; Knowledge compilation; Nonmonotonic logic programs; Reasoning about actions; Computability and decidability
Logical queries over views: Decidability and expressiveness,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249106397&doi=10.1145%2f1656242.1656243&partnerID=40&md5=8f5764040e4bb8bb380d397b4135a3ae,"We study the problem of deciding the satisfiability of first-order logic queries over views, with our aim to delimit the boundary between the decidable and the undecidable fragments of this language. Views currently occupy a central place in database research due to their role in applications such as information integration and data warehousing. Our main result is the identification of a decidable class of first-order queries over unary conjunctive views that generalizes the decidability of the classical class of first-order sentences over unary relations known as the Löwenheim class. We then demonstrate how various extensions of this class lead to undecidability and also provide some expressivity results. Besides its theoretical interest, our new decidable class is potentially interesting for use in applications such as deciding implication of complex dependencies, analysis of a restricted class of active database rules, and ontology reasoning. © 2010 ACM.",Conjunctive query; Containment; Database query; Database view; Decidability; First-order logic; Löwenheim class; Monadic logic; Ontology reasoning; Satisfiability; Unary logic; Unary view,Automata theory; Communication channels (information theory); Data warehouses; Ontology; Query languages; Conjunctive-query containment; Database queries; Database views; Decidability; First order logic; Monadic logic; Satisfiability; Computability and decidability
Weyl's predicative classical mathematics as a logic-enriched type theory,2010,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249085395&doi=10.1145%2f1656242.1656246&partnerID=40&md5=eef4d595fec5c329e42a5ad038a9996b,"We construct a logic-enriched type theory LTT W that corresponds closely to the predicative system of foundations presented by Hermann Weyl in Das Kontinuum. We formalize many results from that book in LTT W, including Weyl's definition of the cardinality of a set and several results from real analysis, using the proof assistant Plastic that implements the logical framework LF. This case study shows how type theory can be used to represent a nonconstructive foundation for mathematics. © 2010 ACM.",Formalization of mathematics; Logic-enriched type theories; Predicativism,Cardinalities; Logical frameworks; Proof assistant; Type theory; Mathematical techniques
Tableau-based decision procedures for logics of strategic ability in multiagent systems,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-72649106869&doi=10.1145%2f1614431.1614434&partnerID=40&md5=9deb927302cf22b26ff330e937674fa1,"We develop an incremental tableau-based decision procedure for the alternating-time temporal logic ATL and some of its variants. While running within the theoretically established complexity upper bound, we believe that our tableaux are practically more efficient in the average case than other decision procedures for ATL known so far. Besides, the ease of its adaptation to variants of ATL demonstrates the flexibility of the proposed procedure. © 2009 ACM.",Alternating-time temporal logic; Decision procedures; Logics for multiagent systems; Tableaux,Semantic Web; Alternating time temporal logic; Average case; Decision procedure; Upper Bound; Temporal logic
A general framework for sound and complete Floyd-Hoare logics,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649094878&doi=10.1145%2f1614431.1614438&partnerID=40&md5=27dbb697fee8bc2df151dba6ce1d15e6,"This article presents an abstraction of Hoare logic to traced symmetric monoidal categories, a very general framework for the theory of systems. Our abstraction is based on a traced monoidal functor from an arbitrary traced monoidal category into the category of preorders and monotone relations. We give several examples of how our theory generalizes usual Hoare logics (partial correctness of while programs, partial correctness of pointer programs), and provide some case studies on how it can be used to develop new Hoare logics (runtime analysis of while programs and stream circuits). © 2009 ACM.",Hoare logic; Stream circuits; Traced monoidal categories,Abstracting; Hydraulics; Hoare Logic; Monoidal categories; Monoidal functor; Partial correctness; Pointer programs; Preorders; Run-time analysis; While-programs; Logic circuits
Finitary winning in ω-regular games,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649152053&doi=10.1145%2f1614431.1614432&partnerID=40&md5=8b24ce01cf49741c878c7f6c6e6a5076,"Games on graphs with ω-regular objectives provide a model for the control and synthesis of reactive systems. Every ω-regular objective can be decomposed into a safety part and a liveness part. The liveness part ensures that something good happens eventually. Two main strengths of the classical, infinite-limit formulation of liveness are robustness (independence from the granularity of transitions) and simplicity (abstraction of complicated time bounds). However, the classical liveness formulation suffers from the drawback that the time until something good happens may be unbounded. A stronger formulation of liveness, so-called finitary liveness, overcomes this drawback, while still retaining robustness and simplicity. Finitary liveness requires that there exists an unknown, fixed bound b such that something good happens within b transitions. While for one-shot liveness (reachability) objectives, classical and finitary liveness coincide, for repeated liveness (Büchi) objectives, the finitary formulation is strictly stronger. In this work we study games with finitary parity and Streett objectives. We prove the determinacy of these games, present algorithms for solving these games, and characterize the memory requirements of winning strategies. We show that finitary parity games can be solved in polynomial time, which is not known for infinitary parity games. For finitary Streett games, we give an EXPTIME algorithm and show that the problem is NP-hard. Our algorithms can be used, for example, for synthesizing controllers that do not let the response time of a system increase without bound. © 2009 ACM.",Finitary objectives; Games on graphs; Model checking; ω-regular objectives,Game theory; Polynomial approximation; B transitions; Finitary objectives; Games on graphs; Memory requirements; Polynomial-time; Reachability; Reactive system; Winning strategy; Model checking
Regular tree languages definable in FO and in FOmod,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649107815&doi=10.1145%2f1614431.1614435&partnerID=40&md5=7d22fc659730adbbd1868a7dd0d28911,We consider regular languages of labeled trees. We give an effective characterization of the regular languages over such trees that are definable in first-order logic in the language of labeled graphs. These languages are the analog on trees of the locally threshold testable languages on strings. We show that this characterization yields a decision procedure for determining whether a regular tree language is first-order definable: The procedure is polynomial time in the minimal automaton presenting the regular language. We also provide an algorithm for deciding whether a regular language is definable in first-order logic supplemented with modular quantifiers. © 2009 ACM.,First-order logic; Regular tree languages,Context free languages; Formal logic; Linguistics; Polynomial approximation; Decision procedure; First order logic; First-order; Labeled graphs; Labeled trees; Minimal automaton; Polynomial-time; Regular languages; Regular tree languages; Query languages
The formal system Δ,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649105012&doi=10.1145%2f1614431.1614436&partnerID=40&md5=67e9bf7080c4413642289713d2e4a103,"The formal system Δ is a typed -calculus that pursues the unification of terms, types, environments, and contexts as the main goal. Δ takes some features from the Automath-related -calculi and some from the pure type systems, but differs from both in that it does not include the construction while it provides for an abbreviation mechanism at the level of terms. Δ enjoys some important desirable properties such as the confluence of reduction, the correctness of types, the uniqueness of types up to conversion, the subject reduction of the type assignment, the strong normalization of the typed terms, and, as a corollary, the decidability of type inference problem. © 2009 ACM.",Abbreviations; Environments as terms; Terms as types,Biomineralization; Formal systems; Pure type systems; Strong normalization; Subject reduction; Type inferences; Computability and decidability
Higher-order term indexing using substitution trees,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649129695&doi=10.1145%2f1614431.1614437&partnerID=40&md5=892d54399df957799dd17e2f0df51637,"We present a higher-order term indexing strategy based on substitution trees for simply typed lambda-terms. There are mainly two problems in adapting first-order indexing techniques. First, many operations used in building an efficient term index and retrieving a set of candidate terms from a large collection are undecidable in general for higher-order terms. Second, the scoping of variables and binders in the higher-order case presents challenges. The approach taken in this article is to reduce the problem to indexing linear higher-order patterns, a decidable fragment of higher-order terms, and delay solving terms outside of this fragment. We present insertion of terms into the index based on computing the most specific linear generalization of two linear higher-order patterns, and retrieval based on matching two linear higher-order patterns. Our theoretical framework maintains that terms are in Βη-normal form, thereby eliminating the need to renormalize and raise terms during insertion and retrieval. Finally, we prove correctness of our presented algorithms. This indexing structure is implemented as part of the Twelf system to speed up the execution of the tabled higher-logic programming interpreter. © 2009 ACM.",Indexing; Logical frameworks; Type theory,Computability and decidability; Logic programming; Program interpreters; First-order; Higher order; In-buildings; Indexing structures; Indexing techniques; Lambda terms; Logical frameworks; Normal form; Scoping; Speed-ups; Theoretical framework; Type theory; Indexing (of information)
Automated termination proofs for logic programs by term rewriting,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949154970&doi=10.1145%2f1614431.1614433&partnerID=40&md5=19aa254c4deb068ef71a26ae4aaa92f1,"There are two kinds of approaches for termination analysis of logic programs: transformational and direct ones. Direct approaches prove termination directly on the basis of the logic program. Transformational approaches transform a logic program into a Term Rewrite System (TRS) and then analyze termination of the resulting TRS instead. Thus, transformational approaches make all methods previously developed for TRSs available for logic programs as well. However, the applicability of most existing transformations is quite restricted, as they can only be used for certain subclasses of logic programs. (Most of them are restricted to well-moded programs.) In this article we improve these transformations such that they become applicable for any definite logic program. To simulate the behavior of logic programs by TRSs, we slightly modify the notion of rewriting by permitting infinite terms. We show that our transformation results in TRSs which are indeed suitable for automated termination analysis. In contrast to most other methods for termination of logic programs, our technique is also sound for logic programming without occur check, which is typically used in practice. We implemented our approach in the termination prover AProVE and successfully evaluated it on a large collection of examples. © 2009 ACM.",Dependency pairs; Logic programming; Term rewriting; Termination analysis,Automated termination; Automated termination proofs; Dependency pairs; Direct approach; Logic programs; Term rewrite systems; Term rewriting; Termination analysis; Transformational approach; Logic programming
A new function algebra of EXPTIME functions by safe nested recursion,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149102873&doi=10.1145%2f1555746.1555748&partnerID=40&md5=6c6736024e62a22732e24d497022c123,"Bellantoni and Cook have given a function-algebra characterization of the polynomial-time computable functions via an unbounded recursion scheme which is called safe recursion. Inspired by their work, we characterize the exponential-time computable functions with the use of a safe variant of nested recursion. © 2009 ACM.",EXPTIME; Implicit computational complexity,Algebra; Computable functions; EXPTIME; Function algebra; Implicit computational complexity; Polynomial-time computable functions; Recursion schemes; Recursions; Computational complexity
Guest editorial: Special issue on implicit computational complexity,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149098347&doi=10.1145%2f1555746.1555747&partnerID=40&md5=cf0a7cb736b0bb560aeeeb65fbdca6dd,[No abstract available],,
"Context semantics, linear logic, and computational complexity",2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149087745&doi=10.1145%2f1555746.1555749&partnerID=40&md5=4c402ceec2a726b7f1dddcf3557e7db2,"We show that context semantics can be fruitfully applied to the quantitative analysis of proof normalization in linear logic. In particular, context semantics lets us define the weight of a proof-net as a measure of its inherent complexity: it is both an upper bound to normalization time (modulo a polynomial overhead, independently on the reduction strategy) and a lower bound to the amount of resources needed to compute the normal form. Weights are then exploited in proving strong soundness theorems for various subsystems of linear logic, namely elementary linear logic, soft linear logic, and light linear logic. © 2009 ACM.",Geometry of interaction; Implicit computational complexity; Linear logic,Computational geometry; Computational linguistics; Control theory; Semantics; Geometry of interaction; Implicit computational complexity; Inherent complexity; Light linear logic; Linear logic; Lower bounds; Normal form; Quantitative analysis; Reduction strategy; Upper Bound; Computational complexity
Resource control graphs,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149093346&doi=10.1145%2f1555746.1555753&partnerID=40&md5=e262338fca75e25729ec16204bbf65e5,"Resource Control Graphs are an abstract representation of programs. Each state of the program is abstracted by its size, and each instruction is abstracted by the effects it has on the state size whenever it is executed. The abstractions of instruction effects are then used as weights on the arcs of a program's Control Flow Graph. Termination is proved by finding decreases in a well-founded order on state-size, in line with other termination analyses, resulting in proofs similar in spirit to those produced by Size Change Termination analysis. However, the size of states may also be used to measure the amount of space consumed by the program at each point of execution. This leads to an alternative characterisation of the Non Size Increasing programs, that is, of programs that can compute without allocating new memory. This new tool is able to encompass several existing analyses and similarities with other studies, suggesting that even more analyses might be expressable in this framework, thus giving hopes for a generic tool for studying programs. © 2009 ACM.",Implicit computational complexity; Non-size increasing computation; Program analysis; Program termination; Size change termination,Abstracting; Implicit computational complexity; Non-size increasing computation; Program analysis; Program termination; Size change termination; Computational complexity
Extending the loop language with higher-order procedural variables,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149088745&doi=10.1145%2f1555746.1555750&partnerID=40&md5=91c904090a8a70fc27bbeea063405f2e,"We extend Meyer and Ritchie's Loop language with higher-order procedures and procedural variables and we show that the resulting programming language (called Loop Ω) is a natural imperative counterpart of Gödel System T. The argument is two-fold: (1) we define a translation of the Loop Ω language into System T and we prove that this translation actually provides a lock-step simulation, (2) using a converse translation, we show that Loop Ω is expressive enough to encode any term of System T. Moreover, we define the iteration rank of a Loop Ω program, which corresponds to the classical notion of recursion rank in System T, and we show that both translations preserve ranks. Two applications of these results in the area of implicit complexity are described. © 2009 ACM.",Gödel System T; Higher-order procedures; Loop language; Procedural variables,Linguistics; Higher order; Higher-order procedures; Implicit complexity; Loop language; Procedural variables; Programming language; Recursions; Ritchie; Step simulation; Translation (languages)
"Sup-interpretations, a semantic method for static analysis of program resources",2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149108989&doi=10.1145%2f1555746.1555751&partnerID=40&md5=196955d10cd5665f7a93c6dd59ef4641,"The sup-interpretation method is proposed as a new tool to control memory resources of first order functional programs with pattern matching by static analysis. It has been introduced in order to increase the intensionality, that is the number of captured algorithms, of a previous method, the quasi-interpretations. Basically, a sup-interpretation provides an upper bound on the size of function outputs. A criterion, which can be applied to terminating as well as nonterminating programs, is developed in order to bound the stack frame size polynomially. Since this work is related to quasi-interpretation, dependency pairs, and size-change principle methods, we compare these notions obtaining several results. The first result is that, given any program, we have heuristics for finding a sup-interpretation when we consider polynomials of bounded degree. Another result consists in the characterizations of the sets of functions computable in polynomial time and in polynomial space. A last result consists in applications of sup-interpretations to the dependency pair and the size-change principle methods. © 2009 ACM.",Resources control; Static analysis of first-order languages,Linguistics; Pattern matching; Polynomial approximation; Static analysis; Bounded degree; Control memory; Dependency pairs; First-order functional programs; Frame size; Intensionality; Interpretation methods; New tools; Polynomial space; Polynomial-time; Quasi-interpretation; Resources control; Size-change principle; Upper Bound; Program interpreters
A flow calculus of mwp-bounds for complexity analysis,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69149108116&doi=10.1145%2f1555746.1555752&partnerID=40&md5=0685c99642ac64a62f1f09697fbd033f,"We present a method for certifying that the values computed by an imperative program will be bounded by polynomials in the program's inputs. To this end, we introduce mwp-matrices and define a semantic relation C : M, where C is a program and M is an mwp-matrix. It follows straightforwardly from our definitions that there exists M such that C : M holds iff every value computed by C is bounded by a polynomial in the inputs. Furthermore, we provide a syntactical proof calculus and define the relation ⊢ C : M to hold iff there exists a derivation in the calculus where C : M is the bottom line. We prove that ⊢ C : M implies C : M. By means of exhaustive proof search, an algorithm can decide if there exists M such that the relation ⊢ C : M holds, and thus, our results yield a computational method. © 2009 ACM.",Automatable complexity analysis of imperative programs; Implicit computational complexity; Static program anaysis,Calculations; Automatable complexity analysis of imperative programs; Bottom lines; Complexity analysis; Imperative programs; Implicit computational complexity; matrix; Proof calculus; Proof search; Semantic relations; Static program anaysis; Computational complexity
Checking timed Büchi automata emptiness on simulation graphs,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249158791&doi=10.1145%2f1507244.1507245&partnerID=40&md5=f15c68517a123bdd6e4443ce6fd53c08,"Timed automata [Alur and Dill 1994] comprise a popular model for describing real-time and embedded systems and reasoning formally about them. Efficient model-checking algorithms have been developed and implemented in tools such as Kronos [Daws et al. 1996] or Uppaal [Larsen et al. 1997] for checking safety properties on this model, which amounts to reachability. These algorithms use the so-called zone-closed simulation graph, a finite graph that admits efficient representation and has been recently shown to preserve reachability [Bouyer 2004]. Building upon Bouyer [2004] and our previous work [Bouajjani et al. 1997; Tripakis et al. 2005], we show that this graph can also be used for checking liveness properties, in particular, emptiness of timed B uchi automata. © 2009 ACM.",Formal methods; Model checking; Property-preserving abstractions; Specification languages; Timed Büchi automata,Abstracting; Automata theory; Embedded systems; Formal methods; Linguistics; Real time systems; Robots; Simulators; Specification languages; Specifications; Translation (languages); Finite graphs; Liveness properties; Model-checking algorithms; Property-preserving abstractions; Reachability; Real-time and embedded systems; Safety property; Simulation graphs; Timed Automata; Model checking
Tableau calculus for preference-based conditional logics: PCL and its extensions,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249116910&doi=10.1145%2f1507244.1507251&partnerID=40&md5=6188c130ff8899630a9c52f2141c7856,"We present a tableau calculus for some fundamental systems of propositional conditional logics. We consider the conditional logics that can be characterized by preferential semantics (i.e., possible world structures equipped with a family of preference relations). For these logics, we provide a uniform completeness proof of the axiomatization with respect to the semantics, and a uniform labeled tableau procedure. © 2009 ACM.",Conditional logics; Tableaux calculi,Biomineralization; Semantic Web; Semantics; Axiomatization; Conditional logics; Possible worlds; Preference relation; Preference-based; Preferential semantics; Tableaux calculi; Pathology
Analytic tableaux calculi for KLM logics of nonmonotonic reasoning,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249084310&doi=10.1145%2f1507244.1507248&partnerID=40&md5=e26aa0d0399d7c1fccc56e82da0936b0,"We present tableau calculi for the logics of nonmonotonic reasoning defined by Kraus, Lehmann and Magidor (KLM). We give a tableau proof procedure for all KLM logics, namely preferential, loop-cumulative, cumulative, and rational logics. Our calculi are obtained by introducing suitable modalities to interpret conditional assertions. We provide a decision procedure for the logics considered and we study their complexity. © 2009 ACM.",Analytic tableaux calculi; Nonmonotonic reasoning,Pathology; Semantic Web; Analytic tableaux calculi; Decision procedure; Nonmonotonic reasoning; Proof procedures; Biomineralization
Differential recursion,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249144381&doi=10.1145%2f1507244.1507252&partnerID=40&md5=9206c0b7b1fd262a616c4a9b8162a0be,"We present a redevelopment of the theory of real-valued recursive functions that was introduced by C. Moore in 1996 by analogy with the standard formulation of the integer-valued recursive functions. While his work opened a new line of research on analog computation, the original paper contained some technical inaccuracies. We discuss possible attempts to remove the ambiguity in the behavior of the operators on partial functions, with a focus on his ""primitive recursive"" functions generated by the differential recursion operator that solves initial value problems. Under a reasonable reformulation, the functions in this class are shown to be analytic and computable in a strong sense in computable analysis. Despite this well-behavedness, the class turns out to be too big to have the originally purported relation to differentially algebraic functions, and hence to C. E. Shannon's model of analog computation. © 2009 ACM.",Analog computation; Differentially algebraic functions; Initial value problems; Real recursive functions; Transcendentally transcendental functions,Algebra; Analog computers; Differential equations; Initial value problems; Algebraic functions; Analog computation; Computable analysis; Differentially algebraic functions; Partial functions; Real recursive functions; Recursion; Recursion operators; Transcendentally transcendental functions; Recursive functions
LTL with the freeze quantifier and register automata,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249143974&doi=10.1145%2f1507244.1507246&partnerID=40&md5=16980ef7dce898a4177eefc64fc51f7c,"A data word is a sequence of pairs of a letter from a finite alphabet and an element from an infinite set, where the latter can only be compared for equality. To reason about data words, linear temporal logic is extended by the freeze quantifier, which stores the element at the current word position into a register, for equality comparisons deeper in the formula. By translations from the logic to alternating automata with registers and then to faulty counter automata whose counters may erroneously increase at any time, and from faulty and error-free counter automata to the logic, we obtain a complete complexity table for logical fragments defined by varying the set of temporal operators and the number of registers. In particular, the logic with future-time operators and 1 register is decidable but not primitive recursive over finite data words. Adding past-time operators or 1 more register, or switching to infinite data words, causes undecidability. © 2009 ACM.",Computational complexity; Expressiveness,Automata theory; Computability and decidability; Computational complexity; Robots; Translation (languages); Alternating automata; Counter automata; Expressiveness; Finite alphabet; Linear temporal logic; Temporal operators; Undecidability; Temporal logic
Generalizing consistency and other constraint properties to quantified constraints,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249118153&doi=10.1145%2f1507244.1507247&partnerID=40&md5=1c64f7d5583eb27faff15ef3f8c761b8,"Quantified constraints and Quantified Boolean Formulae are typically much more difficult to reason with than classical constraints, because quantifier alternation makes the usual notion of solution inappropriate. As a consequence, basic properties of Constraint Satisfaction Problems (CSPs), such as consistency or substitutability, are not completely understood in the quantified case. These properties are important because they are the basis of most of the reasoning methods used to solve classical (existentially quantified) constraints, and it is desirable to benefit from similar reasoning methods in the resolution of quantified constraints. In this article, we show that most of the properties that are used by solvers for CSP can be generalized to quantified CSP. This requires a rethinking of a number of basic concepts; in particular, we propose a notion of outcome that generalizes the classical notion of solution and on which all definitions are based. We propose a systematic study of the relations which hold between these properties, as well as complexity results regarding the decision of these properties. Finally, and since these problems are typically intractable, we generalize the approach used in CSP and propose weaker, easier to check notions based on locality, which allow to detect these properties incompletely but in polynomial time. © 2009 ACM.",Constraint satisfaction; Quantified Boolean formulae; Quantified constraints,Boolean functions; Computer operating procedures; Polynomial approximation; Basic concepts; Basic properties; Complexity results; Constraint satisfaction; Constraint satisfaction problems; Polynomial-time; Quantified Boolean formulae; Quantified Boolean formulas; Quantified constraints; Reasoning methods; Systematic study; Steelmaking
An algebra of quantum processes,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249141506&doi=10.1145%2f1507244.1507249&partnerID=40&md5=a85020b69c76d60939b841340571b65f,"We introduce an algebra qCCS of pure quantum processes in which communications by moving quantum states physically are allowed and computations are modeled by super-operators, but no classical data is explicitly involved. An operational semantics of qCCS is presented in terms of (nonprobabilistic) labeled transition systems. Strong bisimulation between processes modeled in qCCS is defined, and its fundamental algebraic properties are established, including uniqueness of the solutions of recursive equations. To model sequential computation in qCCS, a reduction relation between processes is defined. By combining reduction relation and strong bisimulation we introduce the notion of strong reduction-bisimulation, which is a device for observing interaction of computation and communication in quantum systems. Finally, a notion of strong approximate bisimulation (equivalently, strong bisimulation distance) and its reduction counterpart are introduced. It is proved that both approximate bisimilarity and approximate reduction-bisimilarity are preserved by various constructors of quantum processes. This provides us with a formal tool for observing robustness of quantum processes against inaccuracy in the implementation of its elementary gates. © 2009 ACM.",Bisimulation; Process algebra; Quantum communication; Quantum computation; Super-operator,Communication; Computational linguistics; Quantum computers; Quantum electronics; Quantum optics; Bisimulation; Process algebra; Quantum communication; Quantum computation; Super-operator; Algebra
Simultaneous checking of completeness and ground confluence for algebraic specifications,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67249165776&doi=10.1145%2f1507244.1507250&partnerID=40&md5=c11c5b28471a30dc17aaead5ff895f46,"Algebraic specifications provide a powerful method for the specification of abstract data types in programming languages and software systems. Completeness and ground confluence are fundamental notions for building algebraic specifications in a correct and modular way. Related works for checking ground confluence are based on the completion techniques or on the test that all critical pairs between axioms are valid with respect to a sufficient criterion for ground confluence. It is generally accepted that such techniques may be very inefficient, even for very small specifications. Indeed, the completion procedure often diverges and there often exist many critical pairs of the axioms. In this article, we present a procedure for simultaneously checking completeness and ground confluence for specifications with free/nonfree constructors and parameterized specifications. If the specification is not complete or not ground confluent, then our procedure will output the set of patterns on whose ground instances a function is not defined and it can easily identify the rules that break ground confluence. In contrast to previous work, our method does not rely on completion techniques and does not require the computation of critical pairs of the axioms. The method is entirely implemented and allowed us to prove the completeness and the ground confluence of many specifications in a completely automatic way, where related techniques diverge or generate very complex proofs. Our system offers two main components: (i) a completeness and ground confluence analyzer that computes pattern trees of defined functions and may generate some proof obligations; and (ii) a procedure to prove (joinable) inductive conjectures which is used to discharge these proof obligations. © 2009 ACM.",Algebraic specifications; Automated deduction; Completeness; Ground confluence; Parameterization; Term rewriting systems,Algebra; Computational mechanics; Computer software; Algebraic specifications; Automated deduction; Completeness; Ground confluence; Term rewriting systems; Specifications
On the proof complexity of deep inference,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149132432&doi=10.1145%2f1462179.1462186&partnerID=40&md5=0a36869e25219f7c5bcf48efc152cd0d,"We obtain two results about the proof complexity of deep inference: (1) Deep-inference proof systems are as powerful as Frege ones, even when both are extended with the Tseitin extension rule or with the substitution rule; (2) there are analytic deep-inference proof systems that exhibit an exponential speedup over analytic Gentzen proof systems that they polynomially simulate. © 2009 ACM.",Analyticity; Calculus of structures; Deep inference; Frege systems; Statman tautologies,Analyticity; Calculus of structures; Deep inference; Frege systems; Statman tautologies; Signal theory
Probabilistic bisimulation as a congruence,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149125110&doi=10.1145%2f1462179.1462181&partnerID=40&md5=80f96e31bd90190d83562a8a67ef0a0d,"We propose both an SOS transition rule format for the generative model of probabilistic processes, and an SOS transition rule format for the reactive model of the probabilistic processes. Our rule formats guarantee that probabilistic bisimulation is a congruence with respect to process algebra operations. Moreover, our rule format for generative process algebras guarantees that the probability of the moves of a given process, if there are any, sum up to 1, and the rule format for reactive process algebras guarantees that the probability of the moves of a given process labeled with the same action, if there are any, sum up to 1. We show that most operations of the probabilistic process algebras studied in the literature are captured by our formats, which, therefore, have practical applications. © 2009 ACM.",Bisimulation; Congruence; Probabilistic process algebra; Transition rule format,Semiconductor switches; Bisimulation; Congruence; Generative models; If there ares; Probabilistic bisimulation; Probabilistic process; Probabilistic process algebra; Process algebras; Reactive models; Reactive process; Rule formats; Transition rule format; Algebra
"Proofs, tests and continuation passing style",2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149134865&doi=10.1145%2f1462179.1462184&partnerID=40&md5=8e2762cb20a956892b7176de52d21f05,"The concept of syntactical duality is central in logic. In particular, the duality defined by classical negation, or more syntactically by left and right in sequents, has been widely used to relate logic and computations. We study the proof/test duality proposed by Girard in his 1999 paper on the meaning of logical rules. In detail, starting from the notion of test proposed by Girard, we develop a notion of test for intuitionistic logic and we give a complete deductive system whose computational interpretation is the target language of the call-by-value and call-by-name continuation passing style translations. © 2009 ACM.",Call-by-name; Call-by-value; Continuations passing style; Intutionistic logic; Lambda calculus; Linear logic; Minimal logic,Computational mechanics; Differentiation (calculus); Call-by-name; Call-by-value; Continuations passing style; Intutionistic logic; Lambda calculus; Linear logic; Minimal logic; Formal logic
The geometry of linear higher-order recursion,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149110351&doi=10.1145%2f1462179.1462180&partnerID=40&md5=f45cec7caed527ce09f4fc4ab13e16dd,"Imposing linearity and ramification constraints allows to weaken higher-order (primitive) recursion in such a way that the class of representable functions equals the class of polynomial-time computable functions, as the works by Leivant, Hofmann, and others show. This article shows that fine-tuning these two constraints leads to different expressive strengths, some of them lying well beyond polynomial time. This is done by introducing a new semantics, called algebraic context semantics. The framework stems from Gonthier's original work (itself a model of Girard's geometry of interaction) and turns out to be a versatile and powerful tool for the quantitative analysis of normalization in the lambda calculus with constants and higher-order recursion. © 2009 ACM.",Geometry of interaction; Higher-order recursion; Implicit computational complexity; Lambda calculus; Type systems,Calculations; Computational complexity; Computational linguistics; Computational mechanics; Differentiation (calculus); Information theory; Polynomial approximation; Semantics; Geometry of interaction; Higher-order recursion; Implicit computational complexity; Lambda calculus; Type systems; Computational geometry
Termination of rewriting under strategies,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62249168036&doi=10.1145%2f1462179.1462182&partnerID=40&md5=32b428f3c3992581d878b96f35d641bb,"A termination proof method for rewriting under strategies, based on an explicit induction on the termination property, is presented and instantiated for the innermost, outermost, and local strategies. Rewriting trees are simulated by proof trees generated with an abstraction mechanism, narrowing and constraints representing sets of ground terms. Abstraction introduces variables to represent normal forms without computing them and to control the narrowing mechanism, well known to easily diverge. The induction ordering is not given a priori, but defined with ordering constraints, incrementally set during the proof. It is established that termination under strategy is equivalent to the construction of finite proof trees schematizing terminating rewriting trees. Sufficient effective conditions to ensure finiteness are studied and the method is illustrated on several examples for each specific strategy. © 2009 ACM.",Abstraction; Induction; Innermost; Local strategy; Narrowing; Ordering constraint; Outermost; Termination,Decision trees; Abstraction; Induction; Innermost; Local strategy; Narrowing; Ordering constraint; Outermost; Termination; Abstracting
A compositional semantics for CHR,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149112521&doi=10.1145%2f1462179.1462183&partnerID=40&md5=defcbfe51714ae7ac2df35205c6c44e9,"Constraint Handling Rules (CHR) is a committed-choice declarative language which has been designed for writing constraint solvers. A CHR program consists of multiheaded guarded rules which allow to rewrite constraints into simpler ones until a solved form is reached. CHR has received considerable attention, both from the practical and from the theoretical side. Nevertheless, due the use of multiheaded clauses, there are several aspects of the CHR semantics which have not been clarified yet. In particular, no compositional semantics for CHR has been defined so far. In this article we introduce a fix-point semantics which characterizes the input/output behavior of a CHR program and which is and-compositional, that is, which allows to retrieve the semantics of a conjunctive query from the semantics of its components. Such a semantics can be used as a basis to define incremental and modular analysis and verification tools. © 2009 ACM.",Semantics,Query languages; Real time systems; Semantics; Compositional semantics; Conjunctive queries; Constraint handling rules; Declarative languages; Fix-point semantics; Input/output behaviors; Modular analysis; Verification tools; Writing constraints; Information theory
PSPACE bounds for rank-1 modal logics,2009,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-62149127322&doi=10.1145%2f1462179.1462185&partnerID=40&md5=d6f9469e415ae2790a2b40f9692f18dd,"For lack of general algorithmic methods that apply to wide classes of logics, establishing a complexity bound for a given modal logic is often a laborious task. The present work is a step towards a general theory of the complexity of modal logics. Our main result is that all rank-1 logics enjoy a shallow model property and thus are, under mild assumptions on the format of their axiomatisation, in PSPACE. This leads to a unified derivation of tight PSPACE-bounds for a number of logics, including K, KD, coalition logic, graded modal logic, majority logic, and probabilistic modal logic. Our generic algorithm moreover finds tableau proofs that witness pleasant proof-theoretic properties including a weak subformula property. This generality is made possible by a coalgebraic semantics, which conveniently abstracts from the details of a given model class and thus allows covering a broad range of logics in a uniform way. © 2009 ACM.",Coalgebra; Resolution; Shallow models,Information theory; Majority logic; Parallel processing systems; Threshold logic; Algorithmic methods; Axiomatisation; Coalgebra; Coalgebraic semantics; Complexity bounds; General theories; Generic algorithms; Modal logic; Model properties; Resolution; Shallow models; Probabilistic logics
A finite equational base for CCS with left merge and communication merge,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449097974&doi=10.1145%2f1459010.1459016&partnerID=40&md5=34e31505b5b9b86269e70454b447158b,"Using the left merge and the communication merge from ACP, we present an equational base (i.e., a ground-complete and ω-complete set of valid equations) for the fragment of CCS without recursion, restriction and relabeling modulo (strong) bisimilarity. Our equational base is finite if the set of actions is finite. © 2009 ACM.",Bisimilarity; CCS; Communication merge; Concurrency; Finite equational base; Handshaking; Left merge; Parallel composition; Process algebra,Algebra; Communication; Bisimilarity; CCS; Communication merge; Concurrency; Finite equational base; Handshaking; Left merge; Parallel composition; Process algebra; Mergers and acquisitions
New results on rewrite-based satisfiability procedures,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449090380&doi=10.1145%2f1459010.1459014&partnerID=40&md5=cd8398e4befdb265f076526791804d3e,"Program analysis and verification require decision procedures to reason on theories of data structures. Many problems can be reduced to the satisfiability of sets of ground literals in theory T. If a sound and complete inference system for first-order logic is guaranteed to terminate on T-satisfiability problems, any theorem-proving strategy with that system and a fair search plan is a T-satisfiability procedure. We prove termination of a rewrite-based first-order engine on the theories of records, integer offsets, integer offsets modulo and lists. We give a modularity theorem stating sufficient conditions for termination on a combination of theories, given termination on each. The above theories, as well as others, satisfy these conditions. We introduce several sets of benchmarks on these theories and their combinations, including both parametric synthetic benchmarks to test scalability, and real-world problems to test performances on huge sets of literals. We compare the rewrite-based theorem prover E with the validity checkers CVC and CVC Lite. Contrary to the folklore that a general-purpose prover cannot compete with reasoners with built-in theories, the experiments are overall favorable to the theorem prover, showing that not only the rewriting approach is elegant and conceptually simple, but has important practical implications. © 2009 ACM.",Automated reasoning; Combination of theories; Decision procedures; Inference; Rewriting; Satisfiability modulo a theory; Scalability; Superposition; Termination,Automata theory; Data structures; Formal logic; Problem solving; Programming theory; Scalability; Theorem proving; Automated reasoning; Combination of theories; Decision procedures; Inference; Rewriting; Satisfiability modulo a theory; Superposition; Termination; Decision theory
Certainty closure: Reliable constraint reasoning with incomplete or erroneous data,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449106909&doi=10.1145%2f1459010.1459013&partnerID=40&md5=3d31410d1226adf4f076bcf190badb3e,"Constraint Programming (CP) has proved an effective paradigm to model and solve difficult combinatorial satisfaction and optimization problems from disparate domains. Many such problems arising from the commercial world are permeated by data uncertainty. Existing CP approaches that accommodate uncertainty are less suited to uncertainty arising due to incomplete and erroneous data, because they do not build reliable models and solutions guaranteed to address the user's genuine problem as she perceives it. Other fields such as reliable computation offer combinations of models and associated methods to handle these types of uncertain data, but lack an expressive framework characterizing the resolution methodology independently of the model. We present a unifying framework that extends the CP formalism in both model and solutions, to tackle ill-defined combinatorial problems with incomplete or erroneous data. The certainty closure framework brings together modeling and solving methodologies from different fields into the CP paradigm to provide reliable and efficient approches for uncertain constraint problems. We demonstrate the applicability of the framework on a case study in network diagnosis. We define resolution forms that give generic templates, and their associated operational semantics, to derive practical solution methods for reliable solutions. © 2009 ACM.",Closure; Incomplete and erroneous data; Reliable solutions; Uncertain constraint satisfaction problem,Automata theory; Computer programming; Constraint theory; Information theory; Programming theory; Steelmaking; Closure; Combinatorial problems; Constraint problems; Constraint programming; Constraint reasonings; Data uncertainties; Generic templates; In networks; Incomplete and erroneous data; Operational semantics; Optimization problems; Practical solutions; Reliable models; Reliable solutions; Uncertain constraint satisfaction problem; Uncertain datum; Constrained optimization
Reasoning about actions with sensing under qualitative and probabilistic uncertainty,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449099833&doi=10.1145%2f1459010.1459015&partnerID=40&md5=ea7c2d9a6899bd21f6c3a0a4dad7a4b3,"We focus on the aspect of sensing in reasoning about actions under qualitative and probabilistic uncertainty. We first define the action language E for reasoning about actions with sensing, which has a semantics based on the autoepistemic description logic ALCK NF, and which is given a formal semantics via a system of deterministic transitions between epistemic states. As an important feature, the main computational tasks in E can be done in linear and quadratic time. We then introduce the action language E+ for reasoning about actions with sensing under qualitative and probabilistic uncertainty, which is an extension of E by actions with nondeterministic and probabilistic effects, and which is given a formal semantics in a system of deterministic, nondeterministic, and probabilistic transitions between epistemic states. We also define the notion of a belief graph, which represents the belief state of an agent after a sequence of deterministic, nondeterministic, and probabilistic actions, and which compactly represents a set of unnormalized probability distributions. Using belief graphs, we then introduce the notion of a conditional plan and its goodness for reasoning about actions under qualitative and probabilistic uncertainty. We formulate the problems of optimal and threshold conditional planning under qualitative and probabilistic uncertainty, and show that they are both uncomputable in general. We then give two algorithms for conditional planning in our framework. The first one is always sound, and it is also complete for the special case in which the relevant transitions between epistemic states are cycle-free. The second algorithm is a sound and complete solution to the problem of finite-horizon conditional planning in our framework. Under suitable assumptions, it computes every optimal finite-horizon conditional plan in polynomial time. We also describe an application of our formalism in a robotic-soccer scenario, which underlines its usefulness in realistic applications. © 2009 ACM.",Action languages; Description logics; Imprecise probabilities; Qualitative and probabilistic uncertainty; Reasoning about actions; Sensing,Computational linguistics; Data description; Formal methods; Information theory; Linguistics; Polynomial approximation; Probabilistic logics; Probability; Query languages; Semantics; Action languages; Description logics; Imprecise probabilities; Qualitative and probabilistic uncertainty; Reasoning about actions; Sensing; Probability distributions
A logical characterization of the counting hierarchy,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449087452&doi=10.1145%2f1459010.1459017&partnerID=40&md5=d395b8bd98e14b4cee75e94f839889de,"In this article we give a logical characterization of the counting hierarchy. The counting hierarchy is the analogue of the polynomial hierarchy, the building block being Probabilistic polynomial time PP instead of NP. We show that the extension of first-order logic by second-order majority quantifiers of all arities describes exactly the problems in the counting hierarchy. We also consider extending the characterization to general proportional quantifiers Q k r interpreted as ""more than an r-fraction of k-ary relations"". We show that the result holds for rational numbers of the form s/2 m but for any other 0 < r < 1 the corresponding logic satisfies the 0-1 law. © 2009 ACM.",Counting hierarchy; Majority quantifiers; Quantifier elimination; The 0-1 law,Formal logic; Polynomial approximation; Building blocks; Counting hierarchy; First-order logic; Logical characterizations; Majority quantifiers; Polynomial hierarchies; Probabilistic polynomial time; Quantifier elimination; Rational numbers; Second orders; The 0-1 law; Majority logic
Arithmetic complexity,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449097809&doi=10.1145%2f1459010.1459012&partnerID=40&md5=f7fdc08beac6acf3a2eb77da346e9618,"We obtain lower bounds on the cost of computing various arithmetic functions and deciding various arithmetic relations from specified primitives. This includes lower bounds for computing the greatest common divisor and deciding coprimeness of two integers, from primitives like addition, subtraction, division with remainder and multiplication. Some of our results are in terms of recursive programs, but they generalize directly to most (plausibly all) algorithms from the specified primitives. Our methods involve some elementary number theory as well as the development of some basic notions and facts about recursive algorithms. © 2009 ACM.",Coprimeness; Greatest common divisor; Lower bounds for arithmetical problems; Recursive programs,Algebra; Control theory; Number theory; Programming theory; Arithmetic complexity; Arithmetic functions; Coprimeness; Elementary number theories; Greatest common divisor; Lower bounds for arithmetical problems; Recursive algorithms; Recursive programs; Recursive functions
Specifying norm-governed computational societies,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59549107586&doi=10.1145%2f1459010.1459011&partnerID=40&md5=a18d8b4e6bac47f963a7910fa1b41417,"Electronic markets, dispute resolution and negotiation protocols are three types of application domains that can be viewed as open agent societies. Key characteristics of such societies are agent heterogeneity, conflicting individual goals and unpredictable behavior. Members of such societies may fail to, or even choose not to, conform to the norms governing their interactions. It has been argued that systems of this type should have a formal, declarative, verifiable, and meaningful semantics. We present a theoretical and computational framework being developed for the executable specification of open agent societies. We adopt an external perspective and view societies as instances of normative systems. In this article, we demonstrate how the framework can be applied to specifying and executing a contract-net protocol. The specification is formalized in two action languages, the C+ language and the Event Calculus, and executed using respective software implementations, the Causal Calculator and the Society Visualizer. We evaluate our executable specification in the light of the presented case study, discussing the strengths and weaknesses of the employed action languages for the specification of open agent societies. © 2009 ACM.",Action language; Agent; Contract-net; Event calculus; Executable specification; Norm; Policy,Calculations; Computational linguistics; Electronic commerce; Formal logic; Information theory; Intelligent agents; Linguistics; Multi agent systems; Query languages; Specifications; Action language; Agent; Contract-net; Event calculus; Executable specification; Norm; Policy; Societies and institutions
Reasoning with recursive loops under the PLP framework,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149115064&doi=10.1145%2f1380572.1380576&partnerID=40&md5=f56c4fd1dfe34a7dc11a08ccf96e5f7a,"Recursive loops in a logic program present a challenging problem to the PLP (Probabilistic Logic Programming) framework. On the one hand, they loop forever so that the PLP backward-chaining inferences would never stop. On the other hand, they may generate cyclic influences, which are disallowed in Bayesian networks. Therefore, in existing PLP approaches, logic programs with recursive loops are considered to be problematic and thus are excluded. In this article, we propose a novel solution to this problem by making use of recursive loops to build a stationary dynamic Bayesian network. We introduce a new PLP formalism, called a Bayesian knowledge base. It allows recursive loops and contains logic clauses of the form A ← A1,Al, true, Context, Types, which naturally formulate the knowledge that the Ais have direct influences on A in the context Context under the type constraints Types. We use the well-founded model of a logic program to define the direct influence relation and apply SLG-resolution to compute the space of random variables together with their parental connections. This establishes a clear declarative semantics for a Bayesian knowledge base. We view a logic program with recursive loops as a special temporal model, where backward-chaining cycles of the form A← A← are interpreted as feedbacks. This extends existing PLP approaches, which mainly aim at (nontemporal) relational models. © 2008 ACM.",Bayesian networks; Cyclic influences; Logic programming; Recursive loops; The well-founded model,Computer networks; Computer programming; Distributed parameter networks; Inference engines; Intelligent networks; Knowledge based systems; Logic programming; Recursive functions; Speech analysis; Speech recognition; Cyclic influences; Logic programs; Recursive loops; The well-founded model; Bayesian networks
Complexity results for security protocols with Diffie-Hellman exponentiation and commuting public key encryption,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149119089&doi=10.1145%2f1380572.1380573&partnerID=40&md5=313eb485e9a4b8efa6c91cb6f5ded977,"We show that the insecurity problem for protocols with modular exponentiation and arbitrary products allowed in exponents is NP-complete. This result is based on a protocol and intruder model which is powerful enough to uncover known attacks on the Authenticated Group Diffie-Hellman (A-GDH.2) protocol suite. To prove our results, we develop a general framework in which the Dolev-Yao intruder is extended by generic intruder rules. This framework is also applied to obtain complexity results for protocols with commuting public key encryption. © 2008 ACM.",Algebraic properties; Complexity; Diffie-Hellman exponentiation; Dolev-Yao model; Protocols,Algebraic properties; Complexity; Diffie-Hellman exponentiation; Dolev-Yao model; Protocols; Computer networks
Verifiable agent interaction in abductive logic programming: The SCIFF framework,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149086600&doi=10.1145%2f1380572.1380578&partnerID=40&md5=97c63c12b92f9853fc7d1ca85d92c535,"SCIFF is a framework thought to specify and verify interaction in open agent societies. The SCIFF language is equipped with a semantics based on abductive logic programming; SCIFF's operational component is a new abductive logic programming proof procedure, also named SCIFF, for reasoning with expectations in dynamic environments. In this article we present the declarative and operational semantics of the SCIFF language, and the termination, soundness, and completeness results of the SCIFF proof procedure, and we demonstrate SCIFF's possible application in the multiagent domain. © 2008 ACM.",Abductive logic programming; Agent interaction protocols; Declarative semantics; Formal properties; IFF proof procedure; Proof-procedures; SCIFF; SOCS (SOcieties of ComputeeS),Flow interactions; Information theory; Linguistics; Logic programming; Semantics; Abductive logic programming; Agent interaction protocols; Declarative semantics; Formal properties; IFF proof procedure; Proof-procedures; SCIFF; SOCS (SOcieties of ComputeeS); Computer programming languages
Open answer set programming with guarded programs,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149116102&doi=10.1145%2f1380572.1380575&partnerID=40&md5=3f32ca48f8115bcb3bf3f9b768ffd606,"Open answer set programming (OASP) is an extension of answer set programming where one may ground a program with an arbitrary superset of the program's constants. We define a fixed-point logic (FPL) extension of Clark's completion such that open answer sets correspond to models of FPL formulas and identify a syntactic subclass of programs, called (loosely) guarded programs. Whereas reasoning with general programs in OASP is undecidable, the FPL translation of (loosely) guarded programs falls in the decidable (loosely) guarded fixed-point logic (μ(L)GF). Moreover, we reduce normal closed ASP to loosely guarded OASP, enabling, for the first time, a characterization of an answer set semantics by μLGF formulas. We further extend the open answer set semantics for programs with generalized literals. Such generalized programs (gPs) have interesting properties, for example, the ability to express infinity axioms. We restrict the syntax of gPs such that both rules and generalized literals are guarded. Via a translation to guarded fixed-point logic, we deduce 2-EXPTIME-completeness of satisfiability checking in such guarded gPs (GgPs). Bound GgPs are restricted GgPs with EXPTIME-complete satisfiability checking, but still sufficiently expressive to optimally simulate computation tree logic (CTL). We translate Datalog lite programs to GgPs, establishing equivalence of GgPs under an open answer set semantics, alternation-free μGF, and Datalog LITE. © 2008 ACM.",Answer set programming; Fixed-point logic; Open domains,Boolean functions; Information theory; Satellite navigation aids; Semantics; Syntactics; Translation (languages); Answer set programming; Fixed-point logic; Fixed-point logics; Open domains; Program translators
Flat and one-variable clauses: Complexity of verifying cryptographic protocols with single blind copying,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149113525&doi=10.1145%2f1380572.1380577&partnerID=40&md5=e38cb11e32b4ad5b63d3fc9b2dfbd177,"Cryptographic protocols with single blind copying were defined and modeled by Comon and Cortier using the new class C of first-order clauses. They showed its satisfiability problem to be in 3-DEXPTIME. We improve this result by showing that satisfiability for this class is NEXPTIME-complete, using new resolution techniques. We show satisfiability to be DEXPTIME-complete if clauses are Horn, which is what is required for modeling cryptographic protocols. While translation to Horn clauses only gives a DEXPTIME upper bound for the secrecy problem for these protocols, we further show that this secrecy problem is actually DEXPTIME-complete. © 2008 ACM.",Cryptographic protocols; First-order logic; Horn clauses; Instantiation-based theorem proving; Resolution,Chlorine compounds; Computer networks; Copying; Logic programming; Cryptographic protocols; First-order logic; Horn clauses; Instantiation-based theorem proving; Resolution; Cryptography
Undecidability of the unification and admissibility problems for modal and description logics,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149098126&doi=10.1145%2f1380572.1380574&partnerID=40&md5=9ee475514e09ac58b6d48da3f7c78cc6,"We show that the unification problem is there a substitution instance of a given formula that is provable in a given logic is undecidable for basic modal logics K and K4 extended with the universal modality. It follows that the admissibility problem for inference rules is undecidable for these logics as well. These are the first examples of standard decidable modal logics for which the unification and admissibility problems are undecidable. We also prove undecidability of the unification and admissibility problems for K and K4 with at least two modal operators and nominals (instead of the universal modality), thereby showing that these problems are undecidable for basic hybrid logics. Recently, unification has been introduced as an important reasoning service for description logics. The undecidability proof for K with nominals can be used to show the undecidability of unification for Boolean description logics with nominals (such as ALCO and SHIQO). The undecidability proof for K with the universal modality can be used to show that the unification problem relative to role boxes is undecidable for Boolean description logics with transitive roles, inverse roles, and role hierarchies (such as SHI and SHIQ). © 2008 ACM.",Admissible rule; Decidability; Description logic; Hybrid logic; Unification,Boolean functions; Computability and decidability; Admissible rule; Decidability; Description logic; Hybrid logic; Unification; Data description
"A uniform approach to constraint-solving for lists, multisets, compact lists, and sets",2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749144766&doi=10.1145%2f1352582.1352583&partnerID=40&md5=d932f73c3d480213e0f752c024c6b32f,"Lists, multisets, and sets are well-known data structures whose usefulness is widely recognized in various areas of computer science. They have been analyzed from an axiomatic point of view with a parametric approach in Dovier et al. [1998], where the relevant unification algorithms have been developed. In this article, we extend these results considering more general constraints, namely, equality and membership constraints and their negative counterparts. © 2008 ACM.",Compact lists; Lists; Membership and equality constraints; Multisets; Sets,Aluminum; Computer networks; Computer science; Computers; File organization; Set theory; Technology; Transients; Constraint Solving; General (CO); Multi-sets; Parametric approach; Unification algorithms; Data structures
Conjunctive query containment and answering under description logic constraints,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749133516&doi=10.1145%2f1352582.1352590&partnerID=40&md5=905c98f9dadc911b29061efce243bed5,"Query containment and query answering are two important computational tasks in databases. While query answering amounts to computing the result of a query over a database, query containment is the problem of checking whether, for every database, the result of one query is a subset of the result of another query. In this article, we deal with unions of conjunctive queries, and we address query containment and query answering under description logic constraints. Every such constraint is essentially an inclusion dependency between concepts and relations, and their expressive power is due to the possibility of using complex expressions in the specification of the dependencies, for example, intersection and difference of relations, special forms of quantification, regular expressions over binary relations. These types of constraints capture a great variety of data models, including the relational, the entity-relationship, and the object-oriented model, all extended with various forms of constraints. They also capture the basic features of the ontology languages used in the context of the Semantic Web. We present the following results on both query containment and query answering. We provide a method for query containment under description logic constraints, thus showing that the problem is decidable, and analyze its computational complexity. We prove that query containment is undecidable in the case where we allow inequalities in the right-hand-side query, even for very simple constraints and queries. We show that query answering under description logic constraints can be reduced to query containment, and illustrate how such a reduction provides upper-bound results with respect to both combined and data complexity. © 2008 ACM.",Computational compexity; Conjunctve queries; Description logics; Query containment,Computability and decidability; Computational complexity; Computational methods; Data description; Database systems; Fuzzy logic; Information theory; Mathematical models; Ontology; Query languages; Semantic Web; (algorithmic) complexity; Binary relations (BR); Computational tasks; Conjunctive queries; Conjunctive query containment; Data complexity; Data modelling; Description logic (DL); Entity-relationship; Expressive power; Object oriented (OO) modeling; Ontology languages; query answering; Query containment; Regular expressions; special forms; Data reduction
Abstract state machines capture parallel algorithms: Correction and extension,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749088971&doi=10.1145%2f1352582.1352587&partnerID=40&md5=347e0991701d919139bf576c17d53613,"We consider parallel algorithms working in sequential global time, for example, circuits or parallel random access machines (PRAMs). Parallel abstract state machines (parallel ASMs) are such parallel algorithms, and the parallel ASM thesis asserts that every parallel algorithm is behaviorally equivalent to a parallel ASM. In an earlier article, we axiomatized parallel algorithms, proved the ASM thesis, and proved that every parallel ASM satisfies the axioms. It turned out that we were too timid in formulating the axioms; they did not allow a parallel algorithm to create components on the fly. This restriction did not hinder us from proving that the usual parallel models, like circuits or PRAMs or even alternating Turing machines, satisfy the postulates. But it resulted in an error in our attempt to prove that parallel ASMs always satisfy the postulates. To correct the error, we liberalize our axioms and allow on-the-fly creation of new parallel components. We believe that the improved axioms accurately express what parallel algorithms ought to be. We prove the parallel thesis for the new, corrected notion of parallel algorithms, and we check that parallel ASMs satisfy the new axioms. © 2008 ACM.",Abstract state machine; ASM thesis; Parallel algorithm; Parallel programming; Postulates for parallel computation,Abstracting; Algorithms; Boolean functions; Contour followers; Evolutionary algorithms; Mathematical models; Parallel processing systems; Scheduling algorithms; Sequential machines; Trees (mathematics); Turing machines; Abstract State Machine (ASM); Alternating Turing machines; Global time; On the fly (OTF); Parallel components; Parallel models; Parallel random access machines (PRAMs); Parallel algorithms
What causes a system to satisfy a specification,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749154214&doi=10.1145%2f1352582.1352588&partnerID=40&md5=6d66b8553a71712680afd2806847d5d7,"Even when a system is proven to be correct with respect to a specification, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. Coverage metrics attempt to check which parts of a system are actually relevant for the verification process to succeed. Recent work on coverage in model checking suggests several coverage metrics and algorithms for finding parts of the system that are not covered by the specification. The work has already proven to be effective in practice, detecting design errors that escape early verification efforts in industrial settings. In this article, we relate a formal definition of causality given by Halpern and Pearl to coverage. We show that it gives significant insight into unresolved issues regarding the definition of coverage and leads to potentially useful extensions of coverage. In particular, we introduce the notion of responsibility, which assigns to components of a system a quantitative measure of their relevance to the satisfaction of the specification. © 2008 ACM.",Causality; Coverage metrics; Model checking; Responsibility,Architectural design; Computer networks; Mathematical models; Model checking; Design errors; Early verification; Formal definitions; Industrial settings; Metrics (CO); verification processes; Specifications
Program termination and well partial orderings,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749128662&doi=10.1145%2f1352582.1352586&partnerID=40&md5=986e4e8fb1fd67fbde967b0d0e1c640d,"The following known observation is useful in establishing program termination: if a transitive relation R is covered by finitely many well-founded relations U1, Un then R is well-founded. A question arises how to bound the ordinal height R of the relation R in terms of the ordinals αi = Ui. We introduce the notion of the stature ∥P∥ of a well partial ordering P and show that R ∥α1 × × αn∥ and that this bound is tight. The notion of stature is of considerable independent interest. We define ∥ P ∥ as the ordinal height of the forest of nonempty bad sequences of P, but it has many other natural and equivalent definitions. In particular, ∥ P ∥ is the supremum, and in fact the maximum, of the lengths of linearizations of P. And ∥α1 × × αn∥ is equal to the natural product α1 ⊗ ⊗ αn. © 2008 ACM.",Covering observation; Game criterion; Program termination; Well partial orderings,program terminations; transitive relations; Microfluidics
Foundational certified code in the Twelf metalogical framework,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749127044&doi=10.1145%2f1352582.1352584&partnerID=40&md5=7df5e0afdcb49e5ab8d867ea9eb571ad,"Foundational certified code systems seek to prove untrusted programs to be safe relative to safety policies given in terms of actual machine architectures, thereby improving the systems' flexibility and extensibility. Using the Twelf metalogical framework, we have constructed a safety policy for the IA-32 architecture with a trusted runtime library. The safety policy is based on a formalized operational semantics. We have also developed a complete, foundational proof that a fully expressive typed assembly language satisfies that safety policy. © 2008 ACM.",Foundational certified code; Logic programming; Metalogic,Codes (standards); Codes (symbols); Information theory; Assembly languages; Certified codes; Machine architectures; Operational semantics; Run-time libraries; Safety policies; Binary codes
Contextual modal type theory,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749090964&doi=10.1145%2f1352582.1352591&partnerID=40&md5=ff9515d43b63def39734843f3c746ac9,"The intuitionistic modal logic of necessity is based on the judgmental notion of categorical truth. In this article we investigate the consequences of relativizing these concepts to explicitly specified contexts. We obtain contextual modal logic and its type-theoretic analogue. Contextual modal type theory provides an elegant, uniform foundation for understanding metavariables and explicit substitutions. We sketch some applications in functional programming and logical frameworks. © 2008 ACM.",Intuitionistic modal logic; Logical frameworks; Type theory,Computer programming; Functional programming; Explicit Substitutions; Logical Framework (LF); Metavariables; Modal logics; Some applications; type theories; Fuzzy logic
Inferring non-suspension conditions for logic programs with dynamic scheduling,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749090965&doi=10.1145%2f1352582.1352585&partnerID=40&md5=2c969f54825a19aa64229465f61c59dc,"A logic program consists of a logic component and a control component. The former is a specification in predicate logic whereas the latter defines the order of subgoal selection. The order of subgoal selection is often controlled with delay declarations that specify that a subgoal is to suspend until some condition on its arguments is satisfied. Reasoning about delay declarations is notoriously difficult for the programmer and it is not unusual for a program and a goal to reduce to a state that contains a subgoal that suspends indefinitely. Suspending subgoals are usually unintended and often indicate an error in the logic or the control. A number of abstract interpretation schemes have therefore been proposed for checking that a given program and goal cannot reduce to such a state. This article considers a reversal of this problem, advocating an analysis that for a given program infers a class of goals that do not lead to suspension. This article shows that this more general approach can have computational, implementational and user-interface advantages. In terms of user-interface, this approach leads to a lightweight point-and-click mode of operation in which, after directing the analyser at a file, the user merely has to inspect the results inferred by the analysis. In terms of implementation, the analysis can be straightforwardly realized as two simple fixpoint computations. In terms of computation, by modeling n different schedulings of n subgoals with a single Boolean function, it is possible to reason about the suspension behavior of large programs. In particular, the analysis is fast enough to be applied repeatedly within the program development cycle. The article also demonstrates that the method is precise enough to locate bugs in existing programs. © 2008 ACM.",Abstract interpretation; Concurrency; Debugging; Logic programming,Abstracting; Boolean functions; Computer debugging; Logic programming; Model checking; Program debugging; Scheduling; User interfaces; Abstract interpretations; Concurrency; Control components; Dynamic scheduling; Fixpoint computations; Mode of operations; Program development; Subgoal selections; Computer circuits
Proof search in Hájek's basic logic,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749150393&doi=10.1145%2f1352582.1352589&partnerID=40&md5=056bcafe526cf29ba18d7e5e9abaca6f,"We introduce a proof system for Hájek's logic BL based on a relational hypersequents framework. We prove that the rules of our logical calculus, called RHBL, are sound and invertible with respect to any valuation of BL into a suitable algebra, called ()[0,1]. Refining the notion of reduction tree that arises naturally from RHBL, we obtain a decision algorithm for BL provability whose running time upper bound is 2O(n), where n is the number of connectives of the input formula. Moreover, if a formula is unprovable, we exploit the constructiveness of a polynomial time algorithm for leaves validity for providing a procedure to build countermodels in ()[0, 1]. Finally, since the size of the reduction tree branches is O(n3), we can describe a polynomial time verification algorithm for BL unprovability. © 2008 ACM.",Automated deduction; Countermodel building; Fuzzy logic,Algebra; Computer networks; Fuzzy logic; Basic logic; decision algorithms; Hypersequents; proof search; proof systems; Running time; Upper bounds; Trees (mathematics)
Bounds on the automata size for Presburger arithmetic,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149174493&doi=10.1145%2f1342991.1342995&partnerID=40&md5=a750a11b0ff77bc9ff9019fb5d741394,"Automata provide a decision procedure for Presburger arithmetic. However, until now only crude lower and upper bounds were known on the sizes of the automata produced by the automata-based approach for Presburger arithmetic. In this article, we give an upper bound on the number of states of the minimal deterministic automaton for a Presburger arithmetic formula. This bound depends on the length of the formula and the quantifiers occurring in it. We establish the upper bound by comparing the automata for Presburger arithmetic formulas with the formulas produced by a quantifier-elimination method. We show that our bound is tight, also for nondeterministic automata. Moreover, we provide automata constructions for atomic formulas and establish lower bounds for the automata for linear equations and inequations. © 2008 ACM.",Automata-based decision procedures; Complexity; Presburger arithmetic; Quantifier elimination,Decision theory; Linear equations; Numerical methods; Automata-based decision procedures; Presburger arithmetics; Quantifier elimination; Automata theory
A logic of nonmonotone inductive definitions,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149166294&doi=10.1145%2f1342991.1342998&partnerID=40&md5=d25e882ac9538dd801bb1bb143926307,"Well-known principles of induction include monotone induction and different sorts of nonmonotone induction such as inflationary induction, induction over well-founded sets and iterated induction. In this work, we define a logic formalizing induction over well-founded sets and monotone and iterated induction. Just as the principle of positive induction has been formalized in FO(LFP), and the principle of inflationary induction has been formalized in FO(IFP), this article formalizes the principle of iterated induction in a new logic for Nonmonotone Inductive Definitions (ID-logic). The semantics of the logic is strongly influenced by the well-founded semantics of logic programming. This article discusses the formalisation of different forms of (non-)monotone induction by the well-founded semantics and illustrates the use of the logic for formalizing mathematical and common-sense knowledge. To model different types of induction found in mathematics, we define several subclasses of definitions, and show that they are correctly formalized by the well-founded semantics. We also present translations into classical first or second order logic. We develop modularity and totality results and demonstrate their use to analyze and simplify complex definitions. We illustrate the use of the logic for temporal reasoning. The logic formally extends Logic Programming, Abductive Logic Programming and Datalog, and thus formalizes the view on these formalisms as logics of (generalized) inductive definitions. © 2008 ACM.",Classical logic; Inductive definitions; Logic programming,Database systems; Iterative methods; Mathematical models; Semantics; Classical logic; Inductive definitions; Monotone induction; Nonmonotone induction; Logic programming
A comprehensive combination framework,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149146340&doi=10.1145%2f1342991.1342992&partnerID=40&md5=afae92102d52775889ad83beedaa43e3,"We define a general notion of a fragment within higher-order type theory; a procedure for constraint satisfiability in combined fragments is outlined, following Nelson-Oppen schema. The procedure is in general only sound, but it becomes terminating and complete when the shared fragment enjoys suitable noetherianity conditions and admits an abstract version of a Keisler-Shelah-like isomorphism theorem. We show that this general decidability transfer result covers recent work on combination in first-order theories as well as in various intensional logics such as description, modal, and temporal logics. © 2008 ACM.",Combination; Decision procedures; Higher-order logic; Modal and description logics; Satisfiability modulo theory,Computability and decidability; Decision theory; Modal analysis; Temporal logic; Theorem proving; Combination; Decision procedures; Higher-order logic; Modal and description logics; Satisfiability modulo theory; Combinatorial mathematics
Alternating timed automata,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149167521&doi=10.1145%2f1342991.1342994&partnerID=40&md5=2c1d57e6b60f9f2b7c6bfbeee0a0aa8e,"A notion of alternating timed automata is proposed. It is shown that such automata with only one clock have decidable emptiness problem over finite words. This gives a new class of timed languages that is closed under boolean operations and which has an effective presentation. We prove that the complexity of the emptiness problem for alternating timed automata with one clock is nonprimitive recursive. The proof gives also the same lower bound for the universality problem for nondeterministic timed automata with one clock. We investigate extension of the model with epsilon-transitions and prove that emptiness is undecidable. Over infinite words, we show undecidability of the universality problem. © 2008 ACM.",Alternation; Emptyness problem; Timed automata,Computational complexity; Computer programming languages; Problem solving; Theorem proving; Alternation; Emptyness problem; Timed automata; Automata theory
Durations and parametric model-checking in timed automata,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149107636&doi=10.1145%2f1342991.1342996&partnerID=40&md5=dcebf14b883fae465b98c0082fb343db,"We consider the problem of model-checking a parametric extension of the logic TCTL over timed automata and establish its decidability. Given a timed automaton, we show that the set of durations of runs starting from a region and ending in another region is definable in Presburger arithmetic (when the time domain is discrete) or in a real arithmetic (when the time domain is dense). Using this logical definition, we show that the parametric model-checking problem for the logic TCTL can be solved algorithmically; the proof of this result is simple. More generally, we are able to effectively characterize the values of the parameters that satisfy the parametric TCTL formula with respect to the given timed automaton. © 2008 ACM.",Model-checking; Presburger arithmetic; Timed automata,Automata theory; Computability and decidability; Parameter estimation; Problem solving; Presburger arithmetic; TCTL formulas; Timed automata; Model checking
Coordination in answer set programming,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149093972&doi=10.1145%2f1342991.1342993&partnerID=40&md5=f05264d6c3e0918bf6dc66817ad37a1b,"This article studies a semantics of multiple logic programs, and synthesizes a program having such a collective semantics. More precisely, the following two problems are considered: given two logic programs P1 and P2, which have the collections of answer sets AS(P1) and AS(P2), respectively; (i) find a program Q which has the set of answer sets such that AS(Q) = AS(P1) AS(P2); (ii) find a program R which has the set of answer sets such that AS(R) = AS(P1) ∩ AS(P2). A program Q satisfying the condition (i) is called generous coordination of P1 and P2; and R satisfying (ii) is called rigorous coordination of P1 and P2. Generous coordination retains all of the answer sets of each program, but permits the introduction of additional answer sets of the other program. By contrast, rigorous coordination forces each program to give up some answer sets, but the result remains within the original answer sets for each program. Coordination provides a program that reflects the meaning of two or more programs. We provide methods for constructing these two types of coordination and address its application to logic-based multi-agent systems. © 2008 ACM.",Answer set programming; Coordination; Multiagent systems,Formal logic; Multi agent systems; Problem solving; Semantics; Answer set programming; Answer sets; Coordination; Computer programming
First-order complete and computationally complete query languages for spatio-temporal databases,2008,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149083458&doi=10.1145%2f1342991.1342997&partnerID=40&md5=b55af3526879cf35f34bb15c715edc60,"We address a fundamental question concerning spatio-temporal database systems: ""What are exactly spatio-temporal queries?"" We define spatio-temporal queries to be computable mappings that are also generic, meaning that the result of a query may only depend to a limited extent on the actual internal representation of the spatio-temporal data. Genericity is defined as invariance under groups of geometric transformations that preserve certain characteristics of spatio-temporal data (e.g., collinearity, distance, velocity, acceleration,...). These groups depend on the notions that are relevant in particular spatio-temporal database applications. These transformations also have the distinctive property that they respect the monotone and unidirectional nature of time. We investigate different genericity classes with respect to the constraint database model for spatio-temporal databases and we identify sound and complete languages for the first-order and the computable queries in these genericity classes. We distinguish between genericity determined by time-invariant transformations, genericity notions concerning physical quantities and genericity determined by time-dependent transformations. © 2008 ACM.",Constraint databases; Moving objects; Query languages; Spatial databases; Spatio-temporal databases,Computational geometry; Invariance; Knowledge representation; Mathematical models; Mathematical transformations; Constraint databases; Moving objects; Spatial databases; Spatio-temporal databases; Query languages
Outlier detection by logic programming,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049028103&doi=10.1145%2f1297658.1297665&partnerID=40&md5=211cd997b775afe538f156057e235a51,"The development of effective knowledge discovery techniques has become a very active research area in recent years due to the important impact it has had in several relevant application domains. One interesting task therein is that of singling out anomalous individuals from a given population, for example, to detect rare events in time-series analysis settings, or to identify objects whose behavior is deviant w.r.t. a codified standard set of rules. Such exceptional individuals are usually referred to as outliers in the literature. In this article, the concept of outlier is formally stated in the context of knowledge-based systems, by generalizing that originally proposed in Angiulli et al. [2003] in the context of default theories. The chosen formal framework here is that of logic programming, wherein potential applications of techniques for outlier detection are thoroughly discussed. The proposed formalization is a novel one and helps to shed light on the nature of outliers occurring in logic bases. Also the exploitation of minimality criteria in outlier detection is illustrated. The computational complexity of outlier detection problems arising in this novel setting is also thoroughly investigated and accounted for in the paper. Finally, rewriting algorithms are proposed that transform any outlier detection problem into an equivalent inference problem under stable model semantics, thereby making outlier computation effective and realizable on top of any stable model solver. © 2007 ACM.",Computational complexity; Logic programming; Nonmonotonic reasoning; Outlier detection,Algorithms; Computational complexity; Knowledge based systems; Logic programming; Optimization; Time series analysis; Default theories; Minimality criteria; Nonmonotonic reasoning; Outlier detection; Data mining
A game-based framework for CTL counterexamples and 3-valued abstraction-refinement,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049004150&doi=10.1145%2f1297658.1297659&partnerID=40&md5=0f0b1d433a62e8651ef439599a60cf0b,"This work exploits and extends the game-based framework of CTL model checking for counterexample and incremental abstraction-refinement. We define a game-based CTL model checking for abstract models over the 3-valued semantics, which can be used for verification as well as refutation. The model checking process of an abstract model may end with an indefinite result, in which case we suggest a new notion of refinement, which eliminates indefinite results of the model checking. This provides an iterative abstraction-refinement framework. This framework is enhanced by an incremental algorithm, where refinement is applied only where indefinite results exist and definite results from prior iterations are used within the model checking algorithm. We also define the notion of annotated counterexamples, which are sufficient and minimal counterexamples for full CTL. We present an algorithm that uses the game board of the model checking game to derive an annotated counterexample in case the examined system model refutes the checked formula. © 2007 ACM.",3-valued semantics; Abstraction-refinement; Counterexamples; CTL; Model checking games; Temporal logic,Algorithms; Game theory; Optimization; Problem solving; Semantics; Temporal logic; Abstract models; Abstraction-refinement; Counterexamples; Model checking games; Model checking
A concrete framework for environment machines,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-36448989150&doi=10.1145%2f1297658.1297664&partnerID=40&md5=fe4aa2ce4815613a3fc964db78a8eba4,"We materialize the common understanding that calculi with explicit substitutions provide an intermediate step between an abstract specification of substitution in the lambda-calculus and its concrete implementations. To this end, we go back to Curien's original calculus of closures (an early calculus with explicit substitutions), we extend it minimally so that it can also express one-step reduction strategies, and we methodically derive a series of environment machines from the specification of two one-step reduction strategies for the lambda-calculus: normal order and applicative order. The derivation extends Danvy and Nielsen's refocusing-based construction of abstract machines with two new steps: one for coalescing two successive transitions into one, and the other for unfolding a closure into a term and an environment in the resulting abstract machine. The resulting environment machines include both the Krivine machine and the original version of Krivine's machine, Felleisen et al.'s CEK machine, and Leroy's Zinc abstract machine. © 2007 ACM.",Abstract machines; Closures; Derivation; Explicit substitutions,Differentiation (calculus); Numerical methods; Optimization; Problem solving; Specification languages; Abstract machines; Curien's original calculus; Explicit substitutions; Lambda calculus; Automata theory
Verifying nondeterministic probabilistic channel systems against ω-regular linear-time properties,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049008643&doi=10.1145%2f1297658.1297663&partnerID=40&md5=a7e605066f4c51d6bd2e9e48effaa0bb,"Lossy channel systems (LCS's) are systems of finite state processes that communicate via unreliable unbounded fifo channels. We introduce NPLCS's, a variant of LCS's where message losses have a probabilistic behavior while the component processes behave nondeterministically, and study the decidability of qualitative verification problems for -regular linear-time properties. We show that - -in contrast to finite-state Markov decision processes - -the satisfaction relation for linear-time formulas depends on the type of schedulers that resolve the nondeterminism. While the qualitative model checking problem for the full class of history-dependent schedulers is undecidable, the same question for finite-memory schedulers can be solved algorithmically. Additionally, some special kinds of reachability, or recurrent reachability, qualitative properties yield decidable verification problems for the full class of schedulers, which - -for this restricted class of problems - -are as powerful as finite-memory schedulers, or even a subclass of them. © 2007 ACM.",Communication protocols; Lossy channels; Markov decision processes; Probabilistic models,Automata theory; Hidden Markov models; Linear programming; Network protocols; Problem solving; Lossy channel systems (LCS); Markov decision processes; Probabilistic models; Unbounded fifo channels; Channel estimation
A formally verified proof of the prime number theorem,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049032802&doi=10.1145%2f1297658.1297660&partnerID=40&md5=8ce1900359536af2c292f6a1b0ccc57a,"The prime number theorem, established by Hadamard and de la Vallée Poussin independently in 1896, asserts that the density of primes in the positive integers is asymptotic to 1/ln x. Whereas their proofs made serious use of the methods of complex analysis, elementary proofs were provided by Selberg and Erdös in 1948. We describe a formally verified version of Selberg's proof, obtained using the Isabelle proof assistant. © 2007 ACM.",Formal verification; Prime number theorem,Asymptotic analysis; Formal logic; Integer programming; Large scale systems; Theorem proving; Complex analysis; Formal verification; Prime number theorem; Selberg's proof; Number theory
Polymorphic type inference for the named nested relational calculus,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049028529&doi=10.1145%2f1297658.1297661&partnerID=40&md5=da85c8ee721bb30f75be7de5704fd06a,"The named nested relational calculus is the canonical query language for the complex object database model and is equipped with a natural static type system. Given an expression in the language, without type declarations for the input variables, there is the problem of whether there are any input type declarations under which the expression is well-typed. Moreover, if there are, then which are they, and what is the corresponding output type for each of these This problem is solved by a logic-based approach, and the decision problem is shown to be NP-complete. © 2007 ACM.",Complexity; Named nested relational calculus; Typability; Type inference,Computational complexity; Differentiation (calculus); Model checking; Problem solving; Relational database systems; Database models; Named nested relational calculus; Type inference; Inference engines
Predicate abstraction with indexed predicates,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049005548&doi=10.1145%2f1297658.1297662&partnerID=40&md5=fc2ef561c7da5a1dc1abac72f52819f7,"Predicate abstraction provides a powerful tool for verifying properties of infinite-state systems using a combination of a decision procedure for a subset of first-order logic and symbolic methods originally developed for finite-state model checking. We consider models containing first-order state variables, where the system state includes mutable functions and predicates. Such a model can describe systems containing arbitrarily large memories, buffers, and arrays of identical processes. We describe a form of predicate abstraction that constructs a formula over a set of universally quantified variables to describe invariant properties of the first-order state variables. We provide a formal justification of the soundness of our approach and describe how it has been used to verify several hardware and software designs, including a directory-based cache coherence protocol. © 2007 ACM.",Abstract interpretation; Cache-coherence protocols; Formal verification; Infinite-state verification; Invariant synthesis; Predicate abstraction,Cache memory; Computer aided software engineering; Decision theory; Invariance; Model checking; Software design; Abstract interpretation; Cache coherence protocols; Cache-coherence protocols; Formal verification; Infinite-state verification; Invariant synthesis; Predicate abstraction; Finite automata
First-order queries on structures of bounded degree are computable with constant delay,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548409905&doi=10.1145%2f1276920.1276923&partnerID=40&md5=42491bbaba5890bddeeab9f13cf60923,"A relational structure is d-degree-bounded, for some integer d, if each element of the domain belongs to at most d tuples. In this paper, we revisit the complexity of the evaluation problem of not necessarily Boolean first-order (FO) queries over d-degree-bounded structures. Query evaluation is considered here as a dynamical process. We prove that any FO query on d-degree-bounded structures belongs to the complexity class constant-Delaylin, that is, can be computed by an algorithm that has two separate parts: it has a precomputation step of time linear in the size of the structure and then, it outputs all solutions (i.e., tuples that satisfy the formula) one by one with a constant delay (i.e., depending on the size of the formula only) between each. Seen as a global process, this implies that queries on d-degree-bounded structures can be evaluated in total time f(φ).(S + φ(S)) and space g(φ).S where S is the structure, φ is the formula, φ(S) is the result of the query and f, g are some fixed functions. Among other things, our results generalize a result of Seese on the data complexity of the model-checking problem for d-degree-bounded structures. Besides, the originality of our approach compared to related results is that it does not rely on the Hanf's model-theoretic technique and is simple and informative since it essentially rests on a quantifier elimination method. © 2007 ACM.",Computational complexity; Enumeration problems; First-order logic,Boolean algebra; Computational complexity; Dynamical systems; Integer programming; Problem solving; Query languages; D-degree-bounded; Enumeration problems; First-order logic; Hanf's model-theoretic technique; Data structures
The axiomatic translation principle for modal logic,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548406879&doi=10.1145%2f1276920.1276921&partnerID=40&md5=c0f98520beb6a79cf55860b7cd34b8d8,"In this paper we present a translation principle, called the axiomatic translation, for reducing propositional modal logics with background theories, including triangular properties such as transitivity, Euclideanness and functionality, to decidable fragments of first-order logic. The goal of the axiomatic translation principle is to find simplified theories, which capture the inference problems in the original theory, but in a way that can be readily automated and is easier to deal with by existing (first-order) theorem provers than the standard translation. The principle of the axiomatic translation is conceptually very simple and can be almost completely automated. Soundness is automatic under reasonable assumptions, general decidability results can be stated and termination of ordered resolution is easily achieved. The non-trivial part of the approach is proving completeness. We prove results of completeness, decidability, model generation, the small model property and the interpolation property for a number of common and less common modal logics. We also present results of experiments with a number of first-order logic theorem provers which are very encouraging. © 2007 ACM.",Completeness; Decidability; Small model property; Translation approach,Computability and decidability; Interpolation; Logic programming; Modal analysis; Problem solving; Theorem proving; Axiomatic translation; Euclideanness; Transitivity; Triangular properties; Translation (languages)
Probabilistic abstraction for model checking: An approach based on property testing,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548437525&doi=10.1145%2f1276920.1276922&partnerID=40&md5=f70d9eeb19b0fac1acf73e3fd39af0a7,"The goal of model checking is to verify the correctness of a given program, on all its inputs. The main obstacle, in many cases, is the intractably large size of the program's transition system. Property testing is a randomized method to verify whether some fixed property holds on individual inputs, by looking at a small random part of that input. We join the strengths of both approaches by introducing a new notion of probabilistic abstraction, and by extending the framework of model checking to include the use of these abstractions. Our abstractions map transition systems associated with large graphs to small transition systems associated with small random subgraphs. This reduces the original transition system to a family of small, even constant-size, transition systems. We prove that with high probability, sufficiently incorrect programs will be rejected (ε-robustness). We also prove that under a certain condition (exactness), correct programs will never be rejected (soundness). Our work applies to programs for graph properties such as bipartiteness, k-colorability, or any ∃∀ first order graph properties. Our main contribution is to show how to apply the ideas of property testing to syntactic programs for such properties. We give a concrete example of an abstraction for a program for bipartiteness. Finally, we show that the relaxation of the test alone does not yield transition systems small enough to use the standard model checking method. More specifically, we prove, using methods from communication complexity, that the OBDD size remains exponential for approximate bipartiteness. © 2007 ACM.",Approximate verification; Model checking; Probabilistic abstraction; Probabilistic verification; Property testing,Approximation theory; Computational complexity; Graph theory; Probabilistic logics; Random processes; Approximate verification; Bipartiteness; Program's transition system; Property testing; Syntactic programs; Model checking
A sequent calculus and a theorem prover for standard conditional logics,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548383817&doi=10.1145%2f1276920.1276924&partnerID=40&md5=a0f8ab22dae684f3c5886e83603125df,"In this paper we present a cut-free sequent calculus, called SeqS, for some standard conditional logics. The calculus uses labels and transition formulas and can be used to prove decidability and space complexity bounds for the respective logics. We also show that these calculi can be the base for uniform proof systems. Moreover, we present CondLean, a theorem prover in Prolog for these calculi. © 2007 ACM.",Analytic sequent calculi; Automated deduction; Conditional logics; Labeled deductive systems; Logic programming; Proof theory,Automation; Computational complexity; Logic programming; Theorem proving; Proof systems; Sequent calculus; Space complexity bounds; Differentiation (calculus)
Removing propagation redundant constraints in redundant modeling,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548399753&doi=10.1145%2f1276920.1276925&partnerID=40&md5=25222429a989c746a0f79251d69aacf6,"A widely adopted approach to solving constraint satisfaction problems combines systematic tree search with various degrees of constraint propagation for pruning the search space. One common technique to improve the execution efficiency is to add redundant constraints, which are constraints logically implied by others in the problem model. However, some redundant constraints are propagation redundant and hence do not contribute additional propagation information to the constraint solver. Redundant constraints arise naturally in the process of redundant modeling where two models of the same problem are connected and combined through channeling constraints. In this paper, we give general theorems for proving propagation redundancy of one constraint with respect to channeling constraints and constraints in the other model. We illustrate, on problems from CSPlib (http://www.csplib.org), how detecting and removing propagation redundant constraints in redundant modeling can speed up search by several order of magnitudes. © 2007 ACM.",Constraint propagation; Redundant constraints; Redundant modeling,Computer simulation; Constraint theory; Mathematical models; Online searching; Redundancy; Trees (mathematics); Constraint propagation; Redundant constraints; Redundant modeling; Problem solving
Probabilistic interval XML,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548389660&doi=10.1145%2f1276920.1276926&partnerID=40&md5=6782469fce21986f73c1e571af2f405a,"Interest in XML databases has been expanding rapidly over the last few years. In this paper, we study the problem of incorporating probabilistic information into XML databases. We propose the Probabilistic Interval XML (PIXML for short) data model in this paper. Using this data model, users can express probabilistic information within XML markups. In addition, we provide two alternative formal model-theoretic semantics for PIXML data. The first semantics is a global semantics which is relatively intuitive, but is not directly amenable to computation. The second semantics is a local semantics which supports efficient computation. We prove several correspondence results between the two semantics. To our knowledge, this is the first formal model theoretic semantics for probabilistic interval XML. We then provide an operational semantics that may be used to compute answers to queries and that is correct for a large class of probabilistic instances. © 2007 ACM.",Semistructured Databases; XML,Computation theory; Data structures; Database systems; Information analysis; Probability; Semantics; Probabilistic information; Semistructured Databases; Theoretic semantics; XML
"Ordinary Interactive Small-Step Algorithms, III",2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547509866&doi=10.1145%2f1243996.1243999&partnerID=40&md5=6801ac06e44e01bea90dec570747c69b,"This is the third in a series of three articles extending the proof of the Abstract State Machine thesis-that arbitrary algorithms are behaviorally equivalent to abstract state machines-to algorithms that can interact with their environments during a step, rather than only between steps. As in the first two articles of the series, we are concerned here with ordinary, small-step, interactive algorithms. © 2007, ACM. All rights reserved.",abstract state machines; Algorithms; equivalence of algorithms; interaction; postulates; Sequential algorithms; Theory,Algorithms; Information retrieval; Query languages; Semantics; Abstracting; Abstract state machines; Equivalence of algorithms; Sequential algorithms; Interaction; Postulates; Computational methods
PELCR: Parallel environment for optimal lambda-calculus reduction,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547536545&doi=10.1145%2f1243996.1243997&partnerID=40&md5=67542af13c7b63fc599ec4c04fc32819,"In this article we present the implementation of an environment supporting Lévy's optimal reduction for the -calculus on parallel (or distributed) computing systems. In a similar approach to Lamping's, we base our work on a graph reduction technique, known as directed virtual reduction, which is actually a restriction of Danos-Regnier virtual reduction. The environment, which we refer to as PELCR (parallel environment for optimal lambda-calculus reduction), relies on a strategy for directed virtual reduction, namely half combustion. While developing PELCR we adopted both a message aggregation technique, allowing reduction of the communication overhead, and a fair policy for distributing dynamically originated load among processors. We also present an experimental study demonstrating the ability of PELCR to definitely exploit the parallelism intrinsic to -terms while performing the reduction. We show how PELCR allows achieving up to 70 - 80% of the ideal speedup on last generation multiprocessor computing systems. As a last note, the software modules have been developed with the C language and using a standard interface for message passing, that is, MPI, thus making PELCR itself a highly portable software package. © 2007 ACM.",Functional programming; Geometry of interaction; Linear logic; Optimal reduction; Parallel implementation; Virtual reduction,C (programming language); Computational methods; Functional programming; Message passing; Software packages; Virtual reality; Geometry of interaction; Linear logic; Optimal reduction; Parallel implementation; Virtual reduction; Formal logic
Semantical characterizations and complexity of equivalences in answer set programming,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547509865&doi=10.1145%2f1243996.1244000&partnerID=40&md5=b659d8fa1aa176ce3fe8543645efa175,"In recent research on nonmonotonic logic programming, repeatedly strong equivalence of logic programs P and Q has been considered, which holds if the programs PR and QR have the same answer sets for any other program R. This property strengthens the equivalence of P and Q with respect to answer sets (which is the particular case for R=), and has its applications in program optimization, verification, and modular logic programming. In this article, we consider more liberal notions of strong equivalence, in which the actual form of R may be syntactically restricted. On the one hand, we consider uniform equivalence where R is a set of facts, rather than a set of rules. This notion, which is well-known in the area of deductive databases, is particularly useful for assessing whether programs P and Q are equivalent as components of a logic program which is modularly structured. On the other hand, we consider relativized notions of equivalence where R ranges over rules over a fixed alphabet, and thus generalize our results to relativized notions of strong and uniform equivalence. For all these notions, we consider disjunctive logic programs in the propositional (ground) case as well as some restricted classes, providing semantical characterizations and analyzing the computational complexity. Our results, which naturally extend to answer set semantics for programs with strong negation, complement the results on strong equivalence of logic programs and pave the way for optimizations in answer set solvers as a tool for input-based problem solving. © 2007 ACM.",Answer set semantics; Computational complexity; Program optimization; Stable models; Strong equivalence; Uniform equivalence,Characterization; Computational complexity; Logic programming; Mathematical models; Optimization; Problem solving; Answer set semantics; Program optimization; Stable models; Strong equivalence; Uniform equivalence; Semantics
Paraconsistent reasoning and preferential entailments by signed quantified Boolean formulae,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547499338&doi=10.1145%2f1243996.1244001&partnerID=40&md5=86937c09d948336f544be4a6094e268b,"We introduce a uniform approach of representing a variety ofparaconsistent nonmonotonic formalisms by quantified Booleanformulae (QBFs) in the context of multiple-valued logics. We showthat this framework provides a useful platform for capturing, in asimple and natural way, a wide range of methods for preferentialreasoning. The outcome is a subtle approach to represent theunderlying formalisms, which induces a straightforward way tocompute the corresponding entailments: By incorporatingoff-the-shelf QBF solvers it is possible to simulate within ourframework various kinds of preferential formalisms, among which arePriest's logic LPm of reasoning with minimal inconsistency, Batens'adaptive logic ACLuNs2, Besnard and Schaub's inference relation&vbar;= n, a variety of formula-preferentialsystems, some bilattice-based preferential relations (e.g.,&vbar;= I1 and&vbar;= I2), and consequencerelations for reasoning with graded uncertainty, such as thefour-valued logic &vbar;= 4 c. © 2007 ACM.",Paraconsistent and nonmonotonic reasoning; Preferential semantics; Quantified Boolean formulae,Computational methods; Formal logic; Uncertainty analysis; Nonmonotonic reasoning; Preferential semantics; Quantified Boolean formulae; Boolean algebra
Recycling computed answers in rewrite systems for abduction,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247277187&doi=10.1145%2f1227839.1227841&partnerID=40&md5=b1ab17a1ab1573ec691f51764c5440c7,"In rule-based systems, goal-oriented computations correspond naturally to the possible ways that an observation may be explained. In some applications, we need to compute explanations for a series of observations with the same domain. The question arises as to whether previously computed answers can be recycled. A yes answer could result in substantial savings of repeated computations. For systems based on classical logic, the answer is yes. For nonmonotonic systems, however, one tends to believe that the answer should be no, since recycling is a form of adding information. In this article, we show that computed answers can always be recycled, in a nontrivial way, for the class of rewrite procedures proposed earlier by the authors for logic programs with negation. We present some experimental results on an encoding of the logistics domain. © 2007 ACM.",Abduction; Logic programming; Partial stable model semantics; Recycling; Rewrite systems; Stable model semantics,Computation theory; Computer systems; Encoding (symbols); Information theory; Logic programming; Partial stable model semantics; Rewrite systems; Stable model semantics; Data processing
The arithmetical complexity of dimension and randomness,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247195617&doi=10.1145%2f1227839.1227845&partnerID=40&md5=85631d50785efe5d2713db84070f554e,"Constructive dimension and constructive strong dimension are effectivizations of the Hausdorff and packing dimensions, respectively. Each infinite binary sequence A is assigned a dimension dim(A) [0,1] and a strong dimension Dim(A) [0,1]. Let DIMα and DIMα str be the classes of all sequences of dimension α and of strong dimension α, respectively. We show that DIM0 is properly 02, and that for all Δ0 2-computable α (0, 1], DIMα is properly 03. To classify the strong dimension classes, we use a more powerful effective Borel hierarchy where a coenumerable predicate is used rather than an enumerable predicate in the definition of the 0 1 level. For all Δ02-computable α [0, 1), we show that DIMαstr is properly in the 03 level of this hierarchy. We show that DIM 1str is properly in the 02 level of this hierarchy. We also prove that the class of Schnorr random sequences and the class of computably random sequences are properly 03. © 2007 ACM.",Arithmetical hierarchy; Computable randomness; Constructive dimension; Schnorr randomness; Wadge reductions,Binary sequences; Computational complexity; Digital arithmetic; Hierarchical systems; Arithmetical hierarchy; Computable randomness; Constructive dimension; Schnorr randomness; Wadge reductions; Random processes
Logical definability and query languages over ranked and unranked trees,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247241155&doi=10.1145%2f1227839.1227843&partnerID=40&md5=c7d6214a069fc867233322f167d6d187,"We study relations on trees defined by first-order constraints over a vocabulary that includes the tree extension relation T ≺ T′ (holding if and only if every branch of T extends to a branch of T′), unary node-tests, and a binary relation checking whether the domains of two trees are equal. We consider both ranked and unranked trees. These are trees with and without a restriction on the number of children of nodes. We adopt the model-theoretic approach to tree relations and study relations definable over the structure consisting of the set of all trees and the aforementioned predicates. We relate definability of sets and relations of trees to computability by tree automata. We show that some natural restrictions correspond to familiar logics in the more classical setting where every tree is a structure over a fixed vocabulary, and to logics studied in the context of XML pattern languages. We then look at relational calculi over collections of trees, and obtain quantifier-restriction results that give us bounds on the expressive power and complexity. As unrestricted relational calculi can express problems that are complete for each level of the polynomial hierarchy, we look at their restrictions, corresponding to the restricted logics over the family of all unranked trees, and find several calculi with low (NC1) data complexity which still express properties important for database and document applications. We also give normal forms for safe queries in the calculus. © 2007 ACM.",Model theory; Query languages; Ranked trees; Tree automata; Unranked trees,Binary sequences; Computational complexity; Constraint theory; Polynomial approximation; Query languages; XML; Model theory; Ranked trees; Tree automata; Unranked trees; Decision trees
Where fail-safe default logics fail,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247264467&doi=10.1145%2f1227839.1227842&partnerID=40&md5=c71fa3d7f73d19e9dd619dd34155aa84,"Reiter's original definition of default logic allows for the application of a default that contradicts one previously applied. We call this condition failure. The possibility of generating failures has been in the past considered a semantical problem, and variants have been proposed to solve it. We show that it is instead a computational feature that is needed to encode some domains into default logic. © 2007 ACM.",Default logic; Polynomial-time translations,Computational methods; Computer science; Failure analysis; Problem solving; Semantics; Computational features; Semantical problems; Logic programming
On unification for bounded distributive lattices,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247255520&doi=10.1145%2f1227839.1227844&partnerID=40&md5=2f228cbf753dec6adb25413d174ee275,"We give a method for deciding unifiability in the variety of bounded distributive lattices. For this, we reduce the problem of deciding whether a unification problem S has a solution to the problem of checking the satisfiability of a set S of ground clauses. This is achieved by using a structure-preserving translation to clause form. The satisfiability check can then be performed by either a resolution-based theorem prover or a SAT checker. We apply the method to unification with free constants and to unification with linear constant restrictions, and show that, in fact, it yields a decision procedure for the positive theory of the variety of bounded distributive lattices. We also consider the problem of unification over (i.e., in an algebraic extension of) the free lattice. Complexity issues are also addressed. © 2007 ACM.",Decision procedures for the positive theory; Distributive lattices; SAT solving; Theorem proving; Unification,Computational methods; Logic programming; Mathematical operators; Problem solving; Set theory; Distributive lattices; Free constants; Systems engineering
Sound and complete elimination of singleton kinds,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247199021&doi=10.1145%2f1227839.1227840&partnerID=40&md5=b46f1eaaa70e36fe6d08eccc8a007cfd,"Singleton kinds provide an elegant device for expressing type equality information resulting from modern module languages, but they can complicate the metatheory of languages in which they appear. I present a translation from a language with singleton kinds to one without, and prove this translation to be sound and complete. This translation is useful for type-preserving compilers generating typed target languages. The proof of soundness and completeness is done by normalizing type equivalence derivations using Stone and Harper's type equivalence decision procedure. © 2007 ACM.",Singleton kinds; Type systems,Computer programming languages; Computer systems; Decision theory; Program compilers; Equivalence derivations; Singleton kinds; Type systems; Information theory
On compositionality and its limitations,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846629369&doi=10.1145%2f1182613.1182617&partnerID=40&md5=5e65fd57366e5101cbfe5865948fdacf,"The aim of this article is to examine the applicability of a compositional method developed for a generalized product construction by Feferman and Vaught to the field of program verification.We suggest an instance of the generalized product construction and prove an appropriate composition theorem for modal logic. We illustrate the usefulness of this generalized product by showing that many parallel composition operations are special cases of this generalized product.We obtain positive results (the compositional method works) for basic propositional modal logic, and negative results (the compositional method fails) for more expressive logics which can express EGp - -there is a path such that all the nodes of the path have the property p.Applications of the composition theorem to the model-checking problem and to the parametric model-checking problem are provided. © 2007 ACM.",Composition methods; Compositional verification; Feferman-Vaught theorem; Modal logic,Probabilistic logics; Problem solving; Theorem proving; Composition methods; Compositional verification; Feferman-Vaught theorem; Modal logic; Computation theory
Erratum: Splitting an operator: Algebraic modularity results for logics with fixpoint semantics (ACM Transactions on Computational Logic),2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846644356&doi=10.1145%2f1182613.1189735&partnerID=40&md5=f83dd926e6a7b3e9d1e6dc57dd541e1e,[No abstract available],,
Results on the quantitative μ-calculus qMμ,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846576007&doi=10.1145%2f1182613.1182616&partnerID=40&md5=9730d7ed51c29424c4bd7f8aef8603a0,"The μ-calculus is a powerful tool for specifying and verifying transition systems, including those with both demonic (universal) and angelic (existential) choice; its quantitative generalization qMμ extends to include probabilistic choice. We make two major contributions to the theory of such systems. The first is to show that for a finite-state system, the logical interpretation of qMμ, via fixed points in a domain of real-valued functions into [0, 1], is equivalent to an operational interpretation given as a turn-based gambling game between two players. The second contribution is to show that each player in the gambling game has an optimal memoryless strategy-that is, a strategy which is independent of the game's history, and with which a player can achieve his optimal expected reward however his opponent chooses to play. Moreover, since qMμ is expressive enough to encode stochastic parity games, our result implies the existence of memoryless strategies in that framework, as well. As an additional feature, we include an extensive case study demonstrating the aforementioned duality between games and logic. Among other things, it shows that the use of algorithmic verifi-cation techniques is mathematically justified in the practical computation of probabilistic system properties. © 2007 ACM.",Angelic choice; Demonic choice; Denotational semantics; Game semantics; Minimax theorem; Modal mu-calculus; Probabilistic choice; Quantitative aspects of programming languages,Algorithms; Functions; Game theory; Probabilistic logics; Angelic choice; Demonic choice; Denotational semantics; Game semantics; Minimax theorem; Probabilistic choice; Computation theory
A system of interaction and structure,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846586948&doi=10.1145%2f1182613.1182614&partnerID=40&md5=74ac930b7fc63018b6be7f8b199e7302,"This article introduces a logical system, called BV, which extends multiplicative linear logic by a noncommutative self-dual logical operator. This extension is particularly challenging for the sequent calculus, and so far, it is not achieved therein. It becomes very natural in a new formalism, called the calculus of structures, which is the main contribution of this work. Structures are formulas subject to certain equational laws typical of sequents. The calculus of structures is obtained by generalizing the sequent calculus in such a way that a new top-down symmetry of derivations is observed, and it employs inference rules that rewrite inside structures at any depth. These properties, in addition to allowing the design of BV, yield a modular proof of cut elimination. © 2007 ACM.",Calculus of structures; Cut elimination; Deep inference; Linear logic; Mix rule; Noncommutativity; Pomset logic; Self-duality; Symmetry,Computation theory; Data structures; Calculus of structures; Cut elimination; Deep inference; Linear logic; Noncommutativity; Formal logic
Abstract canonical inference,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846591327&doi=10.1145%2f1182613.1182619&partnerID=40&md5=f01d11c708e439cfe2b3a5d1cc67a91a,"An abstract framework of canonical inference is used to explore how different proof orderings induce different variants of saturation and completeness. Notions like completion, paramodulation, saturation, redundancy elimination, and rewrite-system reduction are connected to proof orderings. Fairness of deductive mechanisms is defined in terms of proof orderings, distinguishing between (ordinary) fairness, which yields completeness, and uniform fairness, which yields saturation. © 2007 ACM.",Canonicity; Completeness; Completion; Fairness; Inference; Proof orderings; Redundancy; Saturation,Inference engines; Knowledge based systems; Redundancy; Canonical inference; Proof orderings; Rewrite-system; Abstracting
Logical characterizations of heap abstractions,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846583234&doi=10.1145%2f1182613.1182618&partnerID=40&md5=9e47ec8cf9c424fe72839532b4e509c0,"Shape analysis concerns the problem of determining shape invariants for programs that perform destructive updating on dynamically allocated storage. In recent work, we have shown how shape analysis can be performed using an abstract interpretation based on three-valued first-order logic. In that work, concrete stores are finite two-valued logical structures, and the sets of stores that can possibly arise during execution are represented (conservatively) using a certain family of finite three-valued logical structures. In this article, we show how three-valued structures that arise in shape analysis can be characterized using formulas in first-order logic with transitive closure. We also define a nonstandard (supervaluational) semantics for three-valued first-order logic that is more precise than a conventional three-valued semantics, and demonstrate that the supervaluational semantics can be implemented using existing theorem provers. © 2007 ACM.",Canonical abstraction; Characterization; Logic; Shape analysis,Data structures; Invariance; Semantics; Storage allocation (computer); Theorem proving; Canonical abstractions; Logical structures; Shape analysis; Supervaluational semantics; Formal logic
Compilability of propositional abduction,2007,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846602159&doi=10.1145%2f1182613.1182615&partnerID=40&md5=693c07353d39d333ae5e47ed74e43c5d,"Abduction is one of the most important forms of reasoning; it has been successfully applied to several practical problems, such as diagnosis. In this article we investigate whether the computational complexity of abduction can be reduced by an appropriate use of preprocessing. This is motivated by the fact that part of the data of the problem (namely, the set of all possible assumptions and the theory relating assumptions and manifestations) is often known before the rest of the problem. In this article, we show some complexity results about abduction when compilation is allowed. © 2007 ACM.",Abduction; Artificial intelligence; Automated diagnosis; Computational complexity; Knowledge representation,Artificial intelligence; Computational complexity; Data acquisition; Knowledge representation; Problem solving; Program compilers; Automated diagnosis; Formal logic
Kleene Algebra with Domain,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750063528&doi=10.1145%2f1183278.1183285&partnerID=40&md5=6294dce98661541a72de07ae77914185,"We propose Kleene algebra with domain (KAD), an extension of Kleene algebra by simple equational axioms for a domain and a codomain operation. KAD considerably augments the expressiveness of Kleene algebra, in particular for the specification and analysis of programs and state transition systems. We develop the basic calculus, present the most interesting models and discuss some related theories. We demonstrate applicability by two examples: algebraic reconstructions of Noethericity and propositional Hoare logic based on equational reasoning. © 2006, ACM. All rights reserved.",codomain; domain; equational reasoning; Idempotent semiring; image and preimage operation; Kleene algebra; program development and analysis; state transition systems; Theory; Verification,
Soft concurrent constraint programming,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748307458&doi=10.1145%2f1149114.1149118&partnerID=40&md5=09c313a5cbd9da7777c211c8e4b792a8,"Soft constraints extend classical constraints to represent multiple consistency levels, and thus provide a way to express preferences, fuzziness, and uncertainty. While there are many soft constraint solving formalisms, even distributed ones, as yet there seems to be no concurrent programming framework where soft constraints can be handled. In this article we show how the classical concurrent constraint (cc) programming framework can work with soft constraints, and we also propose an extension of cc languages which can use soft constraints to prune and direct the search for a solution. We believe that this new programming paradigm, called soft cc (scc), can be also very useful in many Web-related scenarios. In fact, the language level allows Web agents to express their interaction and negotiation protocols, and also to post their requests in terms of preferences, and the underlying soft constraint solver can find an agreement among the agents even if their requests are incompatible. © 2006 ACM.",Concurrent constraint programming; Constraints; Soft constraints,Fuzzy control; Logic programming; Network protocols; Problem solving; Uncertain systems; World Wide Web; Classical concurrent constraint; Concurrent constraint programming; Multiple consistency levels; Soft constraint; Constraint theory
The DLV system for knowledge representation and reasoning,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745244351&doi=10.1145%2f1149114.1149117&partnerID=40&md5=ec48b08d2451430de1a828f5c154148c,"Disjunctive Logic Programming (DLP) is an advanced formalism for knowledge representation and reasoning, which is very expressive in a precise mathematical sense: it allows one to express every property of finite structures that is decidable in the complexity class ∑ 2 p (NP NP). Thus, under widely believed assumptions, DLP is strictly more expressive than normal (disjunction-free) logic programming, whose expressiveness is limited to properties decidable in NP. Importantly, apart from enlarging the class of applications which can be encoded in the language, disjunction often allows for representing problems of lower complexity in a simpler and more natural fashion. This article presents the DLV system, which is widely considered the state-of-the-art implementation of disjunctive logic programming, and addresses several aspects. As for problem solving, we provide a formal definition of its kernel language, function-free disjunctive logic programs (also known as disjunctive datalog), extended by weak constraints, which are a powerful tool to express optimization problems. We then illustrate the usage of DLV as a tool for knowledge representation and reasoning, describing a new declarative programming methodology which allows one to encode complex problems (up to Δ 3 3-complete problems) in a declarative fashion. On the foundational side, we provide a detailed analysis of the computational complexity of the language of DLV, and by deriving new complexity results we chart a complete picture of the complexity of this language and important fragments thereof. Furthermore, we illustrate the general architecture of the DLV system, which has been influenced by these results. As for applications, we overview application front-ends which have been developed on top of DLV to solve specific knowledge representation tasks, and we briefly describe the main international projects investigating the potential of the system for industrial exploitation. Finally, we report about thorough experimentation and benchmarking, which has been carried out to assess the efficiency of the system. The experimental results confirm the solidity of DLV and highlight its potential for emerging application areas like knowledge management and information integration. © 2006 ACM.",Answer sets; Computational complexity; Implementation; Knowledge representation; Nonmonotonic reasoning; Stable models,Benchmarking; Computational complexity; Computer programming languages; Constraint theory; Data structures; Formal logic; Knowledge based systems; Knowledge representation; Disjunctive Logic Programming (DLP); Knowledge management; Nonmonotonic reasoning; Stable models; Logic programming
Fast verification of MLL proof nets via IMLL,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748313125&doi=10.1145%2f1149114.1149116&partnerID=40&md5=db31e95a06678a08f7963444f7865cdc,"We consider the following decision problems: PROOFNET: Is a given multiplicative linear logic (MLL) proof structure a proof net? ESSNET: Is a given essential net (of an intuitionistic MLL sequent) correct? In this article we show how to obtain linear-time algorithms for ESSNET. As a corollary, by showing that PROOFNET is linear-time reducible to ESSNET (by the Trip Translation), we obtain a linear-time algorithm for PROOFNET. We show further that it is possible to optimize the verification so that each node of the input structure is visited at most once. Finally, we present linear-time algorithms for sequentializing proof nets and essential nets, that is, for finding derivations of the underlying sequents. © 2006 ACM.",Disjoint union find; Dominator trees; Essential nets; Multiplicative linear logic; Proof nets,Algorithms; Decision theory; Linear programming; Logic programming; Optimization; Problem solving; Disjoint union; Dominator trees; Essential nets; Multiplicative linear logic (MLL); Proof nets; Formal logic
Logic program-based updates,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748298848&doi=10.1145%2f1149114.1149115&partnerID=40&md5=e72f4e25e05ca7922c04b80921596a1d,"In logic program-based updates, contradictory information elimination, conflict resolution, and syntactic representation are three major issues that interfere with each other and significantly influence the update result. We observe that existing approaches of logic program-based updates, in one way or another, are problematic to deal with these issues. In this article, we address all these problems in a systematic manner. Our approach to the logic program-based update has the following features: (1) a prioritized logic programming language is employed for providing a formal basis of formalizing logic program-based updates, so that information conflict and its related problems in updates can be handled properly; (2) our approach presents both semantic characterization and syntactic representation for the underlying update procedure, and hence is consistent with the nature of updates within the logic program extent-declarative semantics and syntactic sensitivity; and (3) our approach also provides nontrivial solutions to simplify various update evaluation procedures under certain conditions. © 2006 ACM.",Computational complexity; Conflict resolution; Logic program-based update; Prioritized logic programming,Computational complexity; Computer programming languages; Formal logic; Problem solving; Semantics; Syntactics; Conflict resolution; Logic program based update; Nontrivial solutions; Prioritized logic programming; Syntactic sensitivity; Logic programming
Comprehending software correctness implies comprehending an intelligence-related limitation,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748290036&doi=10.1145%2f1149114.1149119&partnerID=40&md5=cf25b32a9e363224bf0fb0283d55a37d,"This article applies mathematical logic to obtain a rigorous foundation for previous inherently nonrigorous results and also extends those previous results. Roughly speaking, our main theorem states: any agent A that comprehends the correctness-related properties of software S also comprehends an intelligence-related limitation of S. The theorem treats the output of S, if any, as an attempt at solving a halting problem. Previous nonrigorous attempts to obtain similar theorems depend on infallibility assumptions on both the agent and the software. The hypothesis that intelligent agents and intelligent software must be infallible has been widely questioned. In addition, recent work by others has determined that well-known previous attempts use a fallacious form of reasoning; that is, the same form of reasoning can yield paradoxical results. Our main theorem avoids infallibility assumptions on both the agent and the software. In addition, our proof is rigorous, in the sense that in principle one can carry it out in Zermelo-Fraenkel set theory. The software correctness framework considered in the main theorem is that of Hoare logic. © 2006 ACM.",Agent; Consistency; Formal proof; Halting problem; Hoare logic; Infallibility; Limitation; Partial correctness; Peano arithmetic; Soundness; Turing machine; Zermelo-Fraenkel set theory,Formal logic; Problem solving; Set theory; Software agents; Theorem proving; Consistency; Halting problem; Hoare logic; Infallibility; Intelligent software; Partial correctness; Peano arithmetic; Turing machine; Zermelo-Fraenkel set theory; Computer software
Decidability results for sets with atoms,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745227426&doi=10.1145%2f1131313.1131317&partnerID=40&md5=b33263f4deebdad50693d1fd64431675,"Formal set theory is traditionally concerned with pure sets; consequently, the satisfiability problem for fragments of set theory was most often addressed (and in many cases positively solved) in the pure framework. In practical applications, however, it is common to assume the existence of a number of primitive objects (sometimes called atoms) that can be members of sets but behave differently from them. If these entities are assumed to be devoid of members, the standard extensionality axiom must be revised; then decidability results can sometimes be achieved via reduction to the pure case and sometimes can be based on direct goal-driven algorithms. An alternative approach to modeling atoms that allows one to retain the original formulation of extensionality was proposed by Quine: atoms are self-singletons. In this article we adopt this approach in coping with the satisfiability problem: We show the decidability of this problem relativized to ∀*∃-sentences, and develop a goal-driven unification algorithm. © 2006 ACM.",Prenex sentences; Quantifier elimination; Satisfiability problem; Set-hyperset theories; Syllogistics; Unification,Atoms; Mathematical models; Problem solving; Set theory; Prenex sentences; Quantifier elimination; Satisfiability problem; Set-hyperset theories; Syllogistics; Unification; Computability and decidability
Ordinary interactive small-step algorithms,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745218013&doi=10.1145%2f1131313.1131320&partnerID=40&md5=23dfa9165425ac19d1b1530c786dea4b,"This is the first in a series of articles extending the abstract state machine thesis - that arbitrary algorithms are behaviorally equivalent to abstract state machines-to algorithms that can interact with their environments during a step rather than only between steps. In the present work, we describe, by means of suitable postulates, those interactive algorithms that (1) proceed in discrete, global steps; (2) perform only a bounded amount of work in each step; (3) use only such information from the environment as can be regarded as answers to queries; and (4) never complete a step until all queries from that step have been answered. We indicate how a great many sorts of interaction meet these requirements. We also discuss in detail the structure of queries and replies and the appropriate definition of equivalence of algorithms. Finally, motivated by our considerations concerning queries, we discuss a generalization of first-order logic in which the arguments of function and relation symbols are not merely tuples of elements but orbits of such tuples under groups of permutations of the argument places. © 2006 ACM.",Abstract state machines; Equivalence of algorithms; Interaction; Postulates; Sequential algorithms,Codes (symbols); Combinatorial mathematics; Query languages; Abstract state machines; Equivalence of algorithms; Interaction; Postulates; Sequential algorithms; Algorithms
Propositional computability logic II,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745205284&doi=10.1145%2f1131313.1131319&partnerID=40&md5=c52286ffc134bf3cbdbfc23c2e5f11f0,"Computability logic is a formal theory of computational tasks and resources. Its formulas represent interactive computational problems, logical operators stand for operations on computational problems, and validity of a formula is understood as its being a scheme of problems that always have algorithmic solutions. The earlier article ""Propositional computability logic I"" proved soundness and completeness for the (in a sense) minimal nontrivial fragment CL1 of computability logic. The present article extends that result to the significantly more expressive prepositional system CL2. What makes CL2 more expressive than CL1 is the presence of two sorts of atoms in its language: elementary atoms, representing elementary computational problems (i.e. predicates), and general atoms, representing arbitrary computational problems. CL2 conservatively extends CL1, with the latter being nothing but the general-atom-free fragment of the former. © 2006 ACM.",Computability logic; Computational resources; Game semantics; Interactive algorithms; Linear logic,Algorithms; Computational methods; Game theory; Problem solving; Semantics; Computability logic; Computational resources; Game semantics; Interactive algorithms; Linear logic; Formal logic
Constant-depth frege systems with counting axioms polynomially simulate nullstellensatz refutations,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745211851&doi=10.1145%2f1131313.1131314&partnerID=40&md5=529fe2877d5e47e99acd62a3cdd257e2,"We show that constant-depth Frege systems with counting axioms modulo m polynomially simulate Nullstellensatz refutations modulo m. Central to this is a new definition of reducibility from propositional formulas to systems of polynomials. Using our definition of reducibility, most previously studied propositional formulas reduce to their polynomial translations. When combined with a previous result of the authors, this establishes the first size separation between Nullstellensatz and polynomial calculus refutations. We also obtain new upper bounds on refutation sizes for certain CNFs in constant-depth Frege with counting axioms systems. © 2006 ACM.",Modular counting axioms; Nullstellensatz refutations; Propositional proof complexity,Differentiation (calculus); Numerical methods; Theorem proving; Modular counting axioms; Nullstellensatz refutations; Propositional proof complexity; Polynomials
Propositional computability logic I,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745211179&doi=10.1145%2f1131313.1131318&partnerID=40&md5=2e0ee43d203c55c06f88a5feeecd542e,"In the same sense as classical logic is a formal theory of truth, the recently initiated approach called computability logic is a formal theory of computability. It understands (interactive) computational problems as games played by a machine against the environment, their computability as existence of a machine that always wins the game, logical operators as operations on computational problems, and validity of a logical formula as being a scheme of ""always computable"" problems. Computability logic has been introduced semantically, and now among its main technical goals is to axiomatize the set of valid formulas or various natural fragments of that set. The present contribution signifies a first step towards this goal. It gives a detailed exposition of a soundness and completeness proof for the rather new type of a deductive propositional system CL1, the logical vocabulary of which contains operators for the so called parallel and choice operations, and the atoms of which represent elementary problems, that is, predicates in the standard sense. This article is self-contained as it explains all relevant concepts. While not technically necessary, familiarity with the foundational paper ""Introduction to Computability Logic"" [Annals of Pure and Applied Logic 123 (2003), pp. 1-99] would greatly help the reader in understanding the philosophy, underlying motivations, potential and utility of computability logic - the context that determines the value of the present results. © 2006 ACM.",Computability logic; Computational resources; Game semantics; Interactive algorithms; Linear logic,Algorithms; Computational methods; Game theory; Problem solving; Semantics; Computability logic; Computational problems; Logical operators; Logical vocabulary; Formal logic
Optimizing optimal reduction: A type inference algorithm for elementary affine logic,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745210089&doi=10.1145%2f1131313.1131315&partnerID=40&md5=d98ec20dbc3c5474c7781236c8ce5848,"We propose a type inference algorithm for lambda terms in elementary affine logic (EAL). The algorithm decorates the syntax tree of a simple typed lambda term and collects a set of linear constraints. The result is a parametric elementary type that can be instantiated with any solution of the set of collected constraints. We point out that the typeability of lambda terms in EAL has a practical counterpart, since it is possible to reduce any EAL-typeable lambda terms with the Lamping's abstract algorithm obtaining a substantial increase of performances. We show how to apply the same techniques to obtain decorations of intuitionistic proofs into linear logic proofs. © 2006 ACM.",Lamping algorithm; Linear logic; Optimal reduction,Algorithms; Constraint theory; Numerical methods; Trees (mathematics); Elementary affine logic (EAL); Lamping algorithm; Linear logic; Optimal reduction; Optimization
Why are there so many loop formulas?,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745189996&doi=10.1145%2f1131313.1131316&partnerID=40&md5=c74cc99343adf5cc867afb5c174c6f91,"A theorem by Lin and Zhao shows how to turn any nondisjunctive logic program, understood in accordance with the answer set semantics, into an equivalent set of propositional formulas. The set of formulas generated by this process can be significantly larger than the original program. In this article we show (assuming P ⊈ NC 1/poly, a conjecture from the theory of computational complexity that is widely believed to be true) that this is inevitable: any equivalent translation from logic programs to propositional formulas involves a significant increase in size. © 2006 ACM.",Answer sets; Loop formulas; P-completeness; Stable models,Computational complexity; Computer programming; Semantics; Theorem proving; Answer sets; Loop formulas; Nondisjunctive logic program; P-completeness; Stable models; Computational methods
Monodic temporal resolution,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745268458&doi=10.1145%2f1119439.1119443&partnerID=40&md5=67c120db357384de493a63bd67d37fce,"Until recently, First-Order Temporal Logic (FOTL) has been only partially understood. While it is well known that the full logic has no finite axiomatisation, a more detailed analysis of fragments of the logic was not previously available. However, a breakthrough by Hodkinson et al., identifying a finitely axiomatisable fragment, termed the monadic fragment, has led to improved understanding of FOTL. Yet, in order to utilise these theoretical advances, it is important to have appropriate proof techniques for this monodic fragment. In this paper, we modify and extend the clausal temporal resolution technique, originally developed for propositional temporal logics, to enable its use in such monodic fragments. We develop a specific normal form for monodic formulae in FOTL, and provide a complete resolution calculus for formulae in this form. Not only is this clausal resolution technique useful as a practical proof technique for certain monodic classes, but the use of this approach provides us with increased understanding of the monodic fragment. In particular, we here show how several features of monodic FOTL can be established as corollaries of the completeness result for the clausal temporal resolution method. These include definitions of new decidable monodic classes, simplification of existing monodic classes by reductions, and completeness of clausal temporal resolution in the case of monodic logics with expanding domains, a case with much significance in both theory and practice. © 2006 ACM.",Automated theorem proving; Resolution; Temporal logic,Computational complexity; Decision making; Optical resolving power; Problem solving; Automated theorem proving; Corollaries; Monadic fragment; Temporal logic; Formal logic
Defining functions on equivalence classes,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750145458&doi=10.1145%2f1183278.1183280&partnerID=40&md5=a990d0b893988d8854f4e4ce3858c590,"A quotient construction defines an abstract type from a concrete type, using an equivalence relation to identify elements of the concrete type that are to be regarded as indistinguishable. The elements of a quotient type are equivalence classes: sets of equivalent concrete values. Simple techniques are presented for defining and reasoning about quotient constructions, based on a general lemma library concerning functions that operate on equivalence classes. The techniques are applied to a definition of the integers from the natural numbers, and then to the definition of a recursive datatype satisfying equational constraints. © 2006 ACM.",Equivalence classes; Quotients; Theorem proving,Computational methods; Constraint theory; Database systems; Number theory; Theorem proving; Equational constraints; Lemma library; Natural numbers; Quotient construction; Equivalence classes
Splitting an operator: Algebraic modularity results for logics with fixpoint semantics,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750145738&doi=10.1145%2f1183278.1183284&partnerID=40&md5=5435ab6dfce55b452a7c509d82d0bb0e,"It is well known that, under certain conditions, it is possible to split logic programs under stable model semantics, that is, to divide such a program into a number of different ""levels"", such that the models of the entire program can be constructed by incrementally constructing models for each level. Similar results exist for other nonmonotonic formalisms, such as auto-epistemic logic and default logic. In this work, we present a general, algebraic splitting theory for logics with a fixpoint semantics. Together with the framework of approximation theory, a general fixpoint theory for arbitrary operators, this gives us a uniform and powerful way of deriving splitting results for each logic with a fixpoint semantics. We demonstrate the usefulness of these results, by generalizing existing results for logic programming, auto-epistemic logic and default logic. © 2006 ACM.",Auto-epistemic logic; Default logic; Logic programming; Modularity,Algebra; Computational methods; Mathematical models; Semantics; Theorem proving; Auto-epistemic logic; Default logic; Fixpoint semantics; Splitting theory; Logic programming
Domain-dependent knowledge in answer set planning,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750197653&doi=10.1145%2f1183278.1183279&partnerID=40&md5=0d6b597b123635a18c796135725331af,"In this article we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set semantics (AnsProlog*). AnsProlog* is designed to plan without control knowledge. We show how temporal, procedural and HTN-based control knowledge can be incorporated into AnsProlog* by the modular addition of a small number of domain-dependent rules, without the need to modify the planner. We formally prove the correctness of our planner, both in the absence and presence of the control knowledge. Finally, we perform some initial experimentation that demonstrates the potential reduction in planning time that can be achieved when procedural domain knowledge is used to solve planning problems with large plan length. © 2006 ACM.",,Computational methods; Problem solving; Semantics; Set theory; Control knowledge; Domain-dependent rules; Set planning; Set semantics; Logic programming
Extensional equivalence and singleton types,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750151602&doi=10.1145%2f1183278.1183281&partnerID=40&md5=dc0f06785044515c9c223e06dcd3c7d1,"We study the λ≤ΠΣs calculus, which contains singleton types S(M) classifying terms of base type provably equivalent to the term M. The system includes dependent types for pairs and functions (Σ and Π) and a subtyping relation induced by regarding singletons as subtypes of the base type. The decidability of type checking for this language is non-obvious, since to type check we must be able to determine equivalence of well-formed terms. But in the presence of singleton types, the provability of an equivalence judgment Γ ⊢ M1 ≡ M2: A can depend both on the typing context Γ and on the particular type A at which M1 and M2 are compared. We show how to prove decidability of term equivalence, hence of type checking, in λ≤ΠΣs by exhibiting a type-directed algorithm for directly computing normal forms. The correctness of normalization is shown using an unusual variant of Kripke logical relations organized around sets; rather than denning a logical equivalence relation, we work directly with (subsets of) the corresponding equivalence classes. We then provide a more efficient algorithm for checking type equivalence without constructing normal forms. We also show that type checking, subtyping, and all other judgments of the system are decidable. The λ≤ΠΣs calculus models type constructors and kinds in the intermediate language used by the TILT compiler for Standard ML to implement the SML module system. The decidability of λ≤ΠΣs term equivalence allows us to show decidability of type checking for TILT's intermediate language. We also obtain a consistency result that allows us to prove type safety for the intermediate language. The algorithms derived here form the core of the type checker used for internal type checking in TILT. © 2006 ACM.",,Algorithms; Computability and decidability; Computational complexity; Database systems; Program compilers; Set theory; Theorem proving; Intermediate language; Logical equivalence relation; Module systems; Equivalence classes
The strength of replacement in weak arithmetic,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750177915&doi=10.1145%2f1183278.1183283&partnerID=40&md5=a6d5b882fa37cc9f84af8e8b650c929d,"The replacement (or collection or choice) axiom scheme BB(Γ) asserts bounded quantifier exchange as follows: ∀i < |a| ∃x < aφ(i, x) → ∃w ∀i < |a|φ(i, [w]i), for φ in the class Γ of formulas. The theory S21 proves the scheme BB(∑1b), and thus in S 21 every ∑1b formula is equivalent to a strict ∑1b formula (in which all non-sharply-bounded quantifiers are in front). Here we prove (sometimes subject to an assumption) that certain theories weaker than S21 do not prove either BB(∑1b) or BB(∑0 b). We show (unconditionally) that V0 does not prove BB(∑0B), where V0 (essentially I∑01,b) is the two-sorted theory associated with the complexity class AC0. We show that PV does not prove BB(∑0b), assuming that integer factoring is not possible in probabilistic polynomial time. Johannsen and Pollett introduced the theory C20 associated with the complexity class TC 0, and later introduced an apparently weaker theory Δ1b - CR for the same class. We use our methods to show that Δ1b - CR is indeed weaker than C 20, assuming that RSA is secure against probabilistic polynomial time attack. Our main tool is the KPT witnessing theorem. © 2006 ACM.",Bounded arithmetic; Cryptography; PV,Computational complexity; Cryptography; Polynomials; Probabilistic logics; Theorem proving; Axiom scheme; Bounded arithmetic; Bounded quantifiers; Polynomial time attack; Computation theory
Efficient solving of quantified inequality constraints over the real numbers,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750170682&doi=10.1145%2f1183278.1183282&partnerID=40&md5=638fa4ee8c6bf872ea7bf3129c741af0,"Let a quantified inequality constraint over the reals be a formula in the first-order predicate language over the structure of the real numbers, where the allowed predicate symbols are ≤ and <. Solving such constraints is an undecidable problem when allowing function symbols such sin or cos. In this article, we give an algorithm that terminates with a solution for all, except for very special, pathological inputs. We ensure the practical efficiency of this algorithm by employing constraint programming techniques. © 2006 ACM.",Constraint solving; Decision procedures; Numerical constraints,Algorithms; Decision making; Number theory; Numerical methods; Problem solving; Constraint solving; Decision procedures; Numerical constraints; Constraint theory
Heterogeneous temporal probabilistic agents,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745255681&doi=10.1145%2f1119439.1119444&partnerID=40&md5=93bfcfb842bcdd0e3aee04db637f5486,"To date, there has been no work on temporal probabilistic agent reasoning on top of heterogeneous legacy databases and software modules. We will define the concept of a heterogeneous temporal probabilistic (HTP) agent. Such agents can be built on top of existing databases, data structures, and software code bases without explicitly accessing the internal code of those systems and can take actions compatible with a policy or operating principles specified by an agent developer. We will develop a formal semantics for such agents through the notion of a feasible temporal probabilistic status interpretation (FTPSI for short). Intuitively, an FTPSI specifies what all an HTP agent is permitted/forbidden/obliged to do at various times t. As changes occur in the environment, the HTP agent must compute a new FTPSI. HTP agents continuously compute FTPSIs in order to determine what they should do and, hence, the problem of computing FTPSIs is very important. We give a sound and complete algorithm to compute FTPSIs for a very large class of HTP agents called strict HTP agents. In a given state, many FTPSIs may exist. These represent alternative courses of action that the HTP agent can take. We provide a notion of an optimal FTPSI that selects an FTPSI optimizing an objective function and give a sound and complete algorithm to compute an optimal FTPSI. © 2006 ACM.",Logic programming; Multiagent reasoning; Probabilistic reasoning; Temporal reasoning; Uncertainty,Algorithms; Computer software; Data structures; Database systems; Legacy systems; Probability; Problem solving; Semantics; Multiagent reasoning; Probabilistic reasoning; Temporal reasoning; Formal logic
Unfolding partiality and disjunctions in stable model semantics,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745231666&doi=10.1145%2f1119439.1119440&partnerID=40&md5=89f2256d0f0aa338b55e43a08eb175af,"This article studies an implementation methodology for partial and disjunctive stable models where partiality and disjunctions are unfolded from a logic program so that an implementation of stable models for normal (disjunction-free) programs can be used as the core inference engine. The unfolding is done in two separate steps. First, it is shown that partial stable models can be captured by total stable models using a simple linear and modular program transformation. Hence, reasoning tasks concerning partial stable models can be solved using an implementation of total stable models. Disjunctive partial stable models have been lacking implementations which now become available as the translation handles also the disjunctive case. Second, it is shown how total stable models of disjunctive programs can be determined by computing stable models for normal programs. Thus an implementation of stable models of normal programs can be used as a core engine for implementing disjunctive programs. The feasibility of the approach is demonstrated by constructing a system for computing stable models of disjunctive programs using the SMODELS system as the core engine. The performance of the resulting system is compared to that of DLV, which is a state-of-the-art system for disjunctive programs. © 2006 ACM.",Answer set programming; Disjunctive stable models; Inference engine; Minimal models; Partial models; Quantified Boolean formulas,Inference engines; Linear programming; Logic programming; Mathematical models; Mathematical transformations; Answer set programming; Disjunctive stable models; Minimal models; Partial models; Quantified Boolean formulas; Semantics
Predicate-calculus-based logics for modeling and solving search problems,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745233275&doi=10.1145%2f1119439.1119441&partnerID=40&md5=15d65c4ffc06ed104d491ce52664ebd9,"The answer-set programming (ASP) paradigm is a way of using logic to solve search problems. Given a search problem, to solve it one designs a logic theory so that models of this theory represent problem solutions. To compute a solution to the problem, one computes a model of the theory. Several answer-set programming formalisms have been developed on the basis of logic programming with the semantics of answer sets. In this article we show that predicate logic also gives rise to effective implementations of the ASP paradigm, similar in spirit to logic programming with the answer-set semantics and with a similar scope of applicability. Specifically, we propose two logics based on predicate calculus as formalisms for encoding search problems. We show that the expressive power of these logics is given by the class NPMV. We demonstrate their use in programming and discuss computational approaches to model finding. To address this latter issue, we follow a two-pronged approach. On the one hand, we show that the problem can be reduced to that of computing models of propositional theories and, more generally, of collections of pseudo-Boolean constraints. Consequently, programs (solvers) developed in the areas of propositional and seudo-Boolean satisfiability can be used to compute models of theories in our logics. On the other hand, we develop native solvers designed specifically to exploit features of our formalisms. We present experimental results demonstrating the computational effectiveness of the overall approach. © 2006 ACM.",Constraints; Predicate logic; Pseudo-Boolean constraints; Satisfiability; Search problems,Boolean algebra; Computation theory; Computer simulation; Problem solving; Search engines; Semantics; Predicate logic; Pseudo-Boolean constraints; Satisfiability; Search problems; Logic programming
ACM Transactions on Computational Logic: Editorial,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745218950&doi=10.1145%2f1094622.1094623&partnerID=40&md5=1eab68dc8afba583b5761a0477170102,[No abstract available],,
Complexity results on DPLL and resolution,2006,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745232509&doi=10.1145%2f1119439.1119442&partnerID=40&md5=5e53d5899c1c90d34bb84145857beb92,"DPLL and resolution are two popular methods for solving the problem of prepositional satisfiability. Rather than algorithms, they are families of algorithms, as their behavior depends on some choices they face during execution: DPLL depends on the choice of the literal to branch on; resolution depends on the choice of the pair of clauses to resolve at each step. The complexity of making the optimal choice is analyzed in this article. Extending previous results, we prove that choosing the optimal literal to branch on in DPLL is Δp2 [log n]-hard, and becomes NP pp-hard if branching is only allowed on a subset of variables. Optimal choice in regular resolution is both NP-hard and coNP-hard. The problem of determining the size of the optimal proofs is also analyzed: it is coNP-hard for DPLL, and Δp2 [log n]-hard if a conjecture we make is true. This problem is coNP-hard for regular resolution. © 2006 ACM.",Davis-Putnam; NP-completeness; Propositional satisfiability,Algorithms; Computational complexity; Optical resolving power; Trees (mathematics); Davis-Putnam; DPLL; Propositional satisfiability; Problem solving
Convergence law for random graphs with specified degree sequence,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745211432&doi=10.1145%2f1094622.1094627&partnerID=40&md5=7caad32a35bc9d405b826df021a81877,"The degree sequence of an n-vertex graph is d 0, ..., d n-1, where each d i is the number of vertices of degree i in the graph. A random graph with degree sequence d 0,..., d n-1 is a randomly selected member of the set of graphs on {1,..., n} with that degree sequence, all choices being equally likely. Let λ 0, λ 1, ... be a sequence of nonnegative reals summing to 1. A class of finite graphs has degree sequences approximated by λ 0, λ 1,... if, for every i and n, the members of the class of size n have λ in + o(n) vertices of degree i. Our main result is a convergence law for random graphs with degree sequences approximated by some sequence λ 0, λ 1, .... With certain conditions on the sequence λ 0, λ 1, ..., the probability of any first-order sentence on random graphs of size n converges to a limit as n grows. © 2005 ACM.",Finite model theory; Random graphs,Approximation theory; Finite automata; Mathematical models; Probability; Random processes; Convergence; Finite graphs; Finite model theory; Random graphs; Graph theory
LICS 2003 special issue,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745184204&doi=10.1145%2f1094622.1094624&partnerID=40&md5=b5fa59036fcd302a330ade59def77002,[No abstract available],,
A proof theory for generic judgments,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745189795&doi=10.1145%2f1094622.1094628&partnerID=40&md5=f180ca418d4057d13c56f835862bc6b5,"The operational semantics of a computation system is often presented as inference rules or, equivalently, as logical theories. Specifications can be made more declarative and high level if syntactic details concerning bound variables and substitutions are encoded directly into the logic using termlevel abstractions (λ-abstraction) and proof-level abstractions (eigenvariables). When one wishes to use such logical theories to support reasoning about properties of computation, the usual quantifiers and proof-level abstractions do not seem adequate: proof-level abstraction of variables with scope over sequents (global scope) as well as over only formulas (local scope) seem required for many examples. We will present a sequent calculus that provides this local notion of proof-level abstraction via generic judgment and a new quantifier, ∇, which explicitly manipulates such local scope. Intuitionistic logic extended with ∇ satisfies cut-elimination even when the logic is additionally strengthened with a proof theoretic notion of definitions. The resulting logic can be used to encode naturally a number of examples involving abstractions, and we illustrate the uses of ∇ with the π-calculus and an encoding of provability of an object-logic. © 2005 ACM.",λ-tree syntax; Generic judgments; Higher-order abstract syntax; Proof search; Reasoning about operational semantics; V-quantifier,Database systems; Eigenvalues and eigenfunctions; Formal logic; Trees (mathematics); λ-tree syntax; Generic judgements; Higher-order abstract syntax; Proof search; Reasoning about operational semantics; V-quantifier; Semantics
About the undecidability of program equivalence in finitary languages with state,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745201603&doi=10.1145%2f1094622.1094626&partnerID=40&md5=6c3cd0709a9d5769b225ca7e86a524ec,"We show how game semantics can be employed to prove that program equivalence in finitary Idealized Algol with active expressions is undecidable. We also investigate a notion of representability of languages by terms and show that finitary Idealized Algol terms of respectively second, third and higher orders define exactly regular, context-free and recursively enumerable languages. © 2005 ACM.",Game semantics; Idealized Algol; Program equivalence,Algorithms; Finite automata; Semantics; Game semantics; Idealized algol; Program equivalence; Computer programming languages
Proof nets for unit-free multiplicative-additive linear logic,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944467760&doi=10.1145%2f1094622.1094629&partnerID=40&md5=fce20a87e92adb284e79f6fe6e0831ad,"A cornerstone of the theory of proof nets for unit-free multiplicative linear logic (MLL) is the abstract representation of cut-free proofs modulo inessential rule commutation. The only known extension to additives, based on monomial weights, fails to preserve this key feature: a host of cut-free monomial proof nets can correspond to the same cut-free proof. Thus, the problem of finding a satisfactory notion of proof net for unit-free multiplicative-additive linear logic (MALL) has remained open since the inception of linear logic in 1986. We present a new definition of MALL proof net which remains faithful to the cornerstone of the MLL theory. © 2005 ACM.",Additives; Cut elimination; Linear logic; Proof nets,Algebra; Computational methods; Formal logic; Linear systems; cut elimination; Linear logic; Multiplicative-additive linear logic (MALL); Proof nets; Petri nets
Disjunction and modular goal-directed proof search,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244449535&doi=10.1145%2f1071596.1071599&partnerID=40&md5=967a893d97a3d9c4dd790ac308643025,"This article explores goal-directed proof search in first-order multimodal logic. I focus on a family of modal logics which offer the expressive power to specify modular goals and local assumptions. A modular goal must be proved from designated assumptions; conversely, a local assumption can only be used to prove a designated goal. Indefinite modal specifications can avoid combinatorial interactions among independent ambiguities by making separate goals modular and corresponding disjunctive alternatives local. Such specifications can effectively guarantee that provable goals have short proofs. The key result of this article is to establish a sound and complete goal-directed proof system that actively uses the modularity and locality of modal logic to constrain proof search. In particular, logically independent, local ambiguities will not interact in proof search. The challenge is that, in goal-directed proof, a modal prover cannot simply reason locally, in a module, because modularity is a property of formulas rather than proof problems. The result therefore requires prior proof-theoretic justifications of logic programming to be extended, strengthened, and combined with new proof-theoretic analyses of modal deduction. © 2005 ACM.",Goal-directed proof; Indefinite information; Locality; Logic programming; Modal logic; Modularity,Artificial intelligence; Formal languages; Knowledge engineering; Logic programming; Mathematical operators; Modal analysis; Theorem proving; Goal-directed proof; Indefinite information; Knowledge representation formalisms and methods; Locality; Modal logic; Modularity; Natural deduction; Proof theory; Rule-based deduction; Formal logic
An effective decision procedure for linear arithmetic over the integers and reals,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244468556&doi=10.1145%2f1071596.1071601&partnerID=40&md5=d376050791eadbedab2744af42f4f560,"This article considers finite-automata-based algorithms for handling linear arithmetic with both real and integer variables. Previous work has shown that this theory can be dealt with by using finite automata on infinite words, but this involves some difficult and delicate to implement algorithms. The contribution of this article is to show, using topological arguments, that only a restricted class of automata on infinite words are necessary for handling real and integer linear arithmetic. This allows the use of substantially simpler algorithms, which have been successfully implemented. © 2005 ACM.",Decision procedure; Finite-state representations; Integer and real arithmetic; Weak ω-automata,Algorithms; Automata theory; Computational methods; Decision theory; Formal languages; Set theory; Software engineering; Computational logic; Decision procedure; Finite-state representations; Formal methods; Integer and real arithmetic; Program verification; Recursive sets; Regular sets; Resource-bounded; Weak ω-automata; Number theory
"Arithmetic, first-order logic, and counting quantifiers",2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244463041&doi=10.1145%2f1071596.1071602&partnerID=40&md5=ec2bc692b38bea5eaac791c56fa868e4,"This article gives a thorough overview of what is known about first-order logic with counting quan- tifiers and with arithmetic predicates. As a main theorem we show that Presburger arithmetic is closed under unary counting quantifiers. Precisely, this means that for every first-order formula φ(y,z→) over the signature {<, +} there is a first-order formula Ψ(x,z→) which expresses over the structure 〈ℕ, <, +〉 (respectively, over initial segments of this structure) that the variable x is interpreted exactly by the number of possible interpretations of the variable y for which the formula φ(y, z→) is satisfied. Applying this theorem, we obtain an easy proof of Ruhl's result that reachability (and similarly, connectivity) in finite graphs is not expressible in first-order logic with unary counting quantifiers and addition. Furthermore, the above result on Presburger arithmetic helps to show the failure of a particular version of the Crane Beach conjecture. © 2005 ACM.",Counting quantifiers; First-order logic; Presburger arithmetic; Quantifier elimination,Formal languages; Graph theory; Mapping; Number theory; Semantics; Set theory; Theorem proving; Counting quantifiers; First-order logic; Presburger arithmetic; Quantifier elimination; Formal logic
Sequent and hypersequent calculi for Abelian and Łukasiewicz logics,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244433246&doi=10.1145%2f1071596.1071600&partnerID=40&md5=82662d3e2c17b484bfe558e9274c5be2,"We present two embeddings of Łukasiewicz logic Ł into Meyer and Slaney's Abelian logic A, the logic of lattice-ordered Abelian groups. We give new analytic proof systems for A and use the embeddings to derive corresponding systems for Ł. These include hypersequent calculi, terminating hypersequent calculi, co-NP labeled sequent calculi, and unlabeled sequent calculi. © 2005 ACM.",ŁUkasiewicz logic; Abelian logic; Hypersequents; Sequents,Algebra; Algorithms; Artificial intelligence; Decision making; Formal languages; Fuzzy sets; Theorem proving; Abelian logic; Deduction; Hypersequents; Lukasiewicz logic; Probabilistic reasoning; Proof theory; Sequents; Uncertainty; Formal logic
On the complexity of the disjunction property in intuitionistic and modal logics,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244464105&doi=10.1145%2f1071596.1071598&partnerID=40&md5=685665d1fcb7fd5b044b4cfc068754c0,"In this article we study the complexity of disjunction property for intuitionistic logic, the modal logics S4, S4.1, Grzegorczyk logic, Gödel-Löb logic, and the intuitionistic counterpart of the modal logic K. For S4 we even prove the feasible interpolation theorem and we provide a lower bound for the length of proofs. The techniques we use do not require proving structural properties of the calculi in hand, such as the cut-elimination theorem or the normalization theorem. This is a key point of our approach, since it allows us to treat logics for which only Hilbert-style characterizations are known. © 2005 ACM.",Feasible interpolation; Intuitionistic logic; Modal logic; Proof-length,Algorithms; Computational complexity; Formal languages; Interpolation; Mathematical models; Polynomials; Theorem proving; Complexity of proof procedures; Feasible interpolation; Intuitionistic logic; Modal logic; Nonnumerical algorithms; Problem complexity; Proof theory; Proof-length; Formal logic
Datalog programs and their persistency numbers,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244464795&doi=10.1145%2f1071596.1071597&partnerID=40&md5=df47cdf0621a3c2c565d6dd8777757c2,"The relation between Datalog programs and homomorphism problems and between Datalog programs and bounded treewidth structures has been recognized for some time and given much attention recently. Additionally, the essential role of persistent variables (of program expansions) in solving several relevant problems has also started to be observed. It turns out that to understand the contribution of these persistent variables to the difficulty of some expressibility problems, we need to understand the interrelationship among different notions of persistency numbers, some of which we introduce and/or formalize in the present work. This article is a first foundational study of the various persistency numbers and their interrelationships. To prove the relations among these persistency numbers, we had to develop some nontrivial technical tools that promise to help in proving other interesting results too. More precisely, we define the adorned dependency graph of a program, a useful tool for visualizing sets of persistent variables, and we define automata that recognize persistent sets in expansions. We start by elaborating on finer definitions of expansions and queries, which capture aspects of homomorphism problems on bounded treewidth structures. The main results of this article are (a) a program transformation technique, based on automata-theoretic tools, which manipulates persistent variables (leading, in certain cases, to programs of fewer persistent variables); (b) a categorization of the different roles of persistent variables; this is done by defining four notions of persistency numbers which capture the propagation of persistent variables from a syntactical level to a semantical one; (c) decidability results concerning the syntactical notions of persistency numbers that we have defined; and (d) the exhibition of new classes of programs for which boundedness is undecidable. © 2005 ACM.",Bounded-tree width hypergraphs; Boundedness; Datalog; Finite automata; Persistency numbers; Persistent variables; Program transformations,Algorithms; Computational methods; Database systems; Finite automata; Formal languages; Graph theory; Logic programming; Query languages; Bounded-tree width hypergraphs; Boundedness; Datalog; Decision problems; Languages; Models of computation; Persistency numbers; Persistent variables; Program transformations; Resource-bounded; Computer programming
Comparisons and computation of well-founded semantics for disjunctive logic programs,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644384469&doi=10.1145%2f1055686.1055690&partnerID=40&md5=54fa01d663d43c7e8039ce9a9f8e0c1c,"Much work has been done on extending the well-founded semantics to general disjunctive logic programs and various approaches have been proposed. However, these semantics are different from each other and no consensus is reached about which semantics is the most intended. In this article, we look at disjunctive well-founded reasoning from different angles. We show that there is an intuitive form of the well-founded reasoning in disjunctive logic programming which can be characterized by slightly modifying some existing approaches to defining disjunctive well-founded semantics, including program transformations, argumentation, unfounded sets (and resolution-like procedure). By employing the techniques developed by Brass and Dix in their transformation-based approach, we also provide a bottom-up procedure for this semantics. The significance of our work is not only in clarifying the relationship among different approaches, but also shed some light on what is an intended well-founded semantics for disjunctive logic programs. © 2005 ACM.",Argumentation; Disjunctive logic programming; Negation; Nonmonotonic reasoning; Program transformations; Residual programs; Semantics of logic programs and deductive databases; Well-founded semantics,Algorithms; Artificial intelligence; Computational methods; Database systems; Formal languages; Formal logic; Knowledge based systems; Mathematical transformations; Semantics; Set theory; Theorem proving; Argumentation; Disjunctive logic programming; Non-monotonic reasoning; Program transfomations; Residual programs; Semantics of logic programs and deductive databases; Well founded semantics; Logic programming
From linear time to branching time,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644363102&doi=10.1145%2f1055686.1055689&partnerID=40&md5=9513d1fc7626980cb923004ca6117f1d,"Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by calculating fixed-point expressions over the system's set of states. The μ-calculus is a branching-time temporal logic with fixed-point operators. As such, it is a convenient logic for symbolic model-checking tools. In particular, the alternation-free fragment of μ-calculus has a restricted syntax, making the symbolic evaluation of its formulas computationally easy. Formally, it takes time that is linear in the size of the system. On the other hand, specifiers find the μ-calculus inconvenient. In addition, specifiers often prefer to use linear-time formalisms. Such formalisms, however, cannot in general be translated to the alternation-free μ-calculus, and their symbolic evaluation involves nesting of fixed-points, resulting in time complexity that is quadratic in the size of the system. In this article, we characterize linear-time properties that can be specified in the alternation-free μ-calculus. We show that a linear-time property can be specified in the alternation-free μ-calculus iff it can be recognized by a deterministic Büchi automaton. We study the problem of deciding whether a linear-time property, specified by either an automaton or an LTL formula, can be translated to an alternation-free μ.-calculus formula, and describe the translation, when possible. © 2005 ACM.",Alternation-free μ-calculus; Linear temporal logic,Automata theory; Computational complexity; Computational methods; Linear systems; Mathematical models; Problem solving; Syntactics; Theorem proving; Trees (mathematics); Alteration-free μ-calculus; Branching time; Linear temporal logic; Linear time; Formal logic
Reasoning about evolving nonmonotonic knowledge bases,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644368395&doi=10.1145%2f1055686.1055693&partnerID=40&md5=4239257145956aba979d701ddc336430,"Recently, several approaches to updating knowledge bases modeled as extended logic programs have been introduced, ranging from basic methods to incorporate (sequences of) sets of rules into a logic program, to more elaborate methods which use an update policy for specifying how updates must be incorporated. In this article, we introduce a framework for reasoning about evolving knowledge bases, which are represented as extended logic programs and maintained by an update policy. We first describe a formal model which captures various update approaches, and we define a logical language for expressing properties of evolving knowledge bases. We then investigate semantical and computational properties of our framework, where we focus on properties of knowledge states with respect to the canonical reasoning task of whether a given formula holds in a given evolving knowledge base. In particular, we present finitary characterizations of the evolution for certain classes of framework instances, which can be exploited for obtaining decidability results. In more detail, we characterize the complexity of reasoning for some meaningful classes of evolving knowledge bases, ranging from polynomial to double exponential space complexity. © 2005 ACM.",Answer-set semantics; Computational complexity; Knowledge-base evolution; Logic-program updates; Nonmonotonic knowledge bases; Program equivalence; Temporal reasoning,Algorithms; Artificial intelligence; Computational complexity; Computer simulation; Formal languages; Formal logic; Logic programming; Mathematical models; Polynomials; Semantics; Answer set semantics; Knowledge-based evolution; Logic-program updates; Monotonic knowledge bases; Program equivalence; Temporal reasoning; Knowledge based systems
Knuth-Bendix constraint solving is NP-complete,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644391810&doi=10.1145%2f1055686.1055692&partnerID=40&md5=b763a16addac676c0035e22bbe9c206b,We show the NP-completeness of the existential theory of term algebras with the Knuth-Bendix order by giving a nondeterministic polynomial-time algorithm for solving Knuth-Bendix ordering constraints. © 2005 ACM.,Automated deduction; Knuth-Bendix orders; Ordering constraints,Algebra; Algorithms; Artificial intelligence; Automata theory; Computational complexity; Formal languages; Functions; Mathematical models; Polynomials; Problem solving; Theorem proving; Automated deduction; Knuth-Bendix orders; Ordering constraints; Reduction orders; Formal logic
Equivalences among aggregate queries with negation,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644396544&doi=10.1145%2f1055686.1055691&partnerID=40&md5=d88dd9f25b20c6b850595b4ae27dff34,"Query equivalence is investigated for disjunctive aggregate queries with negated subgoals, constants and comparisons. A full characterization of equivalence is given for the aggregation functions count, max, sum, prod, top2 and parity. A related problem is that of determining, for a given natural number N, whether two given queries are equivalent over all databases with at most N constants. This problem is called bounded equivalence. A complete characterization of decidability of bounded equivalence is given. In particular, it is shown that this problem is decidable for all the above aggregation functions as well as for cntd (count distinct) and avg. For quasilinear queries (i.e., queries in which predicates that occur positively are not repeated), it is shown that equivalence can be decided in polynomial time for the aggregation functions count, max, sum, parity, prod, top2 and avg. A similar result holds for cntd provided that a few additional conditions hold. The results are couched in terms of abstract characteristics of aggregation functions, and new proof techniques are used. Finally, the results above also imply that equivalence, under bag-set semantics, is decidable for nonaggregate queries with negation. © 2005 ACM.",Aggregation; Datalog; Negation; Query equivalence,Database systems; Decision theory; Formal logic; Functions; Polynomials; Problem solving; Semantics; Set theory; Datalog; Disjunctive aggregate; Negation; Query equivalence; Query languages
Complexity of prepositional nested circumscription and nested abnormality theories,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644393487&doi=10.1145%2f1055686.1055688&partnerID=40&md5=71715e3b6bd2dae5113d2aa0dd29811c,"Circumscription has been recognized as an important principle for knowledge representation and common-sense reasoning. The need for a circumscriptive formalism that allows for simple yet elegant modular problem representation has led Lifschitz (AIJ, 1995) to introduce nested abnormality theories (NATs) as a tool for modular knowledge representation, tailored for applying circumscription to minimize exceptional circumstances. Abstracting from this particular objective, we propose ℒ CIRC, which is an extension of generic propositional circumscription by allowing propositional combinations and nesting of circumscriptive theories. As shown, NATs are naturally embedded into this language, and are in fact of equal expressive capability. We then analyze the complexity of ℒ CIRC and NATs, and in particular the effect of nesting. The latter is found to be a source of complexity, which climbs the Polynomial Hierarchy as the nesting depth increases and reaches PSPACE-completeness in the general case. We also identify meaningful syntactic fragments of NATs which have lower complexity. In particular, we show that the generalization of Horn circumscription in the NAT framework remains coNP-complete, and that Horn NATs without fixed letters can be efficiently transformed into an equivalent Horn CNF, which implies polynomial solvability of principal reasoning tasks. Finally, we also study extensions of NATs and briefly address the complexity in the first-order case. Our results give insight into the ""cost* of using ℒ CIRC (respectively, NATs) as a host language for expressing other formalisms such as action theories, narratives, or spatial theories. © 2005 ACM.",Circumscription; Computational complexity; Horn theories; Knowledge representation and reasoning; Nested abnormality theories; Nonmonotonic reasoning,Algorithms; Artificial intelligence; Boolean algebra; Computational complexity; Formal logic; Knowledge based systems; Mathematical models; Polynomials; Problem solving; Theorem proving; Circumscription; Horn theories; Knowledge representation and reasoning; Nested abnormality theories; Nonmonotonic reasoning; Learning systems
Minimum model semantics for logic programs with negation-as-failure,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644385361&doi=10.1145%2f1055686.1055694&partnerID=40&md5=d9efbfa005b4a0bd4565fce9c8849557,"We give a purely model-theoretic characterization of the semantics of logic programs with negationas-failure allowed in clause bodies. In our semantics, the meaning of a program is, as in the classical case, the unique minimum model in a program-independent ordering. We use an expanded truth domain that has an uncountable linearly ordered set of truth values between False (the minimum element) and True (the maximum), with a Zero element in the middle. The truth values below Zero are ordered like the countable ordinals. The values above Zero have exactly the reverse order. Negation is interpreted as reflection about Zero followed by a step towards Zero; the only truth value that remains unaffected by negation is Zero. We show that every program has a unique minimum model M P, and that this model can be constructed with a T P iteration which proceeds through the countable ordinals. Furthermore, we demonstrate that M P can alternatively be obtained through a construction that generalizes the well-known model intersection theorem for classical logic programming. Finally, we show that by collapsing the true and false values of the infinite-valued model M P to (the classical) True and False, we obtain a three-valued model identical to the well-founded one. © 2005 ACM.",Infinite-valued logics; Logic programming; Negation-as-failure; Well-founded model,Artificial intelligence; Formal languages; Iterative methods; Linear systems; Logic programming; Mathematical models; Semantics; Theorem proving; Infinite-valued logics; Minimum model semantics; Negation-as-failure; Well-founded models; Formal logic
Induction from answer sets in nonmonotonic logic programs,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644384918&doi=10.1145%2f1055686.1055687&partnerID=40&md5=d8953fe4c3ff1db0cfbc31161787ffa7,"Inductive logic programming (ILP) realizes inductive machine learning in computational logic. However, the present ILP mostly handles classical clausal programs, especially Horn logic programs, and has limited applications to learning nonmonotonic logic programs. This article studies a method for realizing induction in nonmonotonic logic programs. We consider an extended logic program as a background theory, and introduce techniques for inducing new rules using answer sets of the program. The produced new rules explain positive/negative examples in the context of inductive logic programming. The proposed methods extend the present ILP techniques to a syntactically and semantically richer framework, and contribute to a theory of nonmonotonic ILP. © 2005.",Answer sets; Induction; Nonmonotonic logic programs,Algorithms; Artificial intelligence; Computational methods; Data mining; Formal logic; Information analysis; Learning systems; Mathematical models; Semantics; Syntactics; Answer sets; Induction; Inductive nonlinear programming (ILP); Nonmonotonic logic programs; Logic programming
An elementary fragment of second-order lambda calculus,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644363296&doi=10.1145%2f1055686.1055695&partnerID=40&md5=2339e478339997b055544f0b2359c083,"A fragment of second-order lambda calculus (System F) is defined that characterizes the elementary recursive functions. Type quantification is restricted to be noninterleaved and stratified, that is, the types are assigned levels, and a quantified variable can only be instantiated by a type of smaller level, with a slightly liberalized treatment of the level zero. © 2005 ACM.",Complexity; Elementary recursive functions; Lambda calculus; Second order logic,Algorithms; Computational complexity; Computational methods; Formal languages; Mathematical models; Problem solving; Recursive functions; Theorem proving; Trees (mathematics); Complexity; Elementary recursive functions; Lambda calculus; Second order logic; Formal logic
Automatic linear orders and trees,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745205530&doi=10.1145%2f1094622.1094625&partnerID=40&md5=83d4f3c312abd089818d7a786624959c,"We investigate partial orders that are computable, in a precise sense, by finite automata. Our emphasis is on trees and linear orders. We study the relationship between automatic linear orders and trees in terms of rank functions that are related to Cantor-Bendixson rank. We prove that automatic linear orders and automatic trees have finite rank. As an application we provide a procedure for deciding the isomorphism problem for automatic ordinals. We also investigate the complexity and definability of infinite paths in automatic trees. In particular, we show that every infinite path in an automatic tree with countably many infinite paths is a regular language. © 2005 ACM.",Automatic structures; Linear orders; Trees,Computer programming languages; Finite automata; Linear systems; Set theory; Trees (mathematics); Automatic structures; Finite rank; Linear orders; Trees; Data structures
Eternity variables to prove simulation of specifications,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444266154&doi=10.1145%2f1042038.1042044&partnerID=40&md5=603e05e05ebc5d43b1ffb7b981b12ee0,"Simulations of specifications are introduced as a unification and generalization of refinement mappings, history variables, forward simulations, prophecy variables, and backward simulations. A specification implements another specification if and only if there is a simulation from the first one to the second one that satisfies a certain condition. By adding stutterings, the formalism allows that the concrete behaviors take more (or possibly less) steps than the abstract ones. Eternity variables are introduced as a more powerful alternative for prophecy variables and backward simulations. This formalism is semantically complete: every simulation that preserves quiescence is a composition of a forward simulation, an extension with eternity variables, and a refinement mapping. This result does not need finite invisible nondeterminism and machine closure as in the Abadi-Lamport Theorem. The requirement of internal continuity is weakened to preservation of quiescence. Almost all concepts are illustrated by tiny examples or counter-examples.",History variables; Implementation; Invariant; Preservation of quiescence; Prophecy variables; Refinement mapping; Simulation,Algorithms; Computer simulation; Data processing; Finite automata; Hybrid computers; Mathematical transformations; Real time systems; Semantics; Theorem proving; History variables; Invariants; Preservation of quiescence; Prophecy variables; Refinement mapping; Specification implementation; Computer science
A classification of symbolic transition systems,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444249649&doi=10.1145%2f1042038.1042039&partnerID=40&md5=2ee0a67a5f575c4a0b64669514397934,"The five increasingly comprehensive classes of infinite-state systems, from STS1 to STS5, whose state spaces has finitary structure were analyzed. STS1 are the systems with finite bisimilarity quotients and can be analyzed symbolically by iteratively applying predecessor and boolean operations on state sets. STS2 are the systems with finite similarity quotients and can be analyzed symbolically by iterating the predecessor operation and positive boolean operations. STS3 are the systems with trace-equivalence quotients and can be analyzed symbolically by iterating the predecessor operation and a restricted form of positive boolean operations.",Hybrid automata; Infinite-state model checking; Model checking; State equivalences; Symbolic algorithms; Temporal logics,Boolean functions; Finite automata; Formal logic; Graph theory; Hybrid computers; Mathematical models; Problem solving; Theorem proving; Boolean operations; Hybrid automata; Infinite-state model checking; Model checking; State equivalence; Symbolic algorithm; Temporal logics; Computer science
A new decidability technique for ground term rewriting systems with applications,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444252598&doi=10.1145%2f1042038.1042042&partnerID=40&md5=a0e4ca80e58ccb55daa5186ff5a20fce,"Programming language interpreters, proving equations (e.g. x 3 = x implies the ring is Abelian), abstract data types, program transformation and optimization, and even computation itself (e.g., turing machine) can all be specified by a set of rules, called a rewrite system. Two fundamental properties of a rewrite system are the confluence or Church-Rosser property and the unique normalization property. In this article, we develop a standard form for ground rewrite systems and the concept of standard rewriting. These concepts are then used to: prove a pumping lemma for them, and to derive a new and direct decidability technique for decision problems of ground rewrite systems. To illustrate the usefulness of these concepts, we apply them to prove: (i) polynomial size bounds for witnesses to violations of unique normalization and confluence for ground rewrite systems containing unary symbols and constants, and (ii) polynomial height bounds for witnesses to violations of unique normalization and confluence for arbitrary ground systems. Apart from the fact that our technique is direct in contrast to previous decidability results for both problems, which were indirectly obtained using tree automata techniques, this approach also yields tighter bounds for rewrite systems with unary symbols than the ones that can be derived with the indirect approach. Finally, as part of our results, we give a polynomial-time algorithm for checking whether a rewrite system has the unique normalization property for all subterms in the rules of the system. Confluence, decision procedures, pumping lemma, rewriting, standard forms, unique normalization.",,Algorithms; Computer programming languages; Polynomials; Problem solving; Theorem proving; Trees (mathematics); Confluence; Decision procedures; Pumping lemma; Rewriting standard forms; Unique normalization; Program interpreters
A modal logic framework for multi-agent belief fusion,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444255459&doi=10.1145%2f1042038.1042043&partnerID=40&md5=9b5a3f1f80bba99681d416cae1e227b2,"This article provides a modal logic framework for reasoning about multi-agent belief and its fusion. We propose logics for reasoning about cautiously merged agent beliefs that have different degrees of reliability. These logics are obtained by combining the multi-agent epistemic logic and multi-source reasoning systems. The fusion is cautious in the sense that if an agent's belief is in conflict with those of higher priorities, then his belief is completely discarded from the merged result. We consider two strategies for the cautious merging of beliefs. In the first, called level cutting fusion, if inconsistency occurs at some level, then all beliefs at the lower levels are discarded simultaneously. In the second, called level skipping fusion, only the level at which the inconsistency occurs is skipped. We present the formal semantics and axiomatic systems for these two strategies and discuss some applications of the proposed logical systems. We also develop a tableau proof system for the logics and prove the complexity result for the satisfiability and validity problems of these logics.",Belief fusion; Belief revision; Database merging; Epistemic logic; Multi-agent systems; Multi-sources reasoning,Formal logic; Modal analysis; Problem solving; Search engines; Semantics; Set theory; Theorem proving; World Wide Web; Belief fusion; Belief revision; Database merging; Epistemic logic; Multi-sources reasoning; Multi agent systems
On equivalence and canonical forms in the LF type theory,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444266760&doi=10.1145%2f1042038.1042041&partnerID=40&md5=7cdf2ca58a368effc688cab721ad1e2b,"Decidability of definitional equality and conversion of terms into canonical form play a central role in the meta-theory of a type-theoretic logical framework. Most studies of definitional equality are based on a confluent, strongly normalizing notion of reduction. Coquand has considered a different approach, directly proving the correctness of a practical equivalance algorithm based on the shape of terms. Neither approach appears to scale well to richer languages with, for example, unit types or subtyping, and neither provides a notion of canonical form suitable for proving adequacy of encodings. In this article, we present a new, type-directed equivalence algorithm for the LF type theory that overcomes the weaknesses of previous approaches. The algorithm is practical, scales to richer languages, and yields a new notion of canonical form sufficient for adequate encodings of logical systems. The algorithm is proved complete by a Kripke-style logical relations argument similar to that suggested by Coquand. Crucially, both the algorithm itself and the logical relations rely only on the shapes of types, ignoring dependencies on terms.",Logical frameworks; Type theory,Algorithms; Computer science; Encoding (symbols); Theorem proving; Logical frameworks; Meta-language; Type theory; Logic programming
Making abstract domains condensing,2005,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-11444251998&doi=10.1145%2f1042038.1042040&partnerID=40&md5=43b8e007f31de25e2e1a5abd2650e157,"In this article, we show that reversible analyses of logic languages by abstract interpretation can be performed without loss of precision by systematically refining abstract domains. This is obtained by adding to the abstract domain the minimal amount of concrete semantic information so that this refined abstract domain becomes rich enough to allow goal-driven and goal-independent analyses agree. These domains are known as condensing abstract domains. Essentially, an abstract domain A is condensing when the goal-driven analysis performed on A for a program P and a given query can be retrieved with no loss of precision from the goal-independent analysis on A of P. We show that condensation is an abstract domain property and that the problem of making an abstract domain condensing boils down to the problem of making the corresponding abstract interpretation complete, in a weakened form, with respect to unification. In the case of abstract domains for logic program analysis approximating computed answer substitutions, we provide a clean logical characterization of condensing domains as fragments of propositional linear logic. We apply our methodology to the systematic design of condensing domains for freeness and independence analysis.","Abstract domain; Abstract interpretation, completeness; Condensation; Linear logic; Logic program analysis",Approximation theory; Computational complexity; Logic programming; Problem solving; Semantics; Theorem proving; Abstract domain; Abstract interpretation; Linear logic; Logic program analysis; Abstracting
NExpTime-complete Description Logics with concrete domains,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344222658&doi=10.1145%2f1024922.1024925&partnerID=40&md5=54ab6b60d0e6599445d4c5331a16b647,"Concrete domains are an extension of Description Logics (DLs) that allow one to integrate reasoning about conceptual knowledge with reasoning about ""concrete qualities"" of real-world entities such as their sizes, weights, and durations. In this article, we are concerned with the complexity of Description Logics providing for concrete domains: starting from the complexity result established in Lutz [2002b], which states that reasoning with the basic propositionally closed DL with concrete domains AℒC(D) is PSPACE-complete (provided that some weak conditions are satisfied), we perform an in-depth analysis of the complexity of extensions of this logic. More precisely, we consider five natural and seemingly ""harmless"" extensions of AℒC(D) and prove that, for all five extensions, reasoning is NEXPTIME-complete (again if some weak conditions are satisfied). Thus, we show that the PSPACE upper bound for reasoning with AℒC(D) cannot be considered robust with respect to extensions of the language.",Computational complexity; Concrete domains; Description logic; Domino problem; Nexptime-completeness; Post correspondence problem,Computational complexity; Data reduction; Formal logic; Mathematical models; Problem solving; Robustness (control systems); Semantics; Theorem proving; Concrete domains; Description logic; Domino problem; Post correspondence problem; Knowledge engineering
Abstract versus concrete computation on metric partial algebras,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344226801&doi=10.1145%2f1024922.1024924&partnerID=40&md5=2a9f09ddfaabdf031235c359625de56f,"In the theory of computation on topological algebras there is a considerable gap between so-called abstract and concrete models of computation. In concrete models, unlike abstract models, the computations depend on the representation of the algebra. First, we show that with abstract models, one needs algebras with partial operations, and computable functions that are both continuous and many-valued. This many-valuedness is needed even to compute single-valued functions, and so abstract models must be nondeterministic even to compute deterministic problems. As an abstract model, we choose the ""while""-array programming language, extended with a nondeterministic ""countable choice"" assignment, called the WhileCC* model. Using this, we introduce the concept of approximable many-valued computation on metric algebras. For our concrete model, we choose metric algebras with effective representations. We prove: (1) for any metric algebra A with an effective representation α, WhileCC* approximability implies computability in α, and (2) also the converse, under certain reasonable conditions on A. From (1) and (2) we derive an equivalence theorem between abstract and concrete computation on metric partial algebras. We give examples of algebras where this equivalence holds.",Abstract computation; Countable choice; Data types; Effective banach space; Effective metric space; Metric algebra; Partial algebra; Topological algebra,Abstracting; Computational complexity; Data reduction; Mathematical models; Problem solving; Topology; Abstract computation; Computability theory; Effective branch space; Metric algebra; Algebra
A theory of normed simulations,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344271210&doi=10.1145%2f1024922.1024923&partnerID=40&md5=2d041c812b85cd8751f0307bfe975ccf,"In existing simulation proof techniques, a single step in a lower-level specification may be simulated by an extended execution fragment in a higher-level one. As a result, it is cumbersome to mechanize these techniques using general-purpose theorem provers. Moreover, it is undecidable whether a given relation is a simulation, even if tautology checking is decidable for the underlying specification logic. This article studies various types of normed simulations. In a normed simulation, each step in a lower-level specification can be simulated by at most one step in the higher-level one, for any related pair of states. In earlier work we demonstrated that normed simulations are quite useful as a vehicle for the formalization of refinement proofs via theorem provers. Here we show that normed simulations also have pleasant theoretical properties: (1) under some reasonable assumptions, it is decidable whether a given relation is a normed forward simulation, provided tautology checking is decidable for the underlying logic; (2) at the semantic level, normed forward and backward simulations together form a complete proof method for establishing behavior inclusion, provided that the higher-level specification has finite invisible nondeterminism.",Automata; Backward simulations; Computer-aided verification; Forward simulations; History variables; Normed simulations; Prophecy variables; Refinement mappings,Computer aided logic design; Computer simulation; Formal logic; Functions; Mathematical models; Problem solving; Semantics; backward simulation; Computer-aided verification; Forward simulation; Refinement mappings; Automata theory
Interval constraint solving for camera control and motion planning,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344271961&doi=10.1145%2f1024922.1024927&partnerID=40&md5=fc00c7c5d4fc5000020f1cf89421a6bb,"Many problems in robust control and motion planning can be reduced to either finding a sound approximation of the solution space determined by a set of nonlinear inequalities, or to the ""guaranteed timing problem"" as defined by Jaulin and Walter, which amounts to finding a value for some tuning parameter such that a set of inequalities be verified for all the possible values of some perturbation vector. A classical approach to solving these problems, which satisfies the strong soundness requirement, involves some quantifier elimination procedure such as Collins' Cylindrical Algebraic Decomposition symbolic method. Sound numerical methods using interval arithmetic and local consistency enforcement to prune the search space are presented in this article as much fester alternatives for both soundly solving systems of nonlinear inequalities, and addressing the guaranteed tuning problem whenever the perturbation vector has dimension 1. The use of these methods in camera control is investigated, and experiments with the prototype of a declarative modeler to express camera motion using a cinematic language are reported and commented upon.",Camera control; Inner approximation; Interval constraint; Universal quantifier,Approximation theory; Cameras; Computational complexity; Computer programming; Control systems; Degrees of freedom (mechanics); Mathematical models; Camera control; Inner approximation; Interval constraints; Universal quantifiers; Constraint theory
Proving correctness of timed concurrent constraint programs,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344233351&doi=10.1145%2f1024922.1024926&partnerID=40&md5=1419ea44f08e6e5accdf31e7e8a8f27c,A temporal logic is presented for reasoning about the correctness of timed concurrent constraint programs. The logic is based on modalities which allow one to specify what a process produces as a reaction to what its environment inputs. These modalities provide an assumption/connnitnient style of specification which allows a sound and complete compositional ayimnatimatron of the reactive behavior of timed concurrent constraint programs.,Concurrency; Constraints; Reactive systems; Temporal logic,Computer software; Data reduction; Embedded systems; Formal logic; Mathematical models; Robustness (control systems); Theorem proving; Concurrency; Constraints; Reactive systems; Temporal logic; Constraint theory
Reflective metalogical frameworks,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142780585&doi=10.1145%2f1013560.1013566&partnerID=40&md5=57583a16344c1bf20c6ca8ffc207bcb0,"A metalogical framework is a logic with an associated methodology that is used to represent other logics and to reason about their metalogical properties. We propose that logical frameworks can be good metalogical frameworks when their theories always have initial models and they support reflective and parameterized reasoning. We develop this thesis both abstractly and concretely. Abstractly, we formalize our proposal as a set of requirements and explain how any logic satisfying these requirements can be used for metalogical reasoning, Concretely, we present membership equational logic as a particular metalogic that satisfies these requirements. Using membership equational logic, and its realization in the Maude system, we show how reflection can be used for different, nontrivial kinds of formal metatheoretic reasoning. In particular, one can prove metatheorems that relate theories or establish properties of parameterized classes of theories.",Membership equational logic; Metalogics; Reflection; Rewriting logic,Algorithms; Artificial intelligence; Electromagnetic wave reflection; Formal languages; Information retrieval; Knowledge acquisition; Mathematical models; Membership equational logic; Metalogics; Rewriting logic; Logic programming
Termination of simply moded logic programs with dynamic scheduling,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142782051&doi=10.1145%2f1013560.1013564&partnerID=40&md5=87e0f65499dc1f3b0a43c773ad7d7227,"In logic programming, dynamic scheduling indicates the feature by means of which the choice of the atom to be selected at each resolution step is done at runtime and does not follow a fixed selection rule such as the left-to-right one of Prolog. Input-consuming derivations were introduced to model dynamic scheduling while abstracting from the technical details. In this article, we provide a sufficient and necessary criterion for termination of input-consuming derivations of simply moded logic programs. The termination criterion we propose is based on a denotational semantics for partial derivations which is defined in the spirit of model-theoretic semantics previously proposed for left-to-right derivations.",Dynamic scheduling; Logic programs; Simply moded; Termination,Algorithms; Formal languages; Mathematical models; Scheduling; Semantics; Dynamic scheduling; Logic programs; Simply moded; Termination; Logic programming
Symbolic semantic rules for producing compact STGLAs from value passing process descriptions,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142742303&doi=10.1145%2f1013560.1013563&partnerID=40&md5=c2a88583077baf32279a7414254e0aa7,"Value passing process algebras with infinite data domains need to be equipped with symbolic semantic models in order for their analysis to be possible. This means that appropriate symbolic models and the related verification algorithms must be developed, together with suitable semantic rules mapping the value passing process descriptions to such symbolic models. In this article, we first introduce the model of the symbolic transition graphs with lookahead assignment (STGLAs), a variant of the symbolic transition graphs with assignment (STGAs) of Lin that can undergo to the strong, weak and observational bisimulation equivalence checking algorithms of Li and Chen. We then define a set of symbolic semantic rules that map a useful fragment of value passing CCS to finite STGLAs without making any assumption about the variable names. We demonstrate that the symbolic semantic rules are correct with respect to both the usual concrete semantic rules and the novel issue of the assignment application order. Finally, we prove that, for the considered fragment of value passing CCS, the STGLAs produced by the symbolic semantic rules are optimal with respect to a certain compactness criterion, thus improving on the symbolic models and the semantic rules previously proposed in the literature.",Process algebras; Symbolic semantics; Value passing,Algebra; Algorithms; Computation theory; Formal languages; Graph theory; Mathematical models; Process algebras; Symbolic semantics; Value passing; Semantics
Hypothesis-based semantics of logic programs in multivalued logics,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142745213&doi=10.1145%2f1013560.1013565&partnerID=40&md5=b0ef57769837998a4859687885ba657b,"We address the problem of defining semantics for logic programs in presence of incomplete and contradictory information coming from different sources. The information consists of facts that a central server collects and tries to combine using (a) a set of logical rules, that is, a logic program, and (b) a hypothesis representing the server's own estimates. In such a setting incomplete information from a source or contradictory information from different sources necessitate the use of many-valued logics in which programs can be evaluated and hypotheses can be tested. To carry out such activities we propose a formal framework based on bilattices such as Belnap's four-valued logics. In this framework we work with the class of programs defined by Fitting and we propose hypothesis-based semantics for such programs. We also establish an intuitively appealing connection between our hypothesis testing mechanism, on the one hand, and the well-founded semantics and Kripke-Kleene semantics of Datalog programs with negation, on the other hand.",Assumptions; Bilattices; Reasoning with incomplete knowledge,Algorithms; Formal languages; Information retrieval; Knowledge acquisition; Mathematical models; Semantics; Assumptions; Bilattices; Reasoning with incomplete knowledge; Logic programming
Basic theory of feature trees,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142686677&doi=10.1145%2f1013560.1013561&partnerID=40&md5=4106529d2df0a83e7c097d78190df803,"We present a decision algorithm for the problem Val(F T) of deciding validity of first-order sentences in the theory of feature trees. Its time complexity is exp⌊c·m⌋ (c·n) where n is the length of a sentence, m is the quantifier depth of a sequence, and c is a constant. The function expi(j) is an exponential tower of 2's of height i, to power j (exp0(j) = j and expi+1(j) = 2 expi(j)). Moreover we prove that the presented algorithm is optimal, deriving a lower bound which matches the upper one.",Complexity; Feature; Tree,Algorithms; Computational complexity; Constraint theory; Database systems; Feature extraction; Information retrieval; Knowledge acquisition; Logic programming; Problem solving; Constraint solving; Data type specification; Feature trees; First-order formulas; Trees (mathematics)
Finite state machines for strings over infinite alphabets,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142676414&doi=10.1145%2f1013560.1013562&partnerID=40&md5=63ebf72f37e0ebcbb52505c580b6c898,"Motivated by formal models recently proposed in the context of XML, we study automata and logics on strings over infinite alphabets. These are conservative extensions of classical automata and logics defining the regular languages on finite alphabets. Specifically, we consider register and pebble automata, and extensions of first-order logic and monadic second-order logic. For each type of automaton we consider one-way and two-way variants, as well as deterministic, nondeterministic, and alternating control, We investigate the expressiveness and complexity of the automata and their connection to the logics, as well as standard decision problems. Some of our results answer open questions of Kaminski and Francez on register automata.",Automata; Expressiveness; First-order logic; Infinite alphabets; Monadic second-order logic; Pebbles; Registers; XML,Algorithms; Decision making; Formal languages; Problem solving; World Wide Web; XML; Expressiveness; First-order logic; Infinite alphabets; Monadic second-order logic; Pebbles; Registers; Finite automata
Automatic generation of rule-based constraint solvers over finite domains,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444269262&doi=10.1145%2f976706.976707&partnerID=40&md5=cb2350cd6945729684bcc70f6f4d6efe,"A general approach to implement propagation and simplification of constraints consists of applying rules over these constraints. However, a difficulty that arises frequently when writing a constraint solver is to determine the constraint propagation algorithm. In this article, we propose a method for generating propagation and simplification rules for constraints over finite domains defined extensionally by, for example, a truth table or their tuples. The generation of rules is performed in two steps, First, propagation rules are generated. Propagation rules do not rewrite constraints but add new ones. Thus, the constraint store may contain superfluous constraints. Removing these constraints not only allows saving of space but also decreases the cost of constraint solving. Constraints can be removed using simplification rules. Thus, in a second step, some propagation rules are transformed into simplification rules. Furthermore, we show that our approach performs well on various examples, including Boolean constraints, multivalued logic, and Allen's qualitative approach to temporal logic. Moreover, an application taken from the field of digital circuit design shows that our approach is of practical use.",Finite domains; Generation of solvers; Rule-based constraint programming,Algorithms; Artificial intelligence; Boolean algebra; Computer programming languages; Computer science; Digital circuits; Mathematical transformations; Set theory; Boolean circuit; Constraint handling rules (CHR); Propagation rules; Superfluous constraints; Constraint theory
Convergent approximate solving of first-order constraints by approximate quantifiers,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444252959&doi=10.1145%2f976706.976709&partnerID=40&md5=aee8869215bd98a936ec758800c5bb42,"Exactly solving first-order constraints (i.e., first-order formulas over a certain predefined structure) can be a very hard, or even undecidable problem. In continuous structures like the real numbers it is promising to compute approximate solutions instead of exact ones. However, the quantifiers of the first-order predicate language are an obstacle to allowing approximations to arbitrary small error bounds. In this article, we remove this obstacle by modifying the first-order language and replacing the classical quantifiers with approximate quantifiers. These also have two additional advantages: First, they are tunable, in the sense that they allow the user to decide on the trade-off between precision and efficiency. Second, they introduce additional expressivity into the first-order language by allowing reasoning over the size of solution sets.",Constraints; Decision procedures; Generalized quantifiers; Real numbers,Algorithms; Computational complexity; Computational linguistics; Computer programming; Information analysis; Mathematical models; Numerical control systems; Set theory; Constraints; Decision procedures; Generalized quantifiers; Real numbers; Constraint theory
A logic programming approach to knowledge-state planning: Semantics and complexity,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444318232&doi=10.1145%2f976706.976708&partnerID=40&md5=fd2077dbcd926d29c12f2c89d390f74f,"We propose a new declarative planning language, called K, which is based on principles and methods of logic programming. In this language, transitions between states of knowledge can be described, rather than transitions between completely described states of the world, which makes the language well suited for planning under incomplete knowledge. Furthermore, our formalism enables the use of default principles in the planning process by supporting negation as failure. Nonetheless, K also supports the representation of transitions between states of the world (i.e., states of complete knowledge) as a special case, which shows that the language is very flexible. As we demonstrate on particular examples, the use of knowledge states may allow for a natural and compact problem representation. We then provide a thorough analysis of the computational complexity of K, and consider different planning problems, including standard planning and secure planning (also known as conformant planning) problems. We show that these problems have different complexities under various restrictions, ranging from NP to NEXPTIME in the propositional case. Our results form the theoretical basis for the DLV K system, which implements the language K on top of the DLV logic programming system.",Answer sets; Computational complexity; Conformant planning; Declarative planning; Incomplete information; Knowledge-states; Secure planning,Artificial intelligence; Computational complexity; Computer programming languages; Large scale systems; Semantics; Sensitivity analysis; Answer sets; Conformant planning; Incomplete information; Knowledge-states; Secure planning; Logic programming
A decomposition-based implementation of search strategies,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444347375&doi=10.1145%2f976706.976714&partnerID=40&md5=15710f899dabda20d04befb04e11f5a5,"Search strategies, that is, strategies that describe how to explore search trees, have raised much interest for constraint satisfaction in recent years. In particular, limited discrepancy search and its variations have been shown to achieve significant improvements in efficiency over depth-first search for some classes of applications. This article reconsiders the implementation of discrepancy search, and of search strategies in general, for applications where the search procedure is dynamic, randomized, and/or generates global cuts (or nogoods) that apply to the remaining search. It illustrates that recomputation-based implementations of discrepancy search are not robust with respect to these extensions and require special care which may increase the memory requirements significantly and destroy the genericity of the implementation. To remedy these limitations, the article proposes a novel implementation scheme based on problem decomposition, which combines the efficiency of the recomputation-based implementations with the robustness of traditional iterative implementations. Experimental results on job-shop scheduling problems illustrate the potential of this new implementation scheme, which, surprisingly, may significantly outperform recomputation-based schemes.",Combinatorial optimization; Constraint programming; Search,Computational complexity; Computer programming; Computer programming languages; Computer science; Computer software; Iterative methods; Logic design; Optimization; Robustness (control systems); Theorem proving; Combinatorial optimization; Constraint programming; Decomposition algorithms; Constraint theory
Some applications of logic to feasibility in higher types,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444341590&doi=10.1145%2f976706.976713&partnerID=40&md5=18191a4d0c3b3cf43f539087bb14f323,"While it is commonly accepted that computability on a Turing machine in polynomial time represents a correct formalization of the notion of a feasibly computable function, there is no similar agreement on how to extend this notion on functional, that is, what functionals should be considered feasible. One possible paradigm was introduced by Mehlhorn, who extended Cobham's definition of feasible functions to type 2 functionals. Subsequently, this class of functionals (with inessential changes of the definition) was studied by Townsend who calls this class POLY, and by Kapron and Cook who call the same class basic feasible functionals. Kapron and Cook gave an oracle Turing machine model characterisation of this class. In this article, we demonstrate that the class of basic feasible functionals has recursion theoretic properties which naturally generalise the corresponding properties of the class of feasible functions, thus giving further evidence that the notion of feasibility of functionals mentioned above is correctly chosen. We also improve the Kapron and Cook result on machine representation. Our proofs are based on essential applications of logic. We introduce a weak fragment of second order arithmetic with second order variables ranging over functions from ℕ ℕ which suitably characterises basic feasible functionals, and show that it is a useful tool for investigating the properties of basic feasible functionals. In particular, we provide an example how one can extract feasible programs from mathematical proofs that use nonfeasible functions.",Bounded arithmetic; Functionals; Higher-order complexity; Second-order theories,Algorithms; Computational complexity; Formal languages; Machine components; Mathematical models; Mathematical techniques; Polynomials; Turing machines; Bounded arithmetic; Functionals; Higher-oder complexity; Second-order theories; Formal logic
Inflationary fixed points in modal logic,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444382503&doi=10.1145%2f976706.976710&partnerID=40&md5=c0bb3a6dcbd92a08ee6963476f54740c,"We consider an extension of modal logic with an operator for constructing inflationary fixed points, just as the modal μ-calculus extends basic modal logic with an operator for least fixed points. Least and inflationary fixed-point operators have been studied and compared in other contexts, particularly in finite model theory, where it is known that the logics IFP and LFP that result from adding such fixed-point operators to first-order logic have equal expressive power. As we show, the situation in modal logic is quite different, as the modal iteration calculus (MIC), we introduce has much greater expressive power than the μ-calculus. Greater expressive power comes at a cost: the calculus is algorithmically much less manageable.",Complexity; Decidability; Expressive power; Fixed-point logics; Modal logic,Algorithms; Computability and decidability; Computer science; Finite automata; Mathematical models; Numerical analysis; Set theory; Theorem proving; Complexity; Expressive power; Fixed-point logics; Modal logic; Natural numbers; Formal logic
Classes of term rewrite systems with polynomial confluence problems,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444282626&doi=10.1145%2f976706.976712&partnerID=40&md5=239951db7ec4811a360229c43a136606,"The confluence property of ground (i.e., variable-free) term rewrite systems (TRS) is well known to be decidable. This was proved independently in Dauchet et al. [1987, 1990] and in Oyamaguchi [1987] using tree automata techniques and ground tree transducer techniques (originated from this problem), yielding EXPTIME decision procedures (PSPACE for strings). Since then, and until last year, the optimality of this bound had been a well-known longstanding open question (see, e.g., RTA-LOOP [2001]). In Comon et al. [2001], we gave the first polynomial-time algorithm for deciding the confluence of ground TRS. Later in Tiwari [2002] this result was extended, using abstract congruent closure techniques, to linear shallow TRS, that is, TRS where no variable occurs twice in the same rule nor at depth greater than one. Here, we give a new and much simpler proof of the latter result.",Confluence; Rewriting,Algorithms; Automata theory; Formal languages; Formal logic; Matrix algebra; Optimal control systems; Polynomials; Theorem proving; Confluence; Rewriting; Term rewrite systems (TRS); Tree transducer techniques; Trees (mathematics)
Optimal length tree-like resolution refutations for 2SAT formulas,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444314501&doi=10.1145%2f976706.976711&partnerID=40&md5=f1d081e16ed2560ddca717812b75e811,"In this article, we exploit the graphical structure of 2SAT formulas to show that the shortest tree-like resolution refutation of an unsatisfiable 2SAT formula can be determined in polynomial time.",2SAT formulas; Resolution; Tree-like proofs,Algorithms; Database systems; Formal languages; Formal logic; Logic design; Polynomials; Theorem proving; Trees (mathematics); 2SAT formulas; Resolutions; Tautologies; Tree-like proofs; Computational complexity
Deterministic generators and games for LTL fragments,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444246434&doi=10.1145%2f963927.963928&partnerID=40&md5=d454837d189c56a1567223295365a6f5,"Deciding infinite two-player games on finite graphs with the winning condition specified by a linear temporal logic (LTL) formula, is known to be 2EXPTIME-complete. In this paper, we identify LTL fragments of lower complexity. Solving LTL games typically involves a doubly exponential translation from LTL formulas to deterministic ω-automata. First, we show that the longest distance (length of the longest simple path) of the generator is also an important parameter, by giving an O(d log n)-space procedure to solve a Büchi game on a graph with n vertices and longest distance d. Then, for the LTL fragment of the Boolean combinations of formulas obtained only by eventualities and conjunctions, we provide a translation to deterministic generators of exponential size and linear longest distance, show both of these bounds to be optimal, and prove the corresponding games to be PSPACE-complete. Introducing next modalities in this fragment, we give a translation to deterministic generators still of exponential size but also with exponential longest distance, show both of these bounds to be optimal, and prove the corresponding games to be EXPTIME-complete. For the fragment resulting by further adding disjunctions, we provide a translation to deterministic generators of doubly exponential size and exponential longest distance, show both of these bounds to be optimal, and prove the corresponding games to be EXPSPACE. We also show tightness of the double exponential bound on the size as well as the longest distance for deterministic generators of LTL formulas without next and until modalities. Finally, we identify a class of deterministic Büchi automata corresponding to a fragment of LTL with restricted use of always and until modalities, for which deciding games is PSPACE-complete.",Automata; Games; Temporal Logic,Automata theory; Boolean algebra; Calculations; Combinatorial mathematics; Computational complexity; Computer graphics; Formal logic; Graph theory; Linear programming; Mathematical models; Problem solving; Theorem proving; Automata; Games; Generators; Temporal logic; Game theory
Precongruence formats for decorated trace semantics,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444349221&doi=10.1145%2f963927.963929&partnerID=40&md5=e024fbf9709c14d08e3d2779eabfc346,"This paper explores the connection between semantic equivalences and preorders for concrete sequential processes, represented by means of labeled transition systems, and formats of transition system specifications using Plotkin's structural approach. For several preorders in the linear time-branching time spectrum a format is given, as general as possible, such that this preorder is a precongruence for all operators specifiable in that format. The formats are derived using the modal characterizations of the corresponding preorders.",Decorated trace semantics; Precongruence,Computer simulation; Equivalence classes; Functions; Mathematical operators; Modal analysis; Theorem proving; Decorated trace semantics; Equivalences; Precongruence; Transition systems; Semantics
Super logic programs,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4444279299&doi=10.1145%2f963927.963931&partnerID=40&md5=067ea221ee776700fba3e228f5619d68,"The Autoepistemic Logic of Knowledge and Belief (AELB) is a powerful nonmonotonic formalism introduced by Teodor Przymusinski in 1994. In this paper, we specialize it to a class of theories called ""super logic programs"". We argue that these programs form a natural generalization of standard logic programs. In particular, they allow disjunctions and default negation of arbitrary positive objective formulas. Our main results are two new and important characterizations of the static semantics of these programs, one syntactic, and one model-theoretic. The syntactic fixed point characterization is much simpler than the fixed point construction of the static semantics for arbitrary AELB theories. The model-theoretic characterization via Kripke models allows one to construct finite representations of the inherently infinite static expansions. Both characterizations can be used as the basis of algorithms for query answering under the static semantics. We describe a query-answering interpreter for super programs that we developed based on the model-theoretic characterization and which is available on the web.",Disjunctive logic programming; Logics of knowledge and beliefs; Minimal models; Negation; Nonmonotonic reasoning; Semantics of logic programs and deductive databases; Static semantics; Well-founded semantics,Algorithms; Computer software; Database systems; Formal languages; Logic programming; Mathematical models; Program interpreters; Semantics; Syntactics; Theory; Disjunctive logic programming; Logics of knowledge and beliefs; Minimal models; Negation; Nonmonotonic reasoning; Semantics of logic programs and deductive databases; Static semantics; Well-founded semantics; Formal logic
A modal logic for mobile agents,2004,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3543141324&doi=10.1145%2f963927.963930&partnerID=40&md5=13eff7bd6bff25255531901473c141e0,"KLAIM is an experimental programming language that supports a programming paradigm where both processes and data can be moved across different computing environments. The language relies on the use of explicit localities. This paper presents a temporal logic for specifying properties of Klaim programs. The logic is inspired by Hennessy-Milner Logic (HML) and the μ-calculus, but has novel features that permit dealing with state properties and impact of actions and movements over the different sites. The logic is equipped with a complete proof system that enables one to prove properties of mobile systems.",Coordination Models; Logics; Mobile Code Languages; Mobility; Proof Systems; Temporal Logics of Programs,Computer programming languages; Computer simulation; Data transfer; Formal languages; Internet; Security of data; Theory; Wide area networks; Languages; Mobile agents; Modal logic; Security; Temporal logic; Verification; Formal logic
Variable Independence for First-Order Definable Constraints,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042813187&doi=10.1145%2f937555.937557&partnerID=40&md5=0d371cfee7798dd077eea1a67a92a451,"Whenever we have data represented by constraints (such as order, linear, polynomial, etc.), running time for many constraint processing algorithms can be considerably lowered if it is known that certain variables in those constraints are independent of each other. For example, when one deals with spatial and temporal databases given by constraints, the projection operation, which corresponds to quantifier elimination, is usually the costliest. Since the behavior of many quantifier elimination algorithms becomes worse as the dimension increases, eliminating certain variables from consideration helps speed up those algorithms. While these observations have been made in the literature, it remained unknown when the problem of testing if certain variables are independent is decidable, and how to efficiently construct a new representation of a constraint-set in which those variables do not appear together in the same atomic constraints. Here we answer this question. We first consider a general condition that gives us decidability of variable independence; this condition is stated in terms of model-theoretic properties of the structures corresponding to constraint classes. We then show that this condition covers the domains most relevant to spatial and temporal applications. For some of these domains, including linear and polynomial constraints over the reals, we provide a uniform decision procedure that gives us tractability as well. For those constraints, we also present a polynomial-time algorithm for producing nice constraint representations. © 2003, ACM. All rights reserved.",definable sets; First-order logic; Languages; linear constraints; polynomial constraints; spatio-temporal databases; Theory; variable independence,Algorithms; Computer simulation; Database systems; Decision making; Formal languages; Formal logic; Logic programming; Mathematical models; Polynomials; Definable sets; First-order logic; Polynomial constraints; Spatio-temporal databases; Variable independence; Constraint theory
Higher-Order Pattern Complement and the Strict λ-Calculus,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042814325&doi=10.1145%2f937555.937559&partnerID=40&md5=2e863d6f17de1ad8c3e1af827be2f1aa,"We address the problem of complementing higher-order patterns without repetitions of existential variables. Differently from the first-order case, the complement of a pattern cannot, in general, be described by a pattern, or even by a finite set of patterns. We therefore generalize the simply-typed λ-calculus to include an internal notion of strict function so that we can directly express that a term must depend on a given variable. We show that, in this more expressive calculus, finite sets of patterns without repeated variables are closed under complement and intersection. Our principal application is the transformational approach to negation in higher-order logic programs. © 2003, ACM. All rights reserved.",Complement; higher-order patterns; Languages; strict λ-calculus; Theory,Algorithms; Boolean algebra; Computer programming languages; Formal languages; Formal logic; Linear programming; Mathematical transformations; Semantics; Complement; Equational theory; Higher-order patterns; Strict λ-calculus; Logic programming
A Dynamic Approach to Characterizing Termination of General Logic Programs,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042856060&doi=10.1145%2f937555.937556&partnerID=40&md5=8af2c30c5d66f35146a8549e64e86bff,"We present a new characterization of termination of general logic programs. Most existing termination analysis approaches rely on some static information about the structure of the source code of a logic program, such as modes/types, norms/level mappings, models/interargument relations, and the like. We propose a dynamic approach that employs some key dynamic features of an infinite (generalized) SLDNF-derivation, such as repetition of selected subgoals and recursive increase in term size. We also introduce a new formulation of SLDNF-trees, called generalized SLDNF-trees. Generalized SLDNF-trees deal with negative subgoals in the same way as Prolog and exist for any general logic programs. © 2003, ACM. All rights reserved.",dynamic characterization; Languages; Prolog; Termination analysis; Theory,Automatic programming; Computer programming languages; Constraint theory; Formal logic; Information analysis; Mapping; Programming theory; Trees (mathematics); Dynamic characterization; Prolog; Subgoals; Termination analysis; Logic programming
Model Checking Stochastic Automata,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042856059&doi=10.1145%2f937555.937558&partnerID=40&md5=4f341177c207c09ecc5c9df7f6ba1850,"Modern distributed systems include a class of applications in which non-functional requirements are important. In particular, these applications include multimedia facilities where real time constraints are crucial to their correct functioning. In order to specify such systems it is necessary to describe that events occur at times given by probability distributions; stochastic automata have emerged as a useful technique by which such systems can be specified and verified. However, stochastic descriptions are very general, in particular they allow the use of general probability distribution functions, and therefore their verification can be complex. In the last few years, model checking has emerged as a useful verification tool for large systems. In this article we describe two model checking algorithms for stochastic automata. These algorithms consider how properties written in a simple probabilistic real-time logic can be checked against a given stochastic automaton. © 2003, ACM. All rights reserved.",Distributed systems; model checking; Performance; stochastic automata; Verification,Algorithms; Computer simulation; Distributed computer systems; Formal languages; Formal logic; Large scale systems; Mathematical models; Matrix algebra; Probability distributions; Software engineering; Model checking; Real-time logic; Stochastic automata; Automata theory
Abstract State Machines Capture Parallel Algorithms,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042773722&doi=10.1145%2f937555.937561&partnerID=40&md5=c08d1e22e7499f8335a3232f8bafc9ef,"We give an axiomatic description of parallel, synchronous algorithms. Our main result is that every such algorithm can be simulated, step for step, by an abstract state machine with a background that provides for multisets. © 2003, ACM. All rights reserved.",abstract state machine; Algorithms; ASM thesis; Languages; Parallel algorithm; postulates for parallel computation; Theory,Computational methods; Computer programming languages; Computer simulation; Mathematical models; Parallel processing systems; Parameter estimation; Abstract state machine (ASM); ASm thesis; Postulates for parallel computation; Parallel algorithms
Interaction Between Path and Type Constraints,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042812068&doi=10.1145%2f937555.937560&partnerID=40&md5=1e75b23e02333e6a8e5d25b5eb120732,"Path constraints are capable of expressing inclusion and inverse relationships and have proved useful in modeling and querying semistructured data [Abiteboul and Vianu 1999; Buneman et al. 2000]. Types also constrain the structure of data and are commonly found in traditional databases. There has also been work on imposing structure or a type system on semistructured data for storing and querying semistructured data in a traditional database system [Alon et al. 2001; Deutsch et al. 1999a; Florescu and Kossmann 1999; Shanmugasundaram et al. 1999]. One wants to know whether complexity results for reasoning about path constraints established in the untyped (semistructured) context could carry over to traditional databases, and vice versa. It is therefore appropriate to understand the interaction between types and path constraints. In addition, XML [Bray et al. 1998], which may involve both an optional schema (e.g., DTDs or XML Schema [Thompson et al. 2001]) and integrity constraints, highlights the importance of the study of the interaction. This article investigates that interaction. In particular it studies constraint implication problems, which are important both in understanding the semantics of type/constraint systems and in query optimization. It shows that path constraints interact with types in a highly intricate way. For that purpose a number of results on path constraint implication are established in the presence and absence of type systems. These results demonstrate that adding a type system may in some cases simplify reasoning about path constraints and in other cases make it harder. For example, it is shown that there is a path constraint implication problem that is decidable in PTIME in the untyped context, but that becomes undecidable when a type system is added. On the other hand, there is an implication problem that is undecidable in the untyped context, but becomes not only decidable in cubic time but also finitely axiomatizable when a type system is imposed. © 2003, ACM. All rights reserved.",Algorithms; Design; implication; integrity constraints; Languages; semistructured data; Theory; types,Algorithms; Computer programming languages; Computer simulation; Data acquisition; Formal logic; Mathematical models; Object oriented programming; Problem solving; Programming theory; Query languages; Semantics; Theorem proving; XML; Implication; Integrity constraints; Semistructured data; Type constraint; Constraint theory
Eliminating Definitions and Skolem Functions in First-Order Logic,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544364318&doi=10.1145%2f772062.772068&partnerID=40&md5=74f6fcc19e6cddc9f4f00c928340244c,"From proofs in any classical first-order theory that proves the existence of at least two elements, one can eliminate definitions in polynomial time. From proofs in any classical first-order theory strong enough to code finite functions, including sequential theories, one can also eliminate Skolem functions in polynomial time. © From proofs in any classical first-order theory that proves the existence of at least two elements, one can eliminate definitions in polynomial time. From proofs in any classical first-order theory strong enough to code finite functions, including sequential theories, one can also eliminate Skolem functions in polynomial time. © 2003, ACM. All rights reserved.",Algorithms; Definitions; lengths of proofs; proof complexity; Skolem functions; Theory,
Substructural Logic and Partial Correctness,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-71049168515&doi=10.1145%2f772062.772066&partnerID=40&md5=2fc50d06879b66122f5485de54b546f8,"We formulate a noncommutative sequent calculus for partial correctness that subsumes propositional Hoare Logic. Partial correctness assertions are represented by intuitionistic linear implication. We prove soundness and completeness over relational and trace models. As a corollary, we obtain a complete sequent calculus for inclusion and equivalence of regular expressions. © We formulate a noncommutative sequent calculus for partial correctness that subsumes propositional Hoare Logic. Partial correctness assertions are represented by intuitionistic linear implication. We prove soundness and completeness over relational and trace models. As a corollary, we obtain a complete sequent calculus for inclusion and equivalence of regular expressions. © 2003, ACM. All rights reserved.",Dynamic logic; Hoare logic; Kleene algebra; Kleene algebra with tests; linear logic; sequent calculus; specification; substructural logic; Theory; Verification,
Typechecking XML Views of Relational Databases,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57849084676&doi=10.1145%2f772062.772065&partnerID=40&md5=b00ddd7ea8987791106b45fe90c6407c,"Motivated by the need to export relational databases as XML data in the context of the Web, we investigate the typechecking problem for transformations of relational data into tree data (XML). The problem consists of statically verifying that the output of every transformation belongs to a given output tree language (specified for XML by a DTD), for input databases satisfying given integrity constraints. The typechecking problem is parameterized by the class of formulas defining the transformation, the class of output tree languages, and the class of integrity constraints. While undecidable in its most general formulation, the typechecking problem has many special cases of practical interest that turn out to be decidable. The main contribution of this article is to trace a fairly tight boundary of decidability for typechecking in this framework. In the decidable cases we examine the complexity, and show lower and upper bounds.We also exhibit a practically appealing restriction for which typechecking is in PTIME. © Motivated by the need to export relational databases as XML data in the context of the Web, we investigate the typechecking problem for transformations of relational data into tree data (XML). The problem consists of statically verifying that the output of every transformation belongs to a given output tree language (specified for XML by a DTD), for input databases satisfying given integrity constraints. The typechecking problem is parameterized by the class of formulas defining the transformation, the class of output tree languages, and the class of integrity constraints. While undecidable in its most general formulation, the typechecking problem has many special cases of practical interest that turn out to be decidable. The main contribution of this article is to trace a fairly tight boundary of decidability for typechecking in this framework. In the decidable cases we examine the complexity, and show lower and upper bounds.We also exhibit a practically appealing restriction for which typechecking is in PTIME. © 2003, ACM. All rights reserved.",Algorithms; Complexity; Languages; logic; relational databases; Theory; typechecking; XML,
An n! Lower Bound on Formula Size,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019463009&doi=10.1145%2f772062.772064&partnerID=40&md5=1d26fde8bb8834781c9dd032f900ff74,"We introduce a new Ehrenfeucht-Fraïssé game for proving lower bounds on the size of first-order formulas. Up until now, such games have only been used to prove bounds on the operator depth of formulas, not their size. We use this game to prove that the CTL+formula, Occurn≡ E[Fp1∧ Fp2∧…∧Fpn], which says that there is a path along which the predicates p1through pnall occur, requires size n! to express in CTL. Our lower bound is optimal. It follows that the succinctness of CTL+with respect to CTL is exactly Θ(n)!. Wilke had shown that the succinctness was at least exponential [Wilke 1999]. We also use our games to prove an optimal Ω(n) lower bound on the number of boolean variables needed for forward reachability logic (RLf) to polynomially embed the language CTL+ The number of booleans needed for full reachability logic RL and the transitive closure logic FO2(TC) remain open [Immerman and Vardi 1997; Alechina and Immerman 2000]. © We introduce a new Ehrenfeucht-Fraïssé game for proving lower bounds on the size of first-order formulas. Up until now, such games have only been used to prove bounds on the operator depth of formulas, not their size. We use this game to prove that the CTL+formula, Occurn≡ E[Fp1∧ Fp2∧…∧Fpn], which says that there is a path along which the predicates p1through pnall occur, requires size n! to express in CTL. Our lower bound is optimal. It follows that the succinctness of CTL+with respect to CTL is exactly Θ(n)!. Wilke had shown that the succinctness was at least exponential [Wilke 1999]. We also use our games to prove an optimal Ω(n) lower bound on the number of boolean variables needed for forward reachability logic (RLf) to polynomially embed the language CTL+ The number of booleans needed for full reachability logic RL and the transitive closure logic FO2(TC) remain open [Immerman and Vardi 1997; Alechina and Immerman 2000]. © 2003, ACM. All rights reserved.",Descriptive complexity; lower bounds; temporal logic; Theory,
Topological Incompleteness and Order Incompleteness of the Lambda Calculus,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006212446&doi=10.1145%2f772062.772067&partnerID=40&md5=a179136d947a936f5d023bee9497f516,"A model of the untyped lambda calculus univocally induces a lambda theory (i.e., a congruence relation on λ-terms closed under α- and β-conversion) through the kernel congruence relation of the interpretation function. A semantics of lambda calculus is (equationally) incomplete if there exists a lambda theory that is not induced by any model in the semantics. In this article, we introduce a new technique to prove in a uniform way the incompleteness of all denotational semantics of lambda calculus that have been proposed so far, including the strongly stable one, whose incompleteness had been conjectured by Bastonero, Gouy and Berline. We apply this technique to prove the incompleteness of any semantics of lambda calculus given in terms of partially ordered models with a bottom element. This incompleteness removes the belief that partial orderings with a bottom element are intrinsic to models of the lambda calculus, and that the incompleteness of a semantics is only due to the richness of the structure of representable functions. Instead, the incompleteness is also due to the richness of the structure of lambda theories. Further results of the article are: (i) an incompleteness theorem for partially ordered models with finitely many connected components (D minimal upward and downward closed sets); (ii) an incompleteness theorem for topological models whose topology satisfies a suitable property of connectedness; (iii) a completeness theorem for topological models whose topology is non-trivial and metrizable. © A model of the untyped lambda calculus univocally induces a lambda theory (i.e., a congruence relation on λ-terms closed under α- and β-conversion) through the kernel congruence relation of the interpretation function. A semantics of lambda calculus is (equationally) incomplete if there exists a lambda theory that is not induced by any model in the semantics. In this article, we introduce a new technique to prove in a uniform way the incompleteness of all denotational semantics of lambda calculus that have been proposed so far, including the strongly stable one, whose incompleteness had been conjectured by Bastonero, Gouy and Berline. We apply this technique to prove the incompleteness of any semantics of lambda calculus given in terms of partially ordered models with a bottom element. This incompleteness removes the belief that partial orderings with a bottom element are intrinsic to models of the lambda calculus, and that the incompleteness of a semantics is only due to the richness of the structure of representable functions. Instead, the incompleteness is also due to the richness of the structure of lambda theories. Further results of the article are: (i) an incompleteness theorem for partially ordered models with finitely many connected components (D minimal upward and downward closed sets); (ii) an incompleteness theorem for topological models whose topology satisfies a suitable property of connectedness; (iii) a completeness theorem for topological models whose topology is non-trivial and metrizable. © 2003, ACM. All rights reserved.",Lambda calculus; Lambda theories; Languages; order and topological incompleteness; orderability/unorderability; partially ordered models; Theory; topological models,
LICS 2001 Special Issue,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024279819&doi=10.1145%2f772062.772063&partnerID=40&md5=e0415fce8f47b5738f83a961295e74d1,[No abstract available],,
Logics of metric spaces,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1942520823&doi=10.1145%2f635499.635504&partnerID=40&md5=053b6ac98b13aa2885e80bf478912220,"We investigate the expressive power and computational properties of two different types of languages intended for speaking about distances. First, we consider a first-order language ℱM the two-variable fragment of which turns out to be undecidable in the class of distance spaces validating the triangular inequality as well as in the class of all metric spaces. Yet, this two-variable fragment is decidable in various weaker classes of distance spaces. Second, we introduce a variable-free modal language ℳS that, when interpreted in metric spaces, has the same expressive power as the two-variable fragment of ℱM. We determine natural and expressive fragments of ℳS which are decidable in various classes of distance spaces validating the triangular inequality, in particular, the class of all metric spaces.",Decidability; Expressive completeness; Metric spaces; Spatial reasoning,Artificial intelligence; Computability and decidability; Computational methods; Formal languages; Knowledge engineering; Modal analysis; Real time systems; Metric spaces; Modal logic; Predicate logic; Logic programming
Simulation-based minimization,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042815539&doi=10.1145%2f635499.635502&partnerID=40&md5=ab1d8970329ecb9b8fb2f81fe22b1a91,"We present a minimization algorithm that receives a Kripke structure M and returns the smallest structure that is simulation equivalent to M. The simulation equivalence relation is weaker than bisimulation but stronger than the simulation preorder. It strongly preserves ACTL and LTL (as sublogics of ACTL*). We show that every structure M has a unique-up-to-isomorphism reduced structure that is simulation equivalent to M and smallest in size. Our Minimizing Algorithm constructs this reduced structure. It first constructs the quotient structure for M, then eliminates transitions to little brothers, and finally deletes unreachable states. Since the first step of the algorithm is based on the simulation preorder over M, it has maximal space requirements. To reduce them, we present the Partitioning Algorithm, which constructs the quotient structure for M without ever building the simulation preorder. The Partitioning Algorithm has improved space complexity, but its time complexity might have worse.",Minimization; Simulation,Computational complexity; Computer simulation; Design aids; Formal logic; Integrated circuits; Iterative methods; Mathematical models; Optimization; Software engineering; Isomorphism; Simulation equivalence; Simulation preorder; Space complexity; Algorithms
On proving left termination of constraint logic programs,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042773721&doi=10.1145%2f635499.635503&partnerID=40&md5=95e60de597a58bd0a8ea96b2bd2ff947,"The Constraint Logic Programming (CLP) Scheme merges logic programming with constraint solving over predefined domains. In this article, we study proof methods for universal left termination of constraint logic programs. We provide a sound and complete characterization of left termination for ideal CLP languages which generalizes acceptability of logic programs. The characterization is then refined to the notion of partial acceptability, which is well suited for automatic modular inference. We describe a theoretical framework for automation of the approach, which is implemented. For nonideal CLP languages and without any assumption on their incomplete constraint solvers, even the most basic sound termination criterion from logic programming does not lift. We focus on a specific system, namely CLP(R), by proposing some additional conditions that make (partial) acceptability sound.",Automatic termination analysis; Constraint logic programming; Left termination; Termination inference,Artificial intelligence; Automation; Computer programming languages; Constraint theory; Mathematical models; Theorem proving; Trees (mathematics); Automatic termination analysis; Left termination; Termination inference; Logic programming
Computational properties of metaquerying problems,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042410625&doi=10.1145%2f635499.635501&partnerID=40&md5=0f2e791aad86e3268b72554275880bd6,"Metaquerying is a data mining technology by which hidden dependencies among several database relations can be discovered. This tool has already been successfully applied to several real-world applications, but only preliminary results about the complexity of metaquerying can be found in the literature. In this article, we define several variants of metaquerying that encompass, as far as we know, all the variants that have been defined in the literature. We study both the combined complexity and the data complexity of these variants. We show that under the combined complexity measure metaquerying is generally intractable (unless P = NP), lying sometimes quite high in the complexity hierarchies (as high as NP PP), depending on the characteristics of the plausibility index. Nevertheless, we are able to single out some tractable and interesting metaquerying cases, whose combined complexity is LOGCFL-complete. As for the data complexity of metaquerying, we prove that, in general, it is within TC 0, but lies within AC 0 in some simpler cases. Finally, we discuss the implementation of metaqueries by providing algorithms that answer them.",Computational complexity; Data mining,Algorithms; Computational complexity; Data mining; Data reduction; Research; Computational properties; Data complexity; Data resources; Metaquerying; Query languages
The marriage of effects and monads,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042814322&doi=10.1145%2f601775.601776&partnerID=40&md5=df2803b628bb07f6a89b2e7ccef0d302,"Gifford and others proposed an effect typing discipline to delimit the scope of computational effects within a program, while Moggi and others proposed monads for much the same purpose. Here we marry effects to monads, uniting two previously separate lines of research. In particular, we show that the type, region, and effect system of Talpin and Jouvelot carries over directly to an analogous system for monads, including a type and effect reconstruction algorithm. The same technique should allow one to transpose any effect system into a corresponding monad system.",Effect; Monad; Region; Type; Type reconstruction,Computer programming languages; Computer worms; Formal logic; Java programming language; Semantics; Set theory; Computational effects; Monad; Regions; Type reconstruction; Computational methods
Resource-distribution via Boolean Constraints,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344994358&doi=10.1145%2f601775.601778&partnerID=40&md5=777940ff48d92438794b17d9cc2b98c9,"We consider the problem of searching for proofs in sequential presentations of logics with multiplicative (or intensional) connectives, Specifically, we start with the multiplicative fragment of linear logic and extend, on the one hand, to linear logic with its additives and, on the other, to the additives of the logic of bunched implications (BI). We give an algebraic method for calculating the distribution of the side-formulse in multiplicative rules which allows the occurrence or non-occurrence of a formula on a branch of a proof to be determined once sufficient information is available. Each formula in the conclusion of such a rule is assigned a Boolean expression. As a search proceeds, a set of Boolean constraint equations is generated. We show that a solution to such a set of equations determines a proof corresponding to the given search. We explain a range of strategies, from the lazy to the eager, for solving sets of constraint equations. We indicate how to apply our methods systematically to large family of relevant systems.",Algebras; Boolean constraints; Proof-search; Relevant logics; Sequent calculus; Substructural logics,Boolean algebra; Computational methods; Computer science; Formal logic; Problem solving; Boolean constraints; Proof-search; Relevant logics; Sequent calculus; Substructural logics; Constraint theory
Fixed-parameter complexity of semantics for logic programs,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2142778440&doi=10.1145%2f601775.601779&partnerID=40&md5=d6f86bf0e35bfcc25ab9633afa9dce11,"A decision problem is called parameterized if its input is a pair of strings. One of these strings is referred to as a parameter. The following problem is an example of a parameterized decision problem with k serving as a parameter: given a prepositional logic program P and a nonnegative integer k, decide whether P has a stable model of size no more than k. Parameterized problems that are NP-complete often become solvable in polynomial time if the parameter is fixed. The problem to decide whether a program P has a stable model of size no more than k, where k is fixed and not a part of input, can be solved in time O(mn k), where m is the size of P and n is the number of atoms in P. Thus, this problem is in the class P. However, algorithms with the running time given by a polynomial of order k are not satisfactory even for relatively small values of k. The key question then is whether significantly better algorithms (with the degree of the polynomial not dependent on k) exist. To tackle it, we use the framework of fixed-parameter complexity, We establish the fixed-parameter complexity for several parameterized decision problems involving models, supported models, and stable models of logic programs. We also establish the fixed-parameter complexity for variants of these problems resulting from restricting attention to definite Horn programs and to purely negative programs. Most of the problems considered in the paper have high fixed-parameter complexity. Thus, it is unlikely that fixing bounds on models (supported models, stable models) will lead to fast algorithms to decide the existence of such models.",Fixed-parameter complexity; Normal logic programs; Stable models; Supported models,Computational complexity; Computer program listings; Formal logic; Mathematical models; Polynomials; Problem solving; Fixed-parameter complexity; Normal logic programs; Stable models; Supported models; Semantics
Deciding the Confluence of Ordered Term Rewrite Systems,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042771400&doi=10.1145%2f601775.601777&partnerID=40&md5=d2a2f2e69ee7433dfaae3af180ea1870,"A term rewrite system (TRS) terminates if, and only if, its rules are contained in a reduction ordering >. In order to deal with any set of equations, including inherently nonterminating ones (like commutativity), TRSs have been generalized to ordered TRS (E, >), where equations of E are applied in whatever direction agrees with >. The confluence of terminating TRSs is well-known to be decidable, but for ordered TRSs the decidability of confluence has been open. Here we show that the confluence of ordered TRSs is decidable if > belongs to a large class of path orderings (including most practical orderings like lexicographic path ordering (LPO), multiset path ordering (MPO), recursive path ordering (RPO) with status, Kapur Narendran Sivakumar ordering (KNS), and recursive decomposition ordering (RDO) since then ordering constraints for > can be solved in an adequate way. For ordered TRSs (E, >) where E consists of constrained equations, confluence is shown to be undecidable. Finally, also ground reducibility is proved undecidable for ordered TRSs.",Confluence; Ordered rewriting; Path orderings; Rewrite systems,Codes (symbols); Computational grammars; Computer programming languages; Decision theory; Formal logic; Confluences; Ordered rewriting; Path orderings; Rewrite systems; Computational methods
A complete characterization of complete intersection-type preorders,2003,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042818025&doi=10.1145%2f601775.601780&partnerID=40&md5=d2fbc0df8ddc22e7e2566842e5c04e1b,"We characterize those type preorders which yield complete intersection-type assignment systems for λ-calculi, with respect to the three canonical set-theoretical semantics for intersection-types: the inference semantics, the simple semantics, and the F-semantics. These semantics arise by taking as interpretation of types subsets of applicative structures, as interpretation of thepreorder relation, ≤≤, set-theoretic inclusion, as interpretation of the intersection constructor, ∩, set-theoretic intersection, and by taking the interpretation of the arrow constructor, ← à la Scott, with respect to either any possible functionality set, or the largest one, or the least one. These results strengthen and generalize significantly all earlier results in the literature, to our knowledge, in at least three respects. First of all the inference semantics had not been considered before. Second, the characterizations are all given just in terms of simple closure conditions on the preorder relation, ≤, on the types, rather than on the typing judgments themselves. The task of checking the condition is made therefore considerably more tractable. Last, we do not restrict attention just to λ-models, but to arbitrary applicative structures which admit an interpretation function. Thus we allow also for the treatment of models of restricted λ-calculi. Nevertheless the characterizations we give can be tailored just to the case of λ-models.",Completeness; Intersection types; Lambda calculus; Lambda models,Computer programming languages; Formal logic; Mathematical models; Semantics; Set theory; Completeness; Intersection types; Lambda calculus; Lambda models; Computational methods
Revisiting Quantification in Autoepistemic Logic,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750741280&doi=10.1145%2f566385.566388&partnerID=40&md5=ed1555b5528b10f5ed26adfd96058922,"In this article, we introduce first-order autoepistemic logic. Our definition is semantical and is based on the intuition similar to that lying behind the definition of first-order default logic. Thus, our definition of first-order autoepistemic logic well complies with that of first-order default logic and circumscription, providing a substantial evidence for its acceptance. © In this article, we introduce first-order autoepistemic logic. Our definition is semantical and is based on the intuition similar to that lying behind the definition of first-order default logic. Thus, our definition of first-order autoepistemic logic well complies with that of first-order default logic and circumscription, providing a substantial evidence for its acceptance. © 2002, ACM. All rights reserved.",Autoepistemic logic; default logic; Herbrand semantics; Theory,
Deciding and Axiomatizing Weak ST Bisimulation for a Process Algebra with Recursion and Action Refinement,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645428345&doi=10.1145%2f566385.566386&partnerID=40&md5=8b701ab0290e53cb76b704761865b888,"Due to the complex nature of bisimulation equivalences that express some form of history dependence, it turned out to be problematic to decide them over nontrivial classes of recursive systems. Moreover, to the best of our knowledge, the problem of axiomatizing them over such classes of systems has never been solved. In this article, we face this problem in the case of weak ST bisimulation, an equivalence that expresses the execution of an action as the combination of the two interdependent events of action start and action termination and that supports the operation of action refinement. We first consider a basic process algebra with CSP multiway synchronization and recursion and we show that a simple technique based on static names is sufficient to decide weak ST bisimulation over processes that are finite state according to the standard interleaving semantics. Then we introduce a different technique based on dynamic names and on the new idea of compositional level-wise renaming of actions (which produces semantic models via SOS such that weak ST bisimulation can be established through standard weak bisimulation) and we show that it can be applied to decide and axiomatize weak ST bisimulation over the same class of processes. Finally, we introduce a third technique based on pointers, updated according to a pseudo-stack discipline, which preserves the possibility of deciding and axiomatizing weak ST bisimulation also when an action refinement operator is considered. © Due to the complex nature of bisimulation equivalences that express some form of history dependence, it turned out to be problematic to decide them over nontrivial classes of recursive systems. Moreover, to the best of our knowledge, the problem of axiomatizing them over such classes of systems has never been solved. In this article, we face this problem in the case of weak ST bisimulation, an equivalence that expresses the execution of an action as the combination of the two interdependent events of action start and action termination and that supports the operation of action refinement. We first consider a basic process algebra with CSP multiway synchronization and recursion and we show that a simple technique based on static names is sufficient to decide weak ST bisimulation over processes that are finite state according to the standard interleaving semantics. Then we introduce a different technique based on dynamic names and on the new idea of compositional level-wise renaming of actions (which produces semantic models via SOS such that weak ST bisimulation can be established through standard weak bisimulation) and we show that it can be applied to decide and axiomatize weak ST bisimulation over the same class of processes. Finally, we introduce a third technique based on pointers, updated according to a pseudo-stack discipline, which preserves the possibility of deciding and axiomatizing weak ST bisimulation also when an action refinement operator is considered. © 2002, ACM. All rights reserved.",Languages; Theory,
Boolean Satisfiability with Transitivity Constraints,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974717885&doi=10.1145%2f566385.566390&partnerID=40&md5=1e0411119a07dc61a83b9c2c57744067,"We consider a variant of the Boolean satisfiability problem where a subset ɛ of the propositional variables appearing in formula Fsatencode a symmetric, transitive, binary relation over N elements. Each of these relational variables, ei, jfor 1 ⩽ i < j ⩽ N, expresses whether or not the relation holds between elements i and j. The task is to either find a satisfying assignment to Fsatthat also satisfies all transitivity constraints over the relational variables (e.g., e1,2∧ e2,3⇒ e1,3), or to prove that no such assignment exists. Solving this satisfiability problem is the final and most difficult step in our decision procedure for a logic of equality with uninterpreted functions. This procedure forms the core of our tool for verifying pipelined microprocessors. To use a conventional Boolean satisfiability checker, we augment the set of clauses expressing Fsatwith clauses expressing the transitivity constraints. We consider methods to reduce the number of such clauses based on the sparse structure of the relational variables. To use Ordered Binary Decision Diagrams (OBDDs), we show that for some sets ɛ, the OBDD representation of the transitivity constraints has exponential size for all possible variable orderings. By considering only those relational variables that occur in the OBDD representation of Fsatour experiments show that we can readily construct an OBDD representation of the relevant transitivity constraints and thus solve the constrained satisfiability problem. © We consider a variant of the Boolean satisfiability problem where a subset ɛ of the propositional variables appearing in formula Fsatencode a symmetric, transitive, binary relation over N elements. Each of these relational variables, ei, jfor 1 ⩽ i < j ⩽ N, expresses whether or not the relation holds between elements i and j. The task is to either find a satisfying assignment to Fsatthat also satisfies all transitivity constraints over the relational variables (e.g., e1,2∧ e2,3⇒ e1,3), or to prove that no such assignment exists. Solving this satisfiability problem is the final and most difficult step in our decision procedure for a logic of equality with uninterpreted functions. This procedure forms the core of our tool for verifying pipelined microprocessors. To use a conventional Boolean satisfiability checker, we augment the set of clauses expressing Fsatwith clauses expressing the transitivity constraints. We consider methods to reduce the number of such clauses based on the sparse structure of the relational variables. To use Ordered Binary Decision Diagrams (OBDDs), we show that for some sets ɛ, the OBDD representation of the transitivity constraints has exponential size for all possible variable orderings. By considering only those relational variables that occur in the OBDD representation of Fsatour experiments show that we can readily construct an OBDD representation of the relevant transitivity constraints and thus solve the constrained satisfiability problem. © 2002, ACM. All rights reserved.",Algorithms; Boolean satisfiability; decision procedures; formal verification; Verification,
Polynomial-Time Computation via Local Inference Relations,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881456410&doi=10.1145%2f566385.566387&partnerID=40&md5=1ec01cc3df3882eba1780afd1d890e13,"We consider the concept of a local set of inference rules. A local rule set can be automatically transformed into a rule set for which bottom-up evaluation terminates in polynomial time. The local-rule-set transformation gives polynomial-time evaluation strategies for a large variety of rule sets that cannot be given terminating evaluation strategies by any other known automatic technique. This article discusses three new results. First, it is shown that every polynomial-time predicate can be defined by an (unstratified) local rule set. Second, a new machine-recognizable subclass of the local rule sets is identified. Finally, we show that locality, as a property of rule sets, is undecidable in general. © We consider the concept of a local set of inference rules. A local rule set can be automatically transformed into a rule set for which bottom-up evaluation terminates in polynomial time. The local-rule-set transformation gives polynomial-time evaluation strategies for a large variety of rule sets that cannot be given terminating evaluation strategies by any other known automatic technique. This article discusses three new results. First, it is shown that every polynomial-time predicate can be defined by an (unstratified) local rule set. Second, a new machine-recognizable subclass of the local rule sets is identified. Finally, we show that locality, as a property of rule sets, is undecidable in general. © 2002, ACM. All rights reserved.",Automated reasoning; complexity theory; decision procedures; Languages; lgorithms; Theory,
Typed Interpretations of Extensible Objects,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048819225&doi=10.1145%2f566385.566389&partnerID=40&md5=ff0fb46790955b062b248b18952a3fb1,"Finding typed encodings of object-oriented into procedural or functional programming sheds light on the theoretical foundations of object-oriented languages and their specific typing constructs and techniques. This article describes a type preserving and computationally adequate interpretation of a full-fledged object calculus that supports message passing and constructs for object update and extension. The target theory is a higher-order λ-calculus with records and recursive folds/unfolds, polymorphic and recursive types, and subtyping. The interpretation specializes to calculi of nonextensible objects, and validates the expected subtyping relationships. © Finding typed encodings of object-oriented into procedural or functional programming sheds light on the theoretical foundations of object-oriented languages and their specific typing constructs and techniques. This article describes a type preserving and computationally adequate interpretation of a full-fledged object calculus that supports message passing and constructs for object update and extension. The target theory is a higher-order λ-calculus with records and recursive folds/unfolds, polymorphic and recursive types, and subtyping. The interpretation specializes to calculi of nonextensible objects, and validates the expected subtyping relationships. © 2002, ACM. All rights reserved.",computational adequacy; extensible object; Object calculus; subtyping; Theory; type specialization; type system; typed encoding; Verification,
Description Logics of Minimal Knowledge and Negation as Failure,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650230253&doi=10.1145%2f505372.505373&partnerID=40&md5=419b0fdca4cba2857174cc1fc1690f92,"We present description logics of minimal knowledge and negation as failure (MKNF-DLs), which augment description logics with modal operators interpreted according to Lifschitz's nonmonotonic logic MKNF. We show the usefulness of MKNF-DLs for a formal characterization of a wide variety of nonmonotonic features that are both commonly available in frame-based systems, and needed in the development of practical knowledge-based applications: defaults, integrity constraints, role, and concept closure. In addition, we provide a correct and terminating calculus for query answering in a very expressive MKNF-DL. © 2002, ACM. All rights reserved.",Description Logics; frame-based systems; nonmonotonic modal logics; tableau calculi; Theory,
Sequent Calculi for Propositional Nonmonotonic Logics,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344243144&doi=10.1145%2f505372.505374&partnerID=40&md5=8a24c8344b1a8f85a351f58dbe3aa21a,"A uniform proof-theoretic reconstruction of the major nonmonotonic logics is introduced. It consists of analytic sequent calculi where the details of nonmonotonic assumption making are modelled by an axiomatic rejection method. Another distinctive feature of the calculi is the use of provability constraints that make reasoning largely independent of any specific derivation strategy. The resulting account of nonmonotonic inference is simple and flexible enough to be a promising playground for investigating and comparing proof strategies, and for describing the behavior of automated reasoning systems. We provide some preliminary evidence for this claim by introducing optimized calculi, and by simulating an existing tableaux-based method for circumscription. The calculi for skeptical reasoning support concise proofs that may depend on a strict subset of the given theory. This is a difficult task, given the nonmonotonic behavior of the logics. © A uniform proof-theoretic reconstruction of the major nonmonotonic logics is introduced. It consists of analytic sequent calculi where the details of nonmonotonic assumption making are modelled by an axiomatic rejection method. Another distinctive feature of the calculi is the use of provability constraints that make reasoning largely independent of any specific derivation strategy. The resulting account of nonmonotonic inference is simple and flexible enough to be a promising playground for investigating and comparing proof strategies, and for describing the behavior of automated reasoning systems. We provide some preliminary evidence for this claim by introducing optimized calculi, and by simulating an existing tableaux-based method for circumscription. The calculi for skeptical reasoning support concise proofs that may depend on a strict subset of the given theory. This is a difficult task, given the nonmonotonic behavior of the logics. © 2002, ACM. All rights reserved.",Autoepistemic Logic; Circumscription; Default Logic; Rejection methods; Sequent calculi; Theory,
Probabilistic Game Semantics,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024266950&doi=10.1145%2f507382.507385&partnerID=40&md5=7f8914887ac5f5fd0825af62d79dcbda,"A category of HO/N-style games and probabilistic strategies is developed where the possible choices of a strategy are quantified so as to give a measure of the likelihood of seeing a given play. A twosided die is shown to be universal in this category, in the sense that any strategy breaks down into a composition between some deterministic strategy and that die. The interpretative power of the category is then demonstrated by delineating a Cartesian closed subcategory that provides a fully abstract model of a probabilistic extension of Idealized Algol. © A category of HO/N-style games and probabilistic strategies is developed where the possible choices of a strategy are quantified so as to give a measure of the likelihood of seeing a given play. A twosided die is shown to be universal in this category, in the sense that any strategy breaks down into a composition between some deterministic strategy and that die. The interpretative power of the category is then demonstrated by delineating a Cartesian closed subcategory that provides a fully abstract model of a probabilistic extension of Idealized Algol. © 2002, ACM. All rights reserved.",Games semantics; Languages; probabilistic Idealized Algol,
On First-Order Topological Queries,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0347252067&doi=10.1145%2f507382.507384&partnerID=40&md5=4bc4a8cadb7de91aea3a514ab0a65471,"One important class of spatial database queries is the class of topological queries, that is, queries invariant under homeomorphisms. We study topological queries expressible in the standard query language on spatial databases, first-order logic with various amounts of arithmetic. Our main technical result is a combinatorial characterization of the expressive power of topological firstorder logic on regular spatial databases. © One important class of spatial database queries is the class of topological queries, that is, queries invariant under homeomorphisms. We study topological queries expressible in the standard query language on spatial databases, first-order logic with various amounts of arithmetic. Our main technical result is a combinatorial characterization of the expressive power of topological firstorder logic on regular spatial databases. © 2002, ACM. All rights reserved.",Constraint databases; first-order logic; Languages; Theory; topological queries,
Abstract Computability and Algebraic Specification,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344237131&doi=10.1145%2f505372.505375&partnerID=40&md5=40032f1e52ae1a5394b3a5a45e4805a5,"Computable functions are defined by abstract finite deterministic algorithms on manysorted algebras. We show that there exist finite universal algebraic specifications that specify uniquely (up to isomorphism) (i) all abstract computable functions on any many-sorted algebra; (ii) all functions effectively approximable by abstract computable functions on any metric algebra. We show that there exist universal algebraic specifications for all the classically computable functions on the set R of real numbers. The algebraic specifications used are mainly bounded universal equations and conditional equations. We investigate the initial algebra semantics of these specifications, and derive situations where algebraic specifications precisely define the computable functions. © 2002, ACM. All rights reserved.",Abstract computability; algebraic specification; computable analysis; conditional equations; equational logic; metric algebras; Theory; topological algebras; Verification,
Editorial,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024263736&doi=10.1145%2f507382.507383&partnerID=40&md5=3bcb22539c786619433e91a45a13fc83,[No abstract available],,
Back and Forth Between Guarded and Modal Logics,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994648433&doi=10.1145%2f507382.507388&partnerID=40&md5=fc5fee08dbe769221f819838905c363b,"Guarded fixed-point logic μGF extends the guarded fragment by means of least and greatest fixed points, and thus plays the same role within the domain of guarded logics as the modal μ-calculus plays within the modal domain. We provide a semantic characterization of μGF within an appropriate fragment of second-order logic, in terms of invariance under guarded bisimulation. The corresponding characterization of the modal μ-calculus, due to Janin and Walukiewicz, is lifted from the modal to the guarded domain by means of model theoretic translations. Guarded second-order logic, the fragment of second-order logic which is introduced in the context of our characterization theorem, captures a natural and robust level of expressiveness with several equivalent characterizations. For a wide range of issues in guarded logics it may take up a role similar to that of monadic second-order in relation to modal logics. At the more general methodological level, the translations between the guarded and modal domains make the intuitive analogy between guarded and modal logics available as a tool in the further analysis of the model theory of guarded logics. © Guarded fixed-point logic μGF extends the guarded fragment by means of least and greatest fixed points, and thus plays the same role within the domain of guarded logics as the modal μ-calculus plays within the modal domain. We provide a semantic characterization of μGF within an appropriate fragment of second-order logic, in terms of invariance under guarded bisimulation. The corresponding characterization of the modal μ-calculus, due to Janin and Walukiewicz, is lifted from the modal to the guarded domain by means of model theoretic translations. Guarded second-order logic, the fragment of second-order logic which is introduced in the context of our characterization theorem, captures a natural and robust level of expressiveness with several equivalent characterizations. For a wide range of issues in guarded logics it may take up a role similar to that of monadic second-order in relation to modal logics. At the more general methodological level, the translations between the guarded and modal domains make the intuitive analogy between guarded and modal logics available as a tool in the further analysis of the model theory of guarded logics. © 2002, ACM. All rights reserved.",Bisimulation; guarded logic; modal logic; model theory; Theory,
Resource-Bounded Continuity and Sequentiality for Type-Two Functionals,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016868854&doi=10.1145%2f507382.507387&partnerID=40&md5=985532a9c92ce30767217f25b788d926,"We define notions of resource-bounded continuity and sequentiality for type-two functionals with total inputs, and prove that in the resource-bounded model there are continuous functionals which cannot be efficiently simulated by sequential functionals. We also show that for some naturally defined classes of continuous functionals an efficient simulation is possible. © We define notions of resource-bounded continuity and sequentiality for type-two functionals with total inputs, and prove that in the resource-bounded model there are continuous functionals which cannot be efficiently simulated by sequential functionals. We also show that for some naturally defined classes of continuous functionals an efficient simulation is possible. © 2002, ACM. All rights reserved.",Algorithms; decision trees; Higher-order complexity; sequential computation; Theory,
A Syntactical Analysis of Non-Size-Increasing Polynomial Time Computation,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646745305&doi=10.1145%2f507382.507386&partnerID=40&md5=9dc84cb6541313db80d5952b0585a124,"A syntactical proof is given that all functions definable in a certain affine linear typed λ-calculus with iteration in all types are polynomial time computable. The proof provides explicit polynomial bounds that can easily be calculated. © A syntactical proof is given that all functions definable in a certain affine linear typed λ-calculus with iteration in all types are polynomial time computable. The proof provides explicit polynomial bounds that can easily be calculated. © 2002, ACM. All rights reserved.",Complexity; lambda calculus; Languages; linear logic; Theory,
Intuitionistic Light Affine Logic,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007617019&doi=10.1145%2f504077.504081&partnerID=40&md5=a1e0d5c3fbbc9c375c67691bb7c08d3b,"This article is a structured introduction to Intuitionistic Light Affine Logic (ILAL). ILAL has a polynomially costing normalization, and it is expressive enough to encode, and simulate, all PolyTime Turing machines. The bound on the normalization cost is proved by introducing the proof-nets for ILAL. The bound follows from a suitable normalization strategy that exploits structural properties of the proof-nets. This allows us to have a good understanding of the meaning of the x modality, which is a peculiarity of light logics. The expressive power of ILAL is demonstrated in full detail. Such a proof gives a hint of the nontrivial task of programming with resource limitations, using ILAL derivations as programs. © 2002, ACM. All rights reserved.",Languages; Theory,
Datalog LITE: A Deductive Query Language with Linear Time Model Checking,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025388590&doi=10.1145%2f504077.504079&partnerID=40&md5=76b61f8517a505c1acde2181c57aedae,"We present Datalog LITE, a new deductive query language with a linear-time model-checking algorithm, that is, linear time data complexity and program complexity. Datalog LITE is a variant of Datalog that uses stratified negation, restricted variable occurrences and a limited form of universal quantification in rule bodies. Despite linear-time evaluation, Datalog LITE is highly expressive: It encompasses popular modal and temporal logics such as CTL or the alternation-free µ-calculus. In fact, these formalisms have natural presentations as fragments of Datalog LITE. Further, Datalog LITE is equivalent to the alternation-free portion of guarded fixed-point logic. Consequently, linear-time model checking algorithms for all mentioned logics are obtained in a unified way. The results are complemented by inexpressibility proofs to the effect that linear-time fragments of stratified Datalog have too limited expressive power. © 2002, ACM. All rights reserved.",Algorithms; Complexity; databases; guarded logics; temporal logics; Theory; Verification; verification,
The Intuitionism Behind Statecharts Steps,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969337318&doi=10.1145%2f504077.504078&partnerID=40&md5=1667c8fbef5c8fffd636edd0d4c4b2d1,"The semantics of Statecharts macro steps, as introduced by Pnueli and Shalev [1991], lacks compositionality. This article first analyzes the compositionality problem and traces it back to the invalidity of the Law of the Excluded Middle. It then characterizes the semantics via a particular class of linear intuitionistic Kripke models. This yields, for the first time in the literature, a simple fully abstract semantics that interprets Pnueli and Shalev's concept of failure naturally. The results not only give insight into the semantic subtleties of Statecharts, but also provide a basis for an implementation, for developing algebraic theories for macro steps, and for comparing different Statecharts variants. © 2002, ACM. All rights reserved.",Compositionality; full abstraction; intuitionistic logic; Kripke semantics; Languages; Statecharts; Theory,
Reasoning with Higher-Order Abstract Syntax in a Logical Framework,2002,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041524803&doi=10.1145%2f504077.504080&partnerID=40&md5=cab57f301a72074481ba1db8ef1f8af5,"Logical frameworks based on intuitionistic or linear logics with higher-type quantification have been successfully used to give high-level, modular, and formal specifications of many important judgments in the area of programming languages and inference systems. Given such specifications, it is natural to consider proving properties about the specified systems in the framework: for example, given the specification of evaluation for a functional programming language, prove that the language is deterministic or that evaluation preserves types. One challenge in developing a framework for such reasoning is that higher-order abstract syntax (HOAS), an elegant and declarative treatment of object-level abstraction and substitution, is difficult to treat in proofs involving induction. In this article, we present a meta-logic that can be used to reason about judgments coded using HOAS; this meta-logic is an extension of a simple intuitionistic logic that admits higher-order quantification over simply typed λ-terms (key ingredients for HOAS) as well as induction and a notion of definition. The latter concept of definition is a proof-theoretic device that allows certain theories to be treated as “closed” or as defining fixed points. We explore the difficulties of formal meta-theoretic analysis of HOAS encodings by considering encodings of intuitionistic and linear logics, and formally derive the admissibility of cut for important subsets of these logics. We then propose an approach to avoid the apparent trade-off between the benefits of higher-order abstract syntax and the ability to analyze the resulting encodings. We illustrate this approach through examples involving the simple functional and imperative programming languages PCF and PCF:=.We formally derive such properties as unicity of typing, subject reduction, determinacy of evaluation, and the equivalence of transition semantics and natural semantics presentations of evaluation. © 2002, ACM. All rights reserved.",Definitions; higher-order abstract syntax; induction; Languages; logical frameworks; Theory; Verification,
Strongly Equivalent Logic Programs,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945953994&doi=10.1145%2f383779.383783&partnerID=40&md5=988aba6820f86025a1c9b1d1eab26ee3,"A logic program Π1is said to be equivalent to a logic program Π2in the sense of the answer set semantics if Π1and Π2have the same answer sets. We are interested in the following stronger condition: for every logic program Π, Π1∪ Π has the same answer sets as Π2∪ Π. The study of strong equivalence is important, because we learn from it how one can simplify a part of a logic program without looking at the rest of it. The main theorem shows that the verification of strong equivalence can be accomplished by checking the equivalence of formulas in a monotonic logic, called the logic of here-and-there, which is intermediate between classical logic and intuitionistic logic. © 2001, ACM. All rights reserved.",Answer sets; Languages; logic programming; stable models; Theory,
Verifying Security Protocols as Planning in Logic Programming,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006614284&doi=10.1145%2f383779.383785&partnerID=40&md5=4e05238e3e7f58b553e9d7daa0d2c7a2,"We illustrate ALSP(Action Language for Security Protocol), a declarative executable specification language for planning attacks to security protocols. ALSPis based on logic programming with negation as failure, and with stable model semantics. In ALSPwe can give a declarative specification of a protocol with the natural semantics of send and receive actions which can be performed in parallel. By viewing a protocol trace as a plan to achieve a goal, attacks are (possibly parallel) plans achieving goals that correspond to security violations. Building on results from logic programming and planning, we map the existence of an attack into the existence of a model for the protocol that satisfies the specification of an attack. We show that our liberal model of parallel actions can adequately represent the traditional Dolev-Yao trace-based model used in the formal analysis of security protocols. Specifications in ALSPare executable, as we can automatically search for attacks via an efficient model generator (smodels), implementing the stable model semantics of normal logic programs. © 2001, ACM. All rights reserved.",AI planning; Design; logic programming; Security; Security protocols; specification language; Theory; Verification,
Editorial,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025402537&doi=10.1145%2f383779.383823&partnerID=40&md5=c8028bce10d0c40fc5cc376daa76b7d4,[No abstract available],,
An Extended Transformation Approach to Inductive Logic Programming,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008021624&doi=10.1145%2f383779.383781&partnerID=40&md5=4848ffb2ef5eac09779558eb2a09cc7b,"Inductive logic programming (ILP) is concerned with learning relational descriptions that typically have the form of logic programs. In a transformation approach, an ILP task is transformed into an equivalent learning task in a different representation formalism. Propositionalization is a particular transformation method, in which the ILP task is compiled to an attribute-value learning task. The main restriction of propositionalization methods such as LINUS is that they are unable to deal with nondeterminate local variables in the body of hypothesis clauses. In this paper we show how this limitation can be overcome, by systematic first-order feature construction using a particular individual-centered feature bias. The approach can be applied in any domain where there is a clear notion of individual.We also show how to improve upon exhaustive first-order feature construction by using a relevancy filter. The proposed approach is illustrated on the “trains” and “mutagenesis” ILP domains. © 2001, ACM. All rights reserved.",Algorithms; Data mining; Experimentation; inductive logic programming; machine learning; relational databases,
Weak Alternating Automata Are Not that Weak,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350683418&doi=10.1145%2f377978.377993&partnerID=40&md5=75524ce82d1a7e4d72d8f5437c7b85a3,"Automata on infinite words are used for specification and verification of nonterminating programs. Different types of automata induce different levels of expressive power, of succinctness, and of complexity. Alternating automata have both existential and universal branching modes and are particularly suitable for specification of programs. In a weak alternating automaton, the state space is partitioned into partially ordered sets, and the automaton can proceed from a certain set only to smaller sets. Reasoning about weak alternating automata is easier than reasoning about alternating automata with no restricted structure. Known translations of alternating automata to weak alternating automata involve determinization, and therefore involve a double-exponential blow-up. In this paper we describe a quadratic translation, which circumvents the need for determinization, of Büchi and co-Büchi alternating automata to weak alternating automata. Beyond the independent interest of such a translation, it gives rise to a simple complementation algorithm for nondeterministic Büchi automata. © 2001, ACM. All rights reserved.",complementation; Theory; Verification; Weak alternating automata,
Incremental Execution of Guarded Theories,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017332829&doi=10.1145%2f383779.383782&partnerID=40&md5=c8ee87ac8fee36aed062faa32a4fa605,"When it comes to building controllers for robots or agents, high-level programming languages like Golog and ConGolog offer a useful compromise between planning-based approaches and low-level robot programming. However, two serious problems typically emerge in practical implementations of these languages: how to evaluate tests in a program efficiently enough in an open-world setting, and how to make appropriate nondeterministic choices while avoiding full lookahead. Recent proposals in the literature suggest that one could tackle the first problem by exploiting sensing information, and tackle the second by specifying the amount of lookahead allowed explicitly in the program. In this paper, we combine these two ideas and demonstrate their power by presenting an interpreter, written in Prolog, for a variant of Golog that is suitable for efficiently operating in open-world setting by exploiting sensing and bounded lookahead. © 2001, ACM. All rights reserved.",agent behavior; Languages; Reasoning about actions; situation calculus; Theory,
A Computational Theory of Normative Positions,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008935532&doi=10.1145%2f383779.383786&partnerID=40&md5=4a1296e9e1d6c4a86b20966e6f4398a7,"The Kanger-Lindahl theory of normative positions attempts to use a combination of deontic logic (the logic of obligation and permission) and a logic of action/agency to give a formal account of obligations, duties, rights, and other complex normative concepts. This paper presents a generalization and further development of this theory, together with methods for its automation and application to practical examples. The resulting theory is intended to be applied in the representation and analysis of laws, regulations, and contracts, in the specification of aspects of computer systems, in multiagent systems, and as a contribution to the formal theory of organizations. Particular attention is paid to representations at varying levels of detail and the relationships that hold between them. The last part presents Norman-G, an automated support system intended to facilitate application of the theory to the analysis of practical problems, with a small example to illustrate its use. © 2001, ACM. All rights reserved.",Algorithms; Deontic logic; logic of action; logic of agency; normative systems; Theory; theory of duties and rights,
On Knowledge-Based Programming with Sensing in the Situation Calculus,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017332807&doi=10.1145%2f383779.383780&partnerID=40&md5=05ecfbe0246650042e2e24c2059d7a39,"We consider a class of knowledge-based Golog programs with sense actions. These programs refer explicitly to an agent's knowledge, and are designed to execute on-line, and under a dynamic closed-world assumption on knowledge. On-line execution of sense actions dynamically updates the background axioms with sentences asserting knowledge of the sense actions outcomes. We formalize what all this might mean, and show that under suitable assumptions the knowledge modality in such programs can be implemented by provability. This leads to an on-line Golog interpreter for such programs, which we demonstrate on a knowledge-based program with sensing for the blocks world. © 2001, ACM. All rights reserved.",dynamic closed-world assumption; Languages; sensing and knowledge; Situation calculus; situation calculus programming languages; theorem-proving; Theory,
Logic Programming Revisited: Logic Programs as Inductive Definitions,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987625889&doi=10.1145%2f383779.383789&partnerID=40&md5=57a196448000a4e394f328a1087384e8,"Logic programming has been introduced as programming in the Horn clause subset of first-order logic. This view breaks down for the negation as failure inference rule. To overcome the problem, one line of research has been to view a logic program as a set of iff-definitions. A second approach was to identify a unique canonical, preferred, or intended model among the models of the program and to appeal to common sense to validate the choice of such model. Another line of research developed the view of logic programming as a nonmonotonic reasoning formalism strongly related to Default Logic and Autoepistemic Logic. These competing approaches have resulted in some confusion about the declarative meaning of logic programming. This paper investigates the problem and proposes an alternative epistemological foundation for the canonical model approach, which is not based on common sense but on a solid mathematical information principle. The thesis is developed that logic programming can be understood as a natural and general logic of inductive definitions. In particular, logic programs with negation represent nonmonotone inductive definitions. It is argued that this thesis results in an alternative justification of the well-founded model as the unique intended model of the logic program. In addition, it equips logic programs with an easy-to-comprehend meaning that corresponds very well with the intuitions of programmers. © 2001, ACM. All rights reserved.",Epistemological foundations; inductive definitions; Languages; Theory,
Inadequacy of Computable Loop Invariants,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149265261&doi=10.1145%2f371282.371285&partnerID=40&md5=4020fa42b1be24a4482a53c93d5f6d55,"Hoare logic is a widely recommended verification tool. There is, however, a problem of finding easily checkable loop invariants; it is known that decidable assertions do not suffice to verify while programs, even when the pre- and postconditions are decidable. We show here a stronger result: decidable invariants do not suffice to verify single-loop programs. We also show that this problem arises even in extremely simple contexts. Let N be the structure consisting of the set of natural numbers together with the functions S(x) = x +1, D(x) = 2x, H(x) = ⌊x/2⌋. There is a single-loop program Π using only three variables x, y, z such that the asserted program x = y = z = 0 Π false is partially correct on N but any loop invariant I (x, y, z) for this asserted program is undecidable. © 2001, ACM. All rights reserved.",Algorithms; Assertion; Automated; Automated deduction; Computable; Hoare logic; Inseparability; Loop invariants; Postcondition; Precondition; Reasoning; Recursive; Theory; Uncomputable; Verification,
Parametric Temporal Logic for “Model Measuring”,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27644510684&doi=10.1145%2f377978.377990&partnerID=40&md5=7a0872e8ff985993a44d3aa1f756bd03,"We extend the standard model checking paradigm of linear temporal logic, LTL, to a “model measuring” paradigm where one can obtain more quantitative information beyond a “Yes/No” answer. For this purpose, we define a parametric temporal logic, PLTL, which allows statements such as “a request p is followed in at most x steps by a response q,” where × is a free variable. We show how one can, given a formula φ(x1, …, xk) of PLTL and a system model K, not only determine whether there exists a valuation of x1, …, xk under which the system K satisfies the property φ, but if so find valuations which satisfy various optimality criteria. In particular, we present algorithms for finding valuations which minimize (or maximize) the maximum (or minimum) of all parameters. These algorithms exhibit the same PSPACE complexity as LTL model checking. We show that our choice of syntax for PLTL lies at the threshold of decidability for parametric temporal logics, in that several natural extensions have undecidable “model measuring” problems. © 2001, ACM. All rights reserved.",Model checking; quantitative analysis; temporal logic; Theory; Verification,
Representation Results for Defeasible Logic,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867763616&doi=10.1145%2f371316.371517&partnerID=40&md5=855444f8613de5710756a84ec615c89f,"The importance of transformations and normal forms in logic programming, and generally in computer science, is well documented. This paper investigates transformations and normal forms in the context of Defeasible Logic, a simple but efficient formalism for nonmonotonic reasoning based on rules and priorities. The transformations described in this paper have two main benefits: on one hand they can be used as a theoretical tool that leads to a deeper understanding of the formalism, and on the other hand they have been used in the development of an efficient implementation of defeasible logic. © 2001, ACM. All rights reserved.",Defeasible logic; normal forms; Theory; transformations,
Proof-Complexity Results for Nonmonotonic Reasoning,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995340324&doi=10.1145%2f377978.377987&partnerID=40&md5=c9bf57d8dd3a7fdbf7f86f6cfd2a2037,"It is well-known that almost all nonmonotonic formalisms have a higher worst-case complexity than classical reasoning. In some sense, this observation denies one of the original motivations of nonmonotonic systems, which was the expectation that nonmonotonic rules should help to speedup the reasoning process, and not make it more difficult. In this paper, we look at this issue from a proof-theoretical perspective. We consider analytic calculi for certain nonmonotonic logics and analyze to what extent the presence of nonmonotonic rules can simplify the search for proofs. In particular, we show that there are classes of first-order formulae which have only extremely long “classical” proofs, i.e., proofs without applications of nonmonotonic rules, but there are short proofs using nonmonotonic inferences. Hence, despite the increase of complexity in the worst case, there are instances where nonmonotonic reasoning can be much simpler than classical (cut-free) reasoning. © 2001, ACM. All rights reserved.",Circumscription; default logic; sequent calculi; Theory,
A Decision Procedure for Term Algebras with Queues,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015274734&doi=10.1145%2f371316.371494&partnerID=40&md5=e859569e5aa8da63f6a1cfcaca54a658,"In software verification it is often required to prove statements about heterogeneous domains containing elements of various sorts, such as counters, stacks, lists, trees and queues. Any domain with counters, stacks, lists, and trees (but not queues) can be easily seen a special case of the term algebra, and hence a decision procedure for term algebras can be applied to decide the first-order theory of such a domain.We present a quantifier-elimination procedure for the first-order theory of term algebras extended with queues. The complete axiomatization and decidability of this theory can be immediately derived from the procedure. © 2001, ACM. All rights reserved.",queues; Term algebras; Theory; trees; Verification; words,
How to Optimize Proof-Search in Modal Logics: New Methods of Proving Redundancy Criteria for Sequent Calculi,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1642540462&doi=10.1145%2f371316.371511&partnerID=40&md5=60ef948b4553eff2a74b41d5b3c0e033,"We present a bottom-up decision procedure for propositional modal logic K based on the inverse method. The procedure is based on the “inverted” version of a sequent calculus. To restrict the search space, we prove a number of redundancy criteria for derivations in the sequent calculus. We introduce a new technique of proving redundancy criteria, based on the analysis of tableaubased derivations in K. Moreover, another new technique is used to prove completeness of proofsearch with a strong notion of subsumption. This technique is based on so-called traces. A new formalization of the inverse method in the form of a path calculus considerably simplifies all proofs as compared to the previously published presentations of the inverse method. Experimental results demonstrate that our method is competitive with many state-of-the-art implementations of K. © 2001, ACM. All rights reserved.",Description logics; Experimentation; inverse method; modal logic; proof-search; theorem proving; Theory,
Clausal Temporal Resolution,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016913363&doi=10.1145%2f371282.371311&partnerID=40&md5=efadc61656805027df3d1ff3276069ea,"In this article, we examine how clausal resolution can be applied to a specific, but widely used, nonclassical logic, namely discrete linear temporal logic. Thus, we first define a normal form for temporal formulae and show how arbitrary temporal formulae can be translated into the normal form, while preserving satisfiability. We then introduce novel resolution rules that can be applied to formulae in this normal form, provide a range of examples, and examine the correctness and complexity of this approach. Finally, we describe related work and future developments concerning this work. © 2001, ACM. All rights reserved.",Algorithms; Resolution; Temporal logic; Theorem proving; Theory; Verification,
MSO Definable String Transductions and Two-Way Finite-State Transducers,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886574830&doi=10.1145%2f371316.371512&partnerID=40&md5=4d68f92a67a2959a72be7e3afcfb03ad,"We extend a classic result of Büchi, Elgot, and Trakhtenbrot: MSO definable string transductions, i.e., string-to-string functions that are definable by an interpretation using monadic second-order (MSO) logic, are exactly those realized by deterministic two-way finite-state transducers, i.e., finite-state automata with a two-way input tape and a one-way output tape. Consequently, the equivalence of two MSO definable string transductions is decidable. In the nondeterministic case however, MSO definable string transductions, i.e., binary relations on strings that are MSO definable by an interpretation with parameters, are incomparable to those realized by nondeterministic two-way finite-state transducers. This is a motivation to look for another machine model, and we show that both classes of MSO definable string transductions are characterized in terms of Hennie machines, i.e., two-way finite-state transducers that are allowed to rewrite their input tape, but may visit each position of their input only a bounded number of times. © 2001, ACM. All rights reserved.",Büchi; Elgot; Hennie machine; interpretation; monadic secondorder logic; string transductions; Theory; Trakhtenbrot; two-way finite-state transducers,
Processor Verification Using Efficient Reductions of the Logic of Uninterpreted Functions to Propositional Logic,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958791713&doi=10.1145%2f371282.371364&partnerID=40&md5=fdf3e9df3f5a52efa27830866adcf7a1,"The logic of Equality with Uninterpreted Functions (EUF) provides a means of abstracting the manipulation of data by a processor when verifying the correctness of its control logic. By reducing formulas in this logic to propositional formulas, we can apply Boolean methods such as ordered Binary Decision Diagrams (BDDs) and Boolean satisfiability checkers to perform the verification. We can exploit characteristics of the formulas describing the verification conditions to greatly simplify the propositional formulas generated. We identify a class of terms we call “p-terms” for which equality comparisons can only be used in monotonically positive formulas. By applying suitable abstractions to the hardware model, we can express the functionality of data values and instruction addresses flowing through an instruction pipeline with p-terms. A decision procedure can exploit the restricted uses of p-terms by considering only “maximally diverse” interpretations of the associated function symbols, where every function application yields a different value except when constrained by functional consistency.We present two methods to translate formulas in EUF into propositional logic. The first interprets the formula over a domain of fixed-length bit vectors and uses vectors of propositional variables to encode domain variables. The second generates formulas encoding the conditions under which pairs of terms have equal valuations, introducing propositional variables to encode the equality relations between pairs of terms. Both of these approaches can exploit maximal diversity to greatly reduce the number of propositional variables that need to be introduced and to reduce the overall formula sizes.We present experimental results demonstrating the efficiency of this approach when verifying pipelined processors using the method proposed by Burch and Dill. Exploiting positive equality allows us to overcome the exponential blow-up experienced previously when verifying microprocessors with load, store, and branch instructions. © 2001, ACM. All rights reserved.",Algorithms; Decision procedures; Processor verification; Uninterpreted functions; Verification,
Logics Capturing Local Properties,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-24044460932&doi=10.1145%2f371282.371388&partnerID=40&md5=ea662345a339cf062a5c35a4baec7d86,"Well-known theorems of Hanf and Gaifman establishing locality of first-order definable properties have been used in many applications. These theorems were recently generalized to other logics, which led to new applications in descriptive complexity and database theory. However, a logical characterization of local properties that correspond to Hanf's and Gaifman's theorems is still lacking. Such a characterization only exists for structures of bounded valence. In this paper, we give logical characterizations of local properties behind Hanf's and Gaifman's theorems. We first deal with an infinitary logic with counting terms and quantifiers that is known to capture Hanf-locality on structures of bounded valence. We show that testing isomorphism of neighborhoods can be added to it without violating Hanf-locality, while increasing its expressive power. We then show that adding local second-order quantification to it captures precisely all Hanf-local properties. To capture Gaifman-locality, one must also add a (potentially infinite) case statement. We further show that the hierarchy based on the number of variants in the case statement is strict. © 2001, ACM. All rights reserved.",Counting; Languages; Locality; Logic; Theory,
Probabilistic Logic Programming with Conditional Constraints,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010842519&doi=10.1145%2f377978.377983&partnerID=40&md5=5891425db72bfb6aba3f6f6f9b18c8e8,"We introduce a new approach to probabilistic logic programming in which probabilities are defined over a set of possible worlds. More precisely, classical program clauses are extended by a subinterval of [0, 1] that describes a range for the conditional probability of the head of a clause given its body. We then analyze the complexity of selected probabilistic logic programming tasks. It turns out that probabilistic logic programming is computationally more complex than classical logic programming. More precisely, the tractability of special cases of classical logic programming generally does not carry over to the corresponding special cases of probabilistic logic programming. Moreover, we also draw a precise picture of the complexity of deciding and computing tight logical consequences in probabilistic reasoning with conditional constraints in general. We then present linear optimization techniques for deciding satisfiability and computing tight logical consequences of probabilistic logic programs. These techniques are efficient in the special case in which we have little relevant purely probabilistic knowledge.We finally show that probabilistic logic programming under certain syntactic and semantic restrictions is closely related to van Emden's quantitative deduction, and thus has computational properties similar to classical logic programming. Based on this result, we present an efficient approximation technique for probabilistic logic programming. © 2001, ACM. All rights reserved.",Algorithms; Computational complexity; conditional constraint; Languages; logic programming; many-valued logic; probabilistic logic; probabilistic logic programming; probabilistic reasoning; probability; quantitative deduction; Theory; uncertainty,
Termination Proofs for Logic Programs with Tabling,2001,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345826233&doi=10.1145%2f371282.371357&partnerID=40&md5=d4d9eaa3cb1ae84116cf29cd2b887e82,"Tabled evaluation is receiving increasing attention in the logic programming community. It avoids many of the shortcomings of SLD execution and provides a more flexible and often considerably more efficient execution mechanism for logic programs. In particular, tabled execution terminates more often than execution based on SLD-resolution. In this article, we introduce two notions of universal termination of logic programming with tabling: quasi-termination and (the stronger notion of) LG-termination. We present sufficient conditions for these two notions of termination, namely quasi-acceptability and LG-acceptability, and we show that these conditions are also necessary in case the selection of tabled predicates meets certain natural criteria. Starting from these conditions, we develop modular termination proofs, i.e., proofs capable of combining termination proofs of separate programs to obtain termination proofs of combined programs. Finally, in the presence of mode information, we state sufficient conditions which form the basis for automatically proving termination in a constraint-based way. © 2001, ACM. All rights reserved.",Languages; Prolog; SLG-Resolution; Tabling; Theory,
Probabilistic Agent Programs,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0347714751&doi=10.1145%2f359496.359508&partnerID=40&md5=d907a3aa2913e0fa32ab195f637e85c3,"Agents are small programs that autonomously take actions based on changes in their environment or “state.” Over the last few years, there has been an increasing number of efforts to build agents that can interact and/or collaborate with other agents. In one of these efforts Eiter et al. [1999] have shown how agents may be built on top of legacy code. However, their framework assumes that agent states are completely determined, and there is no uncertainty in an agent's state. Thus, their framework allows an agent developer to specify how his agents will react when the agent is 100% sure about what is true/false in the world state. In this paper, we propose the concept of a probabilistic agent program and show how, given an arbitrary program written in any imperative language, we may build a declarative “probabilistic” agent program on top of it which supports decision making in the presence of uncertainty. We provide two alternative semantics for probabilistic agent programs. We show that the second semantics, though more epistemically appealing, is more complex to compute. We provide sound and complete algorithms to compute the semantics of positive agent programs. © 2000, ACM. All rights reserved.",Logic programming; Multiagent reasoning; Probabilistic reasoning; Theory; Uncertainty,
A Note on the Complexity of Propositional Hoare Logic,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003550003&doi=10.1145%2f343369.343404&partnerID=40&md5=aee1f0c8d5e6f68557061ed9c8c51f2f,"We provide a simpler alternative proof of the PSPACE-hardness of propositional Hoare logic (PHL). © 2000, ACM. All rights reserved.",Design; Hoare logic; Languages; specification; Theory; Verification,
Mechanizing UNITY in Isabelle,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966544848&doi=10.1145%2f343369.343370&partnerID=40&md5=8d3b32f0c10d2992eb2bd7c46a6d3406,"UNITY is an abstract formalism for proving properties of concurrent systems, which typically are expressed using guarded assignments [Chandy and Misra 1988]. UNITY has been mechanized in higher-order logic using Isabelle, a proof assistant. Safety and progress primitives, their weak forms (for the substitution axiom), and the program composition operator (union) have been formalized. To give a feel for the concrete syntax, this article presents a few extracts from the Isabelle definitions and proofs. It discusses a small example, two-process mutual exclusion. A mechanical theory of unions of programs supports a degree of compositional reasoning. Original work on extending program states is presented and then illustrated through a simple example involving an array of processes. © 2000, ACM. All rights reserved.",Compositional reasoning; Concurrency; Isabelle; Theory; UNITY; Verification,
Model-Checking Continuous-Time Markov Chains,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941709469&doi=10.1145%2f343369.343402&partnerID=40&md5=7987c3d97b0ae1792f5fb91951eb3cf0,"We present a logical formalism for expressing properties of continuous-time Markov chains. The semantics for such properties arise as a natural extension of previous work on discretetime Markov chains to continuous time. The major result is that the verification problem is decidable; this is shown using results in algebraic and transcendental number theory. © 2000, ACM. All rights reserved.",Formal verification; Model checking; Real time; Theory; Transcendental number theory; Verification,
Locality of Order-Invariant First-Order Formulas,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012910090&doi=10.1145%2f343369.343386&partnerID=40&md5=1f208d8cd375f7f06f73c2713cdd294b,"A query is local if the decision of whether a tuple in a structure satisfies this query only depends on a small neighborhood of the tuple. We prove that all queries expressible by order-invariant first-order formulas are local. © 2000, ACM. All rights reserved.",First-order logic; Locality; Logics; Ordered structures; Theory,
Sequential Abstract-State Machines Capture Sequential Algorithms,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947248224&doi=10.1145%2f343369.343384&partnerID=40&md5=6357ea7c10021358a2ed22ca42ade221,"We examine sequential algorithms and formulate a sequential-time postulate, an abstractstatepostulate, and a bounded-exploration postulate. Analysis of the postulates leads us tothe notion of sequential abstract-state machine and to the theorem in the title. First we treatsequential algorithms that are deterministic and noninteractive. Then we consider sequentialalgorithms that may be nondeterministic and that may interact with their environments. © 2000, ACM. All rights reserved.",Abstract-state machine; Algorithms; Design; Documentation; Executable specification; Languages; Sequential algorithm; Sequential ASM thesis; Specification; Theory; Turing's thesis,
Compilability and Compact Representations of Revision of Horn Knowledge Bases,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442477058&doi=10.1145%2f343369.343391&partnerID=40&md5=3d3b327aa27e66799fbaf7441139441b,"Several methods have been proposed as an attempt to deal with dynamically changing scenarios. From a computational point of view, different formalisms have different computational properties. In this article we consider knowledge bases represented as sets of Horn clauses. The importance of this case is twofold: first, inference is polynomial, thus tractable; second, Horn clauses represent causal relations between facts, thus they are of great practical importance, although not all propositional knowledge bases can be represented in Horn form. The complexity of Horn revision is still high, and in some cases coincides with the complexity of the general (non-Horn) case. We analyze the complexity of belief revision from the point of view of the compilation [Cadoli et al. 1996a]: we study the possibility of reducing the complexity by allowing a (possibly expensive) preprocessing of part of the input of the problem. Extending the work of Cadoli et al. [1999], we consider the problem of compact representation of revision in the Horn case, i.e., given a knowledge base T and an update P (both represented by Horn clauses) decide whether T * P, the result of the revision, can be represented with a propositional formula whose size is polynomial in the size of T and P. We give this representation for all formalisms for which it exists, and we show that the existence of a compact representation is related to the possibility of decreasing the complexity of a formalism via a preprocessing. © 2000, ACM. All rights reserved.",Algorithms; Compact representations; Compilability; Theory,
First-Order Conditional Logic for Default Reasoning Revisited,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4243083696&doi=10.1145%2f359496.359500&partnerID=40&md5=9b1e28176335f5695d5a4ead504ae59f,"Conditional logics play an important role in recent attempts to formulate theories of default reasoning. This paper investigates first-order conditional logic. We show that, as for first-order probabilistic logic, it is important not to confound statistical conditionals over the domain (such as “most birds fly”), and subjective conditionals over possible worlds (such as “I believe that Tweety is unlikely to fly”).We then address the issue of ascribing semantics to first-order conditional logic. As in the propositional case, there are many possible semantics. To study the problem in a coherent way, we use plausibility structures. These provide us with a general framework in which many of the standard approaches can be embedded. We show that while these standard approaches are all the same at the propositional level, they are significantly different in the context of a first-order language. Furthermore, we show that plausibilities provide the most natural extension of conditional logic to the first-order case: we provide a sound and complete axiomatization that contains only the KLM properties and standard axioms of first-order modal logic. We show that most of the other approaches have additional properties, which result in an inappropriate treatment of an infinitary version of the lottery paradox. © 2000, ACM. All rights reserved.",Completeness; Conditional logic; Default reasoning; First-order logic; KLM properties; Plausibility measures; Theory,
Search and Strategies in OPL,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976509455&doi=10.1145%2f359496.359529&partnerID=40&md5=efd3f46609a5cc17818c12394593fd5d,"OPL is a modeling language for mathematical programming and combinatorial optimization. It is the first language to combine high-level algebraic and set notations from mathematical modeling languages with a rich constraint language and the ability to specify search procedures and strategies that are the essence of constraint programming. This paper describes the facilities available in OPL to specify search procedures. It describes the abstractions of OPL to specify both the search tree (search) and how to explore it (strategies). The paper also illustrates how to use these high-level constructs to implement traditional search procedures in constraint programming and scheduling. © 2000, ACM. All rights reserved.",Combinatorial; Constraint Programming; Design; Languages; Modeling Languages; Optimization; Search,
On Hoare Logic and Kleene Algebra with Tests,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876887451&doi=10.1145%2f343369.343378&partnerID=40&md5=ca1b702293e525cf974a15ae5069a545,"We show that Kleene algebra with tests (KAT) subsumes propositional Hoare logic (PHL). Thus the specialized syntax and deductive apparatus of Hoare logic are inessential and can be replaced by simple equational reasoning. In addition, we show that all relationally valid inference rules are derivable in KAT and that deciding the relational validity of such rules is PSPACE-complete. © 2000, ACM. All rights reserved.",Design; Dynamic logic; Hoare logic; Kleene algebra; Kleene algebra with tests; Languages; specification; Theory; Verification,
Logics with Counting and Local Properties,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913541976&doi=10.1145%2f343369.343376&partnerID=40&md5=d61c6fdc5f448d74fd9250e049c14166,"The expressive power of first-order logic over finite structures is limited in two ways: it lacks a recursion mechanism, and it cannot count. Overcoming the first limitation has been a subject of extensive study. A number of fixpoint logics have been introduced, and shown to be subsumed by an infinitary logic L∞ωω. This logic is easier to analyze than fixpoint logics, and it still lacks counting power, as it has a 0-1 law. On the counting side, there is no analog of L∞ωω. There are a number of logics with counting power, usually introduced via generalized quantifiers. Most known expressivity bounds are based on the fact that counting extensions of first-order logic preserve the locality properties. This article has three main goals. First, we introduce a new logic L∞*ω (C) that plays the same role for counting as L∞*ω v does for recursion-it subsumes a number of extensions of first-order logic with counting, and has nice properties that make it easy to study. Second, we give a simple direct proof that L∞*ω (C) expresses only local properties: those that depend on the properties of small neighborhoods, but cannot grasp a structure as a whole. This is a general way of saying that a logic lacks a recursion mechanism. Third, we consider a finer analysis of locality of counting logics. In particular, we address the question of how local a logic is, that is, how big are those neighborhoods that local properties depend on. We get a uniform answer for a variety of logics between first-order and L∞*ω (C). This is done by introducing a new form of locality that captures the tightest condition that the duplicator needs to maintain in order to win a game. We also use this technique to give bounds on outputs of L∞*ω(C)-definable queries. © 2000, ACM. All rights reserved.",Counting; First-order logic; Infinitary logic; Languages; Locality; Theory,
Knowledge in Multiagent Systems: Initial Configurations and Broadcast,2000,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038135545&doi=10.1145%2f359496.359527&partnerID=40&md5=6f3a8560c11dacfaf788f6c4f9bbc758,"The semantic framework for the modal logic of knowledge due to Halpern and Moses provides a way to ascribe knowledge to agents in distributed and multiagent systems. In this paper we study two special cases of this framework: full systems and hypercubes. Both model static situations in which no agent has any information about another agent's state. Full systems and hypercubes are an appropriate model for the initial configurations of many systems of interest. We establish a correspondence between full systems and hypercube systems and certain classes of Kripke frames. We show that these classes of systems correspond to the same logic. Moreover, this logic is also the same as that generated by the larger class of weakly directed frames. We provide a sound and complete axiomatization, S5WDn, of this logic, and study its computational complexity. Finally, we show that under certain natural assumptions, in a model where knowledge evolves over time, S5WDn characterises the properties of knowledge not just at the initial configuration, but also at all later configurations. In particular, this holds for homogeneous broadcast systems, which capture settings in which agents are initially ignorant of each others local states, operate synchronously, have perfect recall, and can communicate only by broadcasting. © 2000, ACM. All rights reserved.",Completeness; Computational complexity; Knowledge Representation in Distributed Systems; Modal Logic,
The Temporal Logic of Coalitional Goal Assignments in Concurrent Multiplayer Games,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148061293&doi=10.1145%2f3517128&partnerID=40&md5=dd12dd025df32fa71e2211609b8f10a9,"We introduce and study a natural extension of the Alternating time temporal logic ATL, called Temporal Logic of Coalitional Goal Assignments (TLCGA). It features one new and quite expressive coalitional strategic operator, called the coalitional goal assignment operator 〈[ γ]〉, where γis a mapping assigning to each set of players in the game its coalitional goal, formalised by a path formula of the language of TLCGA, i.e., a formula prefixed with a temporal operator X, U, or G, representing a temporalised objective for the respective coalition, describing the property of the plays on which that objective is satisfied. Then, the formula 〈[ γ]〉 intuitively says that there is a strategy profile Σ for the grand coalition Agt such that for each coalition C, the restriction Σ |C of Σ to C is a collective strategy of C that enforces the satisfaction of its objective γ(C) in all outcome plays enabled by Σ |C.We establish fixpoint characterizations of the temporal goal assignments in a μ-calculus extension of TLCGA, discuss its expressiveness and illustrate it with some examples, prove bisimulation invariance and Hennessy-Milner property for it with respect to a suitably defined notion of bisimulation, construct a sound and complete axiomatic system for TLCGA, and obtain its decidability via finite model property.  © 2022 Copyright held by the owner/author(s).",coalitional goal assignments; concurrent multi-player games; Temporal logic,Computer circuits; Game theory; Alternating time temporal logic; Bisimulations; Coalitional goal assignment; Concurrent multi-player game; Fixpoints; Multiplayer games; Natural extension; Property; Sound and complete; Temporal operators; Temporal logic
Are Two Binary Operators Necessary to Obtain a Finite Axiomatisation of Parallel Composition?,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148083340&doi=10.1145%2f3529535&partnerID=40&md5=6fa707ba2df9493641fb806d04c93728,"Bergstra and Klop have shown that bisimilarity has a finite equational axiomatisation over ACP/CCS extended with the binary left and communication merge operators. Moller proved that auxiliary operators are necessary to obtain a finite axiomatisation of bisimilarity over CCS, and Aceto et al. showed that this remains true when Hennessy's merge is added to that language. These results raise the question of whether there is one auxiliary binary operator whose addition to CCS leads to a finite axiomatisation of bisimilarity. We contribute to answering this question in the simplified setting of the recursion-, relabelling-, and restriction-free fragment of CCS. We formulate three natural assumptions pertaining to the operational semantics of auxiliary operators and their relationship to parallel composition and prove that an auxiliary binary operator facilitating a finite axiomatisation of bisimilarity in the simplified setting cannot satisfy all three assumptions. © 2022 Association for Computing Machinery.",bisimulation; CCS; Equational logic; non-finitely based algebras; parallel composition,Computation theory; Axiomati-sation; Binary operators; Bisimilarity; Bisimulations; CCS; Communication merge; Equational logic; Merge operators; Non-finitely based algebras; Parallel composition; Semantics
The Intersection of Algorithmically Random Closed Sets and Effective Dimension,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148083065&doi=10.1145%2f3545114&partnerID=40&md5=4ca6c1c019e0ebef58ea38d7ba93084d,"In this article, we study several aspects of the intersections of algorithmically random closed sets. First, we answer a question of Cenzer and Weber, showing that the operation of intersecting relatively random closed sets (random with respect to certain underlying measures induced by Bernoulli measures on the space of codes of closed sets), which preserves randomness, can be inverted: a random closed set of the appropriate type can be obtained as the intersection of two relatively random closed sets. We then extend the Cenzer/Weber analysis to the intersection of multiple random closed sets, identifying the Bernoulli measures with respect to which the intersection of relatively random closed sets can be non-empty. We lastly apply our analysis to provide a characterization of the effective Hausdorff dimension of sequences in terms of the degree of intersectability of random closed sets that contain them. © 2022 Association for Computing Machinery.",algorithmic randomness; Computability theory; effective dimension; Galton-Watson processes; random closed sets,Algorithmic randomness; Bernoulli; Closed set; Computability theory; Effective dimensions; Galton-Watson process; Hausdorff dimension; Inverted a; Random closed set; Random processes
A Subatomic Proof System for Decision Trees,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148091978&doi=10.1145%2f3545116&partnerID=40&md5=0794dbf8a8f072a9d10e60ec49a8b186,"We design a proof system for propositional classical logic that integrates two languages for Boolean functions: standard conjunction-disjunction-negation and binary decision trees. We give two reasons to do so. The first is proof-theoretical naturalness: The system consists of all and only the inference rules generated by the single, simple, linear scheme of the recently introduced subatomic logic. Thanks to this regularity, cuts are eliminated via a natural construction. The second reason is that the system generates efficient proofs. Indeed, we show that a certain class of tautologies due to Statman, which cannot have better than exponential cut-free proofs in the sequent calculus, have polynomial cut-free proofs in our system. We achieve this by using the same construction that we use for cut elimination. In summary, by expanding the language of propositional logic, we make its proof theory more regular and generate more proofs, some of which are very efficient. That design is made possible by considering atoms as superpositions of their truth values, which are connected by self-dual, non-commutative connectives. A proof can then be projected via each atom into two proofs, one for each truth value, without a need for cuts. Those projections are semantically natural and are at the heart of the constructions in this article. To accommodate self-dual non-commutativity, we compose proofs in deep inference. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",cut elimination; Deep inference; open deduction; Statman tautologies; subatomic logic,Binary trees; Decision trees; Differentiation (calculus); Formal logic; Binary decision trees; Classical logic; Cut elimination; Deep inference; Open deduction; Proof system; Self-dual; Statman tautology; Subatomic logic; Truth values; Computer circuits
Syntactic Completeness of Proper Display Calculi,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148102547&doi=10.1145%2f3529255&partnerID=40&md5=4f84297746081336c754694a6f94ee04,"A recent strand of research in structural proof theory aims at exploring the notion of analytic calculi (i.e., those calculi that support general and modular proof-strategies for cut elimination) and at identifying classes of logics that can be captured in terms of these calculi. In this context, Wansing introduced the notion of proper display calculi as one possible design framework for proof calculi in which the analyticity desiderata are realized in a particularly transparent way. Recently, the theory of properly displayable logics (i.e., those logics that can be equivalently presented with some proper display calculus) has been developed in connection with generalized Sahlqvist theory (a.k.a. unified correspondence). Specifically, properly displayable logics have been syntactically characterized as those axiomatized by analytic inductive axioms, which can be equivalently and algorithmically transformed into analytic structural rules so the resulting proper display calculi enjoy a set of basic properties: soundness, completeness, conservativity, cut elimination, and the subformula property. In this context, the proof that the given calculus is complete w.r.t. the original logic is usually carried out syntactically, i.e., by showing that a (cut-free) derivation exists of each given axiom of the logic in the basic system to which the analytic structural rules algorithmically generated from the given axiom have been added. However, so far, this proof strategy for syntactic completeness has been implemented on a case-by-case base and not in general. In this article, we address this gap by proving syntactic completeness for properly displayable logics in any normal (distributive) lattice expansion signature. Specifically, we show that for every analytic inductive axiom a cut-free derivation can be effectively generated that has a specific shape, referred to as pre-normal form.  © 2022 Association for Computing Machinery.",analytic inductive inequalities; lattice expansions; Proper display calculi; properly displayable logics; unified correspondence,Biomineralization; Expansion; Pathology; Analytic inductive inequality; Cut elimination; Display calculus; Lattice expansion; Proof strategy; Proper display calculus; Properly displayable logic; Property; Structural rules; Unified correspondence; Syntactics
A Category Theoretic View of Contextual Types: From Simple Types to Dependent Types,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148107034&doi=10.1145%2f3545115&partnerID=40&md5=72b6766772ae201c2b60d4ff6cd72cb9,"We describe the categorical semantics for a simply typed variant and a simplified dependently typed variant of Cocon, a contextual modal type theory where the box modality mediates between the weak function space that is used to represent higher-order abstract syntax (HOAS) trees and the strong function space that describes (recursive) computations about them. What makes Cocon different from standard type theories is the presence of first-class contexts and contextual objects to describe syntax trees that are closed with respect to a given context of assumptions. Following M. Hofmann's work, we use a presheaf model to characterise HOAS trees. Surprisingly, this model already provides the necessary structure to also model Cocon. In particular, we can capture the contextual objects of Cocon using a comonad b that restricts presheaves to their closed elements. This gives a simple semantic characterisation of the invariants of contextual types (e.g. substitution invariance) and identifies Cocon as a type-theoretic syntax of presheaf models. We further extend this characterisation to dependent types using categories with families and show that we can model a fragment of Cocon without recursor in the Fitch-style dependent modal type theory presented by Birkedal et al. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Category theory; contextual types; dependent types; type theory,Formal languages; Functional analysis; Syntactics; Trees (mathematics); Abstract Syntax Trees; Categorical semantics; Category theory; Contextual type; Dependent types; Function spaces; Higher-order abstract syntax; Presheaf; Simple types; Type theory; Semantics
Unifying Operational Weak Memory Verification: An Axiomatic Approach,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143700657&doi=10.1145%2f3545117&partnerID=40&md5=ffafb2a56bcee7b6d57a1790fb53ff47,"In this article, we propose an approach to program verification using an abstract characterisation of weak memory models. Our approach is based on a hierarchical axiom scheme that captures the observational properties of a memory model. In particular, we show that it is possible to prove correctness of a program with respect to a particular axiom scheme, and we show this proof to suffice for any memory model that satisfies the axioms. Our axiom scheme is developed using a characterisation of weakest liberal preconditions for weak memory. This characterisation naturally extends to Hoare logic and Owicki-Gries reasoning by lifting weakest liberal preconditions (defined over read/write events) to the level of programs. We study three memory models (SC, TSO, and RC11-RAR) as example instantiations of the axioms, then we demonstrate the applicability of our reasoning technique on a number of litmus tests. The majority of the proofs in this article are supported by mechanisation within Isabelle/HOL. © 2022 Association for Computing Machinery.",axiom hierarchy; Hoare logic; Isabelle/HOL; Owicki-Gries; verification; Weak memory models,Computer circuits; Axiom hierarchy; Axiomatic approach; Hoare Logic; Isabelle; Isabelle/HOL; Memory modeling; Owicki-gry; Program Verification; Property; Weak memory models; Abstracting
A Meta-theory for Big-step Semantics,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135009157&doi=10.1145%2f3522729&partnerID=40&md5=c66dd8fcda6e8333980ac22378171491,"It is well known that big-step semantics is not able to distinguish stuck and non-terminating computations. This is a strong limitation as it makes it very difficult to reason about properties involving infinite computations, such as type soundness, which cannot even be expressed.We show that this issue is only apparent: the distinction between stuck and diverging computations is implicit in any big-step semantics and it just needs to be uncovered. To achieve this goal, we develop a systematic study of big-step semantics: we introduce an abstract definition of what a big-step semantics is, we define a notion of computation by formalizing the evaluation algorithm implicitly associated with any big-step semantics, and we show how to canonically extend a big-step semantics to characterize stuck and diverging computations.Building on these notions, we describe a general proof technique to show that a predicate is sound, that is, it prevents stuck computation, with respect to a big-step semantics. One needs to check three properties relating the predicate and the semantics, and if they hold, the predicate is sound. The extended semantics is essential to establish this meta-logical result but is of no concerns to the user, who only needs to prove the three properties of the initial big-step semantics. Finally, we illustrate the technique by several examples, showing that it is applicable also in cases where subject reduction does not hold, and hence the standard technique for small-step semantics cannot be used. © 2022 Association for Computing Machinery.",Big-step semantics; type soundness,Computation theory; Big-step semantics; Evaluation algorithm; Meta-theory; Property; Small-step semantics; Subject-reduction; Systematic study; Type soundness; Semantics
Parameterized Complexity of Elimination Distance to First-Order Logic Properties,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135082835&doi=10.1145%2f3517129&partnerID=40&md5=a6ecd9c3088dfc31c99af171c9e20769,"The elimination distance to some target graph property P is a general graph modification parameter introduced by Bulian and Dawar. We initiate the study of elimination distances to graph properties expressible in first-order logic. We delimit the problem's fixed-parameter tractability by identifying sufficient and necessary conditions on the structure of prefixes of first-order logic formulas. Our main result is the following meta-theorem: For every graph property P expressible by a first order-logic formula , that is, of the form where is a quantifier-free first-order formula, checking whether the elimination distance of a graph to P does not exceed , is fixed-parameter tractable parameterized by . Properties of graphs expressible by formulas from include being of bounded degree, excluding a forbidden subgraph, or containing a bounded dominating set. We complement this theorem by showing that such a general statement does not hold for formulas with even slightly more expressive prefix structure: There are formulas , for which computing elimination distance is -hard. © 2022 Association for Computing Machinery.",descriptive complexity; elimination distance; First-order logic; parameterized complexity,Computer circuits; Formal logic; Graph theory; Descriptive complexity; Elimination distance; First order logic; Fixed-parameter tractability; General graph; Graph modifications; Graph properties; Logic formulas; Logic properties; Parameterized complexity; Parameterization
QCSP on Reflexive Tournaments,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135073960&doi=10.1145%2f3508069&partnerID=40&md5=12829c05004a51908a9be233657588d7,"We give a complexity dichotomy for the Quantified Constraint Satisfaction Problem when is a reflexive tournament. It is well known that reflexive tournaments can be split into a sequence of strongly connected components so that there exists an edge from every vertex of to every vertex of if and only if . We prove that if has both its initial and final strongly connected component (possibly equal) of size 1, then is in and otherwise is -hard. © 2022 Association for Computing Machinery.",computational complexity; constraint satisfaction; graph theorem; logic; Quantified constraints,Computational complexity; Graph theory; Complexity dichotomies; Constraint Satisfaction; Graph theorem; Logic; Quantified constraint; Quantified constraints satisfaction problems; Strongly connected component; Constraint satisfaction problems
Verification of Distributed Quantum Programs,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133590066&doi=10.1145%2f3517145&partnerID=40&md5=a9c8891d1612de00d3f78f37c45d2655,"Distributed quantum systems and especially the Quantum Internet have the ever-increasing potential to fully demonstrate the power of quantum computation. This is particularly true given that developing a general-purpose quantum computer is much more difficult than connecting many small quantum devices. One major challenge of implementing distributed quantum systems is programming them and verifying their correctness. In this paper, we propose a CSP-like distributed programming language to facilitate the specification and verification of such systems. After presenting its operational and denotational semantics, we develop a Hoare-style logic for distributed quantum programs and establish its soundness and (relative) completeness with respect to both partial and total correctness. The effectiveness of the logic is demonstrated by its applications in the verification of quantum teleportation and local implementation of non-local CNOT gates, two important algorithms widely used in distributed quantum systems. © 2022 Association for Computing Machinery.",distributed computing; formal verification; Hoare logic; Quantum programming,Computation theory; Computer circuits; Distributed computer systems; Quantum computers; Quantum optics; Semantics; Denotational semantics; Distributed programming languages; Hoare Logic; Operational semantics; Power; Quanta computers; Quantum device; Quantum programming; Quantum system; Specification and verification; Formal verification
Modalities and Parametric Adjoints,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135058578&doi=10.1145%2f3514241&partnerID=40&md5=47006416263ecbacbcdc8affe8dc1b16,"Birkedal et al. recently introduced dependent right adjoints as an important class of (non-fibered) modalities in type theory. We observe that several aspects of their calculus are left underdeveloped and that it cannot serve as an internal language. We resolve these problems by assuming that the modal context operator is a parametric right adjoint. We show that this hitherto unrecognized structure is common. Based on these discoveries we present a new well-behaved Fitch-style multimodal type theory, which can be used as an internal language. Finally, we apply this syntax to guarded recursion and parametricity. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",categorical semantics; dependent types; Fitch-style modalities; guarded recursion; Modal types; parametricity,Formal languages; Semantics; Adjoints; Categorical semantics; Dependent types; Fitch-style modality; Guarded recursion; Internal languages; Modal type; Parametricity; Recursions; Type theory; Calculations
Satisfiability Problems on Sums of Kripke Frames,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135040098&doi=10.1145%2f3508068&partnerID=40&md5=d2c45bbe87d05ea7199070e72c33223e,"We consider the operation of sum on Kripke frames, where a family of frames-summands is indexed by elements of another frame. In many cases, the modal logic of sums inherits the finite model property and decidability from the modal logic of summands [Babenyshev and Rybakov 2010; Shapirovsky 2018]. In this paper we show that, under a general condition, the satisfiability problem on sums is polynomial space Turing reducible to the satisfiability problem on summands. In particular, for many modal logics decidability in PSpace is an immediate corollary from the semantic characterization of the logic. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",decidability; finite model property; Japaridze's polymodal logic; lexicographic product of modal logics; lexicographic sum of modal logics; PSpace; Sum of Kripke frames; Turing reduction,Computer circuits; Semantics; % reductions; Finite model property; Japaridze's Polymodal Logic; Kripke frames; Lexicographic product; Lexicographic product of modal logic; Lexicographic sum of modal logic; Modal logic; Pspace; Sum of kripke frame; Turing reduction; Computability and decidability
On Proof Complexity of Resolution over Polynomial Calculus,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135020022&doi=10.1145%2f3506702&partnerID=40&md5=5db9a2491eb515379903c7faacfb607b,"The proof system Res (PCd,R) is a natural extension of the Resolution proof system that instead of disjunctions of literals operates with disjunctions of degree d multivariate polynomials over a ring R with Boolean variables. Proving super-polynomial lower bounds for the size of Res(PC1,R)-refutations of Conjunctive normal forms (CNFs) is one of the important problems in propositional proof complexity. The existence of such lower bounds is even open for Res(PC1,) when is a finite field, such as 2. In this article, we investigate Res(PCd,R) and tree-like Res(PCd,R) and prove size-width relations for them when R is a finite ring. As an application, we prove new lower bounds and reprove some known lower bounds for every finite field as follows:(1)We prove almost quadratic lower bounds for Res(PCd,)-refutations for every fixed d. The new lower bounds are for the following CNFs:(a)Mod q Tseitin formulas (char() q) and Flow formulas,(b)Random k-CNFs with linearly many clauses.(2)We also prove super-polynomial (more than nk for any fixed k) and also exponential (2nμ for an μ > 0) lower bounds for tree-like Res(PCd,)-refutations based on how big d is with respect to n for the following CNFs:(a)Mod q Tseitin formulas (char()q) and Flow formulas,(b)Random k-CNFs of suitable densities,(c)Pigeonhole principle and Counting mod q principle. The lower bounds for the dag-like systems are the first nontrivial lower bounds for these systems, including the case d=1. The lower bounds for the tree-like systems were known for the case d=1 (except for the Counting mod q principle, in which lower bounds for the case d> 1 were known too). Our lower bounds extend those results to the case where d> 1 and also give new proofs for the case d=1. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",lower bounds; modular counting; Polynomial Calculus; propositional pigeonhole principle; propositional proof complexity; Resolution; resolution over linear equations; size-width relations; Tseitin formulas,Forestry; Polynomials; Low bound; Modular counting; Pigeonhole principle; Polynomial calculus; Propositional pigeonhole principle; Propositional proof complexity; Resolution; Resolution over linear equation; Size-width relation; Tseitin formula; Calculations
O-Minimal Invariants for Discrete-Time Dynamical Systems,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124901979&doi=10.1145%2f3501299&partnerID=40&md5=392db3dc3d2eb1535832246ac50bc39c,"Termination analysis of linear loops plays a key rôle in several areas of computer science, including program verification and abstract interpretation. Already for the simplest variants of linear loops the question of termination relates to deep open problems in number theory, such as the decidability of the Skolem and Positivity Problems for linear recurrence sequences, or equivalently reachability questions for discrete-time linear dynamical systems. In this article, we introduce the class of o-minimal invariants, which is broader than any previously considered, and study the decidability of the existence and algorithmic synthesis of such invariants as certificates of non-termination for linear loops equipped with a large class of halting conditions. We establish two main decidability results, one of them conditional on Schanuel's conjecture is transcendental number theory.  © 2022 Association for Computing Machinery.",Invariants; linear dynamical systems; linear loops; non-termination; o-minimality,Abstracting; Computability and decidability; Dynamical systems; Number theory; Discrete-time dynamical systems; Invariant; Linear dynamical systems; Linear loop; Minimal invariants; Minimality; Non terminations; O-minimality; Program Verification; Termination analysis; Linear control systems
Logics with Multiteam Semantics,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124915025&doi=10.1145%2f3487579&partnerID=40&md5=b46ad5d9c5cd76d42de6a8a12b70e4d0,"Team semantics is the mathematical basis of modern logics of dependence and independence. In contrast to classical Tarski semantics, a formula is evaluated not for a single assignment of values to the free variables, but on a set of such assignments, called a team. Team semantics is appropriate for a purely logical understanding of dependency notions, where only the presence or absence of data matters, but being based on sets, it does not take into account multiple occurrences of data values. It is therefore insufficient in scenarios where such multiplicities matter, in particular for reasoning about probabilities and statistical independencies. Therefore, an extension from teams to multiteams (i.e. multisets of assignments) has been proposed by several authors. In this paper we aim at a systematic development of logics of dependence and independence based on multiteam semantics. We study atomic dependency properties of finite multiteams and discuss the appropriate meaning of logical operators to extend the atomic dependencies to full-fledged logics for reasoning about dependence properties in a multiteam setting. We explore properties and expressive power of a wide spectrum of different multiteam logics and compare them to second-order logic and to logics with team semantics. In many cases the results resemble what is known in team semantics, but there are also interesting differences. While in team semantics, the combination of inclusion and exclusion dependencies leads to a logic with the full power of both independence logic and existential second-order logic, independence properties of multiteams are not definable by any combination of properties that are downwards closed or union closed and thus are strictly more powerful than inclusion-exclusion logic. We also study the relationship of logics with multiteam semantics with existential second-order logic for a specific class of metafinite structures. It turns out that inclusion-exclusion logic can be characterised in a precise sense by the Presburger fragment of this logic, but for capturing independence, we need to go beyond it and add some form of multiplication. Finally, we also consider multiteams with weights in the reals and study the expressive power of formulae by means of topological properties.  © 2022 Association for Computing Machinery.",Logics of dependence and independence; metafinite model theory; multiteam semantics; team semantics,Computer circuits; Formal logic; Topology; Existential second-order logic; Expressive power; Inclusion-exclusion; Logic of dependence and independence; Mathematical basis; Metafinite model theory; Model theory; Multiteam semantic; Property; Team semantic; Semantics
Zero-One Laws for Existential First-Order Sentences of Bounded Quantifier Depth,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124897934&doi=10.1145%2f3489466&partnerID=40&md5=c9f5acdce2c69d838549badb5f8fdf18,"For any fixed positive integer k, let αk denote the smallest α ∈ (0,1) such that the random graph sequence {G(n, n-α)}n does not satisfy the zero-one law for the set ϵk of all existential first-order sentences that are of quantifier depth at most k. This article finds upper and lower bounds on αk, showing that as k → ∞, we have α k = (k - 2 - t(k))-1 for some function t(k) = ⊖ (k-2). We also establish the precise value of αk when k = 4.  © 2022 Association for Computing Machinery.",Ehrenfeucht games; Existential first-order logic; graph extension properties; strictly balanced graphs; zero-one laws; α-safe pairs,Graph theory; Balanced graphs; Ehrenfeucht game; Existential first-order logic; Extension properties; First order logic; Graph extension property; Graph extensions; Strictly balanced graph; Zero-one law; Α-safe pair; Formal logic
Coalgebraic Reasoning with Global Assumptions in Arithmetic Modal Logics,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124878801&doi=10.1145%2f3501300&partnerID=40&md5=ba95226cf6080f92c3a4c578f085d581,"We establish a generic upper bound ExpTime for reasoning with global assumptions (also known as TBoxes) in coalgebraic modal logics. Unlike earlier results of this kind, our bound does not require a tractable set of tableau rules for the instance logics, so that the result applies to wider classes of logics. Examples are Presburger modal logic, which extends graded modal logic with linear inequalities over numbers of successors, and probabilistic modal logic with polynomial inequalities over probabilities. We establish the theoretical upper bound using a type elimination algorithm. We also provide a global caching algorithm that potentially avoids building the entire exponential-sized space of candidate states, and thus offers a basis for practical reasoning. This algorithm still involves frequent fixpoint computations; we show how these can be handled efficiently in a concrete algorithm modelled on Liu and Smolka's linear-time fixpoint algorithm. Finally, we show that the upper complexity bound is preserved under adding nominals to the logic, i.e., in coalgebraic hybrid logic.  © 2022 Association for Computing Machinery.",coalgebraic logic; description logics; Global assumptions; global caching; hybrid logic; Presburger modal logic; probabilistic modal logic; TBoxes,Computer circuits; Probabilistic logics; Coalgebraic logic; Description logic; Global assumption; Global caching; Hybrid logic; Modal logic; Presburger; Presburger modal logic; Probabilistic modal logic; Tboxes; Data description
Asynchronous Announcements,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124893247&doi=10.1145%2f3481806&partnerID=40&md5=87899244f129d6245f35171141e3b7d8,"We propose a multi-agent epistemic logic of asynchronous announcements, where truthful announcements are publicly sent but individually received by agents, and in the order in which they were sent. Additional to epistemic modalities the logic contains dynamic modalities for making announcements and for receiving them. What an agent believes is a function of her initial uncertainty and of the announcements she has received. Beliefs need not be truthful, because announcements already made may not yet have been received. As announcements are true when sent, certain message sequences can be ruled out, just like inconsistent cuts in distributed computing. We provide a complete axiomatization for this asynchronous announcement logic (AA). It is a reduction system that also demonstrates that any formula in AA is equivalent to one without dynamic modalities, just as for public announcement logic. A detailed example modelling message exchanging processes in distributed computing in AA closes our investigation.  © 2022 Association for Computing Machinery.",asynchronous systems; Epistemic logics; public announcements,Computation theory; Computer circuits; Distributed computer systems; Asynchronous system; Complete axiomatizations; Epistemic logic; Message exchanging; Message sequences; Multi-agent epistemic logic; Public announcement; Reduction systems; Uncertainty; Multi agent systems
Being Correct Is Not Enough: Efficient Verification Using Robust Linear Temporal Logic,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124786464&doi=10.1145%2f3491216&partnerID=40&md5=41b090a4955808bff0f240a125531ba3,"While most approaches in formal methods address system correctness, ensuring robustness has remained a challenge. In this article, we present and study the logic rLTL, which provides a means to formally reason about both correctness and robustness in system design. Furthermore, we identify a large fragment of rLTL for which the verification problem can be efficiently solved, i.e., verification can be done by using an automaton, recognizing the behaviors described by the rLTL formula φ, of size at most O(3|φ|), where |φ| is the length of φ. This result improves upon the previously known bound of O(5|φ|) for rLTL verification and is closer to the LTL bound of O(2|φ|). The usefulness of this fragment is demonstrated by a number of case studies showing its practical significance in terms of expressiveness, the ability to describe robustness, and the fine-grained information that rLTL brings to the process of system verification. Moreover, these advantages come at a low computational overhead with respect to LTL verification.  © 2022 Association for Computing Machinery.",Robustness in temporal logics; robustness in verification,Computer circuits; Formal verification; Case-studies; Computational overheads; Fine grained; Linear temporal logic; Robustness in temporal logic; Robustness in verification; System verifications; Verification problems; Temporal logic
Universal Equivalence and Majority of Probabilistic Programs over Finite Fields,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123980711&doi=10.1145%2f3487063&partnerID=40&md5=34fef32b1108b0a403c15e4c3a9ab762,"We study decidability problems for equivalence of probabilistic programs for a core probabilistic programming language over finite fields of fixed characteristic. The programming language supports uniform sampling, addition, multiplication, and conditionals and thus is sufficiently expressive to encode Boolean and arithmetic circuits. We consider two variants of equivalence: The first one considers an interpretation over the finite field Fq, while the second one, which we call universal equivalence, verifies equivalence over all extensions Fqk of Fq. The universal variant typically arises in provable cryptography when one wishes to prove equivalence for any length of bitstrings, i.e., elements of F2k for any k. While the first problem is obviously decidable, we establish its exact complexity, which lies in the counting hierarchy. To show decidability and a doubly exponential upper bound of the universal variant, we rely on results from algorithmic number theory and the possibility to compare local zeta functions associated to given polynomials. We then devise a general way to draw links between the universal probabilistic problems and widely studied problems on linear recurrence sequences. Finally, we study several variants of the equivalence problem, including a problem we call majority, motivated by differential privacy. We also define and provide some insights about program indistinguishability, proving that it is decidable for programs always returning 0 or 1. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",decidability and complexity; finite fields; probabilistic programs; Program equivalence,Computability and decidability; Functions; Number theory; Arithmetic circuit; Boolean circuit; Decidability and complexity; Decidability problems; Finite fields; Probabilistic programming language; Probabilistic programs; Program equivalence; Provable cryptographies; Uniform sampling; Equivalence classes
Graphs Identified by Logics with Counting,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124023092&doi=10.1145%2f3417515&partnerID=40&md5=3915fb9c241c32ee450c070539226ec5,"We classify graphs and, more generally, finite relational structures that are identified by, that is, two-variable first-order logic with counting. Using this classification, we show that it can be decided in almost linear time whether a structure is identified by. Our classification implies that for every graph identified by this logic, all vertex-colored versions of it are also identified. A similar statement is true for finite relational structures.We provide constructions that solve the inversion problem for finite relational structures in linear time. By a result due to Otto, this problem has been known to be polynomial-time solvable. For graphs, we conclude that every-equivalence class contains a representative whose orbits are exactly the classes of the-partition of its vertex set and which has a single automorphism witnessing this fact.We show that such statements are not true for general by providing examples of graphs of order linear in which are identified by, but for which the orbit partition is strictly finer than the-partition. We also construct identified graphs which have vertex-colored versions that are not identified by. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",CFI graphs; color refinement; counting quantifiers; first-order logic; inversion; Weisfeiler-Leman algorithm,Computer circuits; Equivalence classes; Formal logic; Graph theory; Polynomial approximation; CFI graph; Color refinement; Counting quantifiers; Finite relational structures; First order logic; Inversion; Inversion problems; Linear time; Polynomial-time; Weisfeile-leman algorithm; Graphic methods
Local Belief Dynamics in Network Knowledge Bases,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124038377&doi=10.1145%2f3477394&partnerID=40&md5=8cb63565de4581d2848a70ba9ca226b6,"People are becoming increasingly more connected to each other as social networks continue to grow both in number and variety, and this is true for autonomous software agents as well. Taking them as a collection, such social platforms can be seen as one complex network with many different types of relations, different degrees of strength for each relation, and a wide range of information on each node. In this context, social media posts made by users are reflections of the content of their own individual (or local) knowledge bases; modeling how knowledge flows over the network-or how this can possibly occur-is therefore of great interest from a knowledge representation and reasoning perspective. In this article, we provide a formal introduction to the network knowledge base model, and then focus on the problem of how a single agent's knowledge base changes when exposed to a stream of news items coming from other members of the network. We do so by taking the classical belief revision approach of first proposing desirable properties for how such a local operation should be carried out (theoretical characterization), arriving at three different families of local operators, exploring concrete algorithms (algorithmic characterization) for two of the families, and proving properties about the relationship between the two characterizations (representation theorem). One of the most important differences between our approach and the classical models of belief revision is that in our case the input is more complex, containing additional information about each piece of information. © 2021 Association for Computing Machinery.",belief revision; Network knowledge bases; social networks,Autonomous agents; Knowledge representation; Social networking (online); Social sciences computing; Autonomous software agents; Belief revision; Degree of strength; In networks; Local knowledge; Network knowledge basis; Property; Social media; Social network; Types of relations; Complex networks
Symmetric Circuits for Rank Logic,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124005177&doi=10.1145%2f3476227&partnerID=40&md5=d2ad91e2eff1a2f254e319710c8bfd8b,"Fixed-point logic with rank (FPR) is an extension of fixed-point logic with counting (FPC) with operators for computing the rank of a matrix over a finit field. The expressive power of FPR properly extends that of FPC and is contained in P, but it is not known if that containment is proper. We give a circuit characterization for FPR in terms of families of symmetric circuits with rank gates, along the lines of that for FPC given by Anderson and Dawar in 2017. This requires the development of a broad framework of circuits in which the individual gates compute functions that are not symmetric (i.e., invariant under all permutations of their inputs). This framework also necessitates the development of novel techniques to prove the equivalence of circuits and logic. Both the framework and the techniques are of greater generality than the main result. © 2021 Copyright held by the owner/author(s).",circuit characterization; circuit complexity; circuit frameworks; descriptive complexity; Finite model theory; fixed-point logic with rank; fixed-point logics; symmetric circuits; uniform families of circuits,Computer circuits; Logic circuits; Circuit characterization; Circuit complexity; Circuit framework; Descriptive complexity; Finite model theory; Fixed-point logic; Fixed-point logic with rank; Symmetric circuit; Symmetrics; Uniform family of circuit; Timing circuits
A Formal System for the Universal Quantification of Schematic Variables,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124027366&doi=10.1145%2f3470646&partnerID=40&md5=404941df20dd9e83f38ee84e1036947f,"We advocate the use of de Bruijn's universal abstraction for the quantification of schematic variables in the predicative setting, and we present a typed-calculus featuring the quantifier accompanied by other practically useful constructions like explicit substitutions and expected type annotations. Our calculus stands just on two notions, i.e., bound rt-reduction and parametric validity, and has the expressive power of. Thus, while not aiming at being a logical framework by itself, it does enjoy many desired invariants of logical frameworks including confluence of reduction, strong normalization, preservation of type by reduction, decidability, correctness of types and uniqueness of types up to conversion. This calculus belongs to the family of formal systems, which borrow some features from the pure type systems and some from the languages of the Automath tradition, but stand outside both families. In particular, our calculus includes and evolves two earlier systems of this family. Moreover, a machine-checked specification of its theory is available. © 2021 Association for Computing Machinery.",explicit substitutions; extended applicability condition; infinite degrees of terms; preservation of validity; Quantified schematic variables; strong normalization; terms as types,% reductions; Condition; Explicit Substitutions; Extended applicability condition; Formal systems; Infinite degree of term; Preservation of validity; Quantified schematic variable; Strong normalization; Term as type; Calculations
Tractability Frontier of Data Complexity in Team Semantics,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124045694&doi=10.1145%2f3471618&partnerID=40&md5=64c84b1f5a7b23781d81983ee0843964,"We study the data complexity of model checking for logics with team semantics. We focus on dependence, inclusion, and independence logic formulas under both strict and lax team semantics. Our results delineate a clear tractability/intractability frontiers in data complexity of both quantifier-free and quantified formulas for each of the logics. For inclusion logic under the lax semantics, we reduce the model-checking problem to the satisfiability problem of so-called dual-Horn Boolean formulas. Via this reduction, we give an alternative proof for the known result that the data complexity of inclusion logic is in PTIME. © 2021 Association for Computing Machinery.",data complexity; dependence; inclusion; independence; model checking; Team semantics,Boolean algebra; Computer circuits; Model checking; % reductions; Data complexity; Dependence; Horn boolean formulae; Independence; Logic formulas; Model checking problem; Models checking; Satisfiability problems; Team semantic; Semantics
Piecewise Linear Valued CSPs Solvable by Linear Programming Relaxation,2022,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124044922&doi=10.1145%2f3488721&partnerID=40&md5=2d433ea79a22bdd59b06ba4b0074f3eb,"Valued constraint satisfaction problems (VCSPs) are a large class of combinatorial optimisation problems. The computational complexity of VCSPs depends on the set of allowed cost functions in the input. Recently, the computational complexity of all VCSPs for finite sets of cost functions over finite domains has been classified. Many natural optimisation problems, however, cannot be formulated as VCSPs over a finite domain. We initiate the systematic investigation of the complexity of infinite-domain VCSPs with piecewise linear homogeneous cost functions. Such VCSPs can be solved in polynomial time if the cost functions are improved by fully symmetric fractional operations of all arities. We show this by reducing the problem to a finite-domain VCSP which can be solved using the basic linear program relaxation. It follows that VCSPs for submodular PLH cost functions can be solved in polynomial time; in fact, we show that submodular PLH functions form a maximally tractable class of PLH cost functions. © 2021 Association for Computing Machinery.",linear programming relaxation; piecewise linear functions; rational domain; submodularity; Valued constraint satisfaction,Combinatorial optimization; Computational complexity; Constraint satisfaction problems; Cost functions; Linear programming; Polynomial approximation; Rational functions; Cost-function; Finite domains; Linear programming relaxation; Piece-wise linear functions; Piecewise linear; Piecewise-linear; Rational domain; Submodularity; Valued constraint satisfaction; Valued constraint satisfaction problems; Piecewise linear techniques
Slanted Canonicity of Analytic Inductive Inequalities,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127087843&doi=10.1145%2f3460973&partnerID=40&md5=64927c8259d7698e2e37b961f32b45e4,"We prove an algebraic canonicity theorem for normal LE-logics of arbitrary signature, in a generalized setting in which the non-lattice connectives are interpreted as operations mapping tuples of elements of the given lattice to closed or open elements of its canonical extension. Interestingly, the syntactic shape of LE-inequalities which guarantees their canonicity in this generalized setting turns out to coincide with the syntactic shape of analytic inductive inequalities, which guarantees LE-inequalities to be equivalently captured by analytic structural rules of a proper display calculus. We show that this canonicity result connects and strengthens a number of recent canonicity results in two different areas: subordination algebras, and transfer results via Gödel-McKinsey-Tarski translations.  © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",algorithmic correspondence and canonicity; analytic inductive inequalities; non-distributive lattices; Sahlqvist canonicity; subordination algebras; transfer results via Gödel-McKinsey-Tarski translations,Algebra; Calculations; Algorithmic correspondence and canonicity; Algorithmics; Analytic inductive inequality; Closed elements; Mckinsey; Non-distributive lattice; Open elements; Sahlqvist canonicity; Subordination algebra; Transfer result via godel-mckinsey-tarski translation; Syntactics
Expressiveness and Nash Equilibrium in Iterated Boolean Games,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127375910&doi=10.1145%2f3439900&partnerID=40&md5=b69939b7ebbc3f34e3cf854df510e8d1,"We define and investigate a novel notion of expressiveness for temporal logics that is based on game theoretic equilibria of multi-agent systems. We use iterated Boolean games as our abstract model of multi-agent systems [Gutierrez et al. 2013, 2015a]. In such a game, each agent has a goal , represented using (a fragment of) Linear Temporal Logic (). The goal captures agent 's preferences, in the sense that the models of represent system behaviours that would satisfy . Each player controls a subset of Boolean variables , and at each round in the game, player is at liberty to choose values for variables in any way that she sees fit. Play continues for an infinite sequence of rounds, and so as players act they collectively trace out a model for , which for every player will either satisfy or fail to satisfy their goal. Players are assumed to act strategically, taking into account the goals of other players, in an attempt to bring about computations satisfying their goal. In this setting, we apply the standard game-theoretic concept of (pure) Nash equilibria. The (possibly empty) set of Nash equilibria of an iterated Boolean game can be understood as inducing a set of computations, each computation representing one way the system could evolve if players chose strategies that together constitute a Nash equilibrium. Such a set of equilibrium computations expresses a temporal property - which may or may not be expressible within a particular fragment. The new notion of expressiveness that we formally define and investigate is then as follows: What temporal properties are characterised by the Nash equilibria of games in which agent goals are expressed in specific fragments of ? We formally define and investigate this notion of expressiveness for a range of fragments. For example, a very natural question is the following: Suppose we have an iterated Boolean game in which every goal is represented using a particular fragment of : is it then always the case that the equilibria of the game can be characterised within ?We show that this is not true in general. © 2021 Association for Computing Machinery.",Concurrent games; Expressiveness; Game theory; Logic; Multi-agent systems; Nash equilibrium,Computer circuits; Multi agent systems; Temporal logic; Abstract modeling; Boolean games; Concurrent games; Expressiveness; Game-theoretic; Linear temporal logic; Logic; Nash equilibria; System behaviors; Temporal property; Game theory
The Effects of Adding Reachability Predicates in Quantifier-Free Separation Logic,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122525356&doi=10.1145%2f3448269&partnerID=40&md5=f7236d739216dab87078c8e9b77d397b,"The list segment predicate ls used in separation logic for verifying programs with pointers is well suited to express properties on singly-linked lists. We study the effects of adding ls to the full quantifier-free separation logic with the separating conjunction and implication, which is motivated by the recent design of new fragments in which all these ingredients are used indifferently and verification tools start to handle the magic wand connective. This is a very natural extension that has not been studied so far. We show that the restriction without the separating implication can be solved in polynomial space by using an appropriate abstraction for memory states, whereas the full extension is shown undecidable by reduction from first-order separation logic. Many variants of the logic and fragments are also investigated from the computational point of view when ls is added, providing numerous results about adding reachability predicates to quantifier-free separation logic.  © 2021 Association for Computing Machinery.",complexity; decision problems; quantifier elimination.; reachability; Separation logic,Computer circuits; Separation; Complexity; Decision problems; Natural extension; Property; Quantifier elimination; Quantifier elimination.; Reachability; Separation logic; Singly-linked list; Verification tools; Formal logic
Kripke Semantics for Intersection Formulas,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111083039&doi=10.1145%2f3453481&partnerID=40&md5=3122b9f58e78e7b239ed003eb8fbbd3b,"We propose a notion of the Kripke-style model for intersection logic. Using a game interpretation, we prove soundness and completeness of the proposed semantics. In other words, a formula is provable (a type is inhabited) if and only if it is forced in every model. As a by-product, we obtain another proof of normalization for the Barendregt-Coppo-Dezani intersection type assignment system.  © 2021 Copyright held by the owner/author(s).",games in logic; Intersection types; Kripke models,Computer science; Logic programming; Intersection type assignment systems; Kripke semantics; Kripke-style models; Soundness and completeness; Semantics
Strategic Knowledge Acquisition,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108958895&doi=10.1145%2f3459993&partnerID=40&md5=2c53e0aedc7215402d2628558e31e7c7,The article proposes a trimodal logical system that can express the strategic ability of coalitions to learn from their experience. The main technical result is the completeness of the proposed system. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.,action; axiomatization; completeness; epistemic logic; know-how; Knowledge; strategic game; temporal,Computer science; Logic programming; Logical system; Knowledge acquisition
Display to Labeled Proofs and Back Again for Tense Logics,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108970406&doi=10.1145%2f3460492&partnerID=40&md5=76eda21312299668cb030b82669ad506,"We introduce translations between display calculus proofs and labeled calculus proofs in the context of tense logics. First, we show that every derivation in the display calculus for the minimal tense logic Kt extended with general path axioms can be effectively transformed into a derivation in the corresponding labeled calculus. Concerning the converse translation, we show that for Kt extended with path axioms, every derivation in the corresponding labeled calculus can be put into a special form that is translatable to a derivation in the associated display calculus. A key insight in this converse translation is a canonical representation of display sequents as labeled polytrees. Labeled polytrees, which represent equivalence classes of display sequents modulo display postulates, also shed light on related correspondence results for tense logics. © 2021 Association for Computing Machinery.",display calculus; effective translations; labeled calculus; modal logic; Nested calculus; tense logic,Equivalence classes; Canonical representations; Display calculus; Polytrees; Calculations
Collapsible Pushdown Parity Games,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108943230&doi=10.1145%2f3457214&partnerID=40&md5=3a26696f394629ed88a4abb279c9924c,"This article studies a large class of two-player perfect-information turn-based parity games on infinite graphs, namely, those generated by collapsible pushdown automata. The main motivation for studying these games comes from the connections from collapsible pushdown automata and higher-order recursion schemes, both models being equi-expressive for generating infinite trees. Our main result is to establish the decidability of such games and to provide an effective representation of the winning region as well as of a winning strategy. Thus, the results obtained here provide all necessary tools for an in-depth study of logical properties of trees generated by collapsible pushdown automata/recursion schemes. © 2021 Association for Computing Machinery.",Higher-order (collapsible) pushdown automata; logic; two-player perfect-information trun-based parity games,Automata theory; Forestry; Robots; In-depth study; Infinite graph; Infinite trees; Logical properties; Perfect informations; Push-down automata; Recursion schemes; Winning strategy; Game theory
From 2-Sequents and Linear Nested Sequents to Natural Deduction for Normal Modal Logics,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108968818&doi=10.1145%2f3461661&partnerID=40&md5=cdc2bdbd36820d45229accd724d23b3c,"We extend to natural deduction the approach of Linear Nested Sequents and of 2-Sequents. Formulas are decorated with a spatial coordinate, which allows a formulation of formal systems in the original spirit of natural deduction: only one introduction and one elimination rule per connective, no additional (structural) rule, no explicit reference to the accessibility relation of the intended Kripke models. We give systems for the normal modal logics from K to S4. For the intuitionistic versions of the systems, we define proof reduction, and prove proof normalization, thus obtaining a syntactical proof of consistency. For logics K and K4 we use existence predicates (à la Scott) for formulating sound deduction rules. © 2021 Association for Computing Machinery.",2-sequents; intuitionistic logic; linear nested sequents; Natural deduction; normalization,Computer science; Logic programming; Deduction rule; Elimination rules; Existence predicate; Formal systems; Kripke model; Natural deduction; Nested sequents; Spatial coordinates; Formal logic
Inference from Visible Information and Background Knowledge,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121816611&doi=10.1145%2f3452919&partnerID=40&md5=28b993050ad13042004d19a7eb34aa30,"We provide a wide-ranging study of the scenario where a subset of the relations in a relational vocabulary is visible to a user-that is, their complete contents are known-while the remaining relations are invisible. We also have a background theory-invariants given by logical sentences-that may relate the visible relations to invisible ones, and also may constrain both the visible and invisible relations in isolation. We want to determine whether some other information, given as a positive existential formula, can be inferred using only the visible information and the background theory. This formula whose inference we are concerned with is denoted as the query. We consider whether positive information about the query can be inferred, and also whether negative information-the sentence does not hold-can be inferred. We further consider both the instance-level version of the problem, where both the query and the visible instance are given, and the schema-level version, where we want to know whether truth or falsity of the query can be inferred in some instance of the schema. © 2021 Association for Computing Machinery.",GNF; Query answering,Background knowledge; Background theory; Existential formula; GNF; Negative information; Query answering
Higher-order Recursion Schemes and Collapsible Pushdown Automata: Logical Properties,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122527971&doi=10.1145%2f3452917&partnerID=40&md5=7f7788693439fdaf734b4c1ca8aa328a,"This article studies the logical properties of a very general class of infinite ranked trees, namely, those generated by higher-order recursion schemes. We consider, for both monadic second-order logic and modal -calculus, three main problems: model-checking, logical reflection (a.k.a. global model-checking, that asks for a finite description of the set of elements for which a formula holds), and selection (that asks, if exists, for some finite description of a set of elements for which an MSO formula with a second-order free variable holds). For each of these problems, we provide an effective solution. This is obtained, thanks to a known connection between higher-order recursion schemes and collapsible pushdown automata and on previous work regarding parity games played on transition graphs of collapsible pushdown automata.  © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",higher-order (collapsible) pushdown automata; Higher-order recursion schemes; modalμ-calculus; model-checking; monadic second-order logic; reflection; selection; two-player perfect information parity games,Automata theory; Calculations; Computer circuits; Game theory; High-order; High-order (collapsible) pushdown automaton; High-order recursion scheme; Higher-order; Modalμ-calculus; Models checking; Monadic second-order logic; Parity games; Perfect informations; Push-down automata; Recursion schemes; Selection; Two-player perfect information parity game; Model checking
Reasoning about Petri Nets: A Calculus Based on Resolution and Dynamic Logic,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122511651&doi=10.1145%2f3441655&partnerID=40&md5=842209d398d0bc77b0707442afd5ec6f,"Petri Nets are a widely used formalism to deal with concurrent systems. Dynamic Logics (DLs) are a family of modal logics where each modality corresponds to a program. Petri-PDL is a logical language that combines these two approaches: it is a dynamic logic where programs are replaced by Petri Nets. In this work we present a clausal resolution-based calculus for Petri-PDL. Given a Petri-PDL formula, we show how to obtain its translation into a normal form to which a set of resolution-based inference rules are applied. We show that the resulting calculus is sound, complete, and terminating. Some examples of the application of the method are also given.  © 2021 Association for Computing Machinery.",Modal logic; Petri nets; resolution,Calculations; Computer circuits; Formal logic; Clausal resolutions; Concurrent systems; Dynamic logic; Inference rules; Logical language; Modal logic; Normal form; Resolution; Resolution-based calculi; Petri nets
Small Circuits and Dual Weak PHP in the Universal Theory of p-time Algorithms,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122629441&doi=10.1145%2f3446207&partnerID=40&md5=12929cd0267c6362fd568340f0e6dc01,"We prove, under a computational complexity hypothesis, that it is consistent with the true universal theory of p-time algorithms that a specific p-time function extending bits to bits violates the dual weak pigeonhole principle: Every string equals the value of the function for some . The function is the truth-table function assigning to a circuit the table of the function it computes and the hypothesis is that every language in P has circuits of a fixed polynomial size.  © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Boolean circuits; Formal theories; Pigeonhole principle,Logic circuits; Boolean circuit; Formal theory; Pigeonhole principle; Polynomial size; Smallest circuits; Table functions; Time algorithms; Time function; Truth tables; Universal theory; Timing circuits
Action Logic is Undecidable,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102371641&doi=10.1145%2f3445810&partnerID=40&md5=5ee8bf5d1862a18abe66e976f838eabf,"Action logic is the algebraic logic (inequational theory) of residuated Kleene lattices. One of the operations of this logic is the Kleene star, which is axiomatized by an induction scheme. For a stronger system that uses an -rule instead (infinitary action logic), Buszkowski and Palka (2007) proved -completeness (thus, undecidability). Decidability of action logic itself was an open question, raised by Kozen in 1994. In this article, we show that it is undecidable, more precisely, -complete. We also prove the same undecidability results for all recursively enumerable logics between action logic and infinitary action logic, for fragments of these logics with only one of the two lattice (additive) connectives, and for action logic extended with the law of distributivity.  © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",action logic; algorithmic complexity; Residuated Kleene lattices; undecidability,Computer circuits; Formal logic; Lattice theory; Parallel processing systems; Action logic; Additive connectives; Algebraic logic; Algorithmic complexity; Distributivity; Infinitary; Kleene star; Residuated; Residuated kleene lattice; Undecidability; Computational complexity
Complete Abstractions for Checking Language Inclusion,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115306241&doi=10.1145%2f3462673&partnerID=40&md5=7b865bef3bc31629a3f0c1e819f1afd8,"We study the language inclusion problem L1? L2, where L1 is regular or context-free. Our approach relies on abstract interpretation and checks whether an overapproximating abstraction of L1, obtained by approximating the Kleene iterates of its least fixpoint characterization, is included in L2. We show that a language inclusion problem is decidable whenever this overapproximating abstraction satisfies a completeness condition (i.e., its loss of precision causes no false alarm) and prevents infinite ascending chains (i.e., it guarantees termination of least fixpoint computations). This overapproximating abstraction of languages can be defined using quasiorder relations on words, where the abstraction gives the language of all the words ""greater than or equal to"" a given input word for that quasiorder.We put forward a range of such quasiorders that allow us to systematically design decision procedures for different language inclusion problems, such as regular languages into regular languages or into trace sets of one-counter nets, and context-free languages into regular languages. In the case of inclusion between regular languages, some of the induced inclusion checking procedures correspond to well-known state-of-The-Art algorithms, like the so-called antichain algorithms. Finally, we provide an equivalent language inclusion checking algorithm based on a greatest fixpoint computation that relies on quotients of languages and, to the best of our knowledge, was not previously known. © 2022 American Institute of Physics Inc.. All rights reserved.","Abstract interpretation; Automaton, Grammar; Completeness; Context-Free Language; Language Inclusion; One-Counter Net; Regular Language","Computability and decidability; Context free languages; Model checking; Abstract interpretations; Automaton, grammar; Completeness; Context-free; Context-free languages; Fixpoint computations; Fixpoints; Language inclusion; Language inclusion problems; One-counter net; Abstracting"
Alternating Tree Automata with Qualitative Semantics,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100081265&doi=10.1145%2f3431860&partnerID=40&md5=6402f0a3af54c9b7827d61b1e79366c0,"We study alternating automata with qualitative semantics over infinite binary trees: Alternation means that two opposing players construct a decoration of the input tree called a run, and the qualitative semantics says that a run of the automaton is accepting if almost all branches of the run are accepting. In this article, we prove a positive and a negative result for the emptiness problem of alternating automata with qualitative semantics. The positive result is the decidability of the emptiness problem for the case of Büchi acceptance condition. An interesting aspect of our approach is that we do not extend the classical solution for solving the emptiness problem of alternating automata, which first constructs an equivalent non-deterministic automaton. Instead, we directly construct an emptiness game making use of imperfect information. The negative result is the undecidability of the emptiness problem for the case of co-Büchi acceptance condition. This result has two direct consequences: The undecidability of monadic second-order logic extended with the qualitative path-measure quantifier and the undecidability of the emptiness problem for alternating tree automata with non-zero semantics, a recently introduced probabilistic model of alternating tree automata. © 2020 ACM.",almost-sure semantics; Tree automata; ω-regular conditions,Automata theory; Binary trees; Semantics; Acceptance conditions; Alternating automata; Alternating tree automaton; Classical solutions; Imperfect information; Monadic second-order logic; Nondeterministic automata; Probabilistic modeling; Robots
Stratification in Approximation Fixpoint Theory and Its Application to Active Integrity Constraints,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100092830&doi=10.1145%2f3430750&partnerID=40&md5=2295ba78ae50226183d2516f241e5ed9,"Approximation fixpoint theory (AFT) is an algebraic study of fixpoints of lattice operators that unifies various knowledge representation formalisms. In AFT, stratification of operators has been studied, essentially resulting in a theory that specifies when certain types of fixpoints can be computed stratum per stratum. Recently, novel types of fixpoints related to groundedness have been introduced in AFT. In this article, we study how those fixpoints behave under stratified operators. One recent application domain of AFT is the field of active integrity constraints (AICs). We apply our extended stratification theory to AICs and find that existing notions of stratification in AICs are covered by this general algebraic definition of stratification. As a result, we obtain stratification results for a large variety of semantics for AICs. © 2021 ACM.",Active integrity constraints; fixpoints; semantics,Algebra; Knowledge representation; Semantics; Fixpoints; Integrity constraints; ITS applications; Knowledge representation formalism; Lattice operators; Stratification theory; Lattice theory
Decidability of a Sound Set of Inference Rules for Computational Indistinguishability,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100111637&doi=10.1145%2f3423169&partnerID=40&md5=a6c2d061188862adfee3ab8d72bc3c55,"Computational indistinguishability is a key property in cryptography and verification of security protocols. Current tools for proving it rely on cryptographic game transformations. We follow Bana and Comon's approach [7, 8], axiomatizing what an adversary cannot distinguish. We prove the decidability of a set of first-order axioms that are computationally sound, though incomplete, for protocols with a bounded number of sessions whose security is based on an IND-CCA2 encryption scheme. Alternatively, our result can be viewed as the decidability of a family of cryptographic game transformations. Our proof relies on term rewriting and automated deduction techniques. © 2021 ACM.",automated deduction; computational indistinguishability; decision procedure; Security protocols,Computability and decidability; Network security; Automated deduction; Axiomatizing; Encryption schemes; First order; Indistinguishability; Inference rules; Security protocols; Term rewriting; Cryptography
Principles of KLM-style Defeasible Description Logics,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100110834&doi=10.1145%2f3420258&partnerID=40&md5=bc277eba097768810b59fca136db1781,"The past 25 years have seen many attempts to introduce defeasible-reasoning capabilities into a description logic setting. Many, if not most, of these attempts are based on preferential extensions of description logics, with a significant number of these, in turn, following the so-called KLM approach to defeasible reasoning initially advocated for propositional logic by Kraus, Lehmann, and Magidor. Each of these attempts has its own aim of investigating particular constructions and variants of the (KLM-style) preferential approach. Here our aim is to provide a comprehensive study of the formal foundations of preferential defeasible reasoning for description logics in the KLM tradition. We start by investigating a notion of defeasible subsumption in the spirit of defeasible conditionals as studied by Kraus, Lehmann, and Magidor in the propositional case. In particular, we consider a natural and intuitive semantics for defeasible subsumption, and we investigate KLM-style syntactic properties for both preferential and rational subsumption. Our contribution includes two representation results linking our semantic constructions to the set of preferential and rational properties considered. Besides showing that our semantics is appropriate, these results pave the way for more effective decision procedures for defeasible reasoning in description logics. Indeed, we also analyse the problem of non-monotonic reasoning in description logics at the level of entailment and present an algorithm for the computation of rational closure of a defeasible knowledge base. Importantly, our algorithm relies completely on classical entailment and shows that the computational complexity of reasoning over defeasible knowledge bases is no worse than that of reasoning in the underlying classical DL ALC. © 2020 ACM.",defeasible subsumption; Non-monotonic reasoning; preferential semantics; rational closure,Computer circuits; Formal languages; Formal logic; Knowledge based systems; Semantics; Syntactics; Decision procedure; Defeasible reasoning; Description logic; Formal foundation; Knowledge basis; Non-monotonic reasoning; Propositional logic; Syntactic properties; Data description
Strategy Logic with Imperfect Information,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100076186&doi=10.1145%2f3427955&partnerID=40&md5=f474af0d2d16e694a591c5063b52819f,"We introduce an extension of Strategy Logic for the imperfect-information setting, called SLii and study its model-checking problem. As this logic naturally captures multi-player games with imperfect information, this problem is undecidable; but we introduce a syntactical class of ""hierarchical instances""for which, intuitively, as one goes down the syntactic tree of the formula, strategy quantifications are concerned with finer observations of the model, and we prove that model-checking SLii restricted to hierarchical instances is decidable. This result, because it allows for complex patterns of existential and universal quantification on strategies, greatly generalises the decidability of distributed synthesis for systems with hierarchical information. It allows us to easily derive new decidability results concerning strategic problems under imperfect information such as the existence of Nash equilibria or rational synthesis. To establish this result, we go through an intermediary, ""low-level""logic much more adapted to automata techniques. QCTL∗ is an extension of CTL∗ with second-order quantification over atomic propositions that has been used to study strategic logics with perfect information. We extend it to the imperfect information setting by parameterising second-order quantifiers with observations. The simple syntax of the resulting logic, QCTL∗ii, allows us to provide a conceptually neat reduction of SLii to QCTL∗ii that separates concerns, allowing one to forget about strategies and players and focus solely on second-order quantification. While the model-checking problem of QCTL∗ii is, in general, undecidable, we identify a syntactic fragment of hierarchical formulas and prove, using an automata-theoretic approach, that it is decidable. © 2021 ACM.",distributed synthesis; hierarchical information; imperfect information; Nash equilibria; perfect recall; rational synthesis; Strategic reasoning,Automata theory; Computability and decidability; Computer circuits; Hierarchical systems; Robots; Syntactics; Atomic propositions; Automata-theoretic approach; Hierarchical information; Imperfect information; Model checking problem; Multiplayer games; Perfect informations; Rational synthesis; Model checking
Beyond Uniform Equivalence between Answer-set Programs,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100118988&doi=10.1145%2f3422361&partnerID=40&md5=74c2d2c76e9813560f0b40c7c60798cd,"This article deals with advanced notions of equivalence between nonmonotonic logic programs under the answer-set semantics, a topic of considerable interest, because such notions form the basis for program verification and are useful for program optimisation, debugging, and modular programming. In fact, there is extensive research in answer-set programming (ASP) dealing with different notions of equivalence between programs. Prominent among these notions is uniform equivalence, which checks whether two programs have the same semantics when joined with an arbitrary set of facts. In this article, we study a family of more fine-grained versions of uniform equivalence, viz. relativised uniform equivalence with projection, which extends standard uniform equivalence in terms of two additional parameters: One for specifying the input alphabet and one for specifying the output alphabet for programs. In particular, the second parameter is used for projecting answer sets to a set of designated output atoms. Answer-set projection, in particular, allows to compare programs that make use of different auxiliary atoms, which is important for practical programming aspects. We introduce novel semantic characterisations for the program correspondence problems under consideration and analyse their computational complexity. In the general case, deciding these problems lies on the third level of the polynomial hierarchy. Therefore, this task cannot be efficiently reduced to propositional answer-set programs itself (under the usual complexity-theoretic assumptions). However, reductions to quantified Boolean formulas (QBFs) are feasible. Indeed, we provide efficient (in fact, linear-time constructible) reductions to QBFs and discuss simplifications for certain special cases. These QBF reductions yield the basis for a prototype implementation, the system cc ĝŠCurrency sign, for deciding correspondence problems by using off-the-shelf QBF solvers. We discuss an application of cc ĝŠCurrency sign for verifying the correctness of solutions by students drawn from a laboratory course on logic programming and knowledge representation at the Technische Universität Wien, employing relativised uniform equivalence with projection as the underlying program correspondence notion. © 2020 ACM.",Answer-set programming; disjunctive logic programs; nonmonotonic reasoning; program equivalence; quantified Boolean logic,Application programs; Boolean functions; Computer circuits; Equivalence classes; Input output programs; Knowledge representation; Logic programming; Semantics; Temporal logic; Answer set programming; Answer set semantics; Correspondence problems; Nonmonotonic logic programs; Polynomial hierarchies; Program Verification; Prototype implementations; Quantified Boolean formulas; Program debugging
α β-Relations and the Actual Meaning of α-Renaming,2021,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100097828&doi=10.1145%2f3426471&partnerID=40&md5=a9c1d505ec47d0efe0317a792719f728,"In this work we provide an alternative, and equivalent, formulation of the concept of λ-theory without introducing the notion of substitution and the sets of all, free and bound variables occurring in a term. We call α β-relations our alternative versions of λ-theories. We also clarify the actual role of α-renaming in the lambda calculus: It expresses a property of extensionality for a certain class of terms. To motivate the necessity of α-renaming, we construct an unusual denotational model of the lambda calculus that validates all structural and beta conditions but not α-renaming. The article also has a survey character. © 2021 ACM.",extensionality; lambda calculus; Languages with binding operators; models of languages with binding operators; substitution; α-renaming; λ-theory,Calculations; Alpha-beta; Bound variables; Denotational models; Extensionality; Lambda calculus; Differentiation (calculus)
First-Order Interpretations of Bounded Expansion Classes,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095282894&doi=10.1145%2f3382093&partnerID=40&md5=83f75820004cf740ed971283f5b452dd,"The notion of bounded expansion captures uniform sparsity of graph classes and renders various algorithmic problems that are hard in general tractable. In particular, the model-checking problem for first-order logic is fixed-parameter tractable over such graph classes. With the aim of generalizing such results to dense graphs, we introduce classes of graphs with structurally bounded expansion, defined as first-order transductions of classes of bounded expansion. As a first step towards their algorithmic treatment, we provide their characterization analogous to the characterization of classes of bounded expansion via low treedepth covers (or colorings), replacing treedepth by its dense analogue called shrubdepth.  © 2020 ACM.",bounded expansion; first-order logic; logical interpretations; model-checking; Sparse graph classes,Forestry; Model checking; Algorithmic problems; Dense graphs; First order; First order logic; Graph class; Model checking problem; Tree-depth; Expansion
Applying Visible Strong Equivalence in Answer-Set Program Transformations,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096550790&doi=10.1145%2f3412854&partnerID=40&md5=72b03c8306017a2ab050e9c3e36c5af9,"Strong equivalence is one of the basic notions of equivalence that have been proposed for logic programs subject to the answer-set semantics. In this article, we propose a new generalization of strong equivalence (SE) that takes the visibility of atoms into account and we characterize it in terms of appropriately revised SE-models. Our design resembles (relativized) strong equivalence but is substantially different due to adopting a strict one-To-one correspondence of models from the notion of visible equivalence. We additionally tailor the characterization for more convenient use with positive programs and provide formal tools to exploit the tailored version also in the case of some programs that use negation. We illustrate the use of visible strong equivalence and the characterizations in showing the correctness of program transformations that make use of atom visibility. Moreover, we present a translation that enables us to automate the task of verifying visible strong equivalence for particular fragments of answer-set programs. We experimentally study the efficiency of verification when the goal is to check whether an extended rule is visibly strongly equivalent to its normalization, i.e., a subprogram expressing the original rule in terms of normal rules only. In the process, we verify the outputs of several real implementations of normalization schemes on a considerable number of input rules.  © 2020 Owner/Author.",auxiliary atoms; hidden atoms; normalization; program transformations; Stable models; strong equivalence,Logic programming; Program translators; Semantics; Visibility; Answer set; Answer set semantics; Formal tools; Logic programs; Program transformations; Equivalence classes
A New Perspective on FO Model Checking of Dense Graph Classes,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096593679&doi=10.1145%2f3383206&partnerID=40&md5=01695218af2d42229e3ac0857b6a4ff6,"We study the first-order (FO) model checking problem of dense graph classes, namely, those that have FO interpretations in (or are FO transductions of) some sparse graph classes. We give a structural characterization of the graph classes that are FO interpretable in graphs of bounded degree. This characterization allows us to efficiently compute such an FO interpretation for an input graph. As a consequence, we obtain an FPT algorithm for successor-invariant FO model checking on any graph class that is FO interpretable in (or an FO transduction of) a graph class of bounded degree. The approach we use to obtain these results may also be of independent interest.  © 2020 ACM.",algorithmic metatheorems; bounded degree graphs; First-order logic; fixed parameter tractability; interpretations,Bacteriophages; Graph algorithms; Bounded degree; Dense graphs; First order; FPT algorithms; Input graphs; Model checking problem; Sparse graphs; Structural characterization; Model checking
Undecidable Cases of Model Checking Probabilistic Temporal-Epistemic Logic,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096527626&doi=10.1145%2f3409250&partnerID=40&md5=ce4056385eb3f5620e618032d6e299e7,"We investigate the decidability of model checking logics of time, knowledge, and probability, with respect to two epistemic semantics: The clock and synchronous perfect recall semantics in partially observable discrete-Time Markov chains. Decidability results are known for certain restricted logics with respect to these semantics, subject to a variety of restrictions that are either unexplained or involve a longstanding unsolved mathematical problem. We show that mild generalizations of the known decidable cases suffice to render the model checking problem definitively undecidable. In particular, for the synchronous perfect recall semantics, a generalization from temporal operators with finite reach to operators with infinite reach renders model checking undecidable. The case of the clock semantics is closely related to a monadic second-order logic of time and probability that is known to be decidable, except on a set of measure zero. We show that two distinct extensions of this logic make model checking undecidable. One of these involves polynomial combinations of probability terms, the other involves monadic second-order quantification into the scope of probability operators. These results explain some of the restrictions in previous work.  © 2020 ACM.",decidability; Logic of knowledge; logic of probability; model checking; partially observable Markov chains,Clocks; Computability and decidability; Computer circuits; Markov chains; Semantics; Discrete time Markov chains; Mathematical problems; Model checking problem; Monadic second-order logic; Perfect recalls; Probability operators; Temporal epistemic logic; Temporal operators; Model checking
Finite Open-world Query Answering with Number Restrictions,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096587969&doi=10.1145%2f3365834&partnerID=40&md5=0b6bd4464860ce50135b819a2d72aec1,"Open-world query answering is the problem of deciding, given a set of facts, conjunction of constraints, and query, whether the facts and constraints imply the query. This amounts to reasoning over all instances that include the facts and satisfy the constraints. We study finite open-world query answering (FQA), which assumes that the underlying world is finite and thus only considers the finite completions of the instance. The major known decidable cases of FQA derive from the following: The guarded fragment of first-order logic, which can express referential constraints (data in one place points to data in another) but cannot express number restrictions such as functional dependencies; and the guarded fragment with number restrictions but on a signature of arity only two. In this article, we give the first decidability results for FQA that combine both referential constraints and number restrictions for arbitrary signatures: We show that, for unary inclusion dependencies and functional dependencies, the finiteness assumption of FQA can be lifted up to taking the finite implication closure of the dependencies. Our result relies on new techniques to construct finite universal models of such constraints for any bound on the maximal query size.  © 2020 ACM.",chase; FDs; Finite controllability; UIDs,Computability and decidability; First order logic; Functional dependency; Guarded fragment; Inclusion dependencies; Number restrictions; Open world; Query answering; Universal model; Query processing
Model Checking a Logic for True Concurrency,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096626027&doi=10.1145%2f3412853&partnerID=40&md5=136f578399399f7d6cb480b3bada12bf,"We study the model-checking problem for a logic for true concurrency, whose formulae predicate about events in computations and their causal dependencies. The logic, which represents the logical counterpart of history-preserving bisimilarity, is naturally interpreted over event structures or any formalism that can be given a causal semantics, like Petri nets. It includes least and greatest fixpoint operators and thus it can express properties of infinite computations. Since the event structure associated with a system is typically infinite (even if the system is finite state), already the decidability of model-checking is non-Trivial. We first develop a local model-checking technique based on a tableau system, for which, over a class of event structures satisfying a suitable regularity condition, referred to as strong regularity, we prove termination, soundness, and completeness. The tableau system allows for a clean and intuitive proof of decidability, but a direct implementation of the procedure can be extremely inefficient. For easing the development of a more efficient model-checking technique, we move to an automata-Theoretic framework. Given a formula and a strongly regular event structure, we show how to construct a parity tree automaton whose language is non-empty if and only if the event structure satisfies the formula. The automaton is usually infinite. We discuss how it can be quotiented to an equivalent finite automaton, where emptiness can be checked effectively. To show the applicability of the approach, we discuss how it instantiates to finite safe Petri nets, providing also a corresponding proof-of-concept model-checking tool.  © 2020 ACM.",event structures; model checking; Petri nets; tableaux; tree automata; True concurrency,Computability and decidability; Computer circuits; Petri nets; Robots; Semantics; Causal dependencies; History-preserving bisimilarity; Local model checking; Model checking problem; Model-checking techniques; Parity tree automata; Regularity condition; Strong regularities; Model checking
Metric Temporal Description Logics with Interval-Rigid Names,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096521308&doi=10.1145%2f3399443&partnerID=40&md5=6c72dd2b0d96b51f70fbd0e001a62d99,"In contrast to qualitative linear temporal logics, which can be used to state that some property will eventually be satisfied, metric temporal logics allow us to formulate constraints on how long it may take until the property is satisfied. While most of the work on combining description logics (DLs) with temporal logics has concentrated on qualitative temporal logics, there is a growing interest in extending this work to the quantitative case. In this article, we complement existing results on the combination of DLs with metric temporal logics by introducing interval-rigid concept and role names. Elements included in an interval-rigid concept or role name are required to stay in it for some specified amount of time. We investigate several combinations of (metric) temporal logics with Aĝ.,'C by either allowing temporal operators only on the level of axioms or also applying them to concepts. In contrast to most existing work on the topic, we consider a timeline based on the integers and also allow assertional axioms. We show that the worst-case complexity does not increase beyond the previously known bound of 2-ExpSpace and investigate in detail how this complexity can be reduced by restricting the temporal logic and the occurrences of interval-rigid names.  © 2020 ACM.",interval-rigid names; metric temporal logics; Temporal description logics,Data description; Formal languages; Description logic; Linear temporal logic; Metric temporal logic; Temporal operators; Timeline-based; Worst-case complexity; Temporal logic
Non-well-founded Proof Theory of Transitive Closure Logic,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088234399&doi=10.1145%2f3404889&partnerID=40&md5=63156344f3200945cc9bd0e7a6323e03,"Supporting inductive reasoning is an essential component is any framework of use in computer science. To do so, the logical framework must extend that of first-order logic. Transitive closure logic is a known extension of first-order logic that is particularly straightforward to automate. While other extensions of first-order logic with inductive definitions are a priori parametrized by a set of inductive definitions, the addition of a single transitive closure operator has the advantage of uniformly capturing all finitary inductive definitions. To further improve the reasoning techniques for transitive closure logic, we here present an infinitary proof system for it, which is an infinite descent-style counterpart to the existing (explicit induction) proof system for the logic. We show that the infinitary system is complete for the standard semantics and subsumes the explicit system. Moreover, the uniformity of the transitive closure operator allows semantically meaningful complete restrictions to be defined using simple syntactic criteria. Consequently, the restriction to regular infinitary (i.e., cyclic) proofs provides the basis for an effective system for automating inductive reasoning.  © 2020 ACM.",completeness; cyclic proof systems; Henkin semantics; Induction; infinitary proof systems; soundness; standard semantics; transitive closure,Formal logic; Semantics; Extensions of first-order logic; Inductive definitions; Inductive reasoning; Infinitary proof system; Logical frameworks; Reasoning techniques; Syntactic criteria; Transitive closure; Computer circuits
"Why Liveness for Timed Automata Is Hard, and What We Can Do about It",2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085576711&doi=10.1145%2f3372310&partnerID=40&md5=ea263960c0a8ce4e9e15b8c1df75fe4a,"The reachability problem for timed automata asks if a given automaton has a run leading to an accepting state, and the liveness problem asks if the automaton has an infinite run that visits accepting states infinitely often. Both of these problems are known to be Pspace-complete. We show that if P ≠Pspace, the liveness problem is more difficult than the reachability problem; in other words, we exhibit a family of automata for which solving the reachability problem with the standard algorithm is in P but solving the liveness problem is Pspace-hard. This leads us to revisit the algorithmics for the liveness problem. We propose a notion of a witness for the fact that a timed automaton violates a liveness property. We give an algorithm for computing such a witness and compare it to existing solutions. © 2020 ACM.",algorithms; complexity; liveness verification; Timed automata,Computer science; Logic programming; Algorithmics; Liveness; Liveness properties; PSPACE-complete; Reachability problem; Standard algorithms; Timed Automata; Automata theory
Toward a Uniform Theory of Effectful State Machines,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085557535&doi=10.1145%2f3372880&partnerID=40&md5=9f95164b295307e2196a246ddb4b546d,"Using recent developments in coalgebraic and monad-based semantics, we present a uniform study of various notions of machines, e.g., finite state machines, multi-stack machines, Turing machines, valence automata, and weighted automata. They are instances of Jacobs's notion of a T-automaton, where T is a monad. We show that the generic language semantics for T-automata correctly instantiates the usual language semantics for a number of known classes of machines/languages, including regular, context-free, recursively-enumerable, and various subclasses of context free languages (e.g., deterministic and real-time ones). Moreover, our approach provides new generic techniques for studying the expressivity power of various machine-based models. © 2020 ACM.",bialgebraic semantics; coalgebras; Kleene theorem; Monads; side-effects,Semantics; Turing machines; Coalgebraic; Context-free; Language semantics; Real time; Stack machines; State machine; Weighted automata; Context free languages
Typal Heterogeneous Equality Types,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085566872&doi=10.1145%2f3379447&partnerID=40&md5=8af9bdbe414d0dea74fef637641861e5,"The usual homogeneous form of equality type in Martin-Löf Type Theory contains identifications between elements of the same type. By contrast, the heterogeneous form of equality contains identifications between elements of possibly different types. This short note introduces a simple set of axioms for such types. The axioms are shown to be equivalent to the combination of systematic elimination rules for both forms of equality, albeit with typal (also known as ""propositional"") computation properties, together with Streicher's Axiom K, or equivalently, the principle of uniqueness of identity proofs. © 2020 ACM.",equality types; heterogeneous equality; Type theory,Computer science; Logic programming; Computation properties; Elimination rules; Homogeneous forms; Type theory; Computation theory
Dichotomies in Ontology-Mediated Querying with the Guarded Fragment,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085585017&doi=10.1145%2f3375628&partnerID=40&md5=7073e89df5174889f855e6d62eab03e4,"We study ontology-mediated querying in the case where ontologies are formulated in the guarded fragment of first-order logic (GF) or extensions thereof with counting and where the actual queries are (unions of) conjunctive queries. Our aim is to classify the data complexity and Datalog rewritability of query evaluation depending on the ontology O, where query evaluation w.r.t. O is in PTime (resp. Datalog rewritable) if all queries can be evaluated in PTime w.r.t. O (resp. rewritten into Datalog under O), and coNP-hard if at least one query is coNP-hard w.r.t. O. We identify several fragments of GF that enjoy a dichotomy between Datalog-rewritability (which implies PTime) and coNP-hardness as well as several other fragments that enjoy a dichotomy between PTime and coNP-hardness, but for which PTime does not imply Datalog-rewritability. For the latter, we establish and exploit a connection to constraint satisfaction problems. We also identify fragments for which there is no dichotomy between PTime and coNP. To prove this, we establish a non-trivial variation of Ladner's theorem on the existence of NP-intermediate problems. Finally, we study the decidability of whether a given ontology enjoys PTime query evaluation, presenting both positive and negative results, depending on the fragment. © 2020 ACM.",dichotomies; Ontology-based data access; query evaluation,Constraint satisfaction problems; Formal logic; Hardness; Co-np hardness; Conjunctive queries; Data complexity; First order logic; Guarded fragment; Ladner's theorems; Non-trivial; Query evaluation; Ontology
Inputs and Outputs in CSP: A Model and a Testing Theory,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085544673&doi=10.1145%2f3379508&partnerID=40&md5=0e1f5ae1a78e8f3e6c6f05a79ea513b6,"This article addresses refinement and testing based on CSP models, when we distinguish input and output events. In a testing experiment, the tester (or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP, however, do not differentiate inputs and outputs and are not, therefore, entirely suitable for testing. Here, we consider an alphabet of events partitioned into inputs and outputs, and we present a novel refusal-testing model for CSP with a notion of input-output refusal-traces refinement. We compare that with the ioco relation often used in testing, and we find that it is more widely applicable and stronger. This means that mistakes found using traditional ioco testing do indicate mistakes in the development. Finally, we provide a CSP testing theory that takes into account inputs and outputs. With our theory, it becomes feasible to develop techniques and tools for automatic generation of realistic and sound tests from CSP models. Our work reconciles the normally disparate areas of refinement and (formal) testing by identifying how ioco testing can be used to inform refinement-based results and vice-versa. © 2020 ACM.",Exhaustive test set; process algebra; refinement; refusal-testing model,Logic programming; Automatic Generation; Input and outputs; Input-output; System under test; Techniques and tools; Testing modeling; Testing theories; The standard model; Computer science
How Good Is a Strategy in a Game with Nature?,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085545923&doi=10.1145%2f3377137&partnerID=40&md5=c71af489a34f781021e2f8c24876f7cb,"We consider games with two antagonistic players - Éloïse (modelling a program) and Abélard (modelling a Byzantine environment) - and a third, unpredictable and uncontrollable player, which we call Nature. Motivated by the fact that the usual probabilistic semantics very quickly leads to undecidability when considering either infinite game graphs or imperfect-information, we propose two alternative semantics that lead to decidability where the probabilistic one fails: one based on counting and one based on topology. © 2020 ACM.",cardinality constraints; large sets of branches; Qualitative study of games; tree automata,Topology; Alternative Semantics; Imperfect information; Infinite game; Probabilistic semantics; Undecidability; Semantics
Duality between Unprovability and Provability in Forward Refutation-search for Intuitionistic Propositional Logic,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085568454&doi=10.1145%2f3372299&partnerID=40&md5=4b59c0301c525ea4855f41806889fb3a,"The inverse method is a saturation-based theorem-proving technique; it relies on a forward proof-search strategy and can be applied to cut-free calculi enjoying the subformula property. Here, we apply this method to derive the unprovability of a goal formula G in Intuitionistic Propositional Logic. To this aim we design a forward calculus FRJ(G) for Intuitionistic unprovability, which is appropriate for constructively ascertaining the unprovability of a formula G by providing a concise countermodel for it; in particular, we prove that the generated countermodels have minimal height. Moreover, we clarify the role of the saturated database obtained as result of a failed proof-search in FRJ(G) by showing how to extract from such a database a derivation witnessing the Intuitionistic validity of the goal. © 2020 ACM.",intuitionistic propositional logic; Proof-search procedures; sequent calculi,Biomineralization; Calculations; Computer circuits; Inverse problems; Counter-models; Intuitionistic propositional logic; Inverse methods; Proof search; Unprovability; Formal logic
Model Checking MITL Formulae on Timed Automata: A Logic-based Approach,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085543533&doi=10.1145%2f3383687&partnerID=40&md5=7f769d3059c5a8c75f9e4608dbfff391,"Timed Automata (TA) is de facto a standard modelling formalism to represent systems when the interest is the analysis of their behaviour as time progresses. This modelling formalism is mostly used for checking whether the behaviours of a system satisfy a set of properties of interest. Even if efficient model-checkers for Timed Automata exist, these tools are not easily configurable. First, they are not designed to easily allow adding new Timed Automata constructs, such as new synchronization mechanisms or communication procedures, but they assume a fixed set of Timed Automata constructs. Second, they usually do not support the Metric Interval Temporal Logic (MITL) and rely on a precise semantics for the logic in which the property of interest is specified, which cannot be easily modified and customized. Finally, they do not easily allow using different solvers that may speed up verification in different contexts. This article presents a novel technique to perform model checking of Metric Interval Temporal Logic (MITL) properties on TA. The technique relies on the translation of both the TA and the MITL formula into an intermediate Constraint LTL over clocks (CLTLoc) formula, which is verified through an available decision procedure. The technique is flexible, since the intermediate logic allows the encoding of new semantics as well as new TA constructs, by just adding new CLTLoc formulae. Furthermore, our technique is not bound to a specific solver as the intermediate CLTLoc formula can be verified using different procedures. © 2020 ACM.",Model checking; signal-based semantics; timed automata,Automata theory; Computer circuits; Semantics; Temporal logic; Decision procedure; Intermediate logic; Interval temporal logic; Logic-based approach; Novel techniques; Synchronization mechanisms; Time progress; Timed Automata; Model checking
The Bernays-Schönfinkel-Ramsey Class of Separation Logic with Uninterpreted Predicates,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085575926&doi=10.1145%2f3380809&partnerID=40&md5=ddfafe740ca337db9b6edb1ca3453a9a,"This article investigates the satisfiability problem for Separation Logic with k record fields, with unrestricted nesting of separating conjunctions and implications. It focuses on prenex formulæ with a quantifier prefix in the language ĝ&circ;f∗ĝ&circ;€∗that contain uninterpreted (heap-independent) predicate symbols. In analogy with first-order logic, we call this fragment Bernays-Schönfinkel-Ramsey Separation Logic [BSR(SLk)]. In contrast with existing work on Separation Logic, in which the universe of possible locations is assumed to be infinite, we consider both finite and infinite universes in the present article. We show that, unlike in first-order logic, the (in)finite satisfiability problem is undecidable for BSR(SLk). Then we define two non-trivial subsets thereof, for which the finite and infinite satisfiability problems are PSPACE-complete, respectively, assuming that the maximum arity of the uninterpreted predicate symbols does not depend on the input. These fragments are defined by controlling the polarity of the occurrences of separating implications, as well as the occurrences of universally quantified variables within their scope. These decidability results have natural applications in program verification, as they allow to automatically prove lemmas that occur in, e.g., entailment checking between inductively defined predicates and validity checking of Hoare triples expressing partial correctness conditions. © 2020 ACM.",Bernays-Schönfinkel-Ramsey class; complexity; decision procedures; PSPACE-completeness; Separation logic,Application programs; Formal logic; Separation; Finite satisfiability; First order logic; Infinite universe; Partial correctness; Program Verification; PSPACE-complete; Satisfiability problems; Separation logic; Computer circuits
Linking Focusing and Resolution with Selection,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085545323&doi=10.1145%2f3373276&partnerID=40&md5=50581c8fdd935318f1d0c981287fa8ad,"Focusing and selection are techniques that shrink the proof-search space for respectively sequent calculi and resolution. To bring out a link between them, we generalize them both: we introduce a sequent calculus where each occurrence of an atomic formula can have a positive or a negative polarity; and a resolution method where each literal, whatever its sign, can be selected in input clauses. We prove the equivalence between cut-free proofs in this sequent calculus and derivations of the empty clause in that resolution method. Such a generalization is not semi-complete in general, which allows us to consider complete instances that correspond to theories of any logical strength. We present three complete instances: first, our framework allows us to show that ordinary focusing corresponds to hyperresolution and semantic resolution; the second instance is deduction modulo theory and the related framework called superdeduction; and a new setting, not captured by any existing framework, extends deduction modulo theory with rewriting rules having several left-hand sides, which restricts even more the proof-search space. © 2020 ACM.",deduction modulo theory; polarization; refinements of resolution; Sequent calculus,Biomineralization; Calculations; Differentiation (calculus); Semantics; Atomic formulae; Deduction modulo; Hyper-resolution; Negative polarity; Proof search; Resolution methods; Rewriting rules; Sequent calculus; Focusing
Model-Checking on Ordered Structures,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082390001&doi=10.1145%2f3360011&partnerID=40&md5=cb1990c0d8c3d00ab46e44b95fecf7cb,"We study the model-checking problem for first-and monadic second-order logic on finite relational structures. The problem of verifying whether a formula of these logics is true on a given structure is considered intractable in general, but it does become tractable on interesting classes of structures, such as on classes whose Gaifman graphs have bounded treewidth. In this article, we continue this line of research and study model-checking for first-and monadic second-order logic in the presence of an ordering on the input structure. We do so in two settings: the general ordered case, where the input structures are equipped with a fixed order or successor relation, and the order-invariant case, where the formulas may resort to an ordering, but their truth must be independent of the particular choice of order. In the first setting we show very strong intractability results for most interesting classes of structures. In contrast, in the order-invariant case we obtain tractability results for order-invariant monadic second-order formulas on the same classes of graphs as in the unordered case. For first-order logic, we obtain tractability of successor-invariant formulas on classes whose Gaifman graphs have bounded expansion. Furthermore, we show that model-checking for order-invariant first-order formulas is tractable on coloured posets of bounded width. © 2020 Association for Computing Machinery.",algorithmic meta-theorems; Model checking; order-invariance; successor-invariance,Computer circuits; Graph structures; Bounded treewidth; Finite relational structures; First order logic; First-order formulas; Meta-theorems; Model checking problem; Monadic second-order logic; Ordered structures; Model checking
A First-order Logic for Reasoning about Knowledge and Probability,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082382863&doi=10.1145%2f3359752&partnerID=40&md5=ad38fd880410af258d7fd36dd9135ba5,"We present a first-order probabilistic epistemic logic, which allows combining operators of knowledge and probability within a group of possibly infinitely many agents. We define its syntax and semantics and prove the strong completeness property of the corresponding axiomatic system. © 2020 Association for Computing Machinery.",coordinated actions; infinite number of agents; probabilistic common knowledge; Probabilistic epistemic logic; strong completeness,Computer circuits; Semantics; Common knowledge; Coordinated actions; Epistemic logic; Infinite numbers; Strong completeness; Probabilistic logics
Extending liquid types to arrays,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078421691&doi=10.1145%2f3362740&partnerID=40&md5=6625883048500874f8f3c8b087acb2a0,"A liquid type is an ordinary Hindley-Milner type annotated with a logical predicate that states the properties satisfied by the elements of that type. Liquid types are a powerful tool for program verification, as programmers can use them to specify pre- and post conditions of their programs, whereas the predicates of intermediate variables and auxiliary functions are inferred automatically. Type inference is feasible in this context, as the logical predicates within liquid types are constrained to a quantifier-free logic to maintain decidability. In this article, we extend liquid types by allowing them to contain quantified properties on arrays so that they can be used to infer invariants on array-related programs (e.g., implementations of sorting algorithms). Although quantified logic is, in general, undecidable, we restrict properties on arrays to a decidable subset introduced by Bradley et al. We describe in detail the extended type system, the verification condition generator, and the iterative weakening algorithm for inferring invariants. After proving the correctness and completeness of these two algorithms, we apply them to find invariants on a set of algorithms involving array manipulations. © 2019 Association for Computing Machinery.",Dependent types; Invariant synthesis; Liquid types,Computability and decidability; Computer circuits; Iterative methods; Auxiliary functions; Decidable subsets; Dependent types; Liquid types; Pre and post conditions; Program Verification; Quantifier-free logic; Verification condition; Liquids
The power of the weak,2020,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078529694&doi=10.1145%2f3372392&partnerID=40&md5=873002dca7ca7e8fbcaf03b80efb5e44,"A landmark result in the study of logics for formal verification is Janin and Walukiewicz's theorem, stating that the modal μ-calculus (μML) is equivalent modulo bisimilarity to standard monadic second-order logic (here abbreviated as SMSO) over the class of labelled transition systems (LTSs for short). Our work proves two results of the same kind, one for the alternation-free or noetherian fragment μN ML of μML on the modal side and one forWMSO, weak monadic second-order logic, on the second-order side. In the setting of binary trees, with explicit functions accessing the left and right successor of a node, it was known that WMSO is equivalent to the appropriate version of alternation-free μ-calculus. Our analysis shows that the picture changes radically once we consider, as Janin andWalukiewicz did, the standard modal μ-calculus, interpreted over arbitrary LTSs. The first theorem that we prove is that, over LTSs, μN ML is equivalent modulo bisimilarity to noetherian MSO (NMSO), a newly introduced variant of SMSO where second-order quantification ranges over ""conversely well-founded"" subsets only. Our second theorem starts fromWMSO and proves it equivalent modulo bisimilarity to a fragment of μN ML defined by a notion of continuity. Analogously to Janin andWalukiewicz's result, our proofs are automata-theoretic in nature: As another contribution, we introduce classes of parity automata characterising the expressiveness of WMSO and NMSO (on tree models) and of μCML and μN ML (for all transition systems). © 2020 Copyright held by the owner/author(s).",Bisimulation; Modal μ-calculus; Tree automata; Weak monadic second-order logic,Automata theory; Binary trees; Calculations; Computer circuits; Equivalence classes; Bisimulations; Labelled transition systems; Modal mu calculus; Monadic second-order logic; Second orders; Transition system; Tree automata; Weak monadic second-order logic; Temporal logic
"MTL and TPTL for one-counter machines: Expressiveness, model checking, and satisfiability",2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077731101&doi=10.1145%2f3372789&partnerID=40&md5=6bf801a444f4ca408bd625c64e567a32,"Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are quantitative extensions of Linear Temporal Logic (LTL) that are prominent and widely used in the verification of real-timed systems. We study MTL and TPTL as specification languages for one-counter machines. It is known that model checking one-counter machines against formulas of Freeze LTL (FLTL), a strict fragment of TPTL, is undecidable. We prove that in our setting, MTL is strictly less expressive than TPTL, and incomparable in expressiveness to FLTL, so undecidability for MTL is not implied by the result for FLTL. We show, however, that the model-checking problem for MTL is undecidable. We further prove that the satisfiability problem for the unary fragments of TPTL and MTL are undecidable; for TPTL, this even holds for the fragment in which only one register and the finally modality is used. This is opposed to a known decidability result for the satisfiability problem for the same fragment of FLTL. © 2019 Association for Computing Machinery.",Data words; Ehrenfeucht-fraïssé games; Freeze LTL; Metric temporal logic; One-counter machines; Timed propositional temporal logic,Computer circuits; Linearization; Model checking; Specification languages; Time sharing systems; Counter machines; Data words; Linear temporal logic; Metric temporal logic; Model checking problem; Satisfiability; Satisfiability problems; Undecidability; Temporal logic
Intuitionistic linear temporal logics,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077738148&doi=10.1145%2f3365833&partnerID=40&md5=7a84cffdf88fd3b884a33e8412dd488a,"We consider intuitionistic variants of linear temporal logic with “next,” “until,” and “release” based on expanding posets: partial orders equipped with an order-preserving transition function. This class of structures gives rise to a logic that we denote ITLe, and by imposing additional constraints, we obtain the logics ITLp of persistent posets and ITLht of here-and-there temporal logic, both of which have been considered in the literature. We prove that ITLe has the effective finite model property and hence is decidable, while ITLp does not have the finite model property. We also introduce notions of bounded bisimulations for these logics and use them to show that the “until” and “release” operators are not definable in terms of each other, even over the class of persistent posets. © 2019 Copyright held by the owner/author(s).",Bisimulation; Intuitionistic logic; Mathematics of computing; Temporal logic; Theory of computation,Computer circuits; Set theory; Bisimulations; Finite model property; Intuitionistic logic; Linear temporal logic; Mathematics of computing; Order preserving; Theory of computation; Transition functions; Temporal logic
Dynamic QBF dependencies in reduction and expansion,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075612449&doi=10.1145%2f3355995&partnerID=40&md5=027f486a3aa04aeeff8aa2d613c38fea,"We provide the first proof complexity results for QBF dependency calculi. By showing that the reflexive resolution path dependency scheme admits exponentially shorter Q-resolution proofs on a known family of instances, we answer a question first posed by Slivovsky and Szeider in 2014 [37]. Further, we conceive a method of QBF solving in which dependency recomputation is utilised as a form of inprocessing. Formalising this notion, we introduce a new version of Q-resolution in which a dependency scheme is applied dynamically. We demonstrate the further potential of this approach beyond that of the existing static system with an exponential separation. Last, we show that the same picture emerges in an analogous approach to the universal expansion paradigm. © 2019 Copyright held by the owner/author(s).",Dependency schemes; Proof complexity; Quantified Boolean formulas,Biomineralization; Dependency schemes; Path dependency; Proof complexity; Quantified Boolean formulas; Recomputation; Resolution proofs; Static systems; Boolean functions
Adding successor: A transfer theorem for separation and covering,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075592381&doi=10.1145%2f3356339&partnerID=40&md5=3713f94df95858cd6bf98005d6bf0158,"Given a class C of word languages, the C-separation problem asks for an algorithm that, given as input two regular languages, decides whether there exists a third language in C containing the first language, while being disjoint from the second. Separation is usually investigated as a means to obtain a deep understanding of the class C. In this article, we are mainly interested in classes defined by logical formalisms. Such classes are often built on top of each other: given some logic, one builds a stronger one by adding new predicates to its signature. A natural construction is to enrich a logic with the successor relation. In this article, we present a transfer result applying to this construction:We showthat for suitable logically defined classes, separation for the logic enriched with the successor relation reduces to separation for the original logic. Our theorem also applies to a problem that is stronger than separation: covering. Moreover, we actually present two reductions: one for languages of finite words and the other for languages of infinite words. © 2019 Copyright held by the owner/author(s).",Covering problem; Decidable characterization; First-order logic; Membership problem; Regular languages; Separation problem,Computer circuits; Formal languages; Formal logic; Separation; Covering problems; Finite words; First order logic; Infinite word; Logical formalism; Membership problem; Separation problems; Word languages; C (programming language)
Verification methods for the computationally complete symbolic attacker based on indistinguishability,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075614401&doi=10.1145%2f3343508&partnerID=40&md5=f43d1a74282b9d8fe59a1ef1d1bf8279,"In recent years, a new approach has been developed for verifying security protocols with the aim of combining the benefits of symbolic attackers and the benefits of unconditional soundness: the technique of the computationally complete symbolic attacker of Bana and Comon (BC) [8]. In this article, we argue that the real breakthrough of this technique is the recent introduction of its version for indistinguishability [9], because, with the extensions we introduce here, for the first time, there is a computationally sound symbolic technique that is syntactically strikingly simple, to which translating standard computational security notions is a straightforward matter, and that can be effectively used for verification of not only equivalence properties but trace properties of protocols as well. We first fully develop the core elements of this newer version by introducing several new axioms. We illustrate the power and the diverse use of the introduced axioms on simple examples first. We introduce an axiom expressing the Decisional Diffie-Hellman property. We analyze the Diffie-Hellman key exchange, both in its simplest form and an authenticated version as well. We provide computationally sound verification of real-or-random secrecy of the Diffie-Hellman key exchange protocol formultiple sessions, without any restrictions on the computational implementation other than the DDH assumption. We also show authentication for a simplified version of the station-to-station protocol using UF-CMA assumption for digital signatures. Finally, we axiomatize IND-CPA, IND-CCA1, and IND-CCA2 security properties and illustrate their usage. We have formalized the axiomatic system in an interactive theorem prover, Coq, and have machine-checked the proofs of various auxiliary theorems and security properties of Diffie-Hellman and station-to-station protocol. © 2019 Copyright held by the owner/author(s).",Authentication; Computational model; Computational soundness; Dolev-Yao model; First-order logic; Secrecy,Authentication; Formal logic; Theorem proving; Computational model; Computational soundness; Dolev-Yao model; First order logic; Secrecy; Network security
Reason-maintenance Belief Logic with Uncertain Information,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075596434&doi=10.1145%2f3355608&partnerID=40&md5=b067a3842753a449d21a434fbf077bd9,"In this article, we propose a logic for reasoning about belief based on fusion of uncertain information. The resultant reason-maintenance possibilistic belief logic can represent both implicit and explicit uncertain beliefs of an agent. While implicit beliefs stipulate what are believable, explicit beliefs can trace the process of belief formation by information fusion. To set up the formal framework, we start with developing a basic reason-maintenance belief logic, present its syntax and semantics, and investigate its axiomatization and properties. Then, we extend the basic logic to accommodate the possibilistic uncertainty of information and beliefs, provide a complete axiomatization of the extended logic, and show that it can address the reasonmaintenance issue of partially inconsistent beliefs. We also demonstrate the applicability of our formalisms by using several examples in realistic scenarios. © 2019 Copyright held by the owner/author(s).",Explicit belief; Implicit belief; Logic; Modal logic; Possibilistic logic,Maintenance; Semantics; Explicit belief; Implicit belief; Logic; Modal logic; Possibilistic logic; Computer circuits
Satisfiability of modal inclusion logic: Lax and strict semantics,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075599859&doi=10.1145%2f3356043&partnerID=40&md5=1ec06f921af64396aa80332693609623,"We investigate the computational complexity of the satisfiability problem of modal inclusion logic. We distinguish two variants of the problem: one for the strict and another one for the lax semantics. Both problems turn out to be EXPTIME-complete on general structures. Finally,we showhowfor a specific class of structures NEXPTIME-completeness for these problems under strict semantics can be achieved. © 2019 Copyright held by the owner/author(s).",Computational complexity; Modal inclusion logic; Satisfiability; Team semantics,Computational complexity; Formal logic; Semantics; Exptime; General structures; Modal inclusion logic; Satisfiability; Satisfiability problems; Specific class; Computer circuits
Idempotent anti-unification,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074886023&doi=10.1145%2f3359060&partnerID=40&md5=fff48036b720adc848542c32d54db56c,"In this article, we address two problems related to idempotent anti-unification. First, we show that there exists an anti-unification problem with a single idempotent symbol that has an infinite minimal complete set of generalizations. It means that anti-unification with a single idempotent symbol has infinitary or nullary generalization type, similar to anti-unification with two idempotent symbols, shown earlier by Loïc Pottier. Next, we develop an algorithm that takes an arbitrary idempotent anti-unification problem and computes a representation of its solution set in the form of a regular tree grammar. The algorithm does not depend on the number of idempotent function symbols in the input terms. The language generated by the grammar is the minimal complete set of generalizations of the given anti-unification problem, which implies that idempotent anti-unification is infinitary. © 2019 Association for Computing Machinery.",Anti-unification; Generalization; Idempotence; Regular tree grammar,Forestry; Anti-unification; Function symbols; Generalization; Idempotence; Idempotent; Infinitary; Regular tree grammars; Solution set; Trees (mathematics)
"Monadic datalog, tree validity, and limited access containment",2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075613978&doi=10.1145%2f3344514&partnerID=40&md5=4978b6351b0020094b16dc46691f34ea,"We reconsider the problem of containment of monadic datalog (MDL) queries in unions of conjunctive queries (UCQs). Prior work has dealt with special cases of the problem but has left the precise complexity characterization open. In addition, the complexity of one important special case, that of containment under access patterns, was not known before. We start by revisiting the connection between MDL/UCQ containment and containment problems involving regular tree languages. We then present a general approach for getting tighter bounds on the complexity of query containment, based on analysis of the number of mappings of queries into tree-like instances. We give two applications of the machinery. We first give an important special case of the MDL/UCQ containment problem that is in EXPTIME, and we use this bound to show an EXPTIME bound on containment under access patterns. Second, we show that the same technique can be used to get a new tight upper bound for containment of tree automata in UCQs.We finally show that the new MDL/UCQ upper bounds are tight. We establish a 2EXPTIME lower bound on the MDL/UCQ containment problem, resolving an open problem from the early 1990s. This bound holds for the MDL/CQ containment problem as well. We also show that changes to the conditions given in our special cases can not be eliminated, and that in particular slight variations of the problem of containment under access patterns become 2EXPTIME-complete. © 2019 Association for Computing Machinery.",Access patterns; Binding patterns; Deep Web; Monadic datalog; Query containment,Machinery; Access patterns; Binding pattern; Datalog; Deep web; Query containment; Forestry
Fixed-point elimination in the intuitionistic propositional calculus,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075607692&doi=10.1145%2f3359669&partnerID=40&md5=48ab029a29dede6f710eb3b101759bce,"It follows from known results in the literature that least and greatest fixed-points of monotone polynomials on Heyting algebras-that is, the algebraic models of the Intuitionistic Propositional Calculus-always exist, even when these algebras are not complete as lattices. The reason is that these extremal fixed-points are definable by formulas of the IPC. Consequently, the μ-calculus based on intuitionistic logic is trivial, every μ-formula being equivalent to a fixed-point free formula. In the first part of this article, we give an axiomatization of least and greatest fixed-points of formulas, and an algorithm to compute a fixed-point free formula equivalent to a given μ-formula. The axiomatization of the greatest fixed-point is simple. The axiomatization of the least fixed-point is more complex, in particular every monotone formula converges to its least fixed-point by Kleene's iteration in a finite number of steps, but there is no uniform upper bound on the number of iterations. The axiomatization yields a decision procedure for the μ-calculus based on propositional intuitionistic logic. The second part of the article dealswith closure ordinals of monotone polynomials onHeyting algebras and of intuitionistic monotone formulas; these are the least numbers of iterations needed for a polynomial/formula to converge to its least fixed-point. Mirroring the elimination procedure, we show how to compute upper bounds for closure ordinals of arbitrary intuitionistic formulas. For some classes of formulas, we provide tighter upper bounds that, in some cases, we prove exact. © 2019 Association for Computing Machinery.",Elimination; Fixed-points; Intuitionistic propositional calculus,Computer circuits; Iterative methods; Polynomials; Temporal logic; Elimination; Elimination procedure; Fixed points; Greatest fixed points; Intuitionistic logic; Monotone polynomials; Number of iterations; Propositional calculus; Calculations
Incomplete smt techniques for solving non-linear formulas over the integers,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075569486&doi=10.1145%2f3340923&partnerID=40&md5=d33ded31b438f0735b06f81a1fb0c2db,"We present newmethods for solving the SatisfiabilityModulo Theories problem over the theory of Quantifier-Free Non-linear Integer Arithmetic, SMT(QF-NIA), which consists of deciding the satisfiability of ground formulas with integer polynomial constraints. Following previous work, we propose to solve SMT(QF-NIA) instances by reducing them to linear arithmetic: non-linear monomials are linearized by abstracting them with fresh variables and by performing case splitting on integer variables with finite domain. For variables that do not have a finite domain, we can artificially introduce one by imposing a lower and an upper bound and iteratively enlarge it until a solution is found (or the procedure times out). The key for the success of the approach is to determine, at each iteration, which domains have to be enlarged. Previously, unsatisfiable cores were used to identify the domains to be changed, but no clue was obtained as to howlarge the newdomains should be. Here,we explain two novelways to guide this process by analyzing solutions to optimization problems: (i) tominimize the number of violated artificial domain bounds, solved via a Max-SMT solver, and (ii) to minimize the distance with respect to the artificial domains, solved via an Optimization Modulo Theories (OMT) solver. Using this SMT-based optimization technology allows smoothly extending the method to also solve Max-SMT problems over non-linear integer arithmetic. Finally, we leverage the resulting Max-SMT(QF-NIA) techniques to solve formulas in a fragment of quantified non-linear arithmetic that appears commonly in verification and synthesis applications. © 2019 Association for Computing Machinery. All rights reserved.",Non-linear arithmetic; Satisfiability modulo theories,Formal logic; Iterative methods; Artificial domain; Integer arithmetic; Linear arithmetic; Non linear; Optimization problems; Optimization technology; Satisfiability modulo Theories; Unsatisfiable core; Integer programming
Runtime verification over out-of-order streams,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075631347&doi=10.1145%2f3355609&partnerID=40&md5=66094265c14b29b9a7edfa8e6ddc952a,"We present an approach for verifying systems at runtime. Our approach targets distributed systems whose components communicate with monitors over unreliable channels, where messages can be delayed, reordered, or even lost. Furthermore, our approach handles an expressive specification language that extends the real-time logic MTL with freeze quantifiers for reasoning about data values. The logic's main novelty is a new three-valued semantics that is well suited for runtime verification as it accounts for partial knowledge about a system's behavior. Based on this semantics, we present online algorithms that reason soundly and completely about streams where events can occur out of order. We also evaluate our algorithms experimentally. Depending on the specification, our prototype implementation scales to out-of-order streams with hundreds to thousands of events per second. © 2019 Copyright held by the owner/author(s).",Distributed systems; Kleene logic; Runtime verification; Stream processing; Temporal logic,Distributed computer systems; Many valued logics; Semantics; Specification languages; Specifications; Temporal logic; Distributed systems; Freeze quantifiers; Kleene logic; On-line algorithms; Prototype implementations; Run-time verification; Stream processing; Unreliable channels; Computer circuits
A Representation theorem for change through composition of activities,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075560315&doi=10.1145%2f3329121&partnerID=40&md5=47b00c82dff63bb5076aa7aac2c260f0,"The expanding use of information systems in industrial and commercial settings has increased the need for interoperation between software systems. In particular, many social, industrial, and business information systems require a common basis for a seamless exchange of complex process information. This is, however, inhibited, because different systemsmay use distinct terminologies or assume different meanings for the same terms. A common solution to this problem is to develop logical theories that act as an intermediate language between different parties. In this article, we characterize a class of activities that can act as intermediate languages between different parties in those cases. We show that for each domain with finite number of elements there exists a class of activities, we called canonical activities, such that all possible changes within the domain can be represented as a sequence of occurrences of those activities.We use an algebraic structure for representing change and characterizing canonical activities, which enables us to abstract away domaindependent properties of processes and activities, and demonstrate general properties of formalisms required for semantic integration of dynamic information systems. © 2019 Association for Computing Machinery. All rights reserved.",Algebraic representation of change; Canonical activities; First-order logic; Partial automorphisms; Reasoning about action,Abstracting; Algebra; Formal logic; Information systems; Semantics; Algebraic representations; Automorphisms; Canonical activities; First order logic; Reasoning about actions; Information use
Probabilistic epistemic updates on algebras,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075573309&doi=10.1145%2f3341725&partnerID=40&md5=1637d68f42a1b22e690520fe9b2a023e,"The present article contributes to the development of the mathematical theory of epistemic updates using the tools of duality theory. Here, we focus on Probabilistic Dynamic Epistemic Logic (PDEL). We dually characterize the product update construction of PDEL-models as a certain construction transforming the complex algebras associated with the given model into the complex algebra associated with the updated model. Thanks to this construction, an interpretation of the language of PDEL can be defined on algebraic models based on Heyting algebras. This justifies our proposal for the axiomatization of the intuitionistic counterpart of PDEL. © 2019 Copyright held by the owner/author(s).",,Computer science; Logic programming; Algebraic models; Axiomatization; Complex algebra; Duality theory; Heyting algebras; Mathematical theory; Probabilistic dynamics; Product updates; Algebra
Typing messages for free in security protocols,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072520712&doi=10.1145%2f3343507&partnerID=40&md5=b91da1dee57e6ff326839d3376bbc6d3,"Security properties of cryptographic protocols are typically expressed as reachability or equivalence properties. Secrecy and authentication are examples of reachability properties, while privacy properties such as untraceability, vote secrecy, or anonymity are generally expressed as behavioral equivalence in a process algebra that models security protocols. Our main contribution is to reduce the search space for attacks for reachability as well as equivalence properties. Specifically, we show that if there is an attack then there is one that is well-typed. Our result holds for a large class of typing systems, a family of equational theories that encompasses all standard primitives, and protocols without else branches. For many standard protocols, we deduce that it is sufficient to look for attacks that follow the format of the messages expected in an honest execution, therefore considerably reducing the search space. © 2019 Association for Computing Machinery.",Security protocols; Symbolic model; Trace equivalence; Verification,Computer science; Logic programming; Verification; Behavioral equivalence; Cryptographic protocols; Equational theory; Security properties; Security protocols; Standard protocols; Symbolic model; Trace equivalence; Network security
"Modal Resolution: Proofs, Layers, and Refinements",2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075545820&doi=10.1145%2f3331448&partnerID=40&md5=6547e0d0ec9c44a90e997ed1f06cf92b,"Resolution-based provers for multimodal normal logics require pruning of the search space for a proof to ameliorate the inherent intractability of the satisfiability problem for such logics.We present a clausal modallayered hyper-resolution calculus for the basic multimodal logic, which divides the clause set according to the modal level at which clauses occur to reduce the number of possible inferences. We show that the calculus is complete for the logics being considered. We also show that the calculus can be combined with other strategies. In particular, we discuss the completeness of combining modal layering with negative and ordered resolution and provide experimental results comparing the different refinements. © 2019 Association for Computing Machinery. All rights reserved.",Normal modal logics; proof strategies; resolution method,Formal logic; Hyper-resolution; Modal logic; Modal resolutions; Multi-modal logic; Ordered resolution; Proof strategy; Resolution methods; Satisfiability problems; Calculations
Central Limit Model Checking,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069517791&doi=10.1145%2f3331452&partnerID=40&md5=93895accb71e0dcba3afba82b8492041,"We consider probabilistic model checking for continuous-Time Markov chains (CTMCs) induced from Stochastic Reaction Networks against a fragment of Continuous Stochastic Logic (CSL) extended with reward operators. Classical numerical algorithms for CSL model checking based on uniformisation are limited to finite CTMCs and suffer from exponential growth of the state space with respect to the number of species. However, approximate techniques such as mean-field approximations and simulations combined with statistical inference are more scalable but can be time-consuming and do not support the full expressiveness of CSL. In this article, we employ a continuous-space approximation of the CTMC in terms of a Gaussian process based on the Central Limit Approximation, also known as the Linear Noise Approximation, whose solution requires solving a number of differential equations that is quadratic in the number of species and independent of the population size. We then develop efficient and scalable approximate model checking algorithms on the resulting Gaussian process, where we restrict the target regions for probabilistic reachability to convex polytopes. This allows us to derive an abstraction in terms of a time-inhomogeneous discrete-Time Markov chain (DTMC), whose dimension is independent of the number of species, on which model checking is performed. Using results from probability theory, we prove the convergence in distribution of our algorithms to the corresponding measures on the original CTMC. We implement the techniques and, on a set of examples, demonstrate that they allow us to overcome the state space explosion problem, while still correctly characterizing the stochastic behaviour of the system. Our methods can be used for formal analysis of a wide range of distributed stochastic systems, including biochemical systems, sensor networks, and population protocols. © 2019 Copyright held by the owner/author(s).",Chemical reaction networks; continuous time Markov chain; Gaussian process; probabilistic model checking,Biochemistry; Biodiversity; Continuous time systems; Differential equations; Gaussian distribution; Gaussian noise (electronic); Markov processes; Population statistics; Sensor networks; Stochastic models; Stochastic systems; Central limit approximation; Chemical reaction networks; Continuous stochastic logic; Continuous time Markov chain; Convergence in distribution; Discrete time Markov chains; Gaussian Processes; Probabilistic model checking; Model checking
On the verification of livelock-freedom and self-stabilization on parameterized rings,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069188967&doi=10.1145%2f3326456&partnerID=40&md5=c72bd62c532ea4f1dafd39da608ffa30,"This article investigates the verification of livelock-freedom and self-stabilization on parameterized rings consisting of symmetric, constant space, deterministic, and self-disabling processes. The results of this article have a significant impact on several fields, including scalable distributed systems, resilient and self-* systems, and verification of parameterized systems. First, we identify necessary and sufficient local conditions for the existence of global livelocks in parameterized unidirectional rings with unbounded (but finite) number of processes under the interleaving semantics. Using a reduction from the periodic domino problem, we show that, in general, verifying livelock-freedom of parameterized unidirectional rings is undecidable (specifically, Π01-complete) even for constant space, deterministic, and self-disabling processes. This result implies that verifying self-stabilization for parameterized rings of self-disabling processes is also undecidable. We also show that verifying livelock-freedom and self-stabilization remain undecidable under (1) synchronous execution semantics, (2) the FIFO consistency model, and (3) any scheduling policy. We then present a new scope-based method for detecting and constructing livelocks in parameterized rings. The proposed semi-algorithm behind our scope-based verification is based on a novel paradigm for the detection of livelocks that totally circumvents state space exploration. Our experimental results on an implementation of the proposed semi-algorithm 6 are very promising as we have found livelocks in parameterized rings in a few microseconds on a regular laptop. The results of this article have significant implications for scalable distributed systems with cyclic topologies. © 2019 Association for Computing Machinery.",Distributed programs; Parameterized systems; Program verification; Self-stabilization,Semantics; Space research; Stabilization; Distributed program; Distributed systems; Interleaving semantics; Parameterized system; Program Verification; Self stabilization; State space exploration; Unidirectional rings; Parameterization
Reasoning about Cognitive Trust in Stochastic Multiagent Systems,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069459619&doi=10.1145%2f3329123&partnerID=40&md5=efa8cefded860756ac3ad71a62d87196,"We consider the setting of stochastic multiagent systems modelled as stochastic multiplayer games and formulate an automated verification framework for quantifying and reasoning about agents' trust. To capture human trust, we work with a cognitive notion of trust defined as a subjective evaluation that agent A makes about agent B's ability to complete a task, which in turn may lead to a decision by A to rely on B. We propose a probabilistic rational temporal logic PRTL, which extends the probabilistic computation tree logic PCTL with reasoning about mental attitudes (beliefs, goals, and intentions) and includes novel operators that can express concepts of social trust such as competence, disposition, and dependence. The logic can express, for example, that ""agent A will eventually trust agent B with probability at least p that B will behave in a way that ensures the successful completion of a given task."" We study the complexity of the automated verification problem and, while the general problem is undecidable, we identify restrictions on the logic and the system that result in decidable, or even tractable, subproblems. © 2019 Association for Computing Machinery.",cognitive trust; Multi-Agent systems; probabilistic temporal logic; quantitative reasoning; stochastic games,Cognitive systems; Computer circuits; Probabilistic logics; Stochastic systems; Temporal logic; Automated verification; cognitive trust; Probabilistic computation tree logic; Probabilistic temporal logic; Quantitative reasoning; Stochastic game; Stochastic multi-agent systems; Subjective evaluations; Multi agent systems
De Morgan Dual Nominal Quantifiers Modelling Private Names in Non-Commutative Logic,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068043827&doi=10.1145%2f3325821&partnerID=40&md5=c29ce84be31b83e2454703faa95004ec,"This article explores the proof theory necessary for recommending an expressive but decidable first-order system, named MAV1, featuring a De Morgan dual pair of nominal quantifiers. These nominal quantifiers called ""new"" and ""wen"" are distinct from the self-dual Gabbay-Pitts and Miller-Tiu nominal quantifiers. The novelty of these nominal quantifiers is they are polarised in the sense that ""new"" distributes over positive operators while ""wen"" distributes over negative operators. This greater control of bookkeeping enables private names to be modelled in processes embedded as formulae in MAV1. The technical challenge is to establish a cut elimination result from which essential properties including the transitivity of implication follow. Since the system is defined using the calculus of structures, a generalisation of the sequent calculus, novel techniques are employed. The proof relies on an intricately designed multiset-based measure of the size of a proof, which is used to guide a normalisation technique called splitting. The presence of equivariance, which swaps successive quantifiers, induces complex inter-dependencies between nominal quantifiers, additive conjunction, and multiplicative operators in the proof of splitting. Every rule is justified by an example demonstrating why the rule is necessary for soundly embedding processes and ensuring that cut elimination holds. © 2019 Copyright held by the owner/author(s).",Calculus of structures; nominal logic; non-commutative logic,Calculations; Differentiation (calculus); Calculus of structures; First order systems; Inter-dependencies; Multiplicative operators; Nominal logic; Non-commutative logic; Positive operator; Technical challenges; Computer circuits
Parallel-correctness and containment for conjunctive queries with union and negation,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069180190&doi=10.1145%2f3329120&partnerID=40&md5=441f7ccc78448215555cd2ee95d9711d,"Single-round multiway join algorithms first reshuffle data over many servers and then evaluate the query at hand in a parallel and communication-free way. A key question is whether a given distribution policy for the reshuffle is adequate for computing a given query, also referred to as parallel-correctness. This article extends the study of the complexity of parallel-correctness and its constituents, parallel-soundness and parallel-completeness, to unions of conjunctive queries with negation. As a by-product, it is shown that the containment problem for conjunctive queries with negation is coNEXPTIME-complete. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conjunctive queries; Containment; Parallel-correctness,Logic programming; Conjunctive queries; Containment; Distribution policies; Multi-way join; Parallel-correctness; Computer science
1-safe Petri nets and special cube complexes: Equivalence and applications,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069228185&doi=10.1145%2f3322095&partnerID=40&md5=17e282a7a7a7ffb588f7b23b7558f126,"Nielsen et al. [35] proved that every 1-safe Petri net N unfolds into an event structure EN. By a result of Thiagarajan [46], these unfoldings are exactly the trace-regular event structures. Thiagarajan [46] conjectured that regular event structures correspond exactly to trace-regular event structures. In a recent paper (Chalopin and Chepoi [12]), we disproved this conjecture, based on the striking bijection between domains of event structures, median graphs, and CAT(0) cube complexes. However, we proved that Thiagarajan's conjecture is true for regular event structures whose domains are principal filters of universal covers of finite special cube complexes. In the current article, we prove the converse: To any finite 1-safe Petri net N, one can associate a finite special cube complex XN such that the domain of the event structure EN (obtained as the unfolding of N) is a principal filter of the universal cover XN of XN. This establishes a bijection between 1-safe Petri nets and finite special cube complexes and provides a combinatorial characterization of trace-regular event structures. Using this bijection and techniques from graph theory and geometry (MSO theory of graphs, bounded treewidth, and bounded hyperbolicity), we disprove yet another conjecture by Thiagarajan (from the paper with Yang [48]) that the monadic second-order logic of a 1-safe Petri net (i.e., of its event structure unfolding) is decidable if and only if its unfolding is grid-free. It was proven by Thiagarajan and Yang [48] that the MSO logic is undecidable if the unfolding is not grid-free. Our counterexample is the trace-regular event structure that arises from a virtually special square complex Z. The domain of this event structure E Z is the principal filter of the universal cover Z of Z in which to each vertex we added a pendant edge. The graph of the domain of E Z has bounded hyperbolicity (and, thus, the event structure E Z is grid-free) but has infinite treewidth. Using results of Seese, Courcelle, and Müller and Schupp, we show that this implies that the MSO theory of the event structure E Z is undecidable. © 2019 Association for Computing Machinery.",1-safe Petri nets; Context-free graphs; Median graphs and CAT(0) cube complexes; MSO logic; Special cube complexes; Trace-regular event structures; Unfoldings and universal covers,Computer circuits; Graphic methods; Petri nets; Context-free; Event structures; Median graph; Mso logic; Special cube complexes; Unfoldings; Geometry
Synchronizing data words for register automata,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064619971&doi=10.1145%2f3309760&partnerID=40&md5=7b27220dce8c643b1aa064b2632a6d54,"Register automata (RAs) are finite automata extended with a finite set of registers to store and compare data from an infinite domain. We study the concept of synchronizing data words in RAs: does there exist a data word that sends all states of the RA to a single state? For deterministic RAs with k registers (k-DRAs), we prove that inputting data words with 2k + 1 distinct data from the infinite data domain is sufficient to synchronize. We show that the synchronization problem for DRAs is in general PSPACE-complete, and it is NLOGSPACE-complete for 1-DRAs. For nondeterministic RAs (NRAs), we show that Ackermann(n) distinct data (where n is the size of the RA) might be necessary to synchronize. The synchronization problem for NRAs is in general undecidable; however, we establish Ackermann-completeness of the problem for 1-NRAs. Another main result is the NEXPTIME-completeness of the length-bounded synchronization problem for NRAs, where a bound on the length of the synchronizing data word, written in binary, is given. A variant of this last construction allows to prove that the lengthbounded universality problem for NRAs is co-NEXPTIME-complete. © 2019 Association for Computing Machinery.",Bounded universality; Data words; Register automata; Synchronization problem,Computer science; Logic programming; Bounded universality; Data words; Infinite domains; PSPACE-complete; Register automata; Single state; Synchronization problem; Universality problem; Synchronization
Reasoning about strategic abilities: Agents with truly perfect recall,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064702924&doi=10.1145%2f3309761&partnerID=40&md5=62df4b9203b86602411c6facd9f7b4cf,"In alternating-time temporal logic ATL∗, agents with perfect recall assign choices to sequences of states, i.e., to possible finite histories of the game. However, when a nested strategic modality is interpreted, the new strategy does not take into account the previous sequence of events. It is as if agents collect their observations in the nested game again from scratch, thus, effectively forgetting what they observed before. Intuitively, it does not fit the assumption of agents having perfect recall of the past. In this article, we investigate the alternative semantics for ATL∗ where the past is not forgotten in nested games. We show that the standard semantics of ATL∗ coincides with the ""truly perfect recall"" semantics for agents with perfect information and in case of so-called ""objective"" abilities under uncertainty. On the other hand, the two semantics differ significantly for the most popular (""subjective"") notion of ability under imperfect information. The same applies to the standard vs. ""truly perfect recall"" semantics of ATL∗ with persistent strategies. We compare the relevant variants of ATL∗ by looking at their expressive power, sets of validities, and tractability of model checking. © 2019 Association for Computing Machinery.",Alternating-Time temporal logic; Perfect-recall semantics,Computer circuits; Model checking; Temporal logic; Alternating time temporal logic; Alternative Semantics; Expressive power; Imperfect information; Perfect informations; Perfect recalls; Sequence of events; Semantics
Fast query answering over existential rules,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064672621&doi=10.1145%2f3308448&partnerID=40&md5=f283e98cc6097d05ae42e3de9eab4ffd,"Enhancing Datalog with existential quantification gives rise to Datalog∃, a powerful knowledge representation language widely used in ontology-based query answering. In this setting, a conjunctive query is evaluated over a Datalog∃ program consisting of extensional data paired with so-called ""existential"" rules. Owing to their high expressiveness, such rules make the evaluation of queries undecidable, even when the latter are atomic. Decidable generalizations of Datalog by existential rules have been proposed in the literature (such as weakly acyclic and weakly guarded); but they pay the price of higher computational complexity, hindering the implementation of effective systems. Conversely, the results in this article demonstrate that it is definitely possible to enable fast yet powerful query answering over existential rules that strictly generalize Datalog by ensuring decidability without any complexity overhead. On the theoretical side, we define the class of parsimonious programs that guarantees decidability of atomic queries. We then strengthen this class to strongly parsimonious programs ensuring decidability also for conjunctive queries. Since parsimony is an undecidable property, we single out Shy, an easily recognizable class of strongly parsimonious programs that generalizes Datalog while preserving its complexity even under conjunctive queries. Shy also generalizes the class of linear existential programs, while it is uncomparable to the other main classes ensuring decidability. On the practical side, we exploit our results to implement DLV∃, an effective system for query answering over parsimonious existential rules. To assess its efficiency, we carry out an experimental analysis, evaluating DLV∃ performances for ontology-based query answering on both real-world and synthetic ontologies. © 2019 Association for Computing Machinery.",Datalog; Existential rules; Ontology-based query answering,Computability and decidability; Data mining; Knowledge representation; Conjunctive queries; Datalog; Effective systems; Existential quantifications; Existential rules; Experimental analysis; Knowledge representation language; Ontology-based query; Ontology
Tight bounds on the asymptotic descriptive complexity of subgraph isomorphism,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064650930&doi=10.1145%2f3303881&partnerID=40&md5=4bd1b401c7c684f6a54f39e1aaa43551,"Let v(F ) denote the number of vertices in a fixed connected pattern graph F. We show an infinite family of patterns F such that the existence of a subgraph isomorphic to F is expressible by a first-order sentence of quantifier depth 2/3 v(F ) + 1, assuming that the host graph is sufficiently large and connected. However, this is impossible for any F using less than 2/3 v(F) - 2 first-order variables. © 2019 ACM.",And variable width; Descriptive and computational complexity; First-order logic; Quantifier depth; The subgraph isomorphism problem,Formal logic; Descriptive complexity; First order logic; First order sentences; Quantifier depth; Subgraph isomorphism; Subgraph isomorphism problem; Tight bound; Variable width; Set theory
Modularisation of sequent calculi for normal and non-normal modalities,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062324364&doi=10.1145%2f3288757&partnerID=40&md5=d2a3498a855ade0a0e4b5ffc877a59d9,"In this work, we explore the connections between (linear) nested sequent calculi and ordinary sequent calculi for normal and non-normal modal logics. By proposing local versions to ordinary sequent rules, we obtain linear nested sequent calculi for a number of logics, including, to our knowledge, the first nested sequent calculi for a large class of simply dependent multimodal logics and for many standard non-normal modal logics. The resulting systems are modular and have separate left and right introduction rules for the modalities, which makes them amenable to specification as bipole clauses. While this granulation of the sequent rules introduces more choices for proof search, we show how linear nested sequent calculi can be restricted to blocked derivations, which directly correspond to ordinary sequent derivations. © 2019 Association for Computing Machinery.",Labelled systems; Linear nested sequents; Modal logic; Proof theory,Biomineralization; Formal logic; Pathology; Local versions; Modal logic; Multi-modal logic; Nested sequents; Proof search; Proof theory; Sequent calculus; Differentiation (calculus)
The complexity of minimal inference problem for conservative constraint languages,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062220727&doi=10.1145%2f3301410&partnerID=40&md5=b2505029f3fb51a7e33b4ddda2613df6,"                             We study the complexity of the inference problem for propositional circumscription (the minimal inference problem) over arbitrary finite domains. The problem is of fundamental importance in nonmonotonic logics and commonsense reasoning. The complexity of the problem for the two-element domain has been completely classified. In this article, we classify the complexity of the problem over all conservative languages. We consider a version of the problem parameterized by a set of relations (a constraint language), from which we are allowed to build a knowledge base, and where a linear order used to compare models is a part of an input. We show that in this setting the problem is either Π                             2                             P                              -complete, coNP-complete, or in P. The classification is based on a coNP-hardness proof for a new class of languages, an analysis of languages that do not express any member of the class, and a new general polynomial-time algorithm solving the minimal inference problem for a large class of languages.                          © 2019 Association for Computing Machinery.",Algebraic approach; Circumscription; Commonsense reasoning; Computational complexity; Minimal inference problem; Nonmonotonic reasoning; Schaefer's framework; Tractability,Computational complexity; Polynomial approximation; Algebraic approaches; Circumscription; Commonsense reasoning; Inference problem; Non-monotonic reasoning; Schaefer's framework; Tractability; Inference engines
A SAT approach to branchwidth,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066956039&doi=10.1145%2f3326159&partnerID=40&md5=76b3871018f68e43444422b25a90f053,"Branch decomposition is a prominent method for structurally decomposing a graph, a hypergraph, or a propositional formula in conjunctive normal form. The width of a branch decomposition provides a measure of how well the object is decomposed. For many applications, it is crucial to computing a branch decomposition whose width is as small as possible. We propose an approach based on Boolean Satisfiability (SAT) to finding branch decompositions of small width. The core of our approach is an efficient SAT encoding that determines with a single SAT-call whether a given hypergraph admits a branch decomposition of a certain width. For our encoding, we propose a natural partition-based characterization of branch decompositions. The encoding size imposes a limit on the size of the given hypergraph. To break through this barrier and to scale the SAT approach to larger instances, we develop a new heuristic approach where the SAT encoding is used to locally improve a given candidate decomposition until a fixed-point is reached. This new SAT-based local improvement method scales now to instances with several thousands of vertices and edges. © 2019 Association for Computing Machinery.",Branchwidth; Carving-width; Heuristic search; SAT encoding,Encoding (symbols); Graph theory; Heuristic algorithms; Heuristic methods; Signal encoding; Boolean satisfiability; Branch decomposition; Branchwidth; Carving-width; Conjunctive normal forms; Heuristic search; Improvement methods; Propositional formulas; Decomposition
Pure sequent calculi: Analyticity and decision procedure,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066950546&doi=10.1145%2f3319501&partnerID=40&md5=1fb2894223f9acfc767a8756a8d7e9c0,"Analyticity, also known as the subformula property, typically guarantees decidability of derivability in propositional sequent calculi. To utilize this fact, two substantial gaps have to be addressed: (i) What makes a sequent calculus analytic? and (ii) How do we obtain an efficient decision procedure for derivability in an analytic calculus? In the first part of this article, we answer these questions for pure calculi-a general family of fully structural propositional sequent calculi whose rules allow arbitrary context formulas. We provide a sufficient syntactic criterion for analyticity in these calculi, as well as a productive method to construct new analytic calculi from given ones. We further introduce a scalable decision procedure for derivability in analytic pure calculi by showing that it can be (uniformly) reduced to classical satisfiability. In the second part of the article, we study the extension of pure sequent calculi with modal operators. We show that such extensions preserve the analyticity of the calculus and identify certain restricted operators (which we call “Next” operators) that are also amenable for a general reduction of derivability to classical satisfiability. Our proofs are all semantic, utilizing several strong general soundness and completeness theorems with respect to non-deterministic semantic frameworks: bivaluations (for pure calculi) and Kripke models (for their extension with modal operators). © 2019 Association for Computing Machinery.",Analyticity; Sequent calculi; Subformula property,Biomineralization; Calculations; Differentiation (calculus); Formal logic; Semantics; Signal theory; Analyticity; Decision procedure; Deterministic semantics; Modal operators; Sequent calculus; Soundness and completeness; Subformula property; Syntactic criteria; Pathology
Binary Reachability of Timed-register Pushdown Automata and Branching Vector Addition Systems,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066925267&doi=10.1145%2f3326161&partnerID=40&md5=897ce7fcb11baca24ddeb2a30a562fbb,"Timed-register pushdown automata constitute a very expressive class of automata, whose transitions may involve state, input, and top-of-stack timed registers with unbounded differences. They strictly subsume pushdown timed automata of Bouajjani et al., dense-timed pushdown automata of Abdulla et al., and orbit-finite timed-register pushdown automata of Clemente and Lasota. We give an effective logical characterisation of the reachability relation of timed-register pushdown automata. As a corollary, we obtain a doubly exponential time procedure for the non-emptiness problem. We show that the complexity reduces to singly exponential under the assumption of monotonic time. The proofs involve a novel model of one-dimensional integer branching vector addition systems with states. As a result interesting on its own, we show that reachability sets of the latter model are semilinear and computable in exponential time. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Branching vector addition systems; pushdown automata; Timed Automata; timed-register pushdown automata,Petri nets; Vectors; Branching vector addition systems with state; Emptiness problem; Exponential time; Push-down automata; Reachability relations; Reachability set; Timed Automata; Vector addition systems; Automata theory
A theoretical and numerical analysis of the worst-case size of reduced ordered binary decision diagrams,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061245785&doi=10.1145%2f3274279&partnerID=40&md5=000f5c19b1b1292e997a5ea6bfa1e8d4,"Binary Decision Diagrams (BDDs) and in particular ROBDDs (Reduced Ordered BDDs) are a common data structure for manipulating Boolean expressions, integrated circuit design, type inferencers, model checkers, and many other applications. Although the ROBDD is a lightweight data structure to implement, the behavior, in terms of memory allocation, may not be obvious to the program architect. We explore experimentally, numerically, and theoretically the typical and worst-case ROBDD sizes in terms of number of nodes and residual compression ratios, as compared to unreduced BDDs. While our theoretical results are not surprising, as they are in keeping with previously known results, we believe our method contributes to the current body of research by our experimental and statistical treatment of ROBDD sizes. In addition, we provide an algorithm to calculate the worst-case size. Finally, we present an algorithm for constructing a worst-case ROBDD of a given number of variables. Our approach may be useful to projects deciding whether the ROBDD is the appropriate data structure to use, and in building worst-case examples to test their code. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Binary decision diagrams; Boolean simplification; Common lisp; Data structures,Boolean functions; Data structures; Model checking; Binary decision diagrams (BDDs); Boolean expressions; Boolean simplification; Common lisp; Lightweight data structures; Reduced ordered binary decision diagram; Residual compression; Statistical treatment; Binary decision diagrams
A higher-order calculus of computational fields,2019,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061246967&doi=10.1145%2f3285956&partnerID=40&md5=2b8b8a5451840b729f259e3bca382831,"The complexity of large-scale distributed systems, particularly when deployed in physical space, calls for new mechanisms to address composability and reusability of collective adaptive behaviour. Computational fields have been proposed as an effective abstraction to fill the gap between the macro-level of such systems (specifying a system's collective behaviour) and the micro-level (individual devices' actions of computation and interaction to implement that collective specification), thereby providing a basis to better facilitate the engineering of collective APIs and complex systems at higher levels of abstraction. This article proposes a full formal foundation for field computations, in terms of a core (higher-order) calculus of computational fields containing a few key syntactic constructs, and equipped with typing, denotational and operational semantics. Critically, this allows formal establishment of a link between the micro- and macro-levels of collective adaptive systems by a result of computational adequacy and abstraction for the (aggregate) denotational semantics with respect to the (per-device) operational semantics. © 2019 Association for Computing Machinery.",Adequacy; Aggregate programming; Computational field; Core calculus; Full abstraction; Spatial computing; Type inference system; Type soundness,Abstracting; Aggregates; Computer programming languages; Reusability; Semantics; Adequacy; Computational field; CoRE calculus; Full abstraction; Spatial computing; Type inferences; Type soundness; Calculations
An epistemic strategy logic,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061250933&doi=10.1145%2f3233769&partnerID=40&md5=0984f84bfc7654f32679f9bc307871cb,"This article presents an extension of temporal epistemic logic with operators that can express quantification over agent strategies. Unlike previous work on alternating temporal epistemic logic, the semantics works with systems whose states explicitly encode the strategy being used by each of the agents. This provides a natural way to express what agents would know were they to be aware of some of the strategies being used by other agents. A number of examples that rely on the ability to express an agent's knowledge about the strategies being used by other agents are presented to motivate the framework, including reasoning about game-theoretic equilibria, knowledge-based programs, and information-theoretic computer security policies. Relationships to several variants of alternating temporal epistemic logic are discussed. The computational complexity of model checking the logic and several of its fragments are also characterized. © 2018 Association for Computing Machinery.",Computational complexity; Epistemic logic; Strategy logic,Computational complexity; Computer games; Game theory; Information theory; Knowledge based systems; Model checking; Security of data; Security systems; Semantics; Epistemic logic; Game-theoretic; Knowledge based programs; Strategy logic; Temporal epistemic logic; Computer circuits
A modular type reconstruction algorithm,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061228465&doi=10.1145%2f3234693&partnerID=40&md5=2cb3d3e122999bf77f7fa1363f724b9d,"Mmt is a framework for designing and implementing formal systems in a way that systematically abstracts from theoretical and practical aspects of their type of theoretical and logical foundations. Thus, definitions, theorems, and algorithms can be stated independently of the foundation, and language designers can focus on the essentials of a particular foundation and inherit a large-scale implementation from Mmt at low cost. Going beyond the similarly motivated approach of meta-logical frameworks, Mmt does not even commit to a particular meta-logic-that makes Mmt level results harder to obtain but also more general. We present one such result: a type reconstruction algorithm that realizes the foundation-independent aspects generically relative to a set of rules that supply the foundation-specific knowledge. Maybe surprisingly, we see that the former covers most of the algorithm, including the most difficult details. Thus, we can easily instantiate our algorithm with rule sets for several important language features including, e.g., dependent function types. Moreover, our design is modular such that we obtain a type reconstruction algorithm for any combination of these features. © 2018 Association for Computing Machinery.",Dependent types; Logical framework; MMT; Modularity; Type reconstruction,Computer science; Logic programming; Dependent functions; Dependent types; Language features; Logical foundations; Logical frameworks; Modularity; Specific knowledge; Type reconstruction; Foundations
Interval vs. point temporal logic model checking: An expressiveness comparison,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059586312&doi=10.1145%2f3281028&partnerID=40&md5=7d180102d7442204a0ad8bd9b25799b7,"                             In recent years, model checking with interval temporal logics is emerging as a viable alternative to model checking with standard point-based temporal logics, such as LTL, CTL, CTL                             ∗                             , and the like. The behavior of the system is modeled by means of (finite) Kripke structures, as usual. However, while temporal logics which are interpreted “point-wise” describe how the system evolves state-by-state, and predicate properties of system states, those which are interpreted “interval-wise” express properties of computation stretches, spanning a sequence of states. A proposition letter is assumed to hold over a computation stretch (interval) if and only if it holds over each component state (homogeneity assumption). A natural question arises: is there any advantage in replacing points by intervals as the primary temporal entities, or is it just a matter of taste? In this article, we study the expressiveness of Halpern and Shoham's interval temporal logic (HS) in model checking, in comparison with those of LTL, CTL, and CTL                             ∗                             . To this end, we consider three semantic variants of HS: the state-based one, introduced by Montanari et al. in [30, 34], that allows time to branch both in the past and in the future, the computation-tree-based one, that allows time to branch in the future only, and the trace-based variant, that disallows time to branch. These variants are compared among themselves and to the aforementioned standard logics, getting a complete picture. In particular, we show that HS with trace-based semantics is equivalent to LTL (but at least exponentially more succinct), HS with computation-tree-based semantics is equivalent to finitary CTL                             ∗                             , and HS with state-based semantics is incomparable with all of them (LTL, CTL, and CTL                             ∗                             ).                          © 2018 Association for Computing Machinery.",Expressiveness; Model checking; Nterval temporal logics,Computer circuits; Hydraulic structures; Model checking; Semantics; Component state; Computation trees; Expressiveness; Interval temporal logic; Kripke structure; Logic model checking; Standard logic; Trace-based semantics; Temporal logic
Checking admissibility using natural dualities,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059588769&doi=10.1145%2f3275115&partnerID=40&md5=53d43e85a0fe159e6052ff4b680881c8,"This article presents a new method for obtaining small algebras to check the admissibility-equivalently, validity in free algebras-of quasi-identities in a finitely generated quasivariety. Unlike a previous algebraic approach of Metcalfe and Röthlisberger, which is feasible only when the relevant free algebra is not too large, this method exploits natural dualities for quasivarieties to work with structures of smaller cardinality and surjective rather than injective morphisms. A number of case studies are described here that could not be be solved using the algebraic approach, including (quasi)varieties of MS-algebras, double Stone algebras, and involutive Stone algebras. © 2018 Association for Computing Machinery.",Admissibility; Free algebra; Natural duality; Quasivariety,Computer science; Logic programming; Admissibility; Algebraic approaches; Cardinalities; Case-studies; Free algebra; Natural duality; Quasivariety; Surjective; Algebra
Generalized Eilenberg theorem: Varieties of languages in a category,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059578831&doi=10.1145%2f3276771&partnerID=40&md5=ad4fab9fa5574e5389dbb27341778327,"For finite automata as coalgebras in a category C, we study languages they accept and varieties of such languages. This generalizes Eilenberg's concept of a variety of languages, which corresponds to choosing as C the category of Boolean algebras. Eilenberg established a bijective correspondence between pseudovarieties of monoids and varieties of regular languages. In our generalization, we work with a pair C/D of locally finite varieties of algebras that are predual, i.e., dualize on the level of finite algebras, and we prove that pseudovarieties of D-monoids bijectively correspond to varieties of regular languages in C. As one instance, Eilenberg's result is recovered by choosing D = sets and C = Boolean algebras. Another instance, Pin's result on pseudovarieties of ordered monoids, is covered by taking D = posets and C = distributive lattices. By choosing as C = D the self-predual category of join-semilattices, we obtain Polák's result on pseudovarieties of idempotent semirings. Similarly, using the self-preduality of vector spaces over a finite field K, our result covers that of Reutenauer on pseudovarieties of K-algebras. Several new variants of Eilenberg's theorem arise by taking other predualities, e.g., between the categories of non-unital Boolean rings and of pointed sets. In each of these cases, we also prove a local variant of the bijection, where a fixed alphabet is assumed and one considers local varieties of regular languages over that alphabet in the category C. © 2018 Association for Computing Machinery.",Algebraic automata theory; Bimonoids; Category theory; Coalgebra; Eilenberg's theorem,Boolean algebra; Vector spaces; Algebraic automata theories; Bimonoids; Category theory; Coalgebras; Eilenberg's theorem; C (programming language)
Proof complexity meets algebra,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059592853&doi=10.1145%2f3265985&partnerID=40&md5=b76667da68fa3808f04006eed3f72c58,"We analyze how the standard reductions between constraint satisfaction problems affect their proof complexity. We show that, for the most studied propositional, algebraic, and semialgebraic proof systems, the classical constructions of pp-interpretability, homomorphic equivalence, and addition of constants to a core preserve the proof complexity of the CSP. As a result, for those proof systems, the classes of constraint languages for which small unsatisfiability certificates exist can be characterized algebraically. We illustrate our results by a gap theorem saying that a constraint language either has resolution refutations of constant width or does not have bounded-depth Frege refutations of subexponential size. The former holds exactly for the widely studied class of constraint languages of bounded width. This class is also known to coincide with the class of languages with refutations of sublinear degree in Sums of Squares and Polynomial Calculus over the real field, for which we provide alternative proofs. We then ask for the existence of a natural proof system with good behavior with respect to reductions and simultaneously small-size refutations beyond bounded width. We give an example of such a proof system by showing that bounded-degree Lovász-Schrijver satisfies both requirements. Finally, building on the known lower bounds, we demonstrate the applicability of the method of reducibilities and construct new explicit hard instances of the graph three-coloring problem for all studied proof systems. © 2018 Association for Computing Machinery.",Constraint satisfaction problem; Gap theorems; Proof complexity; Reductions,Algebra; Calculations; Reduction; Coloring problems; Constraint language; Gap theorems; Interpretability; Polynomial calculus; Proof complexity; Resolution refutation; Sums of squares; Constraint satisfaction problems
An automatic proving approach to parameterized verification,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052329116&doi=10.1145%2f3232164&partnerID=40&md5=5750dce880d9de2962459f5c43bb2adb,"Formal verification of parameterized protocols such as cache coherence protocols is a significant challenge. In this article, we propose an automatic proving approach and its prototype paraVerifier to handle this challenge within a unified framework as follows: (1) To prove the correctness of a parameterized protocol, our approach automatically discovers auxiliary invariants and the corresponding dependency relations among the discovered invariants and protocol rules from a small instance of the to-be-verified protocol, and (2) the discovered invariants and dependency graph are then automatically generalized into a parameterized form and sent to the theorem prover, Isabelle. As a side product, the final verification result of a protocol is provided by a formal and human-readable proof. Our approach has been successfully applied to a number of benchmarks, including snoopying-based and directory-based cache coherence protocols. © 2018 Association for Computing Machinery.",Automatic verification; Cache coherence protocols; Inductive methods; Invariant and proof generation; Theorem proving,Cache memory; Formal verification; Parameterization; Automatic verification; Cache coherence protocols; Dependency relation; Inductive method; Invariant and proof generation; Parameterized verifications; Unified framework; Verification results; Theorem proving
Automated equivalence checking of concurrent quantum systems,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057207066&doi=10.1145%2f3231597&partnerID=40&md5=1885e0d5b00548523e872dd6fc7280fa,"The novel field of quantum computation and quantum information has gathered significant momentum in the last few years. It has the potential to radically impact the future of information technology and influence the development of modern society. The construction of practical, general purpose quantum computers has been challenging, but quantum cryptographic and communication devices have been available in the commercial marketplace for several years. Quantum networks have been built in various cities around the world and a dedicated satellite has been launched by China to provide secure quantum communication. Such new technologies demand rigorous analysis and verification before they can be trusted in safety- and security-critical applications. Experience with classical hardware and software systems has shown the difficulty of achieving robust and reliable implementations. We present CCSq, a concurrent language for describing quantum systems, and develop verification techniques for checking equivalence between CCSq processes. CCSq has well-defined operational and superoperator semantics for protocols that are functional, in the sense of computing a deterministic input-output relation for all interleavings arising from concurrency in the system. We have implemented QEC (Quantum Equivalence Checker), a tool that takes the specification and implementation of quantum protocols, described in CCSq, and automatically checks their equivalence. QEC is the first fully automatic equivalence checking tool for concurrent quantum systems. For efficiency purposes, we restrict ourselves to Clifford operators in the stabilizer formalism, but we are able to verify protocols over all input states. We have specified and verified a collection of interesting and practical quantum protocols, ranging from quantum communication and quantum cryptography to quantum error correction. © 2018 Association for Computing Machinery.",Concurrency; Equivalence checking; Process calculi; Programming language semantics; Quantum information processing,Equivalence classes; Error correction; Network security; Quantum computers; Quantum cryptography; Quantum optics; Semantics; Concurrency; Equivalence checking; Process calculi; Programming language semantics; Quantum-information processing; Quantum communication
Parallel cost analysis,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057212827&doi=10.1145%2f3274278&partnerID=40&md5=9b83a443d574ebe350023a5933131aa0,"This article presents parallel cost analysis, a static cost analysis targeting to over-approximate the cost of parallel execution in distributed systems. In contrast to the standard notion of serial cost, parallel cost captures the cost of synchronized tasks executing in parallel by exploiting the true concurrency available in the execution model of distributed processing. True concurrency is challenging for static cost analysis, because the parallelism between tasks needs to be soundly inferred, and the waiting and idle processor times at the different locations need to be accounted for. Parallel cost analysis works in three phases: (1) it performs a block-level analysis to estimate the serial costs of the blocks between synchronization points in the program; (2) it then constructs a distributed flow graph (DFG) to capture the parallelism, the waiting, and idle times at the locations of the distributed system; and (3) the parallel cost can finally be obtained as the path of maximal cost in the DFG. We prove the correctness of the proposed parallel cost analysis, and provide a prototype implementation to perform an experimental evaluation of the accuracy and feasibility of the proposed analysis. © 2018 Association for Computing Machinery.",Distributed systems; Resource analysis; Static analysis,Cost accounting; Flow graphs; Static analysis; Distributed processing; Distributed systems; Experimental evaluation; Parallel executions; Prototype implementations; Resource analysis; Synchronization points; True concurrency; Cost benefit analysis
Geometry of interaction for mall via Hughes-van Glabbeek proof-nets,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057153146&doi=10.1145%2f3234694&partnerID=40&md5=74db53e9e6a555fbca859d695505e6fd,"This article presents, for the first time, a Geometry of Interaction (GoI) interpretation inspired from Hughes-Van Glabbeek (HvG) proof-nets for multiplicative additive linear logic (MALL). Our GoI dynamically captures HvG's geometric correctness criterion-the toggling cycle condition-in terms of algebraic operators. Our new ingredient is a scalar extension of the ∗-algebra in Girard's ∗-ring of partial isometries over a Boolean polynomial ring with literals of eigenweights as indeterminates. To capture feedback arising from cuts, we construct a finer-grained execution formula. The expansion of this execution formula is longer than that for collections of slices for multiplicative GoI, hence it is harder to prove termination. Our GoI gives a dynamical, semantical account of Boolean valuations (in particular, pruning sub-proofs), conversion of weights (in particular, α-conversion), and additive (co)contraction, peculiar to additive proof-theory. Termination of our execution formula is shown to correspond to HvG's toggling criterion. The slice-wise restriction of our execution formula (by collapsing the Boolean structure) yields the well-known correspondence, explicit or implicit in previous works on multiplicative GoI, between the convergence of execution formulas and acyclicity of proof-nets. Feedback arising from the execution formula by restricting to the Boolean polynomial structure yields autonomous definability of eigenweights among cuts from the rest of the eigenweights. © 2018 Association for Computing Machinery.",*-algebra; Boolean polynomial ring; Change of coefficient ring; Cut-elimination; Execution formula; Geometry of interaction; Multiplicative additive linear logic; Proof-nets; Semiring of formal languages,Computer circuits; Formal languages; Geometry; Linear algebra; Polynomials; Boolean polynomial; Cut elimination; Execution formula; Geometry of Interaction; Linear logic; Proof net; Semi-ring; Boolean algebra
A simple modal logic for reasoning in multigranulation rough set model,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057147454&doi=10.1145%2f3274664&partnerID=40&md5=389946fc032714291e1000fde7dc8456,"The notions of strong/weak approximations have been studied extensively in recent years. These approximations are based on a structure of the form (W , {Ri }i ∈N ), called the multiple-source approximation system, where Ri is an equivalence relation on W , and N is an initial segment of the set N of natural numbers. We propose and explore a simple modal language and semantics that can be used to reason about the strong/weak approximations of concepts. Moreover, our study is not confined to collections of equivalence relations only, but other types of relations are also considered. This study is important, keeping in view the notions of generalized approximation spaces with relations other than equivalence. © 2018 Association for Computing Machinery.",Axiomatization; Lower and upper approximations; Modal logics; Rough set theory,Approximation algorithms; Formal logic; Semantics; Approximation spaces; Axiomatization; Equivalence relations; Lower and upper approximations; Modal logic; Multigranulation rough set models; Multiple source; Types of relations; Rough set theory
Some subsystems of constant-depth frege with parity,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057166384&doi=10.1145%2f3243126&partnerID=40&md5=47f1dc3ebc3b9dfa7a9f9fa0ac2f495b,"We consider three relatively strong families of subsystems of AC0[2]-Frege proof systems, i.e., propositional proof systems using constant-depth formulas with an additional parity connective, for which exponential lower bounds on proof size are known. In order of increasing strength, the subsystems are (i) constant-depth proof systems with parity axioms and the (ii) treelike and (iii) daglike versions of systems introduced by Krajíček which we call PKd c (). In a PKd c ()-proof, lines are disjunctions (cedents) in which all disjuncts have depth at most d, parities can only appear as the outermost connectives of disjuncts, and all but c disjuncts contain no parity connective at all. We prove that treelike PKO O ( ( 1 1 ) )() is quasipolynomially but not polynomially equivalent to constant-depth systems with parity axioms. We also verify that the technique for separating parity axioms from parity connectives due to Impagliazzo and Segerlind can be adapted to give a superpolynomial separation between daglike PKO O ( ( 1 1 ) )() and AC0[2]-Frege; the technique is inherently unable to prove superquasipolynomial separations. We also study proof systems related to the system Res-Lin introduced by Itsykson and Sokolov. We prove that an extension of treelike Res-Lin is polynomially simulated by a system related to daglike PKO O ( ( 1 1 ) )(), and obtain an exponential lower bound for this system. © 2018 Association for Computing Machinery.",Constant-depth Frege; Counting axioms; Modular counting; Propositional proof complexity,Separation; Constant-depth Frege; Counting axioms; Frege proofs; Lower bounds; Modular counting; Proof system; Propositional proof complexity; Propositional proof systems; Forestry
An operational semantics for the cognitive architecture ACT-R and its translation to constraint handling rules,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053893914&doi=10.1145%2f3218818&partnerID=40&md5=a0645b4a8f4a2de966eab9d808226985,"Computational psychology has the aim to explain human cognition by computational models of cognitive processes. The cognitive architecture Adaptive Control of Thought-Rational (ACT-R) is popular to develop such models. Although ACT-R has a well-defined psychological theory and has been used to explain many cognitive processes, there are two problems that make it hard to reason formally about its cognitive models: First, ACT-R lacks a computational formalization of its underlying production rule system, and, second, there are many different implementations and extensions of ACT-R with many technical artifacts complicating formal reasoning even more. This article describes a formal operational semantics-the very abstract semantics-that abstracts from as many technical details as possible, keeping it open to extensions and different implementations of the ACT-R theory. In a second step, this semantics is refined to define some of its abstract features that are found in many implementations of ACT-R-called the abstract semantics. It concentrates on the procedural core of ACT-R and is suitable for analysis of the general transition system, since it still abstracts from details like timing, the sub-symbolic layer of ACT-R or conflict resolution. Furthermore, a translation of ACT-R models to the declarative programming language Constraint Handling Rules (CHR) is defined. This makes the abstract semantics an executable specification of ACT-R. CHR has been used successfully to embed other rule-based formalisms like graph transformation systems or functional programming. There are many theoretical results and practical tools that support formal reasoning about and analysis of CHR programs. The translation of ACT-R models to CHR is proven sound and complete w.r.t. the abstract operational semantics of ACT-R. This paves the way to analysis of ACT-R models through CHR analysis results and tools. Therefore, to the best of our knowledge, our abstract semantics is the first abstract formulation of ACT-R suitable for both analysis and execution. © 2018 ACM.",ACT-R; Computational cognitive modeling; Constraint Handling Rules; Operational semantics; Source to source transformation,Abstracting; Cognitive systems; Computation theory; Computer programming languages; Functional programming; Program translators; ACT-R; Computational cognitive modeling; Constraint Handling Rules; Operational semantics; Source-to-source transformations; Semantics
Hierarchies in inclusion logic with lax semantics,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053893514&doi=10.1145%2f3204521&partnerID=40&md5=a10029c6f61823002d740ca945013747,"We study the expressive power of fragments of inclusion logic under the so-called lax team semantics. The fragments are defined either by restricting the number of universal quantifiers, the number of inclusion atoms, or the arity of inclusion atoms. We show that the whole expressive power of inclusion logic can be captured using only five inclusion atoms in finite ordered models or, alternatively, only one universal quantifier in general. The arity hierarchy is shown to be strict by relating the question to the study of arity hierarchies in fixed point logics. © 2018 ACM.",Dependence; Descriptive complexity; Hierarchy; Inclusion; Independence; Team semantics,Atoms; Inclusions; Semantics; Dependence; Descriptive complexity; Expressive power; Fixed-point logic; Hierarchy; Independence; Ordered models; Universal quantifiers; Computer circuits
Relating paths in transition systems: The fall of the modal mu-calculus,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053871925&doi=10.1145%2f3231596&partnerID=40&md5=d3b86b4460fe1feb1f401a174285b0f1,"We revisit Janin and Walukiewicz's classic result on the expressive completeness of the modal mu-calculus with respect to Monadic Second Order Logic (MSO), which is where the mu-calculus corresponds precisely to the fragment of MSO that is invariant under bisimulation. We show that adding binary relations over finite paths in the picture may alter the situation. We consider a general setting where finite paths of transition systems are linked by means of a fixed binary relation. This setting gives rise to natural extensions of MSO and the mu-calculus, that we call the MSO with paths relation and the jumping mu-calculus, the expressivities of which we aim at comparing. We first show that “bounded-memory” binary relations bring about no additional expressivity to either of the two logics, and thus preserve expressive completeness. In contrast, we show that for a natural, classic “infinite-memory” binary relation stemming from games with imperfect information, the existence of a winning strategy in such games, though expressible in the bisimulation-invariant fragment of MSO with paths relation, cannot be expressed in the jumping mu-calculus. Expressive completeness thus fails for this relation. These results crucially rely on our observation that the jumping mu-calculus has a tree automata counterpart: the jumping tree automata, hence the name of the jumping mu-calculus. We also prove that for observable winning conditions, the existence of winning strategies in games with imperfect information is expressible in the jumping mu-calculus. Finally, we derive from our main theorem that jumping automata cannot be projected, and ATL with imperfect information does not admit expansion laws. © 2018 ACM.",Expressiveness; Imperfect information; Monadic second order logic; Mu-calculus; Transition systems,Automata theory; Computer circuits; Forestry; Temporal logic; Expressiveness; Imperfect information; Monadic second-order logic; Mu-calculus; Transition system; Calculations
Automated deduction in Gödel logic,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053209871&doi=10.1145%2f3218817&partnerID=40&md5=233ddd3986e5dc57b58a1c0da8f80b9e,"This article addresses the deduction problem of a formula from a countable theory in the first-order Godel logic. We generalise the well-known hyperresolution principle for deduction in Godel logic. Our approach is based on translation of a formula to an equivalent satisfiable finite order clausal theory, consisting of order clauses. We introduce a notion of quantified atom: a formula a is a quantified atom if a = Qx p(t0, ⋯, tn), where Q is a quantifier (∀, ∃), p(t0, ⋯, tn) is an atom, and x is a variable occurring in p(t0, ⋯, tn); for all i ≤ n, either ti = x or x does not occur in ti. Then an order clause is a finite set of order literals of the form ϵ1 ⋄ ϵ2, where ϵi is either an atom, or a truth constant (0, 1), or a quantified atom, and ⋄ is either a connective =, equality, or ≺; strict order. = and ≺ are interpreted by the equality and standard strict linear order on [0, 1], respectively. On the basis of the hyperresolution principle, a calculus operating over order clausal theories is devised. The calculus is proved to be refutation sound and complete for the countable case. As an interesting consequence, we get an affirmative solution to the open problem of recursive enumerability of unsatisfiable formulae in Godel logic. © 2018 ACM.",Computational complexity; Hyperresolution; Many-valued logics,Atoms; Calculations; Computational complexity; Computer circuits; Theorem proving; Automated deduction; Finite order; Finite set; First order; Hyper-resolution; Linear order; Sound and complete; Strict orderings; Many valued logics
Minkowski Games,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053185562&doi=10.1145%2f3230741&partnerID=40&md5=c0f2bd371a73212b940c5782f9356e6b,"We introduce and study Minkowski games. These are two-player games, where the players take turns to choose positions in ℝd based on some rules. Variants include boundedness games, where one player wants to keep the positions bounded, and the other wants to escape to infinity; as well as safety games, where one player wants to stay within a prescribed set, while the other wants to leave it. We provide some general characterizations of which player can win such games and explore the computational complexity of the associated decision problems. A natural representation of boundedness games yields coNP-completeness, whereas the safety games are undecidable. © 2018 ACM.",(stochastic) determinacy; CoNPcomplete; Control in ℝ<sup>d</sup>                         ; Polytopic/arbitrary; Undecidable,Stochastic systems; (stochastic) determinacy; CoNPcomplete; Decision problems; Escape to infinities; Natural representation; Polytopic/arbitrary; Two-player games; Undecidable; Game theory
Interaction graphs: Non-deterministic automata,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053205212&doi=10.1145%2f3226594&partnerID=40&md5=0c9a58ae85d7a3559e1e853cf460f967,"This article exhibits a series of semantic characterisations of sublinear nondeterministic complexity classes. These results fall into the general domain of logic-based approaches to complexity theory and so-called implicit computational complexity (icc), i.e., descriptions of complexity classes without reference to specific machine models. In particular, it relates strongly to icc results based on linear logic, since the semantic framework considered stems from work on the latter. Moreover, the obtained characterisations are of a geometric nature: each class is characterised by a specific action of a group by measure-preserving maps. © 2018 ACM.",Automata; Dynamic semantics; Implicit computational complexity; Interaction graphs; Linear logic; Measurable dynamics,Automata theory; Computational complexity; Linear algebra; Semantics; Automata; Dynamic semantic; Implicit computational complexity; Interaction graphs; Linear logic; Computer circuits
Incremental Linearization for satisfiability and verification modulo nonlinear arithmetic and transcendental functions,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053184581&doi=10.1145%2f3230639&partnerID=40&md5=90a4e643fd2b247506efac90f7cfe9db,"Satisfiability Modulo Theories (SMT) is the problem of deciding the satisfiability of a first-order formula with respect to some theory or combination of theories; Verification Modulo Theories (VMT) is the problem of analyzing the reachability for transition systems represented in terms of SMT formulae. In this article, we tackle the problems of SMT and VMT over the theories of nonlinear arithmetic over the reals (NRA) and of NRA augmented with transcendental (exponential and trigonometric) functions (NTA). We propose a new abstraction-refinement approach for SMT and VMT on NRA or NTA, called Incremental Linearization. The idea is to abstract nonlinear multiplication and transcendental functions as uninterpreted functions in an abstract space limited to linear arithmetic on the rationals with uninterpreted functions. The uninterpreted functions are incrementally axiomatized by means of upper- and lower-bounding piecewiselinear constraints. In the case of transcendental functions, particular care is required to ensure the soundness of the abstraction. The method has been implemented in the MathSAT SMT solver and in the nuXmv model checker. An extensive experimental evaluation on a wide set of benchmarks from verification and mathematics demonstrates the generality and the effectiveness of our approach. © 2018 ACM.",Formal verification; Nonlinear arithmetic; Satisfiability modulo theories; SMT; Symbolic computation; Transcendental functions,Abstracting; Formal verification; Linearization; Model checking; Surface mount technology; Abstraction refinement; Experimental evaluation; First-order formulas; Satisfiability modulo Theories; Symbolic computation; Transcendental functions; Transition system; Uninterpreted Functions; Rational functions
Game-theoretic semantics for alternating-time temporal logic,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053222941&doi=10.1145%2f3179998&partnerID=40&md5=ba2956e6e4a03935c37dc5cd65e17d73,"We introduce several versions of game-theoretic semantics (GTS) for Alternating-Time Temporal Logic (ATL). In GTS, truth is defined in terms of existence of a winning strategy in a semantic evaluation game. Thus, the game-theoretic perspective appears in the framework of ATL on two semantic levels: on the object level in the standard semantics of the strategic operators and on the meta-level, where game-theoretic logical semantics is applied to ATL. We unify these two perspectives into semantic evaluation games specially designed for ATL. The game-theoretic perspective enables us to identify new variants of the semantics of ATL based on limiting the time resources available to the verifier and falsifier in the semantic evaluation game. We introduce and analyze an unbounded and (ordinal) bounded GTS and prove these to be equivalent to the standard (Tarski-style) compositional semantics. We show that, in bounded GTS, truth of ATL formulae can always be determined in finite time, that is, without constructing infinite paths. We also introduce a nonequivalent finitely bounded semantics and argue that it is natural from both logical and game-theoretic perspectives. © 2018 ACM.",Argumentation-based dialogue and protocols; Logic and game theory; Logics for agents and multiagent systems,Computer circuits; Multi agent systems; Semantics; Temporal logic; Alternating time temporal logic; Compositional semantics; Game-theoretic; Game-theoretic perspectives; Logical semantics; Semantic evaluations; Semantic levels; Winning strategy; Game theory
Quantitative aspects of linear and affine closed lambda terms,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061195240&doi=10.1145%2f3173547&partnerID=40&md5=696774b43a18f7adfb4aaf5aa49dbd83,"Affine λ-terms are λ-terms in which each bound variable occurs at most once, and linear λ-terms are λ-terms in which each bound variable occurs once and only once. In this article, we count the number of affine closed λ-terms of size n, linear closed λ-terms of size n, affine closed β-normal forms of size n, and linear closed β-normal forms of size n, for several measures of the size of λ-terms. From these formulas, we show how we can derive programs for generating all the terms of size n for each class. The foundation of all of this is a specific data structure, made of contexts in which one counts all the holes at each level of abstractions by λ's. © 2018 ACM.",Combinatorics; Functional programming; Lambda calculus,Calculations; Differentiation (calculus); Bound variables; Combinatorics; Lambda calculus; Lambda terms; Level of abstraction; Normal form; Functional programming
Path categories and propositional identity types,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061198262&doi=10.1145%2f3204492&partnerID=40&md5=0ddb69cba438ef1d6eb36f313fd8912d,"Connections between homotopy theory and type theory have recently attracted a lot of attention, with Voevodsky's univalent foundations and the interpretation of Martin-Löf's identity types in Quillen model categories as some of the highlights. In this article, we establish a connection between a natural weakening of Martin-Löf's rules for the identity types that has been considered by Cohen, Coquand, Huber and Mörtberg in their work on a constructive interpretation of the univalence axiom on the one hand and the notion of a path category, a slight variation on the classic notion of a category of fibrant objects due to Brown, on the other. This involves showing that the syntactic category associated to a type theory with weak identity types carries the structure of a path category, strengthening earlier results by Avigad, Lumsdaine, and Kapulkin. In this way, we not only relate a well-known concept in homotopy theory with a natural concept in logic but also provide a framework for further developments. © 2018 ACM.",Categorical logic; Homotopy theory; Type theory,Formal languages; Syntactics; Topology; Categorical logic; Further development; Homotopy theory; Type theory; Computer circuits
Modular labelled sequent calculi for abstract separation logics,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061143859&doi=10.1145%2f3197383&partnerID=40&md5=398ed1205d8cb8df3e234735ea9fc40b,"Separation logics are a family of extensions of Hoare logic for reasoning about programs that manipulate resources such as memory locations. These logics are ""abstract"" because they are independent of any particular concrete resource model. Their assertion languages, called Propositional Abstract Separation Logics (PASLs), extend the logic of (Boolean) Bunched Implications (BBI) in various ways. In particular, these logics contain the connectives ∗ and -∗, denoting the composition and extension of resources, respectively. This added expressive power comes at a price, since the resulting logics are all undecidable. Given their wide applicability, even a semi-decision procedure for these logics is desirable. Although several PASLs and their relationships with BBI are discussed in the literature, the proof theory of, and automated reasoning for, these logics were open problems solved by the conference version of this article, which developed a modular proof theory for various PASLs using cut-free labelled sequent calculi. This paper non-trivially improves upon this previous work by giving a general framework of calculi on which any new axiom in the logic satisfying a certain form corresponds to an inference rule in our framework, and the completeness proof is generalised to consider such axioms. Our base calculus handles Calcagno et al.'s original logic of separation algebras by adding sound rules for partial-determinism and cancellativity, while preserving cut-elimination. We then show that many important properties in separation logic, such as indivisible unit, disjointness, splittability, and cross-split, can be expressed in our general axiom form. Thus, our framework offers inference rules and completeness for these properties for free. Finally, we show how our calculi reduce to calculi with global label substitutions, enabling more efficient implementation. © 2018 ACM.",Abstract separation logics; Automated reasoning; Bunched implications; Counter-model construction; Labelled sequent calculus,Abstracting; Biomineralization; Calculations; Differentiation (calculus); Pathology; Separation; Automated reasoning; Bunched implications; Counter-models; Separation logic; Sequent calculus; Computer circuits
Hypersequents and Systems of Rules,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081144635&doi=10.1145%2f3180075&partnerID=40&md5=3a4bc8ac1acbd6ace7e1262948a48af8,"We define a bi-directional embedding between hypersequent calculi and a subclass of systems of rules (2-systems). In addition to showing that the two proof frameworks have the same expressive power, the embedding allows for the recovery of the benefits of locality for 2-systems, analyticity results for a large class of such systems, and a rewriting of hypersequent rules as natural deduction rules. © 2018 ACM.",embedding between formalisms; Hypersequents; intermediate logics; natural deduction; systems of rules,Biomineralization; Analyticity; Bi-directional; Expressive power; Hypersequents; Natural deduction; Embeddings
Syntax-preserving belief change operators for logic programs,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061192032&doi=10.1145%2f3190783&partnerID=40&md5=f85ea2e0bcc3bd747af33198d399e952,"Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results. We address this shortcoming of existing approaches by introducing partial meet and ensconcement constructions for logic program belief change, which allowus to define syntax-preserving operators for satisfying preservation and support. Our work is novel in that our constructions not only preserve more information from a logic program during a change operation than existing ones, but they also facilitate natural definitions of contraction operators, the first in the field to the best of our knowledge. To evaluate the rationality of our operators, we translate the revision and contraction postulates from the AGM and belief base frameworks to the logic programming setting. We show that our operators fully comply with the belief base framework and formally state the interdefinability between our operators. We further compare our approach to two state-of-the-art logic program revision methods and demonstrate that our operators address the shortcomings of one and generalise the other method. © 2018 ACM.",Answer set; Belief change; Logic program; Strong equivalence,Computer circuits; Semantics; Syntactics; Answer set; Belief change; Belief revision; Change operations; Logic programs; Purely semantic; Strong equivalence; Syntax-preserving; Logic programming
Finite satisfiability of the two-variable guarded fragment with transitive guards and related variants,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042549341&doi=10.1145%2f3174805&partnerID=40&md5=166ffb39458937a3463fdea392256d11,"We consider extensions of the two-variable guarded fragment, GF2, where distinguished binary predicates that occur only in guards are required to be interpreted in a special way (as transitive relations, equivalence relations, preorders, or partial orders). We prove that the only fragment that retains the finite (exponential) model property is GF2 with equivalence guards without equality. For remaining fragments, we show that the size of a minimal finite model is at most doubly exponential. To obtain the result, we invent a strategy of building finite models that are formed from a number of multidimensional grids placed over a cylindrical surface. The construction yields a 2-NExpTime upper bound on the complexity of the finite satisfiability problem for these fragments. We improve the bounds and obtain optimal ones for all the fragments considered, in particular NExpTime for GF2 with equivalence guards, and 2-ExpTime for GF2 with transitive guards. To obtain our results, we essentially use some results from integer programming. © 2018 ACM.",Computational complexity; Equivalence relation; Finite satisfiability problem; Guarded fragment; Transitive relation; Two-variable logic,Computational complexity; Integer programming; Set theory; Equivalence relations; Finite satisfiability; Guarded fragment; Transitive relation; Two-variable logic; Formal logic
Compositional synthesis of piece-wise functions by learning classifiers,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061210337&doi=10.1145%2f3173545&partnerID=40&md5=f18226c90701019bd090d2556b31ca82,"We present a novel general technique that uses classifier learning to synthesize piece-wise functions (functions that split the domain into regions and apply simpler functions to each region) against logical synthesis specifications. Our framework works by combining a synthesizer of functions for fixed concrete inputs and a synthesizer of predicates that can be used to define regions. We develop a theory of single-point refutable specifications that facilitate generating concrete counterexamples using constraint solvers. We implement the framework for synthesizing piece-wise functions in linear integer arithmetic, combining leaf expression synthesis using constraint-solving with predicate synthesis using enumeration, and tie them together using a decision tree classifier.We demonstrate that this compositional approach is competitive compared to existing synthesis engines on a set of synthesis specifications. © 2018 ACM.",Constraint solving; Counterexamples; Machine learning; Piece-wise functions; Program synthesis,Codes (symbols); Concretes; Decision trees; Learning systems; Specifications; Classifier learning; Compositional synthesis; Constraint Solving; Counterexamples; Expression synthesis; Learning classifiers; Piece-wise; Program synthesis; Logic programming
Finite-state map-reduce computation and relational algebra queries,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061215809&doi=10.1145%2f3197384&partnerID=40&md5=265f854d377e5e636f409f7093a53355,"We introduce three formal models of distributed systems for query evaluation on massive databases: Distributed Streaming with Register Automata (DSAs), Distributed Streaming with Register Transducers (DSTs), and Distributed Streaming with Register Transducers and Joins (DSTJs). These models are based on the mapreduce paradigm where the input is transformed into a dataset of key-value pairs, and on each key a local computation is performed on the values associated with that key resulting in another set of key-value pairs. Computation proceeds in a constant number of rounds, where the result of the last round is the input to the next round, and transformation of key-value pairs is required to be generic. The difference between the three models is in the local computation part. In DSAs it is limited to making one pass over its input using a register automaton, while in DSTs it can make two passes: in the first pass it uses a finite state automaton and in the second it uses a register transducer. The third model DSTJs is an extension of DSTs, where local computations are capable of constructing the Cartesian product of two sets. We obtain the following results: (1) DSAs can evaluate first-order queries over bounded degree databases; (2) DSTs can evaluate semijoin algebra queries over arbitrary databases; (3) DSTJs can evaluate the whole relational algebra over arbitrary databases; (4) DSTJs are strictly stronger than DSTs, which in turn are strictly stronger than DSAs; (5) within DSAs, DSTs, and DSTJs, there is a strict hierarchy w.r.t. the number of rounds. © 2018 ACM.",Map-reduce computation; Query processing; Relational algebra; Semijoin algebra,Distributed database systems; Query processing; Transducers; Cartesian Products; Distributed streaming; Distributed systems; Key-value pairs; Local computation; Map-reduce; Query evaluation; Relational algebra; Algebra
Subatomic proof systems: Splittable systems,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042515848&doi=10.1145%2f3173544&partnerID=40&md5=48e160a257f2edf2fdf7579a5da2da73,"This article presents the first in a series of results that allow us to develop a theory providing finer control over the complexity of normalization, and in particular of cut elimination. By considering atoms as self-dual noncommutative connectives, we are able to classify a vast class of inference rules in a uniform and very simple way. This allows us to define simple conditions that are easily verifiable and that ensure normalization and cut elimination by way of a general theorem. In this article, we define and consider splittable systems, which essentially make up a large class of linear logics, including Multiplicative Linear Logic and BV, and we prove for them a splitting theorem, guaranteeing cut elimination and other admissibility results as corollaries. In articles to follow, we will extend this result to nonlinear logics. The final outcome will be a comprehensive theory giving a uniform treatment for most existing logics and providing a blueprint for the design of future proof systems. 2018 Copyright is held by the owner,author's.",Cut-elimination; Deep inference; Normalisation; Subatomic proof systems,Logic programming; Cut elimination; Deep inference; Future proofs; Inference rules; Multiplicative linear logic; Non-commutative; Normalisation; Proof system; Computer science
Typed nominal rewriting,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042514513&doi=10.1145%2f3161558&partnerID=40&md5=a4aae218e97f94a4a8a30c7ed979e436,"Nominal terms extend first-order terms with nominal features and as such constitute a meta-language for reasoning about the named variables of an object language in the presence of meta-level variables. This article introduces a number of type systems for nominal terms of increasing sophistication and demonstrates their application in the areas of rewriting and equational reasoning. Two simple type systems inspired by Church’s simply typed lambda calculus are presented where only well-typed terms are considered to exist, over which α-equivalence is then axiomatised. The first requires atoms to be strictly annotated whilst the second explores the consequences of a more relaxed de Bruijn-style approach in the presence of atom-capturing substitution. A final type system of richer ML-like polymorphic types is then given in the style of Curry, in which elements of the term language are deemed typeable or not only subsequent to the definition of alpha-equivalence. Principal types are shown to exist and an inference algorithm given to compute them. This system is then used to define two presentations of typed nominal rewriting, one more expressive and one more efficient, the latter also giving rise to a notion of typed nominal equational reasoning. © 2018 ACM.",Nominal rewriting; Nominal syntax,Calculations; Differentiation (calculus); Alpha-equivalence; Equational reasoning; Inference algorithm; Nominal feature; Nominal rewriting; Nominal syntax; Polymorphic types; Simply typed lambda calculus; Inference engines
Characterisation of normalisation properties for λμ using strict negated intersection types,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042495231&doi=10.1145%2f3149823&partnerID=40&md5=d302303ac5baeb3121f207909cb5bc0f,"We show characterisation results for normalisation, head-normalisation, and strong normalisation for λμ using intersection types. We reach these results for a strict notion of type assignment for λμ that is the natural restriction of the domain-based system of van Bakel et al. (2011) for λμ by limiting the type inclusion relation to just intersection elimination. We show that this system respects βμ-equality, by showing both soundness and completeness results. We then define a notion of reduction on derivations that corresponds to cut-elimination, and show that this is strongly normalisable. We use this strong normalisation result to show an approximation result, and through that a characterisation of head-normalisation. Using the approximation result, we show that there is a very strong relation between the system of van Bakel et al. (2011) and ours. We then introduce a notion of type assignment that eliminates ω as an assignable type, and show, using the strong normalisation result for derivation reduction, that all terms typeable in this system are strongly normalisable as well, and show that all strongly normalisable terms are typeable. © 2018 ACM.",Intersection types; Lambda-mu calculus; Normalisation; Semantics,Calculations; Semantics; Temporal logic; Approximation results; Cut elimination; Inclusion relation; Intersection types; Lambda-mu calculus; Normalisation; Soundness and completeness; Characterization
Completeness of flat coalgebraic fixpoint logics,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042501267&doi=10.1145%2f3157055&partnerID=40&md5=c1d14942feee584e8be7216fe3cc16b5,"Modal fixpoint logics traditionally play a central role in computer science, in particular in artificial intelligence and concurrency. The μ-calculus and its relatives are among the most expressive logics of this type. However, popular fixpoint logics tend to trade expressivity for simplicity and readability and in fact often live within the single variable fragment of the μ-calculus. The family of such flat fixpoint logics includes, e.g., Linear Temporal Logic (LTL), Computation Tree Logic (CTL), and the logic of common knowledge. Extending this notion to the generic semantic framework of coalgebraic logic enables covering a wide range of logics beyond the standard μ-calculus including, e.g., flat fragments of the graded μ-calculus and the alternating-time μ-calculus (such as alternating-time temporal logic), as well as probabilistic and monotone fixpoint logics. We give a generic proof of completeness of the Kozen-Park axiomatization for such flat coalgebraic fixpoint logics. © 2018 ACM.",Algebraic semantics; Alternating-time temporal logic; Branching-time temporal logics; Coalgebraic logic; Completeness; Graded μ-calculus; Kozen/Park axioms,Calculations; Computation theory; Computer circuits; Formal logic; Semantics; Algebraic semantic; Alternating time temporal logic; Coalgebraic logic; Completeness; Kozen/Park axioms; Temporal logic
Definability of cai-fürer-immerman problems in choiceless polynomial time,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042524762&doi=10.1145%2f3154456&partnerID=40&md5=33632e03ebadfb717077fdbc98a31fb0,"Choiceless Polynomial Time (CPT) is one of the most promising candidates in the search for a logic capturing Ptime. The question whether there is a logic that expresses exactly the polynomial-time computable properties of finite structures, which has been open for more than 30 years, is one of the most important and challenging problems in finite model theory. The strength of Choiceless Polynomial Time is its ability to perform isomorphism-invariant computations over structures, using hereditarily finite sets as data structures. But, because of isomorphism-invariance, it is choiceless in the sense that it cannot select an arbitrary element of a set—an operation that is crucial for many classical algorithms. CPT can define many interesting Ptime queries, including (a certain version of) the Cai-Fürer-Immerman (CFI) query. The CFI-query is particularly interesting, because it separates fixed-point logic with counting from Ptime and has since remained the main benchmark for the expressibility of logics within Ptime. The CFI-construction associates with each connected graph a set of CFI-graphs that can be partitioned into exactly two isomorphism classes called odd and even CFI-graphs. The problem is to decide, given a CFI-graph, whether it is odd or even. For the case where the CFI-graphs arise from ordered graphs, Dawar, Richerby, and Rossman proved that the CFI-query is CPT-definable. However, definability of the CFI-query over general graphs remains open. Our first contribution generalises the result by Dawar, Richerby, and Rossman to the variant of the CFI-query derived from graphs with colour classes of logarithmic size, instead of colour class size one. Second, we consider the CFI-query over graph classes where the maximal degree is linear in the size of the graphs. For the latter, we establish CPT-definability using only sets of small, constant rank, which is known to be impossible for the general case. In our CFI-recognising procedures we strongly make use of the ability of CPT to create sets, rather than tuples only, and we further prove that, if CPT worked over tuples instead, then no such procedure would be definable. We introduce a notion of “sequencelike objects” based on the structure of the graphs’ symmetry groups, and we show that no CPT-program that only uses sequencelike objects can decide the CFI-query over complete graphs, which have linear maximal degree. From a broader perspective, this generalises a result by Blass, Gurevich, and van den Bussche about the power of isomorphism-invariant machine models (for polynomial time) to a setting with counting. © 2018 ACM.",Cai-Fürer-Immerman; Choiceless polynomial time; Descriptive complexity; Finite model theory; Logic for PTIME,Computer circuits; Graph theory; Polynomial approximation; Polynomials; Set theory; Descriptive complexity; Finite model theory; Finite structures; Fixed-point logic; Isomorphism class; Logic for PTIME; Polynomial-time; Symmetry groups; Graphic methods
Complexity of propositional logics in team semantic,2018,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042515773&doi=10.1145%2f3157054&partnerID=40&md5=a8680a1399a28423d099b2d4bcc407ed,"We classify the computational complexity of the satisfiability, validity, and model-checking problems for propositional independence, inclusion, and team logic. Our main result shows that the satisfiability and validity problems for propositional team logic are complete for alternating exponential-time with polynomially many alternations. © 2018 ACM.",Dependence; Inclusion; Independence; Model checking; Propositional logic; Satisfiability; Team semantics; Validity,Computer circuits; Inclusions; Model checking; Semantics; Dependence; Independence; Propositional logic; Satisfiability; Validity; Formal logic
Succinctness of order-invariant logics on depth-bounded structures,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041453414&doi=10.1145%2f3152770&partnerID=40&md5=c7feb2652883e52c33c45f34656f5155,"We study the expressive power and succinctness of order-invariant sentences of first-order (FO) and monadic second-order (MSO) logic on structures of bounded tree-depth. Order-invariance is undecidable in general and, thus, one strives for logics with a decidable syntax that have the same expressive power as orderinvariant sentences. We show that on structures of bounded tree-depth, order-invariant FO has the same expressive power as FO. Our proof technique allows for a fine-grained analysis of the succinctness of this translation. We show that for every order-invariant FO sentence there exists an FO sentence whose size is elementary in the size of the original sentence, and whose number of quantifier alternations is linear in the tree-depth.We obtain similar results for MSO. It is known that the expressive power of MSO and FO coincide on structures of bounded tree-depth.We provide a translation from MSO to FO and we show that this translation is essentially optimal regarding the formula size. As a further result, we show that order-invariant MSO has the same expressive power as FO with modulo-counting quantifiers on bounded tree-depth structures.",Expressivity; First-order logic; Monadic second-order logic; Orderinvariance; Succinctness; Tree-depth,Computer circuits; Formal logic; Expressivity; First order logic; Monadic second-order logic; Orderinvariance; Succinctness; Tree-depth; Forestry
Nested weighted automata,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041464969&doi=10.1145%2f3152769&partnerID=40&md5=dfad23530d022d1240e0de880c7c570c,"Recently there has been a significant effort to handle quantitative properties in formal verification and synthesis. While weighted automata over finite and infinite words provide a natural and flexible framework to express quantitative properties, perhaps surprisingly, some basic system properties such as average response time cannot be expressed using weighted automata or in any other known decidable formalism. In this work, we introduce nested weighted automata as a natural extension of weighted automata, which makes it possible to express important quantitative properties such as average response time. In nested weighted automata, a master automaton spins off and collects results from weighted slave automata, each of which computes a quantity along a finite portion of an infinite word. Nested weighted automata can be viewed as the quantitative analogue of monitor automata, which are used in runtime verification. We establish an almost-complete decidability picture for the basic decision problems about nested weighted automata and illustrate their applicability in several domains. In particular, nested weighted automata can be used to decide average response time properties. © 2017 ACM.",Model measuring; Nested automata; Quantitative properties; Weighted automata,Computability and decidability; Formal verification; Decision problems; Flexible framework; Natural extension; Nested automata; Quantitative properties; Run-time verification; Time properties; Weighted automata; Automata theory
Information flow under budget constraints,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041485957&doi=10.1145%2f3152768&partnerID=40&md5=f1438e4e17856206720ed7346df1acb2,"Although first proposed in the database theory as properties of functional dependencies between attributes, Armstrong's axioms capture general principles of information flow by describing properties of dependencies between sets of pieces of information. This article generalizes Armstrong's axioms to a setting in which there is a cost associated with information. The proposed logical system captures general principles of dependencies between pieces of information constrained by a given budget. © 2017 ACM.",Armstrong's axioms; Axiomatization; Budget constraints; Completeness,Computer science; Logic programming; Armstrong's axioms; Axiomatization; Budget constraint; Completeness; Data base theory; Functional dependency; Information flows; Logical system; Budget control
Are short proofs narrow? QBF resolution is not so simple,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040044449&doi=10.1145%2f3157053&partnerID=40&md5=ef8526e3c628442f254bc70c8ff36393,"The ground-breaking paper ""Short Proofs Are Narrow- ResolutionMade Simple"" by Ben-Sasson and Wigderson (J. ACM 2001) introduces what is today arguably the main technique to obtain resolution lower bounds: to show a lower bound for the width of proofs. Another important measure for resolution is space, and in their fundamental work, Atserias and Dalmau (J. Comput. Syst. Sci. 2008) show that lower bounds for space again can be obtained via lower bounds for width. In this article, we assess whether similar techniques are effective for resolution calculi for quantified Boolean formulas (QBFs). There are a number of different QBF resolution calculi like Q-resolution (the classical extension of propositional resolution to QBF) and the more recent calculi ?Exp+Res and IR-calc. For these systems, a mixed picture emerges. Our main results show that the relations both between size and width and between space and width drastically fail in Q-resolution, even in its weaker tree-like version. On the other hand, we obtain positive results for the expansion-based resolution systems ?Exp+Res and IR-calc, however, only in the weak tree-like models. Technically, our negative results rely on showing width lower bounds together with simultaneous upper bounds for size and space. For our positive results, we exhibit space and width-preserving simulations between QBF resolution calculi. 2017 Copyright © is held by the owner/author(s).",Lower bound techniques; Proof complexity; QBF; Resolution; Simulations,Biomineralization; Boolean algebra; Forestry; Optical resolving power; Pathology; Lower bound techniques; Lower bounds; Proof complexity; Propositional resolution; Quantified Boolean formulas; Resolution systems; Simulations; Upper Bound; Boolean functions
One hierarchy spawns another: Graph deconstructions and the complexity classification of conjunctive queries,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041481935&doi=10.1145%2f3143805&partnerID=40&md5=9a4561dc87ee320c9269c6f4663d91e7,"We study the problem of conjunctive query evaluation relative to a class of queries. This problem is formulated here as the relational homomorphism problem relative to a class of structures A, in which each instance must be a pair of structures such that the first structure is an element of A. We present a comprehensive complexity classification of these problems, which strongly links graph-theoretic properties of A to the complexity of the corresponding homomorphism problem. In particular, we define a binary relation on graph classes, which is a preorder, and completely describe the resulting hierarchy given by this relation. This relation is defined in terms of a notion that we call graph deconstruction and that is a variant of the well-known notion of tree decomposition. We then use this hierarchy of graph classes to infer a complexity hierarchy of homomorphism problems that is comprehensive up to a computationally very weak notion of reduction, namely, a parameterized version of quantifier-free, first-order reduction. In doing so, we obtain a significantly refined complexity classification of homomorphism problems as well as a unifying, modular, and conceptually clean treatment of existing complexity classifications. We then present and develop the theory of Ehrenfeucht-Fraussu-style pebble games, which solve the homomorphism problems where the cores of the structures in A have bounded tree depth. This condition characterizes those classical homomorphism problems decidable in logarithmic space, assuming a hypothesis from parameterized space complexity. Finally, we use our framework to classify the complexity of model checking existential sentences having bounded quantifier rank. © 2017 ACM.",,Forestry; Graph theory; Model checking; Query languages; Trees (mathematics); Binary relation; Complexity hierarchies; Conjunctive queries; Existential sentences; Graph-theoretic; Quantifier-rank; Space complexity; Tree decomposition; Problem solving
Managing change in graph-structured data using description logics,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041805678&doi=10.1145%2f3143803&partnerID=40&md5=9571bab12ba717577ef7d7478932dfd0,"In this article, we consider the setting of graph-structured data that evolves as a result of operations carried out by users or applications. We study different reasoning problems, which range from deciding whether a given sequence of actions preserves the satisfaction of a given set of integrity constraints, for every possible initial data instance, to deciding the (non)existence of a sequence of actions that would take the data to an (un)desirable state, starting either from a specific data instance or from an incomplete description of it. For describing states of the data instances and expressing integrity constraints on them, we use description logics (DLs) closely related to the two-variable fragment of first-order logic with counting quantifiers. The updates are defined as actions in a simple yet flexible language, as finite sequences of conditional insertions and deletions, which allow one to use complex DL formulas to select the (pairs of) nodes for which (node or arc) labels are added or deleted. We formalize the preceding data management problems as a static verification problem and several planning problems and showthat, due to the adequate choice of formalisms for describing actions and states of the data, most of these data management problems can be effectively reduced to the (un)satisfiability of suitable formulas in decidable logical formalisms. Leveraging this, we provide algorithms and tight complexity bounds for the formalized problems, both for expressive DLs and for a variant of the popular DL-Lite, advocated for data management in recent years. © 2017 ACM.",Graph-structured data; Integrity constraints; Planning; Static analysis,Computational complexity; Data description; Formal languages; Formal logic; Graphic methods; Information management; Planning; Static analysis; Counting quantifiers; Data management problems; Graph structured data; Insertions and deletions; Integrity constraints; Reasoning problems; Sequence of actions; Static verification; Constraint satisfaction problems
An effective characterization of the alternation hierarchy in two-variable logic,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041460428&doi=10.1145%2f3149822&partnerID=40&md5=042c4bb8b57c3f73eb992f3ee66d3e07,"We give an algebraic characterization, based on the bilateral semidirect product of finite monoids, of the quantifier alternation hierarchy in two-variable first-order logic on finite words. As a consequence, we obtain a new proof that this hierarchy is strict. Moreover, by application of the theory of finite categories, we are able to make our characterization effective: that is, there is an algorithm for determining the exact quantifier alternation depth for a given language definable in two-variable logic.",FO<sub>2</sub>; Identities; J; Pseudovarities; Quantifier Alternation,Characterization; Formal logic; Alternation hierarchies; Finite words; First order logic; Identities; Pseudovarities; Quantifier Alternation; Quantifier-alternation hierarchy; Semidirect product; Computer circuits
Detecting decidable classes of finitely ground logic programs with function symbols,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035310369&doi=10.1145%2f3143804&partnerID=40&md5=5d12f8330ee3bc2b8feb91a4103e51db,"In this article, we propose a new technique for checking whether the bottom-up evaluation of logic programs with function symbols terminates. The technique is based on the definition of mappings from arguments to strings of function symbols, representing possible values which could be taken by arguments during the bottom-up evaluation. Starting from mappings, we identify mapping-restricted arguments, a subset of limited arguments, namely arguments that take values from finite domains.Mapping-restricted programs, consisting of rules whose arguments are all mapping restricted, are terminating under the bottom-up computation, as all of its arguments take values from finite domains. We show that mappings can be computed by transforming the original program into a unary logic program: this allows us to establish decidability of checking if a program is mapping restricted. We study the complexity of the presented approach and compare it to other techniques known in the literature. We also introduce an extension of the proposed approach that is able to recognize a wider class of logic programs. The presented technique provides a significant improvement, as it can detect terminating programs not identified by other criteria proposed so far. Furthermore, it can be combined with other techniques to further enlarge the class of programs recognized as terminating under the bottom-up evaluation. © 2017 ACM.",Answer set programming; Bottom-up evaluation; Computational complexity; Function symbols; Program termination; Stable models,Computability and decidability; Computational complexity; Computer circuits; Computer programming; Function evaluation; Mapping; Answer set programming; Bottom-up evaluations; Function symbols; Program termination; Stable model; Logic programming
Algorithmic compression of finite tree languages by rigid acyclic grammars,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030331472&doi=10.1145%2f3127401&partnerID=40&md5=0dc9cd308598b875b9fb341b7b5c3376,"We present an algorithm to optimally compress a finite set of terms using a vectorial totally rigid acyclic tree grammar. This class of grammars has a tight connection to proof theory, and the grammar compression problem considered in this article has applications in automated deduction. The algorithm is based on a polynomial-time reduction to the MaxSAT optimization problem. The crucial step necessary to justify this reduction consists of applying a term rewriting relation to vectorial totally rigid acyclic tree grammars. Our implementation of this algorithm performs well on a large real-world dataset. © 2017 ACM.",Finite tree languages; Grammar-based compression; MaxSAT,Algorithmic languages; Forestry; Optimization; Polynomial approximation; Automated deduction; Finite trees; Grammar-based compression; Max-SAT; Optimization problems; Polynomial-time reduction; Term rewriting; Tree grammars; Trees (mathematics)
On the parameterized complexity of finding small unsatisfiable subsets of CNF formulas and CSP instances,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028573751&doi=10.1145%2f3091528&partnerID=40&md5=25ba0286136a2851f384bf744984c1d1,"In many practical settings it is useful to find a small unsatisfiable subset of a given unsatisfiable set of constraints. We study this problem from a parameterized complexity perspective, taking the size of the unsatisfiable subset as the natural parameter where the set of constraints is either (i) given a set of clauses, i.e., a formula in conjunctive normal Form (CNF), or (ii) as an instance of the Constraint Satisfaction Problem (CSP). In general, the problem is fixed-parameter intractable. For an instance of the propositional satisfiability problem (SAT), it was known to be W[1]-complete. We establish A[2]-completeness for CSP instances, where A[2]-hardness prevails already for the Boolean case. With these fixed-parameter intractability results for the general case in mind, we consider various restricted classes of inputs and draw a detailed complexity landscape. It turns out that often Boolean CSP and CNF formulas behave similarly, but we also identify notable exceptions to this rule. The main part of this article is dedicated to classes of inputs that are induced by Boolean constraint languages that Schaefer [1978] identified as the maximal constraint languages with a tractable satisfiability problem. We show that for the CSP setting, the problem of finding small unsatisfiable subsets remains fixedparameter intractable for all Schaefer languages for which the problem is non-trivial. We show that this is also the case for CNF formulas with the exception of the class of bijunctive (Krom) formulas, which allows for an identification of a small unsatisfiable subset in polynomial time. In addition, we consider various restricted classes of inputs with bounds on the maximum number of times that a variable occurs (the degree), bounds on the arity of constraints, and bounds on the domain size. For the case of CNF formulas, we show that restricting the degree is enough to obtain fixed-parameter tractability, whereas for the case of CSP instances, one needs to restrict the degree, the arity, and the domain size simultaneously to establish fixed-parameter tractability. Finally, we relate the problem of finding small unsatisfiable subsets of a set of constraints to the problem of identifying whether a given variable-value assignment is entailed or forbidden already by a small subset of constraints. Moreover, we use the connection between the two problems to establish similar parameterized complexity results also for the latter problem.",Backbones; CNF formulas; Constraint Satisfaction; Parameterized complexity; Unsatisfiable subsets,Boolean algebra; Formal logic; Parameterization; Polynomial approximation; Set theory; Backbones; CNF formulas; Conjunctive normal forms; Constraint Satisfaction; Fixed-parameter tractability; Parameterized complexity; Propositional satisfiability problems; Satisfiability problems; Constraint satisfaction problems
Monadic second-order logic with arbitrary monadic predicates,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028576229&doi=10.1145%2f3091124&partnerID=40&md5=613c9eeb813176f5c5ef826d92039c71,"We study Monadic Second-Order Logic (MSO) over finite words, extended with (non-uniform arbitrary) monadic predicates. We show that it defines a class of languages that has algebraic, automata-theoretic, and machine-independent characterizations. We consider the regularity question: Given a language in this class, when is it regular? To answer this, we show a substitution property and the existence of a syntactical predicate. We give three applications. The first two are to give very simple proofs that the Straubing Conjecture holds for all fragments of MSO with monadic predicates and that the Crane Beach Conjecture holds for MSO with monadic predicates. The third is to show that it is decidable whether a language defined by an MSO formula with morphic predicates is regular. © 2017 ACM.",Automata with advice; Monadic predicates; Morphic predicates,Automata theory; Computability and decidability; Computer circuits; Automata with advice; Finite words; Monadic predicates; Monadic second-order logic; Morphic; Non-uniform; Substitution property; Formal logic
Horn fragments of the Halpern-Shoham interval temporal logic,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028537623&doi=10.1145%2f3105909&partnerID=40&md5=f80df5ea82388bc59cc9c72ff024bcf4,"We investigate the satisfiability problem for Horn fragments of the Halpern-Shoham interval temporal logic depending on the type (box or diamond) of the interval modal operators, the type of the underlying linear order (discrete or dense), and the type of semantics for the interval relations (reflexive or irreflexive). For example, we show that satisfiability of Horn formulas with diamonds is undecidable for any type of linear orders and semantics. On the contrary, satisfiability of Horn formulas with boxes is tractable over both discrete and dense orders under the reflexive semantics and over dense orders under the irreflexive semantics but becomes undecidable over discrete orders under the irreflexive semantics. Satisfiability of binary Horn formulas with both boxes and diamonds is always undecidable under the irreflexive semantics. © 2017 ACM.",Computational complexity; Modal logic; Temporal logic,Computational complexity; Computer circuits; Diamonds; Semantics; Temporal logic; Horn formulas; Horn fragments; Interval temporal logic; Linear order; Modal logic; Modal operators; Satisfiability; Satisfiability problems; Formal logic
Collapsible pushdown automata and recursion schemes,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028532809&doi=10.1145%2f3091122&partnerID=40&md5=ab8228014547964a877b35738151e143,"We consider recursion schemes (not assumed to be homogeneously typed, and hence not necessarily safe) and use them as generators of (possibly infinite) ranked trees. A recursion scheme is essentially a finite typed deterministic term rewriting system that generates, when one applies the rewriting rules ad infinitum, an infinite tree, called its value tree. A fundamental question is to provide an equivalent description of the trees generated by recursion schemes by a class of machines. In this article, we answer this open question by introducing collapsible pushdown automata (CPDA), which are an extension of deterministic (higher-order) pushdown automata. A CPDA generates a tree as follows. One considers its transition graph, unfolds it, and contracts its silent transitions, which leads to an infinite tree, which is finally node labelled thanks to a map from the set of control states of the CPDA to a ranked alphabet. Our contribution is to prove that these two models, higher-order recursion schemes and collapsible pushdown automata, are equi-expressive for generating infinite ranked trees. This is achieved by giving effective transformations in both directions. © 2017 ACM.",Higher-order (collapsible) pushdown automata; Higher-order recursion schemes,Automata theory; Equivalence classes; Forestry; Control state; Higher-order; Infinite trees; Push-down automata; Recursion schemes; Rewriting rules; Term rewriting systems; Transition graphs; Trees (mathematics)
The probability of a computable output from a random oracle,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027407950&doi=10.1145%2f3091527&partnerID=40&md5=7c5c3f5d28a7d53e49f3eaa9a6322765,"Consider a universal oracle Turing machine that prints a finite or an infinite binary sequence, based on the answers to the binary queries that it makes during the computation.We study the probability that this output is infinite and computable when the machine is given a random (in the probabilistic sense) stream of bits as the answers to its queries during an infinitary computation. Surprisingly, we find that these probabilities are the entire class of real numbers in (0, 1) that can be written as the difference of two halting probabilities relative to the halting problem. In particular, there are universal Turing machines that produce a computable infinite output with probability exactly 1/2. Our results contrast a large array of facts (the most well-known being the randomness of Chaitin's halting probability) that witness maximal initial segment complexity of probabilities associated with universal machines. Our proof uses recent advances in algorithmic randomness. © 2017 ACM.",Algorithmic information theory; Probabilistic machines; Random oracles; Turing machines,Binary sequences; Bins; Computability and decidability; Information theory; Machinery; Probability; Random processes; Algorithmic information theory; Algorithmic randomness; Halting probabilities; Halting problems; Probabilistic machines; Random Oracle; Universal machines; Universal Turing machine; Turing machines
Differential hybrid games,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027420178&doi=10.1145%2f3091123&partnerID=40&md5=5340147a7cd32014ebeb7901d292bbfe,"This article introduces differential hybrid games, which combine differential games with hybrid games. In both kinds of games, two players interact with continuous dynamics. The difference is that hybrid games also provide all the features of hybrid systems and discrete games, but only deterministic differential equations. Differential games, instead, provide differential equations with continuous-time game input by both players, but not the luxury of hybrid games, such as mode switches and discrete-time or alternating adversarial interaction. This article augments differential game logic with modalities for the combined dynamics of differential hybrid games. It shows how hybrid games subsume differential games and introduces differential game invariants and differential game variants for proving properties of differential games inductively. 2017 Copyright is held by the owner/author(s).",Differential game invariants; Differential games; Game logic; Hybrid games; Partial differential equations viscosity solutions; Real algebraic geometry,Computer circuits; Continuous time systems; Hybrid systems; Time switches; Differential games; Game logic; Hybrid games; Real algebraic geometry; Viscosity solutions; Game theory
The logical view on continuous petri nets,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027415385&doi=10.1145%2f3105908&partnerID=40&md5=3db04f8eb086134d8af7f40fd18c0528,"Continuous Petri nets are a relaxation of classical discrete Petri nets in which transitions can be fired a fractional number of times, and consequently places may contain a fractional number of tokens. Such continuous Petri nets are an appealing object to study, since they over-approximate the set of reachable configurations of their discrete counterparts, and their reachability problem is known to be decidable in polynomial time. The starting point of this article is to show that the reachability relation for continuous Petri nets is definable by a sentence of linear size in the existential theory of the rationals with addition and order. Using this characterization, we obtain decidability and complexity results for a number of classical decision problems for continuous Petri nets. In particular, we settle the open problem about the precise complexity of reachability set inclusion. Finally, we show how continuous Petri nets can be incorporated inside the classical backward coverability algorithm for discrete Petri nets as a pruning heuristic to tackle the symbolic state explosion problem. The cornerstone of the approach we present is that our logical characterization enables us to leverage the power of modern SMT-solvers to yield a highly performant and robust decision procedure for coverability in Petri nets.We demonstrate the applicability of our approach on a set of standard benchmarks from the literature. © 2017 ACM.",Arithmetic theories; Coverability; Linear programming; Petri nets; Vector addition systems,Computability and decidability; Linear programming; Polynomial approximation; Vectors; Classical decision problems; Continuous Petri net; Coverability; Discrete Petri nets; Logical characterization; Reachability problem; Reachability relations; Vector addition systems; Petri nets
The complexity of phylogeny constraint satisfaction problems,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027395867&doi=10.1145%2f3105907&partnerID=40&md5=265cc773cb652f40fe896217eaa46aac,"We systematically study the computational complexity of a broad class of computational problems in phylogenetic reconstruction. The class contains, for example, the rooted triple consistency problem, forbidden subtree problems, the quartet consistency problem, and many other problems studied in the bioinformatics literature. The studied problems can be described as constraint satisfaction problems, where the constraints have a first-order definition over the rooted triple relation. We show that every such phylogeny problem can be solved in polynomial time or is NP-complete. On the algorithmic side, we generalize a well-known polynomial-time algorithm of Aho, Sagiv, Szymanski, and Ullman for the rooted triple consistency problem. Our algorithm repeatedly solves linear equation systems to construct a solution in polynomial time.We then showthat every phylogeny problem that cannot be solved by our algorithm is NP-complete. Our classification establishes a dichotomy for a large class of infinite structures that we believe is of independent interest in universal algebra, model theory, and topology. The proof of our main result combines results and techniques from various research areas: a recent classification of the model-complete cores of the reducts of the homogeneous binary branching C-relation, Leeb's Ramsey theorem for rooted trees, and universal algebra. © 2017 ACM.",Computational complexity; Constraint satisfaction problems; Model theory; Phylogenetic reconstruction; Ramsey theory,Algebra; Binary trees; Biology; Computational complexity; Linear equations; Polynomial approximation; Polynomials; Topology; Computational problem; Consistency problems; Linear equation system; Model theory; Phylogenetic reconstruction; Polynomial-time algorithms; Ramsey theory; Universal algebra; Constraint satisfaction problems
Verifying procedural programs via constrained rewriting induction,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027029952&doi=10.1145%2f3060143&partnerID=40&md5=5b006afb13db574f479b6f6957b31906,"This article aims to develop a verification method for procedural programs via a transformation into logically constrained term rewriting systems (LCTRSs). To this end, we extend transformation methods based on integer term rewriting systems to handle arbitrary data types, global variables, function calls, and arrays, and to encode safety checks. Then we adapt existing rewriting induction methods to LCTRSs and propose a simple yet effective method to generalize equations. We show that we can automatically verify memory safety and prove correctness of realistic functions. Our approach proves equivalence between two implementations; thus, in contrast to other works, we do not require an explicit specification in a separate specification language. © 2017 ACM.",Constrained term rewriting; Inductive theorem proving; Lemma generation; Program analysis; Rewriting induction,Computational mechanics; Specification languages; Specifications; Constrained terms; Inductive Theorem Proving; Lemma generations; Program analysis; Rewriting induction; Metadata
An O(mlog n) algorithm for computing stuttering equivalence and branching bisimulation,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027000745&doi=10.1145%2f3060140&partnerID=40&md5=9a3d7e06d50c720ba7d060dc292683b5,"We provide a new algorithm to determine stuttering equivalence with time complexity O(mlog n), where n is the number of states and mis the number of transitions of a Kripke structure. This algorithm can also be used to determine branching bisimulation in O(m(log |Act| + log n)) time, where Act is the set of actions in a labeled transition system. Theoretically, our algorithm substantially improves upon existing algorithms, which all have time complexity of the form O(mn) at best. Moreover, it has better or equal space complexity. Practical results confirm these findings: they show that our algorithm can outperform existing algorithms by several orders of magnitude, especially when the Kripke structures are large. The importance of our algorithm stretches far beyond stuttering equivalence and branching bisimulation. The known O(mn) algorithms were already far more efficient (both in space and time) than most other algorithms to determine behavioral equivalences (including weak bisimulation), and therefore they were often used as an essential preprocessing step. This new algorithm makes this use of stuttering equivalence and branching bisimulation even more attractive. © 2017 ACM.",Algorithm; Branching bisimulation,Algorithms; Logic programming; Behavioral equivalence; Branching bisimulation; Kripke structure; Labeled transition systems; Orders of magnitude; Pre-processing step; Space complexity; Weak bisimulation; Computer science
The NP search problems of Frege and extended Frege proofs,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023202682&doi=10.1145%2f3060145&partnerID=40&md5=41310d843fcd5fef935c9c2f9dca4618,"We study consistency search problems for Frege and extended Frege proofs-namely the NP search problems of finding syntactic errors in Frege and extended Frege proofs of contradictions. The input is a polynomial time function, or an oracle, describing a proof of a contradiction; the output is the location of a syntactic error in the proof. The consistency search problems for Frege and extended Frege systems are shown to be many-one complete for the provably total NP search problems of the second-order bounded arithmetic theories U12 and V12, respectively. © 2017 ACM.",Bounded arithmetic; Extended Frege proofs; Frege proofs; NP search problems; Proof complexity; Propositional logic; Total functions,Formal logic; Polynomial approximation; Bounded arithmetic; Frege proofs; Proof complexity; Propositional logic; Search problem; Syntactics
Progression of decomposed local-effect action theories,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022325215&doi=10.1145%2f3091119&partnerID=40&md5=8b24992a71597ddfe8af7c541d35c491,"In many tasks related to reasoning about consequences of a logical theory, it is desirable to decompose the theory into a number of weakly related or independent components. However, a theory may represent knowledge that is subject to change, as a result of executing actions that have effects on some of the initial properties mentioned in the theory. Having once computed a decomposition of a theory, it is advantageous to know whether a decomposition has to be computed again in the newly changed theory (obtained from taking into account changes resulting from execution of an action). In this article, we address this problem in the scope of the situation calculus, where a change of an initial theory is related to the notion of progression. Progression provides a form of forward reasoning; it relies on forgetting values of those properties, which are subject to change, and computing new values for them. We consider decomposability and inseparability, two component properties known from the literature, and contribute by studying the conditions (1) when these properties are preserved and (2) when they are lost wrt progression and the related operation of forgetting. To show the latter, we demonstrate the boundaries using a number of negative examples. To show the former, we identify cases when these properties are preserved under forgetting and progression of initial theories in local-effect basic action theories of the situation calculus. Our article contributes to bridging two different communities in knowledge representation, namely, research on modularity and research on reasoning about actions. © 2017 ACM.",Decomposition; Forgetting; Inseparability; Progression; Reasoning about actions,Calculations; Decomposition; Knowledge representation; Forgetting; Forward reasoning; Independent components; Inseparability; Negative examples; Progression; Reasoning about actions; Situation calculus; Computation theory
Uniqueness of normal forms for shallow term rewrite systems,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023178456&doi=10.1145%2f3060144&partnerID=40&md5=41a9eb5a4a51c4bde121b2c166e3de50,"Uniqueness of normal forms (UN=) is an important property of term rewrite systems. UN= is decidable for ground (i.e., variable-free) systems and undecidable in general. Recently, it was shown to be decidable for linear, shallow systems. We generalize this previous result and show that this property is decidable for shallow rewrite systems, in contrast to confluence, reachability, and other related properties, which are all undecidable for flat systems.We also prove an upper bound on the complexity of our algorithm. Our decidability result is optimal in a sense, since we prove that the UN= property is undecidable for two classes of linear rewrite systems: left-flat systems in which right-hand sides are of height at most two and right-flat systems in which left-hand sides are of height at most two. © 2017 ACM.",Decidability/undecidability; Flat rewrite systems; Shallow rewrite systems; Term rewrite systems; Uniqueness of normal forms,Computational complexity; Decidability/undecidability; Flat systems; Normal form; Reachability; Rewrite systems; Right-hand sides; Shallow system; Term rewrite systems; Computability and decidability
Possibilistic justification logic: Reasoning about justified uncertain beliefs,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023166442&doi=10.1145%2f3091118&partnerID=40&md5=bd9acda60b7c0204381cdd865aedea23,"Justification logic originated from the study of the logic of proofs. However, in a more general setting, it may be regarded as a kind of explicit epistemic logic. In such logic, the reasons a fact is believed are explicitly represented as justification terms. Traditionally, the modeling of uncertain beliefs is crucially important for epistemic reasoning. Graded modal logics interpreted with possibility theory semantics have been successfully applied to the representation and reasoning of uncertain beliefs; however, they cannot keep track of the reasons an agent believes a fact. This article is aimed at extending the graded modal logics with explicit justifications. We introduce a possibilistic justification logic, present its syntax and semantics, and investigate its metaproperties, such as soundness, completeness, and realizability. © 2017 ACM.",Justification logic; Modal logic; Possibilistic logic; Realization theorem,Formal logic; Semantics; Epistemic logic; Epistemic reasonings; Justification logic; Modal logic; Possibilistic logic; Possibility theory; Realization theorems; Uncertain beliefs; Computer circuits
Faster statistical model checking for unbounded temporal properties,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027016099&doi=10.1145%2f3060139&partnerID=40&md5=f7b4d084c2f33f1a0f371645c14e9a27,"We present a new algorithm for the statistical model checking of Markov chains with respect to unbounded temporal properties, including full linear temporal logic. The main idea is that we monitor each simulation run on the fly, in order to detect quickly if a bottom strongly connected component is entered with high probability, in which case the simulation run can be terminated early. As a result, our simulation runs are often much shorter than required by termination bounds that are computed a priori for a desired level of confidence on a large state space. In comparison to previous algorithms for statistical model checking our method is not only faster in many cases but also requires less information about the system, namely, only the minimum transition probability that occurs in the Markov chain. In addition, our method can be generalised to unbounded quantitative properties such as mean-payoff bounds. © 2017 ACM.",Markov chains; Mean payoff; Simulation; Statistical model checking; Temporal logic,Chains; Computer circuits; Markov processes; Temporal logic; High probability; Linear temporal logic; Mean payoff; Simulation; Statistical model checking; Strongly connected component; Temporal property; Transition probabilities; Model checking
Expressiveness of logic programs under the general stable model semantics,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019247690&doi=10.1145%2f3039244&partnerID=40&md5=c912dc6da1821a7417fb56f62da302e2,"Stable model semantics had been recently generalized to non-Herbrand structures by several works, which provides a unified framework and solid logical foundations for answer set programming. This article focuses on the expressiveness of normal and disjunctive logic programs under general stable model semantics. A translation from disjunctive logic programs to normal logic programs is proposed for infinite structures. Over finite structures, some disjunctive logic programs are proved to be intranslatable to normal logic programs if the arities of auxiliary predicates and functions are bounded in a certain way. The equivalence of the expressiveness of normal logic programs and disjunctive logic programs over arbitrary structures is also shown to coincide with that over finite structures and coincide with whether the complexity class NP is closed under complement. Moreover, to obtain a more explicit picture of the expressiveness, some intertranslatability results between logic program classes, and fragments of second-order logic are established. © 2017 ACM.",Answer set programming; Complexity; Expressiveness; Nonmonotonic reasoning; Second-order logic,Computer circuits; Computer programming; Equivalence classes; Program translators; Semantics; Answer set programming; Complexity; Expressiveness; Non-monotonic reasoning; Second-order logic; Logic programming
"Automated generation of erotetic search scenarios: Classification, optimization, and knowledge extraction",2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019197179&doi=10.1145%2f3056537&partnerID=40&md5=72290e166fe6ccda11b4aae00fe4d6d0,"This article concerns automated generation and processing of erotetic search scenarios (ESSs). ESSs are formal constructs characterized in Inferential Erotetic Logic that enable finding possible answers to a posed question by decomposing it into auxiliary questions. The first part of this work describes a formal account on ESSs. The formal approach is then applied to automatically generate ESSs, and the resulting scenarios are evaluated according to a number of criteria. These criteria are subjected to discordance analysis that reveals their mutual relationships. Finally, knowledge concerning relationships between different values of evaluation criteria is extracted by applying Apriori-an association rules mining algorithm. The proposed approach of integration of formal erotetic logic with computational tools provides extensive insight into the former and helps with the development of efficient ESSs. © 2017 ACM.",Knowledge extraction; Logic of questions; Multicriteria analysis; Optimal erotetic scenario; Rule mining,Computation theory; Computer circuits; Extraction; Knowledge extraction; Logic of questions; Multi Criteria Analysis; Optimal erotetic scenario; Rule mining; Data mining
Graph logics with rational relations: The role of word combinatorics,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019229049&doi=10.1145%2f3070822&partnerID=40&md5=9238a87dc92151d0cf1a95d7c4ed5e53,"Graph databases make use of logics that combine traditional first-order features with navigation on paths, in the same way logics for model checking do. However, modern applications of graph databases impose a new requirement on the expressiveness of the logics: they need comparing labels of paths based on word relations (such as prefix, subword, or subsequence). This has led to the study of logics that extend basic graph languages with features for comparing labels of paths based on regular relations or the strictly more powerful rational relations. The evaluation problem for the former logic is decidable (and even tractable in data complexity), but already extending this logic with such a common rational relation as subword or suffix makes evaluation undecidable. In practice, however, it is rare to have the need for such powerful logics. Therefore, it is more realistic to study the complexity of less expressive logics that still allow comparing paths based on practically motivated rational relations. Here we concentrate on the most basic languages, which extend graph pattern logics with path comparisons based only on suffix, subword, or subsequence. We pinpoint the complexity of evaluation for each one of these logics, which shows that all of them are decidable in elementary time (PSPACE or NEXPTIME). Furthermore, the extension with suffix is even tractable in data complexity (but the other two are not). In order to obtain our results we establish a link between the evaluation problem for graph logics and two important problems in word combinatorics: word equations with regular constraints and longest common subsequence. © 2017 ACM.",Complexity of evaluation; Logics for graphs; Rational relations; Regular path queries; Shuffle; Word equations,Combinatorial mathematics; Computability and decidability; Model checking; Complexity of evaluation; Logics for graphs; Rational relations; Regular path queries; Shuffle; Word equations; Graph theory
Quantified constraint satisfaction problem on semicomplete digraphs,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018478998&doi=10.1145%2f3007899&partnerID=40&md5=701b4ff5c09f1145fc3e34d1d828b965,"We study the (non-uniform) quantified constraint satisfaction problem QCSP(ℋ)asH ranges over semicomplete digraphs. We obtain a complexity-theoretic trichotomy: QCSP(ℋ) is either in P, is NP-complete, or is Pspace-complete. The largest part of our work is the algebraic classification of precisely which semicomplete digraphs enjoy only essentially unary polymorphisms, which is combinatorially interesting in its own right. © 2017 ACM.",Algorithms; Complexity; Design; F.2.2 [analysis of algorithms and problem complexity]: nonnumerical algorithms and problems; F.4.1 [mathematical logic and formal languages]: mathematical logic; G.2.1 [discrete mathematics]: combinatorics; Performance; Polymorphism; Quantified constraints; Semicomplete digraphs,Algorithms; Computational complexity; Constraint theory; Design; Directed graphs; Formal languages; Graph theory; Polymorphism; Combinatorics; Complexity; Performance; Problem complexity; Quantified constraints; Semicomplete digraph; Constraint satisfaction problems
"Equations, contractions, and unique solutions",2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017170057&doi=10.1145%2f2971339&partnerID=40&md5=1c4eaddd3bb6e54bca3a24fcbcd70d7d,"One of the most studied behavioural equivalences is bisimilarity. Its success is much due to the associated bisimulation proof method, which can be further enhanced by means of ""bisimulation up-to"" techniques such as ""up-to context."" A different proof method is discussed, based on a unique solution of special forms of inequations called contractions and inspired by Milner's theorem on unique solution of equations. The method is as powerful as the bisimulation proof method and its ""up-to context"" enhancements. The definition of contraction can be transferred onto other behavioural equivalences, possibly contextual and non-coinductive. This enables a coinductive reasoning style on such equivalences, either by applying the method based on unique solution of contractions or by injecting appropriate contraction preorders into the bisimulation game. The techniques are illustrated in CCS-like languages; an example dealing with higher-order languages is also shown. © 2017 ACM.",Bisimulation; Coinduction; Contraction; Equations; Unique solution,Logic programming; Shrinkage; Bisimilarity; Bisimulation games; Bisimulations; CCS-like languages; Coinduction; Equations; Higher-order languages; Proof methods; Computer science
Merging in the horn fragment,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017122985&doi=10.1145%2f3043700&partnerID=40&md5=95948e5eff24394490a0f8d2e653382d,"Beliefmerging is a central operation within the field of belief change and addresses the problem of combining multiple, possibly mutually inconsistent knowledge bases into a single, consistent one. A current research trend in belief change is concerned with representation theorems tailored to fragments of logic, in particular Horn logic. Hereby, the goal is to guarantee that the result of the change operations stays within the fragment under consideration. While several such results have been obtained for Horn revision and Horn contraction, merging of Horn theories has been neglected so far. In this article, we provide a novel representation theorem for Horn merging by strengthening the standard merging postulates. Moreover, we present concrete Horn merging operators satisfying all postulates. © 2017 ACM.",Belief change; Belief merging; Horn propositional logic,Computer circuits; Formal logic; Belief change; Change operations; Horn fragments; Knowledge basis; Merging operators; Propositional logic; Representation theorem; Research trends; Merging
Datalog queries distributing over components,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017150966&doi=10.1145%2f3022743&partnerID=40&md5=7e7f492188cf6fb50600aa2374d3a431,"We investigate the class D of queries that distribute over components. These are the queries that can be evaluated by taking the union of the query results over the connected components of the database instance. We show that it is undecidable whether a (positive) Datalog program distributes over components. Additionally, we show that connected Datalog (the fragment of Datalog where all rules are connected) provides an effective syntax for Datalog programs that distribute over components under the stratified as well as under the well-founded semantics. As a corollary, we obtain a simple proof for one of the main results in previous work [Zinn et al. 2012], namely that the classic win-move query is in F2 (a particular class of coordination-free queries). © 2017 ACM.",Coordination-free evaluation; Datalog; Distributed databases; Stratified semantics; Well-founded semantics,Query processing; Semantics; Class-D; Connected component; Coordination-free evaluation; Datalog; Datalog programs; Distributed database; Query results; Well founded semantics; Query languages
A hoare logic for GPU Kernels,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017139314&doi=10.1145%2f3001834&partnerID=40&md5=b4ff40103b9c784c4355cd9b74c3c4b9,"We study a Hoare Logic to reason about parallel programs executed on graphics processing units (GPUS), called GPU kernels. During the execution of GPU kernels, multiple threads execute in lockstep, that is, execute the same instruction simultaneously. When the control branches, the two branches are executed sequentially, but during the execution of each branch only those threads that take it are enabled; after the control converges, all the threads are enabled and again execute in lockstep. In this article, we first consider a semantics in which all threads execute in lockstep (this semantics simplifies the actual execution model of GPUS) and adapt Hoare Logic to this setting by augmenting the usual Hoare triples with an additional component representing the set of enabled threads. It is determined that the soundness and relative completeness of the logic do not hold for all programs; a difficulty arises from the fact that one thread can invalidate the loop termination condition of another thread through shared memory. We overcome this difficulty by identifying an appropriate class of programs for which the soundness and relative completeness hold. Additionally, we discuss thread interleaving, which is present in the actual execution of GPUS but not in the lockstep semantics mentioned above. We show that if a program is race free, then the lockstep and interleaving semantics produce the same result. This implies that our logic is sound and relatively complete for race-free programs, even if the thread interleaving is taken into account. © 2017 ACM.",GPU; Hoare Logic,Computer graphics; Graphics processing unit; Locks (fasteners); Program processors; Semantics; Execution model; Hoare Logic; Interleaving semantics; Multiple threads; Parallel program; Shared memory; Soundness and relative completeness; Termination condition; Computer circuits
Abstract program slicing: An abstract interpretation-based approach to program slicing,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017139333&doi=10.1145%2f3029052&partnerID=40&md5=f31b89fb330752494f1d57a4ce1a56ca,"In the present article, we formally define the notion of abstract program slicing, a general form of program slicing where properties of data are considered instead of their exact value. This approach is applied to a language with numeric and reference values and relies on the notion of abstract dependencies between program statements. The different forms of (backward) abstract slicing are added to an existing formal framework where traditional, nonabstract forms of slicing could be compared. The extended framework allows us to appreciate that abstract slicing is a generalization of traditional slicing, since each form of traditional slicing (dealing with syntactic dependencies) is generalized by a semantic (nonabstract) form of slicing, which is actually equivalent to an abstract form where the identity abstraction is performed on data. Sound algorithms for computing abstract dependencies and a systematic characterization of program slices are provided, which rely on the notion of agreement between program states. © 2017 ACM.",Abstract interpretation; Program slicing; Semantics; Static analysis,Model checking; Semantics; Static analysis; Abstract interpretations; Abstract programs; Formal framework; Program slicing; Program state; Program statements; Reference values; Syntactic dependencies; Abstracting
Parametrised complexity of satisfiability in temporal logic,2017,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010806818&doi=10.1145%2f3001835&partnerID=40&md5=38f36cd22fb9b81462952a88a9382657,"We apply the concept of formula treewidth and pathwidth to computation tree logic, linear temporal logic, and the full branching time logic. Several representations of formulas as graphlike structures are discussed, and corresponding notions of treewidth and pathwidth are introduced. As an application for such structures, we present a classification in terms of parametrised complexity of the satisfiability problem, where we make use of Courcelle's famous theorem for recognition of certain classes of structures. Our classification shows a dichotomy between W[1]-hard and fixed-parameter tractable operator fragments almost independently of the chosen graph representation. The only fragments that are proven to be fixed-parameter tractable (FPT) are those that are restricted to the X operator. By investigating Boolean operator fragments in the sense of Post's lattice, we achieve the same complexity as in the unrestricted case if the set of available Boolean functions can express the function ""negation of the implication."" Conversely, we show containment in FPT for almost all other clones. © 2017 ACM.",Computation tree logic; Linear temporal logic; Parametrised complexity; Pathwidth; Post's lattice; Temporal depth; Temporal logic; Treewidth,Boolean functions; Formal logic; Temporal logic; Computation tree logic; Linear temporal logic; Parametrised complexity; Pathwidth; Post's lattice; Temporal depth; Tree-width; Computer circuits
Taming multirelations,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997107883&doi=10.1145%2f2964907&partnerID=40&md5=8734aed1cf2f07a1d61e696485f2d063,"Binary multirelations generalise binary relations by associating elements of a set to its subsets. We study the structure and algebra of multirelations under the operations of union, intersection, sequential, and parallel composition, as well as finite and infinite iteration. Starting from a set-theoretic investigation, we propose axiom systems for multirelations in contexts ranging from bi-monoids to bi-quantales. © 2016 ACM.",Algebras of multirelations; F.1.2 [computation by abstract devices]: modes of computation - alternation and nondeterminism; F.3.1 [logics and meanings of programs]: specifying and verifying and reasoning about programs - logics of programs; F.3.2 [logics and meanings of programs]: semantics of programming languages - algebraic approaches to semantics; F.4.1 [mathematical logic and formal languages]: mathematical logic - modal logic; I.1.3 [symbolic and algebraic manipulation]: languages and systems - special-purpose algebraic systems; Languages; Parallelism and concurrency; Theory; Verification,Algebra; Bins; Formal languages; Query languages; Semantics; Verification; Languages and systems; Modal logic; Non-determinism; Parallelism and concurrencies; Reasoning about programs; Semantics of programming languages; Theory; Computation theory
Index problems for game automata,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997161440&doi=10.1145%2f2946800&partnerID=40&md5=5f574a516bc34cb15d969426faeea0a6,"For a given regular language of infinite trees, one can ask about the minimal number of priorities needed to recognize this language with a nondeterministic, alternating, or weak alternating parity automaton. These questions are known as, respectively, the nondeterministic, alternating, and weak Rabin-Mostowski index problems. Whether they can be answered effectively is a long-standing open problem, solved so far only for languages recognizable by deterministic automata (the alternating variant trivializes). We investigate a wider class of regular languages, recognizable by so-called game automata, which can be seen as the closure of deterministic ones under complementation and composition. Game automata are known to recognize languages arbitrarily high in the alternating Rabin-Mostowski index hierarchy; that is, the alternating index problem does not trivialize anymore. Our main contribution is that all three index problems are decidable for languages recognizable by game automata. Additionally, we show that it is decidable whether a given regular language can be recognized by a game automaton. © 2016 ACM.",Alternation; Automata over infinite trees; Parity games; Rabin-Mostowski index,Automata theory; Context free languages; Forestry; Formal languages; Alternation; Complementation; Deterministic automata; Infinite trees; Mostowski index; Parity games; Computability and decidability
Complexity of two-variable logic on finite trees,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997830877&doi=10.1145%2f2996796&partnerID=40&md5=666952c4cb2e032b3f270616899ac7ef,"Verification of properties expressed in the two-variable fragment of first-order logic FO2 has been investigated in a number of contexts. The satisfiability problem for FO2 over arbitrary structures is known to be NEXPTIME-complete, with satisfiable formulas having exponential-sized models. Over words, where FO2 is known to have the same expressiveness as unary temporal logic, satisfiability is again NEXPTIME-complete. Over finite labelled ordered trees, FO2 has the same expressiveness as navigational XPath, a popular query language for XML documents. Prior work on XPath and FO2 gives a 2EXPTIME bound for satisfiability of FO2 over trees. This work contains a comprehensive analysis of the complexity of FO2 on trees, and on the size and depth of models. We show that different techniques are required depending on the vocabulary used, whether the trees are ranked or unranked, and the encoding of labels on trees. We also look at a natural restriction of FO2, its guarded version, GF2. Our results depend on an analysis of types in models of FO2 formulas, including techniques for controlling the number of distinct subtrees, the depth, and the size of a witness to satisfiability for FO2 sentences over finite trees. © 2016 ACM.",F.4.1 [mathematical logic]: finite model theory; Logic; Theory; Trees,Computer circuits; Forestry; Query languages; Trees (mathematics); Arbitrary structures; Comprehensive analysis; Finite model theory; Logic; Navigational XPath; Satisfiability problems; Theory; Trees; Formal logic
Two-variable logic with counting and trees,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997402682&doi=10.1145%2f2983622&partnerID=40&md5=84ec0bbcdfdc323109febe0e01b70820,"We consider the two-variable logic with counting quantifiers (C2) interpreted over finite structures that contain two forests of ranked trees. This logic is strictly more expressive than standard C2 and it is no longer a fragment of first-order logic. In particular, it can express that a structure is a ranked tree, a cycle, or a connected graph of bounded degree. It is also strictly more expressive than first-order logic with two variables and two successor relations of two finite linear orders. We present a decision procedure for the satisfiability problem for this logic. The procedure runs in NEXPTIME, which is optimal since the satisfiability problem for plain C2 is NEXPTIME-complete. © 2016 ACM.",Counting quantifier; Satisfiability; Tree; Two-variable logic,Forestry; Formal logic; Graph theory; Counting quantifiers; Decision procedure; Finite structures; First order logic; Satisfiability; Satisfiability problems; Tree; Two-variable logic; Computer circuits
How hard is positive quantification?,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997161497&doi=10.1145%2f2981544&partnerID=40&md5=00c7ab701e44bbbec5db81dd80166c93,"We show that the constructive predicate logic with positive (covariant) quantification is hard for doubly exponential universal time, that is, for the class co-2-NEXPTIME. Our approach is to represent proof-search as computation of an alternating automaton. The memory of the automaton is structured in a way that strictly corresponds to scopes of the binders used in the constructed proof. This provides an application of automata-theoretic techniques in proof theory. © 2016 ACM.",Automata; Complexity; Intuitionistic logic; Positive quantification,Automata theory; Alternating automata; Automata; Complexity; Intuitionistic logic; Positive quantification; Predicate logic; Proof theory; Universal time; Computer circuits
The equivalence of the torus and the product of two circles in homotopy type theory,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997190871&doi=10.1145%2f2992783&partnerID=40&md5=b4987bfff7a5c4df0290c18d73bf2526,"Homotopy type theory is a new branch of mathematics that merges insights from abstract homotopy theory and higher category theory with those of logic and type theory. It allows us to represent a variety of mathematical objects as basic type-theoretic construction, higher inductive types. We present a proof that in homotopy type theory, the torus is equivalent to the product of two circles. This result indicates that the synthetic definition of torus as a higher inductive type is indeed correct. © 2016 ACM.",Higher inductive type; Homotopy type theory; Torus; Unit circle,Computer science; Logic programming; Category theory; Homotopy theory; Homotopy types; Inductive-type; Mathematical objects; New branches; nocv1; Torus; Unit circles; Formal languages
Automated verification of equivalence properties of cryptographic protocols,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989949763&doi=10.1145%2f2926715&partnerID=40&md5=37611b0ea0a919f852934f97fcd9db8a,"Indistinguishability properties are essential in formal verification of cryptographic protocols. They are needed to model anonymity properties, strong versions of confidentiality, and resistance against offline guessing attacks. Indistinguishability properties can be conveniently modeled as equivalence properties. We present a novel procedure to verify equivalence properties for a bounded number of sessions of cryptographic protocols. As in the applied pi calculus, our protocol specification language is parametrized by a first-order sorted term signature and an equational theory that allows formalization of algebraic properties of cryptographic primitives. Our procedure is able to verify trace equivalence for determinate cryptographic protocols. On determinate protocols, trace equivalence coincides with observational equivalence, which can therefore be automatically verified for such processes. When protocols are not determinate, our procedure can be used for both under- and over-approximations of trace equivalence, which proved successful on examples. The procedure can handle a large set of cryptographic primitives, namely those whose equational theory is generated by an optimally reducing convergent rewrite system. The procedure is based on a fully abstract modelling of the traces of a bounded number of sessions of the protocols into first-order Horn clauses on which a dedicated resolution procedure is used to decide equivalence properties. We have shown that our procedure terminates for the class of subterm convergent equational theories. Moreover, the procedure has been implemented in a prototype tool Active Knowledge in Security Protocols and has been effectively tested on examples. Some of the examples were outside the scope of existing tools, including checking anonymity of an electronic voting protocol due to Okamoto. © 2016 ACM.",Applied pi calculus; Automated verification; Process equivalence; Security Protocols,Calculations; Cryptography; Formal verification; Logic programming; Network security; Specification languages; Voting machines; Applied pi calculus; Automated verification; Cryptographic primitives; Electronic voting protocols; Observational equivalences; Offline guessing attacks; Process equivalence; Security protocols; Equivalence classes
On the proof complexity of Paris-harrington and off-diagonal ramsey tautologies,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987984208&doi=10.1145%2f2946801&partnerID=40&md5=87dc7dc16622871ddaf09c3c40b3ed0e,"We study the proof complexity of Paris-Harrington's Large Ramsey Theorem for bi-colorings of graphs and of off-diagonal Ramsey's Theorem. For Paris-Harrington, we prove a non-trivial conditional lower bound in Resolution and a non-trivial upper bound in bounded-depth Frege. The lower bound is conditional on a (very reasonable) hardness assumption for a weak (quasi-polynomial) Pigeonhole principle in RES(2). We show that under such an assumption, there is no refutation of the Paris-Harrington formulas of size quasipolynomial in the number of propositional variables. The proof technique for the lower bound extends the idea of using a combinatorial principle to blow up a counterexample for another combinatorial principle beyond the threshold of inconsistency. A strong link with the proof complexity of an unbalanced off-diagonal Ramsey principle is established. This is obtained by adapting some constructions due to Erd?os and Mills. We prove a non-trivial Resolution lower bound for a family of such off-diagonal Ramsey principles. © 2016 ACM.",Paris-Harrington's principle; Proof complexity; Ramsey's theorem; Resolution,Logic programming; Optical resolving power; Lower bounds; Paris-Harrington's principle; Pigeonhole principle; Proof complexity; Propositional variables; Quasi-poly-nomial; Ramsey theorem; Ramsey's theorem; Computer science
On well-founded set-inductions and locally monotone operators,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987956498&doi=10.1145%2f2963096&partnerID=40&md5=cd34bcb583fe53ecd054e937f5b3350a,"In the past, compelling arguments in favour of the well-founded semantics for autoepistemic logic have been presented. In this article, we show that for certain classes of theories, this semantics fails to identify the unique intended model. We solve this problem by refining the well-founded semantics. We develop our work in approximation fixpoint theory, an abstract algebraical study of semantics of nonmonotonic logics. As such, our results also apply to logic programming, default logic, Dung's argumentation frameworks, and abstract dialectical frameworks. © 2016 ACM.",Approximation fixpoint theory; Autoepistemic logic; Lattice operator; Logic programming; Nonmonotonic reasoning; Well-founded semantics,Abstracting; Algebra; Formal logic; Lattice theory; Logic programming; Reconfigurable hardware; Semantics; Autoepistemic logic; Fixpoints; Lattice operators; Non-monotonic reasoning; Well founded semantics; Computer circuits
Where first-order and monadic second-order logic coincide,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987957280&doi=10.1145%2f2946799&partnerID=40&md5=5846bf94fe471e23256c1c23f706e459,"We study on which classes of graphs first-order logic (FO) and monadic second-order logic (MSO) have the same expressive power. We show that for all classes C of graphs that are closed under taking subgraphs, FO and MSO have the same expressive power on C if and only if, C has bounded tree depth. Tree depth is a graph invariant that measures the similarity of a graph to a star in a similar way that tree width measures the similarity of a graph to a tree. For classes just closed under taking induced subgraphs, we show an analogous result for guarded second-order logic (GSO), the variant of MSO that not only allows quantification over vertex sets but also over edge sets. A key tool in our proof is a Feferman-Vaught-type theorem that works for infinite collections of structures despite being constructive. © 2016 ACM.",First-order logic; Graph classes; Guarded second-order logic; Monadic second-order logic; Tree depth,Computer circuits; Forestry; Reconfigurable hardware; Trees (mathematics); First order logic; Graph class; Monadic second-order logic; Second-order logic; Tree-depth; Formal logic
A model for phase transition of random answer-set programs,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978145313&doi=10.1145%2f2926791&partnerID=40&md5=75c24cf3ed7868589aeee0655cbff654,"The critical behaviors of NP-complete problems have been studied extensively, and numerous results have been obtained for Boolean formula satisfiability (SAT) and constraint satisfaction (CSP), among others. However, few results are known for the critical behaviors of NP-hard nonmonotonic reasoning problems so far; in particular, a mathematical model for phase transition in nonmonotonic reasoning is still missing. In this article, we investigate the phase transition of negative two-literal logic programs under the answer-set semantics. We choose this class of logic programs since it is the simplest class for which the consistency problem of deciding if a program has an answer set is still NP-complete. We first introduce a new model, called quadratic model for generating random logic programs in this class. We then mathematically prove that the consistency problem for this class of logic programs exhibits a phase transition. Furthermore, the phase-transition follows an easy-hard-easy pattern. Given the correspondence between answer sets for negative two-literal programs and kernels for graphs, as a corollary, our result significantly generalizes de la Vega's well-known theorem for phase transition on the existence of kernels in random graphs. We also report some experimental results. Given our mathematical results, these experimental results are not really necessary. We include them here as they suggest that our phase-transition result is more general and likely holds for more general classes of logic programs. © 2016 ACM.",Answer sets; Phase transition; Random logic programs,Boolean algebra; Computational complexity; Constraint satisfaction problems; Graph theory; Logic programming; Phase transitions; Reconfigurable hardware; Semantics; Answer set; Answer set semantics; Boolean formula satisfiability; Consistency problems; Constraint Satisfaction; Non-monotonic reasoning; Quadratic modeling; Random logic; Computer circuits
Rational region-based affine logic of the real plane,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049319149&doi=10.1145%2f2897190&partnerID=40&md5=d84a8ee7debc457c4788fb6fe4208cac,"The region-based spatial logics, where variables are set to range over certain subsets of geometric space, are the focal point of the qualitative spatial reasoning, a subfield of the KR&R research area. A lot of attention has been devoted to developing the topological spatial logics, leaving other systems relatively underexplored. We are concerned with a specific example of a region-based affine spatial logic. Building on the previous results on spatial logics with convexity, we axiomatise the theory of m = 〈ROQ(ℝ2), convm, ≤m〉, where ROQ(ℝ2) is the set of regular open rational polygons of the real plane; convm is the convexity property and ≤m is the inclusion relation. The axiomatisation uses two infinitary rules of inference and a number of axiom schemas. © 2016 ACM.",Axiomatisation; Convexity; Spatial logic,Computer science; Logic programming; Axiom schemas; Axiomati-sation; Convexity; Convexity properties; Geometric space; Inclusion relation; Qualitative spatial reasoning; Spatial logic; Computer circuits
Belief merging within fragments of propositional logic,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017190946&doi=10.1145%2f2898436&partnerID=40&md5=1169010511e453130cb5edc0ce6f4747,"Recently, belief change within the framework of fragments of propositional logic has gained increasing attention. Previous research focused on belief contraction and belief revision on the Horn fragment. However, the problem of belief merging within fragments of propositional logic has been mostly neglected so far. We present a general approach to defining new merging operators derived from existing ones such that the result of merging remains in the fragment under consideration. Our approach is not limited to the case of Horn fragment; it is applicable to any fragment of propositional logic characterized by a closure property on the sets of models of its formulae. We study the logical properties of the proposed operators regarding satisfaction of merging postulates, considering, in particular, distance-based merging operators for Horn and Krom fragments. © 2016 ACM.",Belief merging; Distance-based operators; Model-based operators; Postulates,Computer circuits; Merging; Belief contraction; Closure property; Distance-based; Logical properties; Merging operators; Model-based OPC; Postulates; Propositional logic; Formal logic
Limiting until in ordered tree query languages,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971612301&doi=10.1145%2f2856104&partnerID=40&md5=b42cb5f7e99ac6e29e573480429f1bfd,"Marx and de Rijke have shown that the navigational core of the w3c XML query language XPath is not first-order complete; that is, it cannot express every query definable in first-order logic over the navigational predicates. How can one extend XPath to get a first-order complete language? Marx has shown that Conditional XPath-an extension of XPath with an ""Until"" operator-is first-order complete. The completeness argument makes essential use of the presence of upward axes in Conditional XPath. We examine whether it is possible to get ""forward-only"" languages that are first-order complete for Boolean queries on ordered trees. It is easy to see that a variant of the temporal logic CTL∗ is first-order complete; the variant has path quantifiers for downward, leftward, and rightward paths, while along a path one can check arbitrary formulas of Linear Temporal Logic (LTL). This language has two major disadvantages: It requires path quantification in both horizontal directions (in particular, it requires looking backward at the prior siblings of a node), and it requires the consideration of formulas of LTL of arbitrary complexity on vertical paths. This last is in contrast with Marx's Conditional XPath, which requires only the checking of a single Until operator on a path. We investigate whether either of these restrictions can be eliminated. Our main results are negative ones. We show that if we restrict our CTL∗ language by having an Until operator in only one horizontal direction, then we lose completeness. We also show that no restriction to a ""small"" subset of LTL along vertical paths is sufficient for first-order completeness. Smallness here means of bounded ""Until Depth,"" a measure of complexity of LTL formulas defined by Etessami and Wilke. In particular, it follows from our work that Conditional XPath with only forward axes is not expressively complete; this extends results proved by Rabinovich and Maoz in the context of infinite unordered trees. © 2016 ACM 1529-3785/2016/03-ART14 $15.00.",Hierarchy; Temporal logic; Trees; Xml,Computer circuits; Forestry; Query languages; XML; Boolean queries; First order logic; Hierarchy; Linear temporal logic; Path quantifiers; Trees; Unordered trees; XML query language; Temporal logic
Correctness and completeness of logic programs,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973931634&doi=10.1145%2f2898434&partnerID=40&md5=7e054ac65b96f621cdd28a2660e238e0,"We discuss proving correctness and completeness of definite clause logic programs. We propose a method for proving completeness, while for proving correctness we employ a method that should be well known but is often neglected. Also, we show how to prove completeness and correctness in the presence of SLD-tree pruning, and point out that approximate specifications simplify specifications and proofs. We compare the proof methods to declarative diagnosis (algorithmic debugging), showing that approximate specifications eliminate a major drawback of the latter. We argue that our proof methods reflect natural declarative thinking about programs, and that they can be used, formally or informally, in everyday programming. © 2016 ACM.",Declarative diagnosis/algorithmic debugging; Declarative programming; Logic programming; Program completeness; Program correctness; Specifications,Computer circuits; Computer programming; Logic programming; Program debugging; Reconfigurable hardware; Specifications; Algorithmic debugging; Declarative Programming; Definite clause; Logic programs; Program completeness; Program correctness; Proof methods; Tree pruning; Program diagnostics
Narrow proofs may be maximally long,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973879640&doi=10.1145%2f2898435&partnerID=40&md5=fdb4e4a71dd13e9ad3883a048fe4462d,"We prove that there are 3-conjunctive normal form formulas over n variables that can be refuted in resolution in width w but require resolution proofs of size nΩ(w). This shows that the simple counting argument that any formula refutable in width w must have a proof in size nO(w) is essentially tight. Moreover, our lower bound generalizes to polynomial calculus resolution and Sherali-Adams, implying that the corresponding size upper bounds in terms of degree and rank are tight as well. The lower bound does not extend all the way to Lasserre, however, since we show that there the formulas we study have proofs of constant rank and size polynomial in both n and w. © 2016 ACM.",Degree; PCR; Polynomial calculus; Polynomial calculus resolution; Proof complexity; Resolution; SAR; Sherali-Adams; Width,Optical resolving power; Polynomials; Degree; Polynomial calculus; Proof complexity; Sherali-Adams; Width; Calculations
"Convolution as a unifying concept: Applications in separation logic, interval calculi, and concurrency",2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959287363&doi=10.1145%2f2874773&partnerID=40&md5=bf448ee6f744d9d4dc6255e8810d5df2,"A notion of convolution is presented in the context of formal power series together with lifting constructions characterising algebras of such series, which usually are quantales. A number of examples underpin the universality of these constructions, the most prominent ones being separation logics, where convolution is separating conjunction in an assertion quantale; interval logics, where convolution is the chop operation; and stream interval functions, where convolution is proposed for analysing the trajectories of dynamical or real-time systems. A Hoare logic can be constructed in a generic fashion on the power-series quantale, which applies to each of these examples. In many cases, commutative notions of convolution have natural interpretations as concurrency operations. © 2016 ACM.",Concurrency; Convolution; Formal power series; Formal semantics; Hoare logics; Interval logics; Quantales; Semigroups; Separation logics; Systems verification,Biomineralization; Computer circuits; Convolution; Formal logic; Formal methods; Interactive computer systems; Reconfigurable hardware; Semantics; Separation; Concurrency; Formal power series; Formal Semantics; Hoare Logic; Interval logic; Quantales; Semigroups; Separation logic; Real time systems
"Zeno, Hercules, and the Hydra: Safety metric temporal logic is Ackermann-complete",2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959295008&doi=10.1145%2f2874774&partnerID=40&md5=665e067286fbd1cf591f2acfa68b7b18,"Metric temporal logic (MTL) is one of the most prominent specification formalisms for real-time systems. Over infinite timed words, full MTL is undecidable, but satisfiability for a syntactially defined safety fragment, called safety MTL, was proved decidable several years ago. Satisfiability for safety MTL is also known to be equivalent to a fair termination problem for a class of channel machines with insertion errors. However, hitherto, its precise computational complexity has remained elusive, with only a nonelementary lower bound. Via another equivalent problem, namely termination for a class of rational relations, we show that satisfiability for safety MTL is Ackermann-complete (i.e., among the easiest nonprimitive recursive problems). This is surprising since decidability was originally established using Higman's Lemma, suggesting a much higher nonmultiply recursive complexity. © 2016 ACM.",Channel machines; Complexity hierarchies; Metric temporal logic,Computability and decidability; Computer circuits; Equivalence classes; Interactive computer systems; Linearization; Real time systems; Reconfigurable hardware; Temporal logic; Channel machines; Complexity hierarchies; Fair termination; Insertion errors; Lower bounds; Metric temporal logic; Rational relations; Satisfiability; Formal logic
Power and limits of structural display rules,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959262262&doi=10.1145%2f2874775&partnerID=40&md5=129f45f28a11bd6912bddee7d44ff04b,"What can (and cannot) be expressed by structural display rules? Given a display calculus, we present a systematic procedure for transforming axioms into structural rules. The conditions for the procedure are given in terms of (purely syntactic) abstract properties of the base calculus; thus, the method applies to large classes of calculi and logics. If the calculus satisfies certain additional properties, we prove the converse direction, thus characterising the class of axioms that can be captured by structural display rules. Determining if an axiom belongs to this class or not is shown to be decidable. Applied to the display calculus for tense logic, we obtain a new proof of Kracht's Display Theorem I. © 2016 ACM.",Display calculus; Display theorem; Proof theory; Structural rules,Biomineralization; Display calculus; Proof theory; Structural rules; Calculations
The hoare logic of deterministic and nondeterministic monadic recursion schemes,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964770252&doi=10.1145%2f2835491&partnerID=40&md5=03901099458a7e8361d292f5aa2be6d8,"The equational theory of deterministic monadic recursion schemes is known to be decidable by the result of Śenizergues on the decidability of the problem of DPDA equivalence. In order to capture some properties of the domain of computation, we augment equations with certain hypotheses. This preserves the decidability of the theory, which we call simple implicational theory. The asymptotically fastest algorithm known for deciding the equational theory, and also for deciding the simple implicational theory, has a running time that is nonelementary. We therefore consider a restriction of the properties about schemes to check: instead of arbitrary equations f ≡ g between schemes, we focus on propositional Hoare assertions {p} f {q}, where f is a scheme and p, q are tests. Such Hoare assertions have a straightforward encoding as equations. For this subclass of program properties, we can also handle nondeterminism at the syntactic and/or at the semantic level, without increasing the complexity of the theories.We investigate the Hoare theory of monadic recursion schemes, that is, the set of valid implications whose conclusions are Hoare assertions and whose premises are of a certain simple form. We present a sound and complete Hoare-style calculus for this theory. We also show that the Hoare theory can be decided in exponential time, and that it is complete for this class. © 2016 ACM.",Context-free programs; Hoare logic; Monadic program schemes; Monadic recursion schemes; Propositional hoare logic; Sound and complete hoare calculus,Calculations; Computability and decidability; Reconfigurable hardware; Semantics; Context-free; Hoare calculi; Hoare Logic; Program schemes; Recursion schemes; Computer circuits
Expressive completeness of separation logic with two variables and no separating conjunction,2016,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964721811&doi=10.1145%2f2835490&partnerID=40&md5=86ac957b8f0ac601db8dfa24bc4e8e6b,"Separation logic is used as an assertion language for Hoare-style proof systems about programs with pointers, and there is an ongoing quest for understanding its complexity and expressive power. Herein, we show that first-order separation logic with one record field restricted to two variables and the separating implication (no separating conjunction) is as expressive as weak second-order logic, substantially sharpening a previous result. Capturing weak second-order logic with such a restricted form of separation logic requires substantial updates to known proof techniques. We develop these and, as a by-product, identify the smallest fragment of separation logic known to be undecidable: first-order separation logic with one record field, two variables, and no separating conjunction. Because we forbid ourselves the use ofmany syntactic resources, this underscores even further the power of separating implication on concrete heaps. © 2016 ACM.",Expressive completeness; Separation logic; Two-variable logics; Undecidability,Formal logic; Reconfigurable hardware; Separation; Assertion language; Expressive completeness; Expressive power; Proof system; Second-order logic; Separation logic; Two-variable logics; Undecidability; Computer circuits
The Complexity of LTL Rational Synthesis,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190872541&doi=10.1145%2f3648473&partnerID=40&md5=b2a98b6ca94018cc5ce565ad040139b6,"In rational synthesis, we automatically construct a reactive system that satisfies its specification in all rational environments, namely environments that have objectives and act to fulfill them. We complete the study of the complexity of LTL rational synthesis, when the objectives are given by formulas in Linear Temporal Logic. Our contribution is threefold. First, we tighten the known upper bounds for settings that were left open in earlier work. Second, our complexity analysis is parametric, and we describe tight upper and lower bounds in each of the problem parameters: the game graph, the objectives of the system components, and the objectives of the environment components. Third, we generalize the definition of rational synthesis by adding hostile players to the setting and by combining the cooperative and non-cooperative approaches studied in earlier work.  © 2024 Copyright held by the owner/author(s).",complexity; games; linear temporal logic; Rational synthesis; tree automata,Computer circuits; Complexity; Complexity analysis; Game; Linear temporal logic; Problem parameters; Rational synthesis; Reactive system; Tree automata; Upper and lower bounds; Upper Bound; Temporal logic
"First-Order Temporal Logic on Finite Traces: Semantic Properties, Decidable Fragments, and Applications",2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190949898&doi=10.1145%2f3651161&partnerID=40&md5=dd4a5f21359f01cd2fe2b967a2c41cf2,"Formalisms based on temporal logics interpreted over finite strict linear orders, known in the literature as finite traces, have been used for temporal specification in automated planning, process modelling, (runtime) verification and synthesis of programs, as well as in knowledge representation and reasoning. In this article, we focus on first-order temporal logic on finite traces. We first investigate preservation of equivalences and satisfiability of formulas between finite and infinite traces, by providing a set of semantic and syntactic conditions to guarantee when the distinction between reasoning in the two cases can be blurred. Moreover, we show that the satisfiability problem on finite traces for several decidable fragments of first-order temporal logic is ExpSpace-complete, as in the infinite trace case, while it decreases to NExpTime when finite traces bounded in the number of instants are considered. This leads also to new complexity results for temporal description logics over finite traces. Finally, we investigate applications to planning and verification, in particular by establishing connections with the notions of insensitivity to infiniteness and safety from the literature.  © 2024 Copyright held by the owner/author(s).",automated reasoning; finite traces; First-order temporal logics; temporal description logics,Computability and decidability; Computer circuits; Data description; Formal languages; Knowledge representation; Semantics; Automated planning; Automated reasoning; Description logic; Finite traces; First-order temporal logic; Linear order; Semantic properties; Temporal description logic; Temporal specification; Trace semantics; Temporal logic
Stackelberg-Pareto Synthesis,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190958115&doi=10.1145%2f3651162&partnerID=40&md5=abc9825140564efa4372c5e416aee8d0,"We study the framework of two-player Stackelberg games played on graphs in which Player 0 announces a strategy and Player 1 responds rationally with a strategy that is an optimal response. While it is usually assumed that Player 1 has a single objective, we consider here the new setting where he has several. In this context, after responding with his strategy, Player 1 gets a payoff in the form of a vector of Booleans corresponding to his satisfied objectives. Rationality of Player 1 is encoded by the fact that his response must produce a Pareto-optimal payoff given the strategy of Player 0. We study for several kinds of ω-regular objectives the Stackelberg-Pareto Synthesis problem which asks whether Player 0 can announce a strategy which satisfies his objective, whatever the rational response of Player 1. We show that this problem is fixed-parameter tractable for games in which objectives are all reachability, safety, Büchi, co-Büchi, Boolean Büchi, parity, Muller, Streett, or Rabin objectives. We also show that this problem is NEXPTIME-complete except for the cases of Büchi objectives for which it is NP-complete and co-Büchi objectives for which it is in NEXPTIME and NP-hard. The problem is already NP-complete in the simple case of reachability objectives and graphs that are trees.  © 2024 Copyright held by the owner/author(s).",Additional Key Words and PhrasesTwo-player Stackelberg games played on graphs; omega-regular objectives; synthesis,Pareto principle; Additional key word and phrasestwo-player stackelberg game played on graph; Key words; NP Complete; Omega-regular objective; Optimal response; Pareto-optimal; Reachability; Single objective; Stackelberg; Stackelberg Games; Trees (mathematics)
An Axiomatic Theory for Reversible Computation,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190856797&doi=10.1145%2f3648474&partnerID=40&md5=03c2b80099df8c93a5edff34215cdf0f,"Undoing computations of a concurrent system is beneficial in many situations, such as in reversible debugging of multi-threaded programs and in recovery from errors due to optimistic execution in parallel discrete event simulation. A number of approaches have been proposed for how to reverse formal models of concurrent computation, including process calculi such as CCS, languages like Erlang, and abstract models such as prime event structures and occurrence nets. However, it has not been settled as to what properties a reversible system should enjoy, nor how the various properties that have been suggested, such as the parabolic lemma and the causal-consistency property, are related. We contribute to a solution to these issues by using a generic labelled transition system equipped with a relation capturing whether transitions are independent to explore the implications between various reversibility properties. In particular, we show how all properties we consider are derivable from a set of axioms. Our intention is that when establishing properties of some formalism, it will be easier to verify the axioms rather than proving properties such as the parabolic lemma directly. We also introduce two new properties related to causal-consistent reversibility, namely causal liveness and causal safety, stating, respectively, that an action can be undone if (causal liveness) and only if (causal safety) it is independent from all of the following actions. These properties come in three flavours: defined in terms of independent transitions, independent events, or via an ordering on events. Both causal liveness and causal safety are derivable from our axioms.  © 2024 Copyright held by the owner/author(s).",causal consistency; causal liveness; causal safety; labelled transition system with independence; Reversible computation,Computation theory; Program debugging; Axiomatic theory; Causal consistency; Causal liveness; Causal safety; Labeled transition system with independence; Labelled transition systems; Liveness; Parabolics; Property; Reversible computations; Discrete event simulation
Characterising Modal Formulas with Examples,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190891641&doi=10.1145%2f3649461&partnerID=40&md5=f0aacef0ed9ffee2be35efacbfdedf79,"We study the existence of finite characterisations for modal formulas. A finite characterisation of a modal formula φ is a finite collection of positive and negative examples that distinguishes φ from every other, non-equivalent modal formula, where an example is a finite pointed Kripke structure. This definition can be restricted to specific frame classes and to fragments of the modal language: a modal fragment Ⅎ admits finite characterisations with respect to a frame class ℱ if every formula φ ∈ Ⅎ has a finite characterisation with respect to Ⅎ consisting of examples that are based on frames in ℱ. Finite characterisations are useful for illustration, interactive specification and debugging of formal specifications, and their existence is a precondition for exact learnability with membership queries. We show that the full modal language admits finite characterisations with respect to a frame class ℱ only when the modal logic of ℱ is locally tabular. We then study which modal fragments, freely generated by some set of connectives, admit finite characterisations. Our main result is that the positive modal language without the truth-constants ⊤ and ⊥ admits finite characterisations w.r.t. the class of all frames. This result is essentially optimal: finite characterisability fails when the language is extended with the truth constant ⊤ or ⊥ or with all but very limited forms of negation.  © 2024 Copyright held by the owner/author(s).",dualities; Finite characterisations; modal logic; positive logics; splittings; unique characterisations,Computer circuits; Formal logic; Duality; Finite characterization; Modal formulas; Modal language; Modal logic; Negative examples; Positive examples; Positive logic; Splittings; Unique characterization; Formal specification
Spectrum of FO Logic with Quantifier Depth 4 is Finite,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190836012&doi=10.1145%2f3641547&partnerID=40&md5=91e7e1836b1d2ce22faabc8a962a1b68,"The k-spectrum is the set of all α > 0 such that G(n, n-α) does not obey the 0-1 law for FO sentences with quantifier depth at most k. In this article, we prove that the minimum k such that the k-spectrum is infinite equals 5.  © 2024 Copyright held by the owner/author(s).",first-order logic; Random graphs; spectra of first order sentences; zero-one law,Formal logic; Graph theory; Depth 4; First order logic; First order sentences; Random graphs; Spectra's; Spectrum of first order sentence; Zero-one law; Computer circuits
On the Complexity of Model Checking Knowledge and Time,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183327896&doi=10.1145%2f3637212&partnerID=40&md5=52d6d7b34b415b391b21356b20ab0f2d,"We establish the precise complexity of the model-checking problem for the main logics of knowledge and time. While this problem was known to be non-elementary for agents with perfect recall, with a number of exponentials that increases with the alternation of knowledge operators, the precise complexity of the problem when the maximum alternation is fixed has been an open problem for 20 years. We close it by establishing improved upper bounds for CTL. with knowledge and providing matching lower bounds that also apply for epistemic extensions of LTL and CTL. We also study the model-checking problem for these logics on systems satisfying the ""no learning""property, introduced by Halpern and Vardi in their taxonomy of logics of knowledge and time, and we settle the complexity in almost all cases.  © 2024 Copyright held by the owner/author(s).",complexity; epistemic logic; Model checking; temporal logic,Temporal logic; Complexity; Epistemic logic; Exponentials; Low bound; Matchings; Model checking problem; Models checking; Perfect recalls; Property; Upper Bound; Model checking
Perspective Games,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183321571&doi=10.1145%2f3627705&partnerID=40&md5=0c087a087ffa4584c68274fb773e6544,"We introduce and study perspective games, which model multi-agent systems in which agents can view only the parts of the system that they own. As in standard multi-player turn-based games, the vertices of the game graph are partitioned among the players. Starting from an initial vertex, the players jointly generate a computation, with each player deciding the successor vertex whenever the generated computation reaches a vertex she owns. A perspective strategy for a player depends only on the history of visits in her vertices. Thus, unlike observation-based models of partial visibility, where uncertainty is longitudinal-players partially observe all vertices in the history, uncertainty in the perspective model is transverse-players fully observe part of the vertices in the history. We consider deterministic and probabilistic perspective games, with structural (e.g., Büchi or parity) and behavioral (e.g., LTL formulas) winning conditions. For these settings, we study the theoretical properties of the game as well as the decidability and complexity of the problem of deciding whether a player has a winning perspective strategy, in terms of both the game graph and the objectives. We compare perspective strategies with memoryless ones, and study an extension of the temporal logic ATL with path quantifiers that capture perspective and memoryless strategies.  © 2024 Copyright held by the owner/author(s).",deterministic and probabilistic games; Multi-agent systems; partial visibility,Graph theory; Visibility; Deterministic games; Deterministics; Game graphs; LTL formulae; Observation-based model; Partial visibility; Perspective models; Probabilistic games; Probabilistics; Uncertainty; Multi agent systems
"Products, Polynomials and Differential Equations in the Stream Calculus",2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183324100&doi=10.1145%2f3632747&partnerID=40&md5=dcd18f5002ccd4dba5fd174657496a5a,"We study connections among polynomials, differential equations, and streams over a field K, in terms of algebra and coalgebra. We first introduce the class of (F, G)-products on streams, those where the stream derivative of a product can be expressed as a polynomial function of the streams and their derivatives. Our first result is that, for every (F, G)-product, there is a canonical way to construct a transition function on polynomials such that the resulting unique final coalgebra morphism from polynomials into streams is the (unique) commutative K-algebra homomorphism-and vice versa. This implies that one can algebraically reason on streams via their polynomial representation. We apply this result to obtain an algebraic-geometric decision algorithm for polynomial stream equivalence, for an underlying generic (F, G)-product. Finally, we extend this algorithm to solve a more general problem: finding all valid polynomial equalities that fit in a user specified polynomial template. © 2024 Copyright held by the owner/author(s).",algebraic geometry; coalgebra; differential equations; polynomials; Streams,Differential equations; Differentiation (calculus); Algebra homomorphisms; Algebraic geometry; Coalgebras; Final coalgebras; K-algebras; Morphisms; Polynomial functions; Polynomial representations; Stream; Transition functions; Polynomials
Algebraic Proof Theory for LE-logics,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183330736&doi=10.1145%2f3632526&partnerID=40&md5=d4e8b9b834e224b0e19e80857ce64546,"In this article, we extend the research programme in algebraic proof theory from axiomatic extensions of the full Lambek calculus to logics algebraically captured by certain varieties of normal lattice expansions (normal LE-logics). Specifically, we generalize the residuated frames in Reference [34] to arbitrary signatures of normal lattice expansions (LE). Such a generalization provides a valuable tool for proving important properties of LElogics in full uniformity. We prove semantic cut elimination for the display calculi D.LE associated with the basic normal LE-logics and their axiomatic extensionswith analytic inductive axioms. We also prove the finite model property (FMP) for each such calculus D.LE, as well as for its extensions with analytic structural rules satisfying certain additional properties.  © 2024 Copyright held by the owner/author(s).",Algebraic proof theory polarity-based semantics; cut-elimination; display sequent calculi; finite model property; non-distributive logics; normal lattice expansions; substructural logics,Algebra; Biomineralization; Differentiation (calculus); Expansion; Lattice theory; Pathology; Algebraic proof theory polarity-based semantic; Cut elimination; Display sequent calculus; Finite model property; Lattice expansion; Non-distributive logic; Normal lattice expansion; Proof theory; Sequent calculus; Substructural logic; Semantics
Decidability of the Satisfiability Problem for Boolean Set Theory with the Unordered Cartesian Product Operator,2024,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181079237&doi=10.1145%2f3626823&partnerID=40&md5=d3fc0e888b6618e63bf0a28e700bd41f,"We give a positive solution to the decidability problem for the fragment of set theory, dubbed BST., consisting of quantifier-free formulae involving the Boolean set operators of union, intersection, and set difference, along with the unordered Cartesian product operator ⊗ (where s ⊗ t := {u, v} | u ∈ s Λ v ∈ t }), and the equality predicate, but no membership. Specifically, we provide nondeterministic exponential decision procedures for both the ordinary and the finite satisfiability problems for BST. We expect that these decision procedures can be adapted for the standard Cartesian product and, with added technicalities, to the cases involving membership, providing a solution to a longstanding problem in computable set theory.  © 2024 Copyright held by the owner/author(s).",Computable Set Theory; NEXPTIME satisfiability tests; Satisfiability problem and decision procedures; unordered Cartesian product,Computability and decidability; Decision theory; Cartesian Products; Computable set theory; Computable sets; Decision procedure; NEXPTIME satisfiability test; Satisfiability; Satisfiability problem and decision procedure; Satisfiability problems; Sets theory; Unordered cartesian product; Set theory
A Decision Procedure for a Theory of Finite Sets with Finite Integer Intervals,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177443825&doi=10.1145%2f3625230&partnerID=40&md5=e2008718489227c3c98e3f2640669dd9,"In this paper we extend a decision procedure for the Boolean algebra of finite sets with cardinality constraints (Ⅎ|·|) to a decision procedure for Ⅎ|·| extended with set terms denoting finite integer intervals (L[ ]). In L[ ] interval limits can be integer linear terms including unbounded variables. These intervals are a useful extension because they allow to express non-trivial set operators such as the minimum and maximum of a set, still in a quantifier-free logic. Hence, by providing a decision procedure for L[ ] it is possible to automatically reason about a new class of quantifier-free formulas. The decision procedure is implemented as part of the {log} ('setlog') tool. The paper includes a case study based on the elevator algorithm showing that {log} can automatically discharge all its invariance lemmas, some of which involve intervals.  © 2023 Copyright held by the owner/author(s).",constraint logic programming; decision procedure; integer intervals; set theory; {log},Boolean algebra; Computer circuits; Computer programming languages; Constraint programming; Constraint theory; Decision theory; Integer programming; Cardinality constraints; Constraint Logic Programming; Decision procedure; Finite set; Integer interval; Interval limits; Linear terms; Non-trivial; Sets theory; {log}; Set theory
Comparing the Expressiveness of the π-calculus and CCS,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183313351&doi=10.1145%2f3611013&partnerID=40&md5=ea4bb44828f2a83a12901dd25a66ca50,"This paper shows that the π-calculus with implicit matching is no more expressive than CCSγ, a variant of CCS in which the result of a synchronisation of two actions is itself an action subject to relabelling or restriction, rather than the silent action τ. This is done by exhibiting a compositional translation from the π-calculus with implicit matching to CCSγ that is valid up to strong barbed bisimilarity. The full π-calculus can be similarly expressed in CCSγ enriched with the triggering operation of Meije. I also show that these results cannot be recreated with CCS in the role of CCSγ, not even up to reduction equivalence, and not even for the asynchronous π-calculus without restriction or replication. Finally, I observe that CCS cannot be encoded in the π-calculus.  Copyright © 2023 held by the owner/author(s).",CCS; compositionality; Expressiveness; mobility; strong barbed bisimilarity; translations; valid encodings; π-calculus,Bisimilarity; CCS; Compositionality; Encodings; Expressiveness; Mobility; Strong barbed bisimilarity; Translation; Valid encoding; Π-calculus; Encoding (symbols)
Extensible Proof Systems for Infinite-State Systems,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174787725&doi=10.1145%2f3622786&partnerID=40&md5=1001d7b2ae63e535cbcae2db86b712c0,"This article revisits soundness and completeness of proof systems for proving that sets of states in infinitestate labeled transition systems satisfy formulas in the modal mu-calculus in order to develop proof techniques that permit the seamless inclusion of new features in this logic. Our approach relies on novel results in lattice theory, which give constructive characterizations of both greatest and least fixpoints of monotonic functions over complete lattices. We show how these results may be used to reason about the sound and complete tableau method for this problem due to Bradfield and Stirling. We also show how the flexibility of our lattice-theoretic basis simplifies reasoning about tableau-based proof strategies for alternative classes of systems. In particular, we extend the modal mu-calculus with timed modalities, and prove that the resulting tableau method is sound and complete for timed transition systems. © 2023 Association for Computing Machinery. All rights reserved.",infinite-state systems; model checking; Mu-calculus; tableaux; timed systems,Lattice theory; Temporal logic; Infinite state systems; Infinite-state; Models checking; Mu-calculus; Proof system; Sound and complete; Soundness and completeness; Tableau-methods; Tableaux; Timed systems; Model checking
Living without Beth and Craig: Definitions and Interpolants in Description and Modal Logics with Nominals and Role Inclusions,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171145042&doi=10.1145%2f3597301&partnerID=40&md5=6b6a78065b4a9ccba3930fc462f387a7,"The Craig interpolation property (CIP) states that an interpolant for an implication exists iff it is valid. The projective Beth definability property (PBDP) states that an explicit definition exists iff a formula stating implicit definability is valid. Thus, the CIP and PBDP reduce potentially hard existence problems to entailment in the underlying logic. Description (and modal) logics with nominals and/or role inclusions do not enjoy the CIP nor the PBDP, but interpolants and explicit definitions have many applications, in particular in concept learning, ontology engineering, and ontology-based data management. In this article, we show that, even without Beth and Craig, the existence of interpolants and explicit definitions is decidable in description logics with nominals and/or role inclusions such as ALCO, ALCH, and ALCHOI and corresponding hybrid modal logics. However, living without Beth and Craig makes these problems harder than entailment: the existence problems become 2ExpTime-complete in the presence of an ontology or the universal modality, and coNExpTime-complete otherwise. We also analyze explicit definition existence if all symbols (except the one that is defined) are admitted in the definition. In this case, the complexity depends on whether one considers individual or concept names. Finally, we consider the problem of computing interpolants and explicit definitions if they exist and turn the complexity upper bound proof into an algorithm computing them, at least for description logics with role inclusions. © 2023 Copyright held by the owner/author(s).",beth definability; computational complexity; craig interpolants; Description logic; explicit definitions; modal logic,Computational complexity; Computer circuits; Formal languages; Fuzzy logic; Information management; Interpolation; Ontology; Beth definability; Craig interpolants; Craig interpolation; Definability; Description logic; Explicit definition; Interpolants; Interpolation properties; Modal logic; Property; Data description
"Inputs, Outputs, and Composition in the Logic of Information Flows",2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171969201&doi=10.1145%2f3604553&partnerID=40&md5=f42e5c07ed6b960e8fcb18031ec3387b,"The logic of information flows (LIF) is a general framework in which tasks of a procedural nature can be modeled in a declarative, logic-based fashion. The first contribution of this article is to propose semantic and syntactic definitions of inputs and outputs of LIF expressions. We study how the two relate and show that our syntactic definition is optimal in a sense that is made precise. The second contribution is a systematic study of the expressive power of sequential composition in LIF. Our results on composition tie in the results on inputs and outputs and relate LIF to first-order logic (FO) and bounded-variable LIF to bounded- variable FO.This article is the extended version of a paper presented at KR 2020 [2]. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",binary relations on valuations; Dynamic logic; expressive power,Computer circuits; Formal logic; Semantics; Binary relation; Binary relation on valuation; Bounded variables; Declarative logic; Dynamic logic; Expressive power; First order logic; Information flows; Input and outputs; Input-output; Syntactics
Local Search For Satisfiability Modulo Integer Arithmetic Theories,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174956953&doi=10.1145%2f3597495&partnerID=40&md5=f8c2562817489d158d1ad12c00b5ab0f,"Satisfiability Modulo Theories (SMT) refers to the problem of deciding the satisfiability of a formula with respect to certain background first-order theories. In this article, we focus on Satisfiablity Modulo Integer Arithmetic, which is referred to as SMT(IA), including both linear and non-linear integer arithmetic theories. Dominant approaches to SMT rely on calling a CDCL-based SAT solver, either in a lazy or eager flavour. Local search, a competitive approach to solving combinatorial problems including SAT, however, has not been well studied for SMT. We develop the first local-search algorithm for SMT(IA) by directly operating on variables, breaking through the traditional framework. We propose a local-search framework by considering the distinctions between Boolean and integer variables. Moreover, we design a novel operator and scoring functions tailored for integer arithmetic, as well as a two-level operation selection heuristic. Putting these together, we develop a local search SMT(IA) solver called LocalSMT. Experiments are carried out to evaluate LocalSMT on benchmark sets from SMT-LIB. The results show that LocalSMT is competitive and complementary with state-of-the-art SMT solvers, and performs particularly well on those formulae with only integer variables. A simple sequential portfolio with Z3 improves the state-of-the-art on satisfiable benchmark sets from SMT-LIB. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",linear integer arithmetic; local search; non-linear integer arithmetic; SMT,Formal logic; Integer arithmetic; Integer variables; Linear integer arithmetic; Local search; Non linear; Non-linear integer arithmetic; Satisfiability; Satisfiability modulo Theories; State of the art; Local search (optimization)
Generating Extended Resolution Proofs with a BDD-Based SAT Solver,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174905602&doi=10.1145%2f3595295&partnerID=40&md5=040fabae0253171b43b8580485724f6c,"In 2006, Biere, Jussila, and Sinz made the key observation that the underlying logic behind algorithms for constructing Reduced, Ordered Binary Decision Diagrams (BDDs) can be encoded as steps in a proof in the extended resolution logical framework. Through this, a BDD-based Boolean satisfiability (SAT) solver can generate a checkable proof of unsatisfiability. Such a proof indicates that the formula is truly unsatisfiable without requiring the user to trust the BDD package or the SAT solver built on top of it. We extend their work to enable arbitrary existential quantification of the formula variables, a critical capability for BDD-based SAT solvers. We demonstrate the utility of this approach by applying a BDD-based solver, implemented by extending an existing BDD package, to several challenging Boolean satisfiability problems. Our results demonstrate scaling for parity formulas as well as the Urquhart, mutilated chessboard, and pigeonhole problems far beyond that of other proof-generating SAT solvers. © 2023 Copyright held by the owner/author(s).",binary decision diagrams; Boolean satisfiability; extended resolution; mutilated chessboard; pigeonhole problem; Urquhart formulas,Boolean functions; Decision theory; Model checking; Boolean satisfiability; Existential quantifications; Extended resolution; Logical frameworks; Mutilated chessboard; Pigeonhole problem; Reduced ordered binary decision diagram; Resolution proofs; Satisfiability solvers; Urquhart formula; Binary decision diagrams
First-order Logic with Connectivity Operators,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174968580&doi=10.1145%2f3595922&partnerID=40&md5=beb5f2989876691ae4e9cc8f3be9c22c,"First-order logic (FO) can express many algorithmic problems on graphs, such as the independent set and dominating set problem parameterized by solution size. However, FO cannot express the very simple algorithmic question whether two vertices are connected. We enrich FO with connectivity predicates that are tailored to express algorithmic graph problems that are commonly studied in parameterized algorithmics. By adding the atomic predicates connk(x,y,z_1,..., zk) that hold true in a graph if there exists a path between (the valuations of) x and y after (the valuations of) z1,..., zk have been deleted, we obtain separator logic FO + conn. We show that separator logic can express many interesting problems, such as the feedback vertex set problem and elimination distance problems to first-order definable classes. Denote by FO + connk the fragment of separator logic that is restricted to connectivity predicates with at most k + 2 variables (that is, at most k deletions), we show that FO + connk + 1 is strictly more expressive than FO + connk for all k ≥ 0. We then study the limitations of separator logic and prove that it cannot express planarity, and, in particular, not the disjoint paths problem. We obtain the stronger disjoint-paths logic FO + DP by adding the atomic predicates disjoint-pathsk[(x1, y1),..., (xk, yk) that evaluate to true if there are internally vertex-disjoint paths between (the valuations of) xi and yi for all 1 ≤ i ≤ k. Disjoint-paths logic can express the disjoint paths problem, the problem of (topological) minor containment, the problem of hitting (topological) minors, and many more. Again, we show that the fragments FO + DPk that use predicates for at most k disjoint paths form a strict hierarchy of expressiveness. Finally, we compare the expressive power of the new logics with that of transitive-closure logics and monadic second-order logic. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",connectivity; First-order logic; graph theory,Computer circuits; Formal logic; Parameter estimation; Separators; Algorithmic problems; Algorithmics; Connectivity; Disjoint paths; Disjoint paths problem; Dominating set problems; First order logic; Independent set; Parameterized; Topological-minor; Graph theory
A Decidable Fragment of First Order Modal Logic: Two Variable Term Modal Logic,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171712904&doi=10.1145%2f3593584&partnerID=40&md5=7b45c9488f5853cfed6542846b199447,"First order modal logic () is built by extending First Order Logic () with modal operators. A typical formula is of the form . Not only is undecidable, even simple fragments like that of restriction to unary predicate symbols, guarded fragment and two variable fragment, which are all decidable for become undecidable for . In this paper we study Term Modal logic () which allows modal operators to be indexed by terms. A typical formula is of the form . There is a close correspondence between and and we explore this relationship in detail in the paper.In contrast to , we show that the two variable fragment (without constants, equality) of is decidable. Further, we prove that adding a single constant makes the two variable fragment of undecidable. On the other hand, when equality is added to the logic, it loses the finite model property. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",decidability; equality; normal form; Term modal logic; two variable fragment,Computer circuits; Equality; First order; First order logic; Modal logic; Modal operators; Normal form; Simple++; Term modal logic; Two variable fragment; Variable fragment; Computability and decidability
Interpolation Results for Arrays with Length and MaxDiff,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174912222&doi=10.1145%2f3587161&partnerID=40&md5=3b28a29f6cae4d47f470f85296f0da1b,"In this article, we enrich McCarthy's theory of extensional arrays with a length and a maxdiff operation. As is well-known, some diff operation (i.e., some kind of difference function showing where two unequal arrays differ) is needed to keep interpolants quantifier free in array theories. Our maxdiff operation returns the max index where two arrays differ; thus, it has a univocally determined semantics.The length function is a natural complement of such a maxdiff operation and is needed to handle real arrays. Obtaining interpolation results for such a rich theory is a surprisingly hard task. We get such results via a thorough semantic analysis of the models of the theory and of their amalgamation and strong amalgamation properties. The results are modular with respect to the index theory; we show how to convert them into concrete interpolation algorithms via a hierarchical approach realizing a polynomial reduction to interpolation in linear arithmetics endowed with free function symbols. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",amalgamation; arrays; interpolation; SMT,Semantics; Amalgamation; Array; Difference functions; Hard task; Interpolants; Length functions; Modulars; Property; Semantic analysis; Two arrays; Interpolation
"Mixed Iterated Revisions: Rationale, Algorithms, and Complexity",2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162177805&doi=10.1145%2f3583071&partnerID=40&md5=a524cc97bd976e94c21463de35b87c92,"Several forms of iterable belief change exist, differing in the kind of change and its strength: some operators introduce formulae, others remove them; some add formulae unconditionally, others only as additions to the previous beliefs; some only relative to the current situation, others in all possible cases. A sequence of changes may involve several of them: for example, the first step is a revision, the second a contraction and the third a refinement of the previous beliefs. The ten operators considered in this article are shown to be all reducible to three: lexicographic revision, refinement, and severe withdrawal. In turn, these three can be expressed in terms of lexicographic revision at the cost of restructuring the sequence. This restructuring needs not to be done explicitly: an algorithm that works on the original sequence is shown. The complexity of mixed sequences of belief change operators is also analyzed. Most of them require only a polynomial number of calls to a satisfiability checker, some are even easier.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",computational complexity; Iterated belief revision; translation algorithm,Algorithms and complexity; Belief change; Belief revision; Change operators; Current situation; Iterable; Iterated belief revision; Polynomial number; Satisfiability checker; Translation algorithms; Computational complexity
Parameterized Complexity of Logic-based Argumentation in Schaefer's Framework,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164301929&doi=10.1145%2f3582499&partnerID=40&md5=ece45d83faad274691b7bc8a8e1969fc,"Argumentation is a well-established formalism dealing with conflicting information by generating and comparing arguments. It has been playing a major role in AI for decades. In logic-based argumentation, we explore the internal structure of an argument. Informally, a set of formulas is the support for a given claim if it is consistent, subset-minimal, and implies the claim. In such a case, the pair of the support and the claim together is called an argument. In this article, we study the propositional variants of the following three computational tasks studied in argumentation: ARG (exists a support for a given claim with respect to a given set of formulas), ARG-Check (is a given set a support for a given claim), and ARG-Rel (similarly as ARG plus requiring an additionally given formula to be contained in the support). ARG-Check is complete for the complexity class DP, and the other two problems are known to be complete for the second level of the polynomial hierarchy (Creignou et al. 2014 and Parson et al., 2003) and, accordingly, are highly intractable. Analyzing the reason for this intractability, we perform a two-dimensional classification: First, we consider all possible propositional fragments of the problem within Schaefer's framework (STOC 1978) and then study different parameterizations for each of the fragments. We identify a list of reasonable structural parameters (size of the claim, support, knowledge base) that are connected to the aforementioned decision problems. Eventually, we thoroughly draw a fine border of parameterized intractability for each of the problems showing where the problems are fixed-parameter tractable and when this exactly stops. Surprisingly, several cases are of very high intractability (para-NP and beyond).  © 2023 Copyright held by the owner/author(s).",logic-based argumentation; Parameterized complexity; Schaefer's framework,Computer circuits; Knowledge based systems; Complexity class; Computational task; Consistent subset; Internal structure; Logic-based argumentations; Parameterized complexity; Polynomial hierarchies; Schaefe framework; Second level; Two-dimensional; Parameterization
Faster Property Testers in a Variation of the Bounded Degree Model,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164282531&doi=10.1145%2f3584948&partnerID=40&md5=0fb35a2b1f034a2bfc0a196fd3e2c973,"Property testing algorithms are highly efficient algorithms that come with probabilistic accuracy guarantees. For a property P, the goal is to distinguish inputs that have P from those that are far from having P with high probability correctly, by querying only a small number of local parts of the input. In property testing on graphs, the distance is measured by the number of edge modifications (additions or deletions) that are necessary to transform a graph into one with property P. Much research has focused on the query complexity of such algorithms, i. e., the number of queries the algorithm makes to the input, but in view of applications, the running time of the algorithm is equally relevant.In (Adler, Harwath, STACS 2018), a natural extension of the bounded degree graph model of property testing to relational databases of bounded degree was introduced, and it was shown that on databases of bounded degree and bounded tree-width, every property that is expressible in monadic second-order logic with counting (CMSO) is testable with constant query complexity and sublinear running time. It remains open whether this can be improved to constant running time.In this article we introduce a new model, which is based on the bounded degree model, but the distance measure allows both edge (tuple) modifications and vertex (element) modifications. We show that every property that is testable in the classical model is testable in our model with the same query complexity and running time, but the converse is not true. Our main theorem shows that on databases of bounded degree and bounded tree-width, every property that is expressible in CMSO is testable with constant query complexity and constant running time in the new model. Our proof methods include the semilinearity of the neighborhood histograms of databases having the property and a result by Alon (Proposition 19.10 in Lovász, Large networks and graph limits, 2012) that states that for every bounded degree graph there exists a constant size graph that has a similar neighborhood distribution to .It can be derived from a result in (Benjamini et al., Advances in Mathematics 2010) that hyperfinite hereditary properties are testable with constant query complexity and constant running time in the classical model (and hence in the new model). Using our methods, we give an alternative proof that hyperfinite hereditary properties are testable with constant query complexity and constant running time in the new model.We argue that our model is natural and our meta-theorem showing constant-time CMSO testability supports this.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",bounded degree model; Constant time algorithms; logic and databases; property testing,Complex networks; Computer circuits; Graphic methods; Trees (mathematics); Bounded degree; Bounded degree graphs; Bounded-degree models; Constant time algorithms; Logic and database; Property; Property-testing; Query complexity; Running time; Tree-width; Computational complexity
Interval Temporal Logic for Visibly Pushdown Systems,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164295954&doi=10.1145%2f3583756&partnerID=40&md5=0b267075203356b979ea00e4681f23c4,"In this article, we introduce and investigate an extension of Halpern and Shoham's interval temporal logic HS for the specification and verification of branching-time context-free requirements of pushdown systems under a state-based semantics over Kripke structures enforcing visibility of the pushdown operations. The proposed logic, called nested BHS, supports branching-time both in the past and in the future and is able to express non-regular properties of linear and branching behaviours of procedural contexts in a natural way. It strictly subsumes well-known linear time context-free extensions of LTL such as CaRet [4] and NWTL [2]. The main result is the decidability of the visibly pushdown model-checking problem against nested BHS. The proof exploits a non-trivial automata-theoretic construction.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",interval temporal logic; model checking; Pushdown systems,Computer circuits; Semantics; Temporal logic; Branching time; Context-free; Interval temporal logic; Kripke structure; Models checking; Pushdown; Pushdown systems; Specification and verification; State based; Time contexts; Model checking
Precise Subtyping for Asynchronous Multiparty Sessions,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154022788&doi=10.1145%2f3568422&partnerID=40&md5=64a402047502cd1bd8989691884d9aa5,"Session subtyping is a cornerstone of refinement of communicating processes: A process implementing a session type (i.e., a communication protocol) T can be safely used whenever a process implementing one of its supertypes T′ is expected, in any context, without introducing deadlocks nor other communication errors. As a consequence, whenever T ≤ T′ holds, it is safe to replace an implementation of T′ with an implementation of the subtype T, which may allow for more optimised communication patterns. We present the first formalisation of the precise subtyping relation for asynchronous multiparty sessions. We show that our subtyping relation is sound(i.e., guarantees safe process replacement, as outlined above) and also complete: Any extension of the relation is unsound. To achieve our results, we develop a novel session decomposition technique, from fullsession types (including internal/external choices) into single input/output session trees (without choices). We cover multiparty sessions with asynchronousinteraction, where messages are transmitted via FIFO queues (as in the TCP/IP protocol), and prove that our subtyping is both operationally and denotationally precise. Our session decomposition technique expresses the subtyping relation as a composition of refinement relations between single input/output trees and provides a simple reasoning principle for asynchronous message optimisations.  © 2023 Copyright held by the owner/author(s).",asynchronous multiparty session types; completeness; Session types; soundness; subtyping; typing systems; π-calculus,Asynchronoi multiparty session type; Completeness; Multiparty sessions; Session types; Soundness; Subtyping relation; Subtypings; Typing systems; Π-calculus; Formal languages
A Generalized Realizability and Intuitionistic Logic,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152484637&doi=10.1145%2f3565367&partnerID=40&md5=44951b417b0e7554cccd195c3bc483be,"Let V be a set of number-theoretical functions. We define a notion of V-realizability for predicate formulas in such a way that the indices of functions in V are used for interpreting the implication and the universal quantifier. In this article, we prove that Intuitionistic Predicate Calculus is sound with respect to the semantics of V-realizability if and only if some natural conditions for V hold. © 2023 Copyright held by the owner/author(s).",absolute realizability; Constructive semantics; intuitionistic logic; realizability,Computer circuits; Absolute realizability; Constructive semantics; Intuitionistic logic; Natural conditions; Realizability; Universal quantifiers; Semantics
Eager Equality for Rational Number Arithmetic,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164285439&doi=10.1145%2f3580365&partnerID=40&md5=e52b4f9c67e1e5bed30c9db5f0268517,"Eager equality for algebraic expressions over partial algebras distinguishes or separates terms only if both have defined values and they are different. We consider arithmetical algebras with division as a partial operator, called meadows, and focus on algebras of rational numbers. To study eager equality, we use common meadows, which are totalisations of partial meadows by means of absorptive elements. An axiomatisation of common meadows is the basis of an axiomatisation of eager equality as a predicate on a common meadow. Applied to the rational numbers, we prove completeness and decidability of the equational theory of eager equality. To situate eager equality theoretically, we consider two other partial equalities of increasing strictness: Kleene equality, which is equivalent to the native equality of common meadows, and one we call cautious equality. Our methods of analysis for eager equality are quite general, and so we apply them to these two other partial equalities; and, in addition to common meadows, we use three other kinds of algebra designed to totalise division. In summary, we are able to compare 13 forms of equality for the partial meadow of rational numbers. We focus on the decidability of the equational theories of these equalities. We show that for the four total algebras, eager and cautious equality are decidable. We also show that for others the Diophantine Problem over the rationals is one-one computably reducible to their equational theories. The Diophantine Problem for rationals is a longstanding open problem. Thus, eager equality has substantially less complex semantics.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",cautious equality; common meadow; eager equality; flattening; fracterm calculus; Kleene equality; Partial algebras; transrationals; wheels,Computability and decidability; Semantics; Cautious equality; Common meadow; Eager equality; Equational theory; Flattening; Fracterm calculus; Kleene equality; Partial algebra; Rational numbers; Transrational; Algebra
Reasoning about Quality and Fuzziness of Strategic Behaviors,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162699550&doi=10.1145%2f3582498&partnerID=40&md5=21e75b95bfeee35e506155771a5bd711,"Temporal logics are extensively used for the specification of on-going behaviors of computer systems. Two significant developments in this area are the extension of traditional temporal logics with modalities that enable the specification of on-going strategic behaviors in multi-agent systems, and the transition of temporal logics to a quantitative setting, where different satisfaction values enable the specifier to formalize concepts such as certainty or quality. In the first class, SL (Strategy Logic) is one of the most natural and expressive logics describing strategic behaviors. In the second class, a notable logic is LTL[F] , which extends LTL with quality operators.In this work, we introduce and study SL[F] , which enables the specification of quantitative strategic behaviors. The satisfaction value of an SL[F] formula is a real value in [0,1], reflecting ""how much""or ""how well""the strategic on-going objectives of the underlying agents are satisfied. We demonstrate the applications of SL[F] in quantitative reasoning about multi-agent systems, showing how it can express and measure concepts like stability in multi-agent systems, and how it generalizes some fuzzy temporal logics. We also provide a model-checking algorithm for SL[F] , based on a quantitative extension of Quantified CTL∗. Our algorithm provides the first decidability result for a quantitative extension of Strategy Logic. In addition, it can be used for synthesizing strategies that maximize the quality of the systems' behavior.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",fuzzy; quantitative; Synthesis,Computer circuits; Fuzzy systems; Model checking; Multi agent systems; Specifications; Class A; Fuzzy; Model-checking algorithms; Quantitative; Quantitative reasoning; Real values; Second class; Strategic Behavior; System behaviors; Temporal logic
Circular (Yet Sound) Proofs in Propositional Logic,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164301709&doi=10.1145%2f3579997&partnerID=40&md5=43c2edd19d12a2470cef6d9c57b4a2b6,"Proofs in propositional logic are typically presented as trees of derived formulas or, alternatively, as directed acyclic graphs of derived formulas. This distinction between tree-like vs. dag-like structure is particularly relevant when making quantitative considerations regarding, for example, proof size. Here we analyze a more general type of structural restriction for proofs in rule-based proof systems. In this definition, proofs are directed graphs of derived formulas in which cycles are allowed as long as every formula is derived at least as many times as it is required as a premise. We call such proofs ""circular"". We show that, for all sets of standard inference rules with single or multiple conclusions, circular proofs are sound. We start the study of the proof complexity of circular proofs at Circular Resolution, the circular version of Resolution. We immediately see that Circular Resolution is stronger than dag-like Resolution since, as we show, the propositional encoding of the pigeonhole principle has circular Resolution proofs of polynomial size. Furthermore, for derivations of clauses from clauses, we show that Circular Resolution is, surprisingly, equivalent to Sherali-Adams, a proof system for reasoning through polynomial inequalities that has linear programming at its base. As corollaries we get: (1) polynomial-time (LP-based) algorithms that find Circular Resolution proofs of constant width, (2) examples that separate Circular from dag-like Resolution, such as the pigeonhole principle and its variants, and (3) exponentially hard cases for Circular Resolution. Contrary to the case of Circular Resolution, for Frege we show that circular proofs can be converted into tree-like proofs with at most polynomial overhead.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Frege; Proof complexity; resolution,Computer circuits; Directed graphs; Formal logic; Polynomial approximation; Trees (mathematics); Acyclic graphs; Circular resolutions; Derived formulae; Frege; Pigeonhole principle; Proof complexity; Proof system; Propositional logic; Resolution; Resolution proofs; Linear programming
On Composing Finite Forests with Modal Logics,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152943708&doi=10.1145%2f3569954&partnerID=40&md5=5a6c8ee4c7ec4b13fe303f1cf911b1a6,"We study the expressivity and complexity of two modal logics interpreted on finite forests and equipped with standard modalities to reason on submodels. The logic extends the modal logic K with the composition operator from ambient logic whereas features the separating conjunction from separation logic. Both operators are second-order in nature. We show that is as expressive as the graded modal logic (on trees) whereas is strictly less expressive than . Moreover, we establish that the satisfiability problem is Tower-complete for , whereas it is (only) AExpPol-complete for , a result that is surprising given their relative expressivity. As by-products, we solve open problems related to sister logics such as static ambient logic and modal separation logic.  © 2023 Copyright held by the owner/author(s).",complexity; expressive power; graded modal logic; Modal logic on trees; separation logic; static ambient logic,Computer circuits; Ambient logic; Complexity; Composition operators; Expressive power; Graded modal logic; Modal logic; Modal logic on tree; Separation logic; Static ambient logic; Submodels; Formal logic
Number of Variables for Graph Differentiation and the Resolution of Graph Isomorphism Formulas,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164300759&doi=10.1145%2f3580478&partnerID=40&md5=6a2a440c1f93152a2e59453f8740fe32,"We show that the number of variables and the quantifier depth needed to distinguish a pair of graphs by first-order logic sentences exactly match the complexity measures of clause width and depth needed to refute the corresponding graph isomorphism formula in propositional narrow resolution.Using this connection, we obtain upper and lower bounds for refuting graph isomorphism formulas in (normal) resolution. In particular, we show that if k is the minimum number of variables needed to distinguish two graphs with n vertices each, then there is an nO(k) resolution refutation size upper bound for the corresponding isomorphism formula, as well as lower bounds of 2k-1 and k for the treelike resolution size and resolution clause space for this formula. We also show a (normal) resolution size lower bound of exp (ω (k2/n)) for the case of colored graphs with constant color class sizes.Applying these results, we prove the first exponential lower bound for graph isomorphism formulas in the proof system SRC-1, a system that extends resolution with a global symmetry rule, thereby answering an open question posed by Schweitzer and Seebach.  © 2023 Copyright held by the owner/author(s).",graph isomorphism; Immerman's pebble game; k-variable fragment first-order logic L<sub>k</sub>; narrow width; Proof complexity; resolution; SRC-1; symmetry rule,Formal logic; Graph theory; Set theory; First order logic; Graph isomorphism; Immerman pebble game; K-variable fragment first-order logic Lk; Narrow width; Pebble game; Proof complexity; Resolution; SRC-1; Symmetry rule; Variable fragment; Computer circuits
On Monotonic Determinacy and Rewritability for Recursive Queries and Views,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152897999&doi=10.1145%2f3572836&partnerID=40&md5=1f5cc6edf2dd7c9cc085918aa8675e5c,"A query Q is monotonically determined over a set of views V if Q can be expressed as a monotonic function of the view image. In the case of relational algebra views and queries, monotonic determinacy coincides with rewritability as a union of conjunctive queries, and it is decidable in important special cases, such as for conjunctive query views and queries. We investigate the situation for views and queries in the recursive query language Datalog. We give both positive and negative results about the ability to decide monotonic determinacy, and also about the co-incidence of monotonic determinacy with Datalog rewritability.  © 2023 Association for Computing Machinery.",Datalog; Views,Algebra; Algebra view; Datalog; Monotonic functions; Monotonics; Relational algebra; View; Query languages
Semantic Analysis of a Linear Temporal Extension of Quantum Logic and Its Dynamic Aspect,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164297668&doi=10.1145%2f3576926&partnerID=40&md5=de980d1f6a1bf21d288c9ac582e479f7,"Although various dynamic or temporal logics have been proposed to verify quantum protocols and systems, these two viewpoints have not been studied comprehensively enough. We propose Linear Temporal Quantum Logic (LTQL), a linear temporal extension of quantum logic with a quantum implication, and extend it to Dynamic Linear Temporal Quantum Logic (DLTQL). This logic has temporal operators to express transitions by unitary operators (quantum gates) and dynamic ones to express those by projections (projective measurement). We then prove some logical properties of the relationship between these two transitions expressed by LTQL and DLTQL. A drawback in applying LTQL to the verification of quantum protocols is that these logics cannot express the future operator in linear temporal logic. We propose a way to mitigate this drawback by using a translation from (D)LTQL to Linear Temporal Modal Logic (LTML) and a simulation. This translation reduces the satisfiability problem of (D)LTQL formulas to that of LTML with the classical semantics over quantum states.  © 2023 Association for Computing Machinery.",dynamic logic; Kripke semantics; linear temporal logic; modal logic; Quantum logic; simulation; transition system,Computer circuits; Quantum theory; Semantics; Dynamic linear; Dynamic logic; Kripke semantics; Linear temporal logic; Modal logic; Quantum logic; Quantum protocols; Simulation; Temporal extensions; Transition system; Temporal logic
Generalizing Parikh's Criterion for Relevance-Sensitive Belief Revision,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147945804&doi=10.1145%2f3572907&partnerID=40&md5=46ad5138a1abddce15ff31cd86e240fa,"Parikh proposed his relevance-sensitive axiom to remedy the weakness of the classical AGM paradigm in addressing relevant change. An insufficiency of Parikh's criterion, however, is its dependency on the contingent beliefs of a belief set to be revised, since the former only constrains the revision process of splittable theories (i.e., theories that can be divided in mutually disjoint compartments). The case of arbitrary non-splittable belief sets remains out of the scope of Parikh's approach. On that premise, we generalize Parikh's criterion, introducing (both axiomatically and semantically) a new notion of relevance, which we call relevance at the sentential level. We show that the proposed notion of relevance is universal (as it is applicable to arbitrary belief sets) and acts in a more refined way as compared to Parikh's proposal; as we illustrate, this latter feature of relevance at the sentential level potentially leads to a significant drop in the computational resources required for implementing belief revision. Furthermore, we prove that Dalal's popular revision operator respects, to a certain extent, relevance at the sentential level. Last but not least, the tight relation between local and relevance-sensitive revision is pointed out.  © 2023 Association for Computing Machinery.",Belief change; Dalal's revision operator; knowledge representation; local revision; Parikh's splittability; relevance,Belief change; Belief revision; Belief sets; Computational resources; Dalal revision operator; Knowledge-representation; Local revision; Parikh splittability; Relevance; Revision operator; Knowledge representation
"Testing using CSP Models: Time, Inputs, and Outputs",2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152491032&doi=10.1145%2f3572837&partnerID=40&md5=973cf275f32a9e9b5cb0d31ec2809313,"The existing testing theories for CSP cater for verification of interaction patterns (traces) and deadlocks, but not time. We address here refinement and testing based on a dialect of CSP, called tock-CSP, which can capture discrete time properties. This version of CSP has been of widespread interest for decades; recently, it has been given a denotational semantics, and model checking has become possible using a well established tool. Here, we first equip tock-CSP with a novel semantics for testing, which distinguishes input and output events: the standard models of (tock-)CSP do not differentiate them, but for testing this is essential. We then present a new testing theory for timewise refinement, based on novel definitions of test and test execution. Finally, we reconcile refinement and testing by relating timed ioco testing and refinement in tock-CSP with inputs and outputs. With these results, this paper provides, for the first time, a systematic theory that allows both timed testing and timed refinement to be expressed. An important practical consequence is that this ensures that the notion of correctness used by developers guarantees that tests pass when applied to a correct system and, in addition, faults identified during testing correspond to development mistakes.  © 2023 Association for Computing Machinery.",exhaustive test set; Model-based testing; process algebra; refinement,Semantics; CSP model; Exhaustive test set; Exhaustive tests; Input and outputs; Interaction pattern; Model based testing; Process algebras; Refinement; Test sets; Testing theories; Model checking
Hardness Characterisations and Size-width Lower Bounds for QBF Resolution,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152477963&doi=10.1145%2f3565286&partnerID=40&md5=8368d8372edb8d82b570c503fd45833c,"We provide a tight characterisation of proof size in resolution for quantified Boolean formulas (QBF) via circuit complexity. Such a characterisation was previously obtained for a hierarchy of QBF Frege systems [16], but leaving open the most important case of QBF resolution. Different from the Frege case, our characterisation uses a new version of decision lists as its circuit model, which is stronger than the CNFs the system works with. Our decision list model is well suited to compute countermodels for QBFs. Our characterisation works for both Q-Resolution and QU-Resolution.Using our characterisation, we obtain a size-width relation for QBF resolution in the spirit of the celebrated result for propositional resolution [4]. However, our result is not just a replication of the propositional relation - intriguingly ruled out for QBF in previous research [12] - but shows a different dependence between size, width, and quantifier complexity. An essential ingredient is an improved relation between the size and width of term decision lists; this may be of independent interest. We demonstrate that our new technique elegantly reproves known QBF hardness results and unifies previous lower-bound techniques in the QBF domain. © 2023 Association for Computing Machinery.",proof complexity; Quantified Boolean formulas; size-width tradeoff,Boolean functions; Circuit complexity; Circuit modeling; Counter-models; Decision lists; Hardness result; Low bound; Proof complexity; Propositional resolution; Quantified Boolean formulas; Size-width tradeoff; Hardness
Linear Logic Properly Displayed,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152969642&doi=10.1145%2f3570919&partnerID=40&md5=8f29331189dc919247384dda72cf8bb1,"We introduce proper display calculi for intuitionistic, bi-intuitionistic and classical linear logics with exponentials, which are sound, complete, conservative, and enjoy cut elimination and subformula property. Based on the same design, we introduce a variant of Lambek calculus with exponentials, aimed at capturing the controlled application of exchange and associativity. Properness (i.e., closure under uniform substitution of all parametric parts in rules) is the main technical novelty of the present proposal, allowing both for the smoothest proof of cut elimination and for the development of an overarching and modular treatment for a vast class of axiomatic extensions and expansions of intuitionistic, bi-intuitionistic, and classical linear logics with exponentials. Our proposal builds on an algebraic and order-theoretic analysis of linear logic and applies the guidelines of the multi-type methodology in the design of display calculi.  © 2023 Association for Computing Machinery.",analytic inductive inequalities; lattice expansions; Proper display calculi; properly displayable logics; unified correspondence,Biomineralization; Computer circuits; Differentiation (calculus); Linear algebra; Analytic inductive inequality; Classical linear logic; Display calculus; Exponentials; Intuitionistic linear logic; Lattice expansion; Linear logic; Proper display calculus; Properly displayable logic; Unified correspondence; Pathology
Witnesses for Answer Sets of Logic Programs,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152914072&doi=10.1145%2f3568955&partnerID=40&md5=2207fda6ffb9c7aaf2e568d84fda68e8,"In this article, we consider Answer Set Programming (ASP). It is a declarative problem solving paradigm that can be used to encode a problem as a logic program whose answer sets correspond to the solutions of the problem. It has been widely applied in various domains in AI and beyond. Given that answer sets are supposed to yield solutions to the original problem, the question of ""why a set of atoms is an answer set""becomes important for both semantics understanding and program debugging. It has been well investigated for normal logic programs. However, for the class of disjunctive logic programs, which is a substantial extension of that of normal logic programs, this question has not been addressed much. In this article, we propose a notion of reduct for disjunctive logic programs and show how it can provide answers to the aforementioned question. First, we show that for each answer set, its reduct provides a resolution proof for each atom in it. We then further consider minimal sets of rules that will be sufficient to provide resolution proofs for sets of atoms. Such sets of rules will be called witnesses and are the focus of this article. We study complexity issues of computing various witnesses and provide algorithms for computing them. In particular, we show that the problem is tractable for normal and headcycle-free disjunctive logic programs, but intractable for general disjunctive logic programs. We also conducted some experiments and found that for many well-known ASP and SAT benchmarks, computing a minimal witness for an atom of an answer set is often feasible.  © 2023 Association for Computing Machinery.",answer set semantics; Logic programming; minimal models; witness,Atoms; Computer circuits; Program debugging; Semantics; Answer set; Answer set programming; Answer set semantics; Disjunctive logic programs; Logic programs; Logic-programming; Minimal model; Resolution proofs; Set of rules; Witness; Logic programming
Continuous One-counter Automata,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147330223&doi=10.1145%2f3558549&partnerID=40&md5=f3003744795a18efdda30491c332fbee,"We study the reachability problem for continuous one-counter automata, COCA for short. In such automata, transitions are guarded by upper- and lower-bound tests against the counter value. Additionally, the counter updates associated with taking transitions can be (non-deterministically) scaled down by a nonzero factor between zero and one. Our three main results are as follows: we prove (1) that the reachability problem for COCA with global upper- and lower-bound tests is in NC2; (2) that, in general, the problem is decidable in polynomial time; and (3) that it is NP-complete for COCA with parametric counter updates and bound tests. © 2023 Copyright held by the owner/author(s).",continuous relaxation; Counter automata; parametric automata; reachability problem,Automata theory; Bounds test; Continuous relaxation; Counter automata; NP Complete; Parametric automaton; Polynomial-time; Reachability problem; Upper and lower bounds; Polynomial approximation
"The Complexity of Quantified Constraints: Collapsibility, Switchability, and the Algebraic Formulation",2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147327795&doi=10.1145%2f3568397&partnerID=40&md5=5637ee2df4b7fb445492f4e402fbd4d1,"Let be an idempotent algebra on a finite domain. By mediating between results of Chen [1] and Zhuk [2], we argue that if satisfies the polynomially generated powers property (PGP) and ĝ.,¬ is a constraint language invariant under (i.e., in Inv()), then QCSP ĝ.,¬ is in NP. In doing this, we study the special forms of PGP, switchability, and collapsibility, in detail, both algebraically and logically, addressing various questions such as decidability on the way.We then prove a complexity-theoretic converse in the case of infinite constraint languages encoded in propositional logic, that if Inv}() satisfies the exponentially generated powers property (EGP), then QCSP (Inv()) is co-NP-hard. Since Zhuk proved that only PGP and EGP are possible, we derive a full dichotomy for the QCSP, justifying what we term the Revised Chen Conjecture. This result becomes more significant now that the original Chen Conjecture (see [3]) is known to be false [4].Switchability was introduced by Chen [1] as a generalization of the already-known collapsibility [5]. There, an algebra :=({ 0,1,2};r) was given that is switchable and not collapsible. We prove that, for all finite subsets Δof Inv ( A), Pol (δ) is collapsible. The significance of this is that, for QCSP on finite structures, it is still possible all QCSP tractability (in NP) explained by switchability is already explained by collapsibility. At least, no counterexample is known to this. © 2023 Association for Computing Machinery.",computational complexity; constraint satisfaction; logic; Quantified constraints; universal algebra,Computer circuits; Formal logic; Constraint language; Constraint Satisfaction; Finite domains; Idempotent; Logic; Power; Property; Quantified constraint; Switchability; Universal algebra; Algebra
MaxSAT Resolution and Subcube Sums,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147325895&doi=10.1145%2f3565363&partnerID=40&md5=c5be5f8954524bfb5f8d22cf08c08fec,"We study the MaxSAT Resolution (MaxRes) rule in the context of certifying unsatisfiability. We show that it can be exponentially more powerful than tree-like resolution, and when augmented with weakening (the system MaxResW), p-simulates tree-like resolution. In devising a lower bound technique specific to MaxRes (and not merely inheriting lower bounds from Res), we define a new proof system called the SubCubeSums proof system. This system, which p-simulates MaxResW, can be viewed as a special case of the semi-algebraic Sherali-Adams proof system. In expressivity, it is the integral restriction of conical juntas studied in the contexts of communication complexity and extension complexity. We show that it is not simulated by Res. Using a proof technique qualitatively different from the lower bounds that MaxResW inherits from Res, we show that Tseitin contradictions on expander graphs are hard to refute in SubCubeSums. We also establish a lower bound technique via lifting: for formulas requiring large degree in SubCubeSums, their XOR-ification requires large size in SubCubeSums. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",conical juntas; MaxSAT; proof complexity; resolution; Sherali-Adams,Communication complexity; Conical junta; Extension complexity; Low bound; Lower bound techniques; MaxSAT; Proof complexity; Proof system; Resolution; Sherali-adam
Canonisation and Definability for Graphs of Bounded Rank Width,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147329500&doi=10.1145%2f3568025&partnerID=40&md5=5db0903d93cb8014efd864fc468a399a,"We prove that the combinatorial Weisfeiler-Leman algorithm of dimension (3k+4) is a complete isomorphism test for the class of all graphs of rank width at most k. Rank width is a graph invariant that, similarly to tree width, measures the width of a certain style of hierarchical decomposition of graphs; it is equivalent to clique width.It was known that isomorphism of graphs of rank width k is decidable in polynomial time (Grohe and Schweitzer, FOCS 2015), but the best previously known algorithm has a running time nf(k) for a non-elementary function f. Our result yields an isomorphism test for graphs of rank width k running in time nO(k). Another consequence of our result is the first polynomial-time canonisation algorithm for graphs of bounded rank width.Our second main result is that fixed-point logic with counting captures polynomial time on all graph classes of bounded rank width. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",canonisation; fixed-point logic with counting; rank width; Weisfeiler-Leman algorithm,Computer circuits; Graphic methods; Set theory; Trees (mathematics); Canonization; Definability; Fixed-point logic; Fixed-point logic with counting; Graph invariant; Hierarchical decompositions; Polynomial-time; Rank-width; Tree-width; Weisfeile-leman algorithm; Polynomial approximation
Good-for-Game QPTL: An Alternating Hodges Semantics,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147324783&doi=10.1145%2f3565365&partnerID=40&md5=d0c1a45f39091ce4510987605b2ab563,"An extension of QPTL is considered where functional dependencies among the quantified variables can be restricted in such a way that their current values are independent of the future values of the other variables. This restriction is tightly connected to the notion of behavioral strategies in game-theory and allows the resulting logic to naturally express game-theoretic concepts. Inspired by the work on logics of dependence and independence, we provide a new compositional semantics for QPTL that allows for expressing such functional dependencies among variables. The fragment where only restricted quantifications are considered, called behavioral quantifications, allows for linear-time properties that are satisfiable if and only if they are realisable in the Pnueli-Rosner sense. This fragment can be decided, for both model checking and satisfiability, in 2Exp Time and is expressively equivalent to QPTL, though significantly less succinct. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",behavioral quantifications; compositional and game-theoretical semantics; good-for-game logics; Quantified Propositional Temporal Logic; reactive synthesis; realizability; satisfiability and model-checking; Strategic Reasoning,Computer circuits; Game theory; Model checking; Temporal logic; Behavioral quantification; Compositional and game-theoretical semantic; Functional dependency; Good-for-game logic; Models checking; Quantified propositional temporal logic; Reactive synthesis; Realizability; Satisfiability checking; Strategic reasoning; Semantics
Logics for Temporal Information Systems in Rough Set Theory,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147255308&doi=10.1145%2f3549075&partnerID=40&md5=f10cbe0aa45e5a5916aa9d4faa68d4b8,"The article discusses temporal information systems (TISs) that add the dimension of time to complete or incomplete information systems. Through TISs, one can accommodate the possibility of domains or attribute values for objects changing with time or the availability of currently missing information with time. Different patterns of flow of information give different TISs. The corresponding logics with sound and complete axiomatization are presented. © 2023 Association for Computing Machinery.",approximation operator; axiomatization; modal logic; Rough set theory; temporal logic,Approximation algorithms; Computer circuits; Information systems; Information use; Temporal logic; Approximation operators; Attribute values; Axiomati-sation; Complete axiomatizations; Complete information; Incomplete information systems; Missing information; Modal logic; Sound and complete; Temporal information; Rough set theory
SAT-Inspired Eliminations for Superposition,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147333822&doi=10.1145%2f3565366&partnerID=40&md5=50a3e5f060242e244b1e7c6236043a88,"Optimized SAT solvers not only preprocess the clause set, they also transform it during solving as inprocessing. Some preprocessing techniques have been generalized to first-order logic with equality. In this article, we port inprocessing techniques to work with superposition, a leading first-order proof calculus, and we strengthen known preprocessing techniques. Specifically, we look into elimination of hidden literals, variables (predicates), and blocked clauses. Our evaluation using the Zipperposition prover confirms that the new techniques usefully supplement the existing superposition machinery. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",first-order logic; SAT solving; superposition calculus; Theorem proving,Computer circuits; Formal logic; First order; First order logic; First-order logic with equality; Literals; Pre-processing techniques; Preprocess; Proof calculus; SAT solvers; SAT-solving; Superposition calculus; Theorem proving
A Decision Procedure for Guarded Separation Logic Complete Entailment Checking for Separation Logic with Inductive Definitions,2023,ACM Transactions on Computational Logic,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147328052&doi=10.1145%2f3534927&partnerID=40&md5=edd7cec86b30dbd21120ef2b9924a376,"We develop a doubly exponential decision procedure for the satisfiability problem of guarded separation logic - a novel fragment of separation logic featuring user-supplied inductive predicates, Boolean connectives, and separating connectives, including restricted (guarded) versions of negation, magic wand, and septraction. Moreover, we show that dropping the guards for any of the preceding connectives leads to an undecidable fragment.We further apply our decision procedure to reason about entailments in the popular symbolic heap fragment of separation logic. In particular, we obtain a doubly exponential decision procedure for entailments between (quantifier-free) symbolic heaps with inductive predicate definitions of bounded treewidth (SLbtw) - one of the most expressive decidable fragments of separation logic. Together with the recently shown 2ExpTime-hardness for entailments in said fragment, we conclude that the entailment problem for SLbtw is 2ExpTime-complete - thereby closing a previously open complexity gap. © 2023 Association for Computing Machinery.",Decision procedures; entailment; inductive predicates; magic wands,Formal logic; Boolean connectives; Bounded treewidth; Decision procedure; Entailment; Exponentials; Inductive definitions; Inductive predicate; Magic wand; Satisfiability problems; Separation logic; Computer circuits
